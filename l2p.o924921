### Starting TaskPrologue of job 924921 on tg071 at Sun 03 Nov 2024 01:18:46 AM CET
Running on cores 0-1,8-9,17-18,24-25 with governor ondemand
Sun Nov  3 01:18:46 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:18:00.0 Off |                    0 |
| N/A   31C    P0             27W /  250W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', patience_epochs=10, pin_mem=True, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, unscale_lr=True, use_prompt_mask=False, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
Train: Epoch[1/5]  [  0/313]  eta: 0:59:36  Loss: 2.2968 (2.2968)  ASR: 11.1111 (11.1111)  ACC: 28.5714 (28.5714)  time: 11.4257  data: 0.5732  max mem: 2377
Train: Epoch[1/5]  [ 10/313]  eta: 0:06:07  Loss: 2.2864 (2.2857)  ASR: 23.0769 (20.4939)  ACC: 12.5000 (14.7541)  time: 1.2140  data: 0.0525  max mem: 2380
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:33  Loss: 2.2864 (2.2906)  ASR: 18.1818 (17.4496)  ACC: 0.0000 (14.8148)  time: 0.1925  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [ 30/313]  eta: 0:02:36  Loss: 2.2888 (2.2899)  ASR: 8.3333 (16.5608)  ACC: 16.6667 (16.9935)  time: 0.1921  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:07  Loss: 2.2859 (2.2881)  ASR: 15.3846 (16.6020)  ACC: 16.6667 (16.2562)  time: 0.1919  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:48  Loss: 2.2782 (2.2866)  ASR: 15.3846 (16.2004)  ACC: 16.6667 (17.6000)  time: 0.1918  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:35  Loss: 2.2850 (2.2859)  ASR: 11.1111 (16.5431)  ACC: 12.5000 (16.3462)  time: 0.1917  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:25  Loss: 2.2875 (2.2859)  ASR: 16.6667 (16.6109)  ACC: 12.5000 (17.1271)  time: 0.1918  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:17  Loss: 2.2776 (2.2843)  ASR: 18.1818 (17.6560)  ACC: 16.6667 (16.8704)  time: 0.1924  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:10  Loss: 2.2809 (2.2848)  ASR: 18.1818 (16.9163)  ACC: 0.0000 (15.9389)  time: 0.1924  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [100/313]  eta: 0:01:04  Loss: 2.2766 (2.2839)  ASR: 15.3846 (17.6142)  ACC: 0.0000 (15.3082)  time: 0.1922  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [110/313]  eta: 0:00:59  Loss: 2.2702 (2.2831)  ASR: 16.6667 (17.7580)  ACC: 0.0000 (14.8080)  time: 0.1924  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [120/313]  eta: 0:00:55  Loss: 2.2694 (2.2820)  ASR: 22.2222 (18.4317)  ACC: 0.0000 (14.3098)  time: 0.1924  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [130/313]  eta: 0:00:50  Loss: 2.2650 (2.2811)  ASR: 22.2222 (18.4746)  ACC: 12.5000 (14.6605)  time: 0.1920  data: 0.0004  max mem: 2380
Train: Epoch[1/5]  [140/313]  eta: 0:00:47  Loss: 2.2655 (2.2802)  ASR: 22.2222 (18.7522)  ACC: 16.6667 (14.7186)  time: 0.1913  data: 0.0003  max mem: 2380
Train: Epoch[1/5]  [150/313]  eta: 0:00:43  Loss: 2.2574 (2.2783)  ASR: 25.0000 (19.5633)  ACC: 11.1111 (14.6341)  time: 0.1910  data: 0.0002  max mem: 2381
Train: Epoch[1/5]  [160/313]  eta: 0:00:40  Loss: 2.2514 (2.2768)  ASR: 25.0000 (19.7937)  ACC: 0.0000 (14.6497)  time: 0.1913  data: 0.0002  max mem: 2381
Train: Epoch[1/5]  [170/313]  eta: 0:00:36  Loss: 2.2521 (2.2753)  ASR: 23.0769 (20.0280)  ACC: 0.0000 (14.4910)  time: 0.1904  data: 0.0002  max mem: 2381
Train: Epoch[1/5]  [180/313]  eta: 0:00:33  Loss: 2.2484 (2.2732)  ASR: 27.2727 (20.8411)  ACC: 12.5000 (14.6727)  time: 0.1894  data: 0.0002  max mem: 2381
Train: Epoch[1/5]  [190/313]  eta: 0:00:30  Loss: 2.2275 (2.2707)  ASR: 40.0000 (22.0475)  ACC: 0.0000 (14.7154)  time: 0.1913  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [200/313]  eta: 0:00:27  Loss: 2.2223 (2.2679)  ASR: 46.1538 (23.8300)  ACC: 0.0000 (14.6490)  time: 0.1930  data: 0.0005  max mem: 2381
Train: Epoch[1/5]  [210/313]  eta: 0:00:25  Loss: 2.2240 (2.2656)  ASR: 54.5455 (25.4432)  ACC: 0.0000 (14.4101)  time: 0.1931  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [220/313]  eta: 0:00:22  Loss: 2.2122 (2.2627)  ASR: 53.8462 (26.9086)  ACC: 0.0000 (14.4968)  time: 0.1930  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [230/313]  eta: 0:00:19  Loss: 2.1863 (2.2592)  ASR: 66.6667 (29.0576)  ACC: 14.2857 (14.7627)  time: 0.1928  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [240/313]  eta: 0:00:17  Loss: 2.1675 (2.2552)  ASR: 72.7273 (30.9545)  ACC: 20.0000 (15.0338)  time: 0.1928  data: 0.0005  max mem: 2381
Train: Epoch[1/5]  [250/313]  eta: 0:00:14  Loss: 2.1509 (2.2509)  ASR: 81.8182 (33.1703)  ACC: 0.0000 (14.5749)  time: 0.1927  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [260/313]  eta: 0:00:12  Loss: 2.1434 (2.2469)  ASR: 88.8889 (35.1860)  ACC: 0.0000 (14.6967)  time: 0.1930  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [270/313]  eta: 0:00:10  Loss: 2.1282 (2.2420)  ASR: 90.9091 (37.2241)  ACC: 16.6667 (14.8232)  time: 0.1932  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [280/313]  eta: 0:00:07  Loss: 2.1102 (2.2374)  ASR: 90.9091 (39.0850)  ACC: 14.2857 (14.9492)  time: 0.1932  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [290/313]  eta: 0:00:05  Loss: 2.1102 (2.2328)  ASR: 90.9091 (40.9169)  ACC: 0.0000 (14.8772)  time: 0.1937  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 2.1084 (2.2286)  ASR: 92.8571 (42.7378)  ACC: 0.0000 (14.8951)  time: 0.1953  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 2.1055 (2.2240)  ASR: 92.3077 (44.3431)  ACC: nan (nan)  time: 0.1949  data: 0.0004  max mem: 2381
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 2.1010 (2.2230)  ASR: 91.6667 (44.5836)  ACC: nan (nan)  time: 0.4049  data: 0.0004  max mem: 2381
Train: Epoch[1/5] Total time: 0:01:15 (0.2420 s / it)
Averaged stats: Loss: 2.1010 (2.2230)  ASR: 91.6667 (44.5836)  ACC: nan (nan)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:52  Loss: 2.0997 (2.0997)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (20.0000)  time: 0.3601  data: 0.1635  max mem: 2381
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Loss: 2.0725 (2.0830)  ASR: 100.0000 (93.1818)  ACC: 10.0000 (13.4615)  time: 0.2061  data: 0.0150  max mem: 2381
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 2.0616 (2.0712)  ASR: 100.0000 (95.1361)  ACC: 0.0000 (11.3402)  time: 0.1917  data: 0.0002  max mem: 2381
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Loss: 2.0516 (2.0643)  ASR: 100.0000 (95.2187)  ACC: 0.0000 (11.3475)  time: 0.1930  data: 0.0003  max mem: 2381
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 2.0403 (2.0603)  ASR: 100.0000 (95.9599)  ACC: 14.2857 (15.0259)  time: 0.1933  data: 0.0003  max mem: 2381
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 2.0420 (2.0595)  ASR: 100.0000 (96.3436)  ACC: 20.0000 (16.8675)  time: 0.1938  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 2.0387 (2.0548)  ASR: 100.0000 (96.4052)  ACC: 16.6667 (15.7534)  time: 0.1942  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 2.0281 (2.0520)  ASR: 100.0000 (96.6376)  ACC: 12.5000 (15.4070)  time: 0.1937  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 2.0114 (2.0486)  ASR: 100.0000 (96.7955)  ACC: 16.6667 (16.2437)  time: 0.1935  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 2.0044 (2.0445)  ASR: 100.0000 (96.7730)  ACC: 0.0000 (15.3670)  time: 0.1939  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 2.0066 (2.0433)  ASR: 100.0000 (96.9688)  ACC: 0.0000 (15.3374)  time: 0.1936  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 2.0203 (2.0405)  ASR: 100.0000 (97.2419)  ACC: 16.6667 (15.0278)  time: 0.1919  data: 0.0003  max mem: 2381
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 2.0103 (2.0381)  ASR: 100.0000 (97.3195)  ACC: 0.0000 (14.6010)  time: 0.1908  data: 0.0002  max mem: 2381
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 2.0043 (2.0343)  ASR: 100.0000 (97.4287)  ACC: 0.0000 (14.3533)  time: 0.1915  data: 0.0002  max mem: 2381
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.9891 (2.0308)  ASR: 100.0000 (97.6111)  ACC: 0.0000 (14.6843)  time: 0.1938  data: 0.0003  max mem: 2381
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 2.0013 (2.0294)  ASR: 100.0000 (97.7693)  ACC: 16.6667 (14.5578)  time: 0.1946  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.9948 (2.0266)  ASR: 100.0000 (97.9079)  ACC: 14.2857 (14.5408)  time: 0.1944  data: 0.0004  max mem: 2381
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.9692 (2.0232)  ASR: 100.0000 (97.9717)  ACC: 10.0000 (14.6312)  time: 0.1933  data: 0.0003  max mem: 2381
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.9808 (2.0221)  ASR: 100.0000 (98.0838)  ACC: 0.0000 (14.2857)  time: 0.1913  data: 0.0002  max mem: 2381
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.9847 (2.0199)  ASR: 100.0000 (98.1259)  ACC: 11.1111 (15.0480)  time: 0.1917  data: 0.0002  max mem: 2381
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.9593 (2.0180)  ASR: 100.0000 (98.2192)  ACC: 12.5000 (14.7475)  time: 0.1926  data: 0.0003  max mem: 2381
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.9468 (2.0145)  ASR: 100.0000 (98.2641)  ACC: 0.0000 (14.5753)  time: 0.1929  data: 0.0002  max mem: 2382
Train: Epoch[2/5]  [220/313]  eta: 0:00:18  Loss: 1.9489 (2.0114)  ASR: 100.0000 (98.3426)  ACC: 16.6667 (15.2433)  time: 0.1939  data: 0.0003  max mem: 2382
Train: Epoch[2/5]  [230/313]  eta: 0:00:16  Loss: 1.9528 (2.0086)  ASR: 100.0000 (98.4144)  ACC: 16.6667 (15.2632)  time: 0.1948  data: 0.0004  max mem: 2382
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.9352 (2.0054)  ASR: 100.0000 (98.4802)  ACC: 14.2857 (15.2101)  time: 0.1953  data: 0.0004  max mem: 2382
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.9067 (2.0008)  ASR: 100.0000 (98.5101)  ACC: 0.0000 (15.0041)  time: 0.1946  data: 0.0003  max mem: 2382
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.8521 (1.9960)  ASR: 100.0000 (98.5672)  ACC: nan (nan)  time: 0.1941  data: 0.0003  max mem: 2382
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.8667 (1.9916)  ASR: 100.0000 (98.6200)  ACC: nan (nan)  time: 0.1940  data: 0.0003  max mem: 2382
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.8893 (1.9884)  ASR: 100.0000 (98.6418)  ACC: 0.0000 (nan)  time: 0.1933  data: 0.0002  max mem: 2382
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.8824 (1.9846)  ASR: 100.0000 (98.6884)  ACC: 0.0000 (nan)  time: 0.1940  data: 0.0003  max mem: 2382
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.8698 (1.9807)  ASR: 100.0000 (98.7320)  ACC: 0.0000 (nan)  time: 0.1941  data: 0.0002  max mem: 2382
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.8695 (1.9776)  ASR: 100.0000 (98.7406)  ACC: 16.6667 (nan)  time: 0.1931  data: 0.0002  max mem: 2382
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.8695 (1.9765)  ASR: 100.0000 (98.7467)  ACC: 12.5000 (nan)  time: 0.1885  data: 0.0002  max mem: 2382
Train: Epoch[2/5] Total time: 0:01:00 (0.1939 s / it)
Averaged stats: Loss: 1.8695 (1.9765)  ASR: 100.0000 (98.7467)  ACC: 12.5000 (nan)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:57  Loss: 1.7863 (1.7863)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.3760  data: 0.1779  max mem: 2382
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Loss: 1.8373 (1.8630)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (18.9655)  time: 0.2105  data: 0.0164  max mem: 2382
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Loss: 1.8359 (1.8456)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (16.0377)  time: 0.1930  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Loss: 1.7621 (1.8305)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.4362)  time: 0.1926  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.7603 (1.8160)  ASR: 100.0000 (99.8258)  ACC: 0.0000 (14.0541)  time: 0.1929  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.7858 (1.8189)  ASR: 100.0000 (99.8599)  ACC: 0.0000 (12.6050)  time: 0.1925  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.8101 (1.8171)  ASR: 100.0000 (99.8829)  ACC: 0.0000 (12.1951)  time: 0.1924  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.7615 (1.8042)  ASR: 100.0000 (99.8994)  ACC: 0.0000 (12.9630)  time: 0.1932  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.7534 (1.8007)  ASR: 100.0000 (99.9118)  ACC: 0.0000 (13.2791)  time: 0.1932  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.7595 (1.7982)  ASR: 100.0000 (99.8370)  ACC: 0.0000 (12.9808)  time: 0.1927  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.7255 (1.7922)  ASR: 100.0000 (99.8531)  ACC: 0.0000 (12.8540)  time: 0.1929  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.7502 (1.7921)  ASR: 100.0000 (99.8664)  ACC: 10.0000 (12.8405)  time: 0.1928  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.7774 (1.7915)  ASR: 100.0000 (99.8774)  ACC: 16.6667 (13.0511)  time: 0.1927  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.7552 (1.7882)  ASR: 100.0000 (99.8868)  ACC: 11.1111 (13.2137)  time: 0.1944  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.7378 (1.7860)  ASR: 100.0000 (99.8948)  ACC: 16.6667 (13.8554)  time: 0.1956  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.7283 (1.7828)  ASR: 100.0000 (99.8466)  ACC: 20.0000 (14.3662)  time: 0.1998  data: 0.0004  max mem: 2382
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.7283 (1.7837)  ASR: 100.0000 (99.8561)  ACC: 12.5000 (13.9687)  time: 0.2035  data: 0.0004  max mem: 2382
Train: Epoch[3/5]  [170/313]  eta: 0:00:28  Loss: 1.7252 (1.7816)  ASR: 100.0000 (99.8645)  ACC: 0.0000 (13.9535)  time: 0.2023  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [180/313]  eta: 0:00:26  Loss: 1.6965 (1.7774)  ASR: 100.0000 (99.8720)  ACC: 20.0000 (14.3353)  time: 0.2019  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [190/313]  eta: 0:00:24  Loss: 1.6803 (1.7728)  ASR: 100.0000 (99.8787)  ACC: 16.6667 (14.5055)  time: 0.2038  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [200/313]  eta: 0:00:22  Loss: 1.7148 (1.7723)  ASR: 100.0000 (99.8847)  ACC: 14.2857 (14.8760)  time: 0.2141  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [210/313]  eta: 0:00:20  Loss: 1.7142 (1.7678)  ASR: 100.0000 (99.8902)  ACC: 14.2857 (14.8221)  time: 0.2191  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [220/313]  eta: 0:00:18  Loss: 1.6940 (1.7655)  ASR: 100.0000 (99.8952)  ACC: 14.2857 (15.0517)  time: 0.2148  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [230/313]  eta: 0:00:16  Loss: 1.6940 (1.7627)  ASR: 100.0000 (99.8997)  ACC: 20.0000 (15.1842)  time: 0.2137  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.7241 (1.7629)  ASR: 100.0000 (99.9039)  ACC: 0.0000 (14.9063)  time: 0.2128  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.7477 (1.7609)  ASR: 100.0000 (99.9077)  ACC: 0.0000 (14.8571)  time: 0.2119  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.6842 (1.7581)  ASR: 100.0000 (99.9112)  ACC: 0.0000 (14.6782)  time: 0.2100  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.6839 (1.7569)  ASR: 100.0000 (99.9145)  ACC: 0.0000 (14.7037)  time: 0.2075  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.6685 (1.7530)  ASR: 100.0000 (99.9176)  ACC: 14.2857 (14.8256)  time: 0.2073  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.6073 (1.7466)  ASR: 100.0000 (99.9204)  ACC: 14.2857 (14.9752)  time: 0.2078  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.6073 (1.7431)  ASR: 100.0000 (99.9230)  ACC: 25.0000 (15.1995)  time: 0.2069  data: 0.0003  max mem: 2382
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.6217 (1.7397)  ASR: 100.0000 (99.9255)  ACC: 25.0000 (15.5645)  time: 0.2058  data: 0.0002  max mem: 2382
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.6217 (1.7389)  ASR: 100.0000 (99.9259)  ACC: 25.0000 (15.7019)  time: 0.2008  data: 0.0002  max mem: 2382
Train: Epoch[3/5] Total time: 0:01:03 (0.2023 s / it)
Averaged stats: Loss: 1.6217 (1.7389)  ASR: 100.0000 (99.9259)  ACC: 25.0000 (15.7019)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:08  Loss: 1.7770 (1.7770)  ASR: 100.0000 (100.0000)  ACC: 42.8571 (42.8571)  time: 0.4114  data: 0.2168  max mem: 2382
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Loss: 1.7260 (1.6942)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (19.6721)  time: 0.2144  data: 0.0199  max mem: 2382
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:01  Loss: 1.6544 (1.6636)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2003  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:59  Loss: 1.6306 (1.6597)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2061  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:56  Loss: 1.6289 (1.6566)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2064  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:54  Loss: 1.6792 (1.6584)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2092  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:53  Loss: 1.6792 (1.6633)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2152  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:51  Loss: 1.6199 (1.6540)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2189  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:49  Loss: 1.5284 (1.6443)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2187  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:47  Loss: 1.5518 (1.6385)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2161  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [100/313]  eta: 0:00:45  Loss: 1.5678 (1.6312)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2140  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [110/313]  eta: 0:00:43  Loss: 1.5611 (1.6260)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2134  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [120/313]  eta: 0:00:41  Loss: 1.5463 (1.6228)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [130/313]  eta: 0:00:38  Loss: 1.5558 (1.6200)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [140/313]  eta: 0:00:36  Loss: 1.5558 (1.6139)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [150/313]  eta: 0:00:34  Loss: 1.5756 (1.6123)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [160/313]  eta: 0:00:32  Loss: 1.5824 (1.6063)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [170/313]  eta: 0:00:30  Loss: 1.5347 (1.6036)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2110  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [180/313]  eta: 0:00:28  Loss: 1.5940 (1.6053)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2103  data: 0.0004  max mem: 2382
Train: Epoch[4/5]  [190/313]  eta: 0:00:26  Loss: 1.5940 (1.6004)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2096  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [200/313]  eta: 0:00:23  Loss: 1.5207 (1.5979)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2085  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [210/313]  eta: 0:00:21  Loss: 1.5335 (1.5970)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2093  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [220/313]  eta: 0:00:19  Loss: 1.5267 (1.5936)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2103  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [230/313]  eta: 0:00:17  Loss: 1.4495 (1.5876)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2099  data: 0.0003  max mem: 2382
Train: Epoch[4/5]  [240/313]  eta: 0:00:15  Loss: 1.4443 (1.5846)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [250/313]  eta: 0:00:13  Loss: 1.4954 (1.5837)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2084  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [260/313]  eta: 0:00:11  Loss: 1.5866 (1.5854)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2084  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [270/313]  eta: 0:00:09  Loss: 1.5446 (1.5826)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2083  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.5193 (1.5809)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2083  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.5193 (1.5792)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2080  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.5063 (1.5760)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2082  data: 0.0001  max mem: 2382
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.5066 (1.5747)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2085  data: 0.0002  max mem: 2382
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.5066 (1.5744)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2035  data: 0.0002  max mem: 2382
Train: Epoch[4/5] Total time: 0:01:05 (0.2106 s / it)
Averaged stats: Loss: 1.5066 (1.5744)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:22  Loss: 1.5414 (1.5414)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (20.0000)  time: 0.4555  data: 0.2547  max mem: 2382
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:08  Loss: 1.5414 (1.5465)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.8148)  time: 0.2255  data: 0.0233  max mem: 2382
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:05  Loss: 1.4826 (1.5300)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (20.5882)  time: 0.2137  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:03  Loss: 1.4505 (1.5144)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (21.0884)  time: 0.2234  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:00  Loss: 1.4218 (1.5037)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (19.0476)  time: 0.2201  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:58  Loss: 1.4235 (1.4920)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (17.4672)  time: 0.2167  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:55  Loss: 1.4429 (1.4846)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.2362)  time: 0.2147  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:53  Loss: 1.4916 (1.4920)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.0494)  time: 0.2137  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:50  Loss: 1.5476 (1.5009)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (14.8148)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:48  Loss: 1.4965 (1.4959)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.9644)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [100/313]  eta: 0:00:46  Loss: 1.4893 (1.4965)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.0424)  time: 0.2120  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [110/313]  eta: 0:00:43  Loss: 1.5118 (1.4960)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.1631)  time: 0.2117  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [120/313]  eta: 0:00:41  Loss: 1.4321 (1.4941)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.9648)  time: 0.2119  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [130/313]  eta: 0:00:39  Loss: 1.3769 (1.4843)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.1163)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [140/313]  eta: 0:00:37  Loss: 1.4024 (1.4839)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.5929)  time: 0.2124  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [150/313]  eta: 0:00:35  Loss: 1.4256 (1.4809)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.7989)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [160/313]  eta: 0:00:32  Loss: 1.3526 (1.4729)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.2263)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [170/313]  eta: 0:00:30  Loss: 1.3526 (1.4712)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (15.5727)  time: 0.2125  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [180/313]  eta: 0:00:28  Loss: 1.4397 (1.4689)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.6671)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [190/313]  eta: 0:00:26  Loss: 1.4429 (1.4691)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (15.3403)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [200/313]  eta: 0:00:24  Loss: 1.4328 (1.4677)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.4015)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [210/313]  eta: 0:00:22  Loss: 1.5804 (1.4707)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.3368)  time: 0.2128  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [220/313]  eta: 0:00:19  Loss: 1.5327 (1.4685)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.1635)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [230/313]  eta: 0:00:17  Loss: 1.3875 (1.4654)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.2526)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [240/313]  eta: 0:00:15  Loss: 1.3692 (1.4623)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.4904)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [250/313]  eta: 0:00:13  Loss: 1.3964 (1.4621)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.3509)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [260/313]  eta: 0:00:11  Loss: 1.4683 (1.4639)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.1591)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [270/313]  eta: 0:00:09  Loss: 1.4137 (1.4596)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.2721)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [280/313]  eta: 0:00:07  Loss: 1.4429 (1.4609)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0078)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.4597 (1.4610)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.9813)  time: 0.2101  data: 0.0001  max mem: 2382
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.4257 (1.4590)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.0218)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.4418 (1.4603)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.1220)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.4521 (1.4599)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.0694)  time: 0.2047  data: 0.0002  max mem: 2382
Train: Epoch[5/5] Total time: 0:01:06 (0.2134 s / it)
Averaged stats: Loss: 1.4521 (1.4599)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.0694)
Train: Epoch[6/5]  [  0/313]  eta: 0:02:12  Loss: 1.7123 (1.7123)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (12.5000)  time: 0.4220  data: 0.2239  max mem: 2382
Train: Epoch[6/5]  [ 10/313]  eta: 0:01:04  Loss: 1.4278 (1.4241)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (5.8824)  time: 0.2145  data: 0.0205  max mem: 2382
Train: Epoch[6/5]  [ 20/313]  eta: 0:01:01  Loss: 1.4278 (1.4250)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.1976  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [ 30/313]  eta: 0:00:58  Loss: 1.4068 (1.4029)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2040  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [ 40/313]  eta: 0:00:56  Loss: 1.4068 (1.4122)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2069  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [ 50/313]  eta: 0:00:54  Loss: 1.4192 (1.4172)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2066  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [ 60/313]  eta: 0:00:52  Loss: 1.3871 (1.4112)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2070  data: 0.0001  max mem: 2382
Train: Epoch[6/5]  [ 70/313]  eta: 0:00:51  Loss: 1.3632 (1.4135)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2176  data: 0.0001  max mem: 2382
Train: Epoch[6/5]  [ 80/313]  eta: 0:00:49  Loss: 1.4073 (1.4131)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2248  data: 0.0001  max mem: 2382
Train: Epoch[6/5]  [ 90/313]  eta: 0:00:47  Loss: 1.4073 (1.4149)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2208  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [100/313]  eta: 0:00:45  Loss: 1.4427 (1.4143)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2193  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [110/313]  eta: 0:00:43  Loss: 1.3998 (1.4111)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2173  data: 0.0001  max mem: 2382
Train: Epoch[6/5]  [120/313]  eta: 0:00:41  Loss: 1.3998 (1.4161)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2141  data: 0.0001  max mem: 2382
Train: Epoch[6/5]  [130/313]  eta: 0:00:39  Loss: 1.3995 (1.4151)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [140/313]  eta: 0:00:36  Loss: 1.3726 (1.4130)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2141  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [150/313]  eta: 0:00:34  Loss: 1.4155 (1.4133)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2140  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [160/313]  eta: 0:00:32  Loss: 1.3955 (1.4097)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [170/313]  eta: 0:00:30  Loss: 1.4402 (1.4147)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2090  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [180/313]  eta: 0:00:28  Loss: 1.4970 (1.4144)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2087  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [190/313]  eta: 0:00:26  Loss: 1.3248 (1.4114)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [200/313]  eta: 0:00:23  Loss: 1.4573 (1.4155)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2090  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [210/313]  eta: 0:00:21  Loss: 1.4766 (1.4163)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2091  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [220/313]  eta: 0:00:19  Loss: 1.4499 (1.4182)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2090  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [230/313]  eta: 0:00:17  Loss: 1.3977 (1.4143)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2096  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [240/313]  eta: 0:00:15  Loss: 1.3759 (1.4141)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [250/313]  eta: 0:00:13  Loss: 1.3371 (1.4106)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2102  data: 0.0003  max mem: 2382
Train: Epoch[6/5]  [260/313]  eta: 0:00:11  Loss: 1.2792 (1.4082)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2107  data: 0.0003  max mem: 2382
Train: Epoch[6/5]  [270/313]  eta: 0:00:09  Loss: 1.3715 (1.4108)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (nan)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [280/313]  eta: 0:00:06  Loss: 1.4491 (1.4119)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2094  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [290/313]  eta: 0:00:04  Loss: 1.3351 (1.4077)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [300/313]  eta: 0:00:02  Loss: 1.3329 (1.4046)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [310/313]  eta: 0:00:00  Loss: 1.3799 (1.4073)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2090  data: 0.0002  max mem: 2382
Train: Epoch[6/5]  [312/313]  eta: 0:00:00  Loss: 1.4013 (1.4088)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2039  data: 0.0002  max mem: 2382
Train: Epoch[6/5] Total time: 0:01:06 (0.2114 s / it)
Averaged stats: Loss: 1.4013 (1.4088)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[7/5]  [  0/313]  eta: 0:02:09  Loss: 1.1027 (1.1027)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4128  data: 0.2101  max mem: 2382
Train: Epoch[7/5]  [ 10/313]  eta: 0:01:06  Loss: 1.3743 (1.3649)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (20.7547)  time: 0.2204  data: 0.0193  max mem: 2382
Train: Epoch[7/5]  [ 20/313]  eta: 0:01:04  Loss: 1.3714 (1.3646)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (17.3469)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [ 30/313]  eta: 0:01:01  Loss: 1.3146 (1.3684)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8649)  time: 0.2183  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [ 40/313]  eta: 0:00:59  Loss: 1.2937 (1.3638)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.4103)  time: 0.2181  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [ 50/313]  eta: 0:00:57  Loss: 1.3501 (1.3767)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.5378)  time: 0.2181  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [ 60/313]  eta: 0:00:55  Loss: 1.4135 (1.3726)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.1616)  time: 0.2179  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [ 70/313]  eta: 0:00:53  Loss: 1.3064 (1.3640)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.9763)  time: 0.2175  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [ 80/313]  eta: 0:00:50  Loss: 1.3029 (1.3678)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.3846)  time: 0.2157  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [ 90/313]  eta: 0:00:48  Loss: 1.4173 (1.3753)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.0271)  time: 0.2144  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [100/313]  eta: 0:00:46  Loss: 1.3145 (1.3706)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8436)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [110/313]  eta: 0:00:43  Loss: 1.3145 (1.3749)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.3704)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [120/313]  eta: 0:00:41  Loss: 1.3884 (1.3738)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.1104)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [130/313]  eta: 0:00:39  Loss: 1.3215 (1.3667)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [140/313]  eta: 0:00:37  Loss: 1.3724 (1.3721)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [150/313]  eta: 0:00:35  Loss: 1.3724 (1.3707)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [160/313]  eta: 0:00:32  Loss: 1.3847 (1.3739)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [170/313]  eta: 0:00:30  Loss: 1.3973 (1.3723)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [180/313]  eta: 0:00:28  Loss: 1.3653 (1.3694)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [190/313]  eta: 0:00:26  Loss: 1.2578 (1.3604)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [200/313]  eta: 0:00:24  Loss: 1.2857 (1.3619)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2110  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [210/313]  eta: 0:00:22  Loss: 1.3696 (1.3616)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2109  data: 0.0001  max mem: 2382
Train: Epoch[7/5]  [220/313]  eta: 0:00:19  Loss: 1.3465 (1.3609)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [230/313]  eta: 0:00:17  Loss: 1.2786 (1.3593)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2112  data: 0.0001  max mem: 2382
Train: Epoch[7/5]  [240/313]  eta: 0:00:15  Loss: 1.3353 (1.3608)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [250/313]  eta: 0:00:13  Loss: 1.3353 (1.3574)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [260/313]  eta: 0:00:11  Loss: 1.2682 (1.3544)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [270/313]  eta: 0:00:09  Loss: 1.3046 (1.3548)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [280/313]  eta: 0:00:07  Loss: 1.4101 (1.3576)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2106  data: 0.0001  max mem: 2382
Train: Epoch[7/5]  [290/313]  eta: 0:00:04  Loss: 1.3726 (1.3551)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [300/313]  eta: 0:00:02  Loss: 1.3511 (1.3555)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [310/313]  eta: 0:00:00  Loss: 1.3161 (1.3515)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2110  data: 0.0002  max mem: 2382
Train: Epoch[7/5]  [312/313]  eta: 0:00:00  Loss: 1.2356 (1.3510)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2060  data: 0.0002  max mem: 2382
Train: Epoch[7/5] Total time: 0:01:06 (0.2132 s / it)
Averaged stats: Loss: 1.2356 (1.3510)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[8/5]  [  0/313]  eta: 0:02:12  Loss: 1.3082 (1.3082)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4249  data: 0.2249  max mem: 2382
Train: Epoch[8/5]  [ 10/313]  eta: 0:01:05  Loss: 1.3949 (1.3732)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.0351)  time: 0.2153  data: 0.0206  max mem: 2382
Train: Epoch[8/5]  [ 20/313]  eta: 0:01:01  Loss: 1.3949 (1.3972)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.6667)  time: 0.2003  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [ 30/313]  eta: 0:00:59  Loss: 1.3909 (1.3939)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.0602)  time: 0.2079  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [ 40/313]  eta: 0:00:57  Loss: 1.3401 (1.3906)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.6119)  time: 0.2093  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [ 50/313]  eta: 0:00:55  Loss: 1.3220 (1.3878)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.8672)  time: 0.2090  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [ 60/313]  eta: 0:00:53  Loss: 1.3272 (1.3875)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.2080)  time: 0.2088  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [ 70/313]  eta: 0:00:50  Loss: 1.2872 (1.3730)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.0326)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [ 80/313]  eta: 0:00:48  Loss: 1.2845 (1.3613)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8151)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [ 90/313]  eta: 0:00:46  Loss: 1.3743 (1.3666)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0215)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [100/313]  eta: 0:00:45  Loss: 1.3790 (1.3658)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.0232)  time: 0.2168  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [110/313]  eta: 0:00:42  Loss: 1.4021 (1.3732)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7439)  time: 0.2167  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [120/313]  eta: 0:00:40  Loss: 1.4021 (1.3742)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.3724)  time: 0.2169  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [130/313]  eta: 0:00:38  Loss: 1.3336 (1.3710)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.2941)  time: 0.2170  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [140/313]  eta: 0:00:36  Loss: 1.2468 (1.3634)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0000)  time: 0.2169  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [150/313]  eta: 0:00:34  Loss: 1.2631 (1.3573)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0919)  time: 0.2167  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [160/313]  eta: 0:00:32  Loss: 1.2631 (1.3505)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.2985)  time: 0.2157  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [170/313]  eta: 0:00:30  Loss: 1.2801 (1.3469)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.2123)  time: 0.2147  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [180/313]  eta: 0:00:28  Loss: 1.3165 (1.3486)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.6493)  time: 0.2148  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [190/313]  eta: 0:00:26  Loss: 1.3425 (1.3482)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.4737)  time: 0.2141  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [200/313]  eta: 0:00:24  Loss: 1.2937 (1.3466)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0451)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [210/313]  eta: 0:00:21  Loss: 1.3061 (1.3465)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8855)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [220/313]  eta: 0:00:19  Loss: 1.2984 (1.3427)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.9267)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [230/313]  eta: 0:00:17  Loss: 1.3307 (1.3439)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.1092)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [240/313]  eta: 0:00:15  Loss: 1.2912 (1.3379)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8305)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [250/313]  eta: 0:00:13  Loss: 1.2039 (1.3368)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8780)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [260/313]  eta: 0:00:11  Loss: 1.2639 (1.3359)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8670)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [270/313]  eta: 0:00:09  Loss: 1.3486 (1.3360)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.6727)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [280/313]  eta: 0:00:07  Loss: 1.3341 (1.3346)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.5455)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [290/313]  eta: 0:00:04  Loss: 1.2499 (1.3336)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.5070)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [300/313]  eta: 0:00:02  Loss: 1.3323 (1.3343)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.4407)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [310/313]  eta: 0:00:00  Loss: 1.3994 (1.3357)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.6310)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[8/5]  [312/313]  eta: 0:00:00  Loss: 1.3448 (1.3347)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.5644)  time: 0.2063  data: 0.0002  max mem: 2382
Train: Epoch[8/5] Total time: 0:01:06 (0.2129 s / it)
Averaged stats: Loss: 1.3448 (1.3347)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.5644)
Train: Epoch[9/5]  [  0/313]  eta: 0:02:05  Loss: 1.5575 (1.5575)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (12.5000)  time: 0.4021  data: 0.2033  max mem: 2382
Train: Epoch[9/5]  [ 10/313]  eta: 0:01:04  Loss: 1.2521 (1.2638)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (10.2041)  time: 0.2127  data: 0.0187  max mem: 2382
Train: Epoch[9/5]  [ 20/313]  eta: 0:01:01  Loss: 1.2459 (1.2578)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2007  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [ 30/313]  eta: 0:00:59  Loss: 1.3211 (1.2719)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2086  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [ 40/313]  eta: 0:00:57  Loss: 1.3745 (1.2892)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [ 50/313]  eta: 0:00:55  Loss: 1.3596 (1.2939)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [ 60/313]  eta: 0:00:53  Loss: 1.3259 (1.2998)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2093  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [ 70/313]  eta: 0:00:50  Loss: 1.3061 (1.2985)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [ 80/313]  eta: 0:00:48  Loss: 1.2891 (1.2977)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [ 90/313]  eta: 0:00:46  Loss: 1.3490 (1.3077)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [100/313]  eta: 0:00:44  Loss: 1.3213 (1.3015)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2085  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [110/313]  eta: 0:00:42  Loss: 1.3153 (1.3058)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [120/313]  eta: 0:00:40  Loss: 1.3226 (1.3065)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [130/313]  eta: 0:00:38  Loss: 1.3130 (1.3033)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [140/313]  eta: 0:00:36  Loss: 1.3173 (1.3060)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [150/313]  eta: 0:00:34  Loss: 1.2680 (1.3006)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [160/313]  eta: 0:00:32  Loss: 1.2680 (1.3021)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [170/313]  eta: 0:00:30  Loss: 1.2912 (1.3015)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [180/313]  eta: 0:00:28  Loss: 1.1475 (1.2937)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [190/313]  eta: 0:00:25  Loss: 1.2468 (1.2936)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [200/313]  eta: 0:00:23  Loss: 1.2639 (1.2925)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [210/313]  eta: 0:00:21  Loss: 1.2639 (1.2931)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [220/313]  eta: 0:00:19  Loss: 1.3114 (1.2922)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [230/313]  eta: 0:00:17  Loss: 1.3114 (1.2965)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [240/313]  eta: 0:00:15  Loss: 1.3798 (1.2974)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [250/313]  eta: 0:00:13  Loss: 1.2945 (1.2964)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [260/313]  eta: 0:00:11  Loss: 1.2591 (1.2952)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [270/313]  eta: 0:00:09  Loss: 1.3018 (1.2957)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [280/313]  eta: 0:00:06  Loss: 1.3201 (1.2976)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [290/313]  eta: 0:00:04  Loss: 1.2946 (1.2972)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [300/313]  eta: 0:00:02  Loss: 1.2946 (1.2958)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [310/313]  eta: 0:00:00  Loss: 1.3040 (1.2961)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[9/5]  [312/313]  eta: 0:00:00  Loss: 1.3040 (1.2965)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2072  data: 0.0002  max mem: 2382
Train: Epoch[9/5] Total time: 0:01:06 (0.2117 s / it)
Averaged stats: Loss: 1.3040 (1.2965)  ASR: 100.0000 (100.0000)  ACC: nan (nan)
Train: Epoch[10/5]  [  0/313]  eta: 0:02:05  Loss: 1.0261 (1.0261)  ASR: 100.0000 (100.0000)  ACC: 50.0000 (50.0000)  time: 0.4006  data: 0.2014  max mem: 2382
Train: Epoch[10/5]  [ 10/313]  eta: 0:01:05  Loss: 1.2714 (1.2844)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (11.3208)  time: 0.2146  data: 0.0185  max mem: 2382
Train: Epoch[10/5]  [ 20/313]  eta: 0:01:02  Loss: 1.2076 (1.2489)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.7660)  time: 0.2036  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [ 30/313]  eta: 0:01:00  Loss: 1.2679 (1.2864)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.2318)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [ 40/313]  eta: 0:00:58  Loss: 1.2961 (1.2944)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (18.6275)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [ 50/313]  eta: 0:00:56  Loss: 1.2323 (1.2775)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (18.1070)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [ 60/313]  eta: 0:00:53  Loss: 1.2232 (1.2802)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (18.0272)  time: 0.2134  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [ 70/313]  eta: 0:00:51  Loss: 1.3423 (1.2881)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (17.1920)  time: 0.2132  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [ 80/313]  eta: 0:00:49  Loss: 1.2985 (1.2829)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9898)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [ 90/313]  eta: 0:00:47  Loss: 1.2854 (1.2859)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.5919)  time: 0.2137  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [100/313]  eta: 0:00:45  Loss: 1.2761 (1.2893)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.2978)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [110/313]  eta: 0:00:43  Loss: 1.2950 (1.2975)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.7266)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [120/313]  eta: 0:00:41  Loss: 1.2741 (1.2951)  ASR: 100.0000 (100.0000)  ACC: 22.2222 (17.0813)  time: 0.2133  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [130/313]  eta: 0:00:39  Loss: 1.2529 (1.2943)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.8712)  time: 0.2121  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [140/313]  eta: 0:00:36  Loss: 1.2957 (1.2943)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.5242)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [150/313]  eta: 0:00:34  Loss: 1.2022 (1.2922)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.5554)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [160/313]  eta: 0:00:32  Loss: 1.2969 (1.2957)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.6460)  time: 0.2106  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [170/313]  eta: 0:00:30  Loss: 1.3114 (1.3002)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.0880)  time: 0.2104  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [180/313]  eta: 0:00:28  Loss: 1.2427 (1.2939)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7603)  time: 0.2108  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [190/313]  eta: 0:00:26  Loss: 1.2417 (1.2957)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8115)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [200/313]  eta: 0:00:23  Loss: 1.3821 (1.2998)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.4832)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [210/313]  eta: 0:00:21  Loss: 1.3807 (1.3029)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.4706)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [220/313]  eta: 0:00:19  Loss: 1.3120 (1.3032)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.6584)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [230/313]  eta: 0:00:17  Loss: 1.1934 (1.3003)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.8120)  time: 0.2114  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [240/313]  eta: 0:00:15  Loss: 1.1738 (1.2965)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.9110)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [250/313]  eta: 0:00:13  Loss: 1.2680 (1.2981)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6151)  time: 0.2032  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [260/313]  eta: 0:00:11  Loss: 1.3281 (1.2955)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7774)  time: 0.1948  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [270/313]  eta: 0:00:09  Loss: 1.2149 (1.2948)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.0176)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [280/313]  eta: 0:00:06  Loss: 1.2149 (1.2915)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.8945)  time: 0.2236  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [290/313]  eta: 0:00:04  Loss: 1.1949 (1.2911)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7605)  time: 0.2203  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [300/313]  eta: 0:00:02  Loss: 1.3466 (1.2904)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.7124)  time: 0.2167  data: 0.0001  max mem: 2382
Train: Epoch[10/5]  [310/313]  eta: 0:00:00  Loss: 1.2870 (1.2902)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.5284)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[10/5]  [312/313]  eta: 0:00:00  Loss: 1.2588 (1.2891)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6069)  time: 0.2074  data: 0.0002  max mem: 2382
Train: Epoch[10/5] Total time: 0:01:07 (0.2155 s / it)
Averaged stats: Loss: 1.2588 (1.2891)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6069)
Train: Epoch[11/5]  [  0/313]  eta: 0:02:11  Loss: 1.1083 (1.1083)  ASR: 100.0000 (100.0000)  ACC: 33.3333 (33.3333)  time: 0.4199  data: 0.2215  max mem: 2382
Train: Epoch[11/5]  [ 10/313]  eta: 0:01:04  Loss: 1.2235 (1.2391)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (18.0000)  time: 0.2140  data: 0.0203  max mem: 2382
Train: Epoch[11/5]  [ 20/313]  eta: 0:01:01  Loss: 1.2612 (1.2854)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (18.0952)  time: 0.1998  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [ 30/313]  eta: 0:00:59  Loss: 1.3458 (1.2827)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.1290)  time: 0.2057  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [ 40/313]  eta: 0:00:57  Loss: 1.2131 (1.2611)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7360)  time: 0.2077  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [ 50/313]  eta: 0:00:55  Loss: 1.2019 (1.2531)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [ 60/313]  eta: 0:00:53  Loss: 1.1841 (1.2464)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2142  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [ 70/313]  eta: 0:00:51  Loss: 1.1623 (1.2448)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2139  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [ 80/313]  eta: 0:00:49  Loss: 1.2011 (1.2397)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2145  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [ 90/313]  eta: 0:00:47  Loss: 1.2183 (1.2420)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2149  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [100/313]  eta: 0:00:45  Loss: 1.2064 (1.2399)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [110/313]  eta: 0:00:43  Loss: 1.2023 (1.2428)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2141  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [120/313]  eta: 0:00:41  Loss: 1.2023 (1.2456)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2138  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [130/313]  eta: 0:00:38  Loss: 1.1878 (1.2431)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2138  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [140/313]  eta: 0:00:36  Loss: 1.1885 (1.2460)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2139  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [150/313]  eta: 0:00:34  Loss: 1.1933 (1.2451)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2137  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [160/313]  eta: 0:00:32  Loss: 1.2341 (1.2465)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2138  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [170/313]  eta: 0:00:30  Loss: 1.2253 (1.2450)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2141  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [180/313]  eta: 0:00:28  Loss: 1.2360 (1.2479)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2139  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [190/313]  eta: 0:00:26  Loss: 1.2505 (1.2509)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [200/313]  eta: 0:00:24  Loss: 1.2640 (1.2497)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [210/313]  eta: 0:00:21  Loss: 1.2807 (1.2530)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2117  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [220/313]  eta: 0:00:19  Loss: 1.1924 (1.2474)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (nan)  time: 0.2116  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [230/313]  eta: 0:00:17  Loss: 1.1750 (1.2502)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [240/313]  eta: 0:00:15  Loss: 1.2845 (1.2514)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [250/313]  eta: 0:00:13  Loss: 1.2860 (1.2521)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2118  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [260/313]  eta: 0:00:11  Loss: 1.1887 (1.2492)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2119  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [270/313]  eta: 0:00:09  Loss: 1.1887 (1.2525)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2119  data: 0.0001  max mem: 2382
Train: Epoch[11/5]  [280/313]  eta: 0:00:07  Loss: 1.1540 (1.2487)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [290/313]  eta: 0:00:04  Loss: 1.1894 (1.2497)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [300/313]  eta: 0:00:02  Loss: 1.2298 (1.2490)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [310/313]  eta: 0:00:00  Loss: 1.2023 (1.2494)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[11/5]  [312/313]  eta: 0:00:00  Loss: 1.2171 (1.2483)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2065  data: 0.0002  max mem: 2382
Train: Epoch[11/5] Total time: 0:01:06 (0.2124 s / it)
Averaged stats: Loss: 1.2171 (1.2483)  ASR: 100.0000 (100.0000)  ACC: nan (nan)
Train: Epoch[12/5]  [  0/313]  eta: 0:02:00  Loss: 1.0858 (1.0858)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.3834  data: 0.1861  max mem: 2382
Train: Epoch[12/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0858 (1.1643)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (19.5652)  time: 0.2112  data: 0.0171  max mem: 2382
Train: Epoch[12/5]  [ 20/313]  eta: 0:01:00  Loss: 1.2539 (1.2261)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.4639)  time: 0.1982  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [ 30/313]  eta: 0:00:58  Loss: 1.2539 (1.2299)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.6667)  time: 0.2047  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [ 40/313]  eta: 0:00:56  Loss: 1.2487 (1.2275)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8936)  time: 0.2086  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [ 50/313]  eta: 0:00:54  Loss: 1.1852 (1.2364)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.3866)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [ 60/313]  eta: 0:00:52  Loss: 1.2383 (1.2476)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.4384)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [ 70/313]  eta: 0:00:50  Loss: 1.2383 (1.2304)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (15.9509)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [ 80/313]  eta: 0:00:48  Loss: 1.2419 (1.2388)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.5789)  time: 0.2102  data: 0.0001  max mem: 2382
Train: Epoch[12/5]  [ 90/313]  eta: 0:00:46  Loss: 1.2568 (1.2445)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (16.3972)  time: 0.2101  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [100/313]  eta: 0:00:44  Loss: 1.2325 (1.2396)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.1765)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [110/313]  eta: 0:00:42  Loss: 1.1686 (1.2357)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9615)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [120/313]  eta: 0:00:40  Loss: 1.1838 (1.2348)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.4311)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [130/313]  eta: 0:00:38  Loss: 1.2470 (1.2394)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8320)  time: 0.2100  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [140/313]  eta: 0:00:36  Loss: 1.2639 (1.2393)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9159)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [150/313]  eta: 0:00:34  Loss: 1.2373 (1.2405)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.0839)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [160/313]  eta: 0:00:32  Loss: 1.2330 (1.2380)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.7895)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [170/313]  eta: 0:00:29  Loss: 1.2394 (1.2370)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8612)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [180/313]  eta: 0:00:27  Loss: 1.1705 (1.2346)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.9198)  time: 0.2100  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [190/313]  eta: 0:00:25  Loss: 1.1535 (1.2310)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.8605)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [200/313]  eta: 0:00:23  Loss: 1.2252 (1.2311)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8849)  time: 0.2100  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [210/313]  eta: 0:00:21  Loss: 1.2019 (1.2289)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6282)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [220/313]  eta: 0:00:19  Loss: 1.2164 (1.2340)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.8960)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [230/313]  eta: 0:00:17  Loss: 1.2341 (1.2328)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.9112)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [240/313]  eta: 0:00:15  Loss: 1.1839 (1.2291)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.8177)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [250/313]  eta: 0:00:13  Loss: 1.2019 (1.2297)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.5822)  time: 0.2138  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [260/313]  eta: 0:00:11  Loss: 1.2289 (1.2291)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6069)  time: 0.2180  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [270/313]  eta: 0:00:09  Loss: 1.1819 (1.2261)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6800)  time: 0.2189  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [280/313]  eta: 0:00:06  Loss: 1.1767 (1.2258)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.5212)  time: 0.2189  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [290/313]  eta: 0:00:04  Loss: 1.2045 (1.2283)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.7661)  time: 0.2168  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [300/313]  eta: 0:00:02  Loss: 1.3089 (1.2312)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.2642)  time: 0.2140  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [310/313]  eta: 0:00:00  Loss: 1.2390 (1.2323)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.3014)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[12/5]  [312/313]  eta: 0:00:00  Loss: 1.2200 (1.2304)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2081  data: 0.0002  max mem: 2382
Train: Epoch[12/5] Total time: 0:01:06 (0.2113 s / it)
Averaged stats: Loss: 1.2200 (1.2304)  ASR: 100.0000 (100.0000)  ACC: nan (nan)
Train: Epoch[13/5]  [  0/313]  eta: 0:02:11  Loss: 1.0593 (1.0593)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4214  data: 0.2252  max mem: 2382
Train: Epoch[13/5]  [ 10/313]  eta: 0:01:04  Loss: 1.2523 (1.2194)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (23.0769)  time: 0.2133  data: 0.0206  max mem: 2382
Train: Epoch[13/5]  [ 20/313]  eta: 0:01:01  Loss: 1.2477 (1.2237)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.3265)  time: 0.1986  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [ 30/313]  eta: 0:00:59  Loss: 1.2493 (1.2351)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.1074)  time: 0.2066  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [ 40/313]  eta: 0:00:56  Loss: 1.2436 (1.2233)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2084  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [ 50/313]  eta: 0:00:54  Loss: 1.2093 (1.2324)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2085  data: 0.0001  max mem: 2382
Train: Epoch[13/5]  [ 60/313]  eta: 0:00:52  Loss: 1.1706 (1.2203)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2085  data: 0.0001  max mem: 2382
Train: Epoch[13/5]  [ 70/313]  eta: 0:00:50  Loss: 1.1706 (1.2192)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2077  data: 0.0001  max mem: 2382
Train: Epoch[13/5]  [ 80/313]  eta: 0:00:48  Loss: 1.1812 (1.2125)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2072  data: 0.0001  max mem: 2382
Train: Epoch[13/5]  [ 90/313]  eta: 0:00:46  Loss: 1.1812 (1.2245)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2071  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [100/313]  eta: 0:00:44  Loss: 1.3056 (1.2288)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2165  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [110/313]  eta: 0:00:42  Loss: 1.2534 (1.2250)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2254  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [120/313]  eta: 0:00:40  Loss: 1.1803 (1.2268)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2219  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [130/313]  eta: 0:00:38  Loss: 1.2342 (1.2309)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2183  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [140/313]  eta: 0:00:36  Loss: 1.2216 (1.2322)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2168  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [150/313]  eta: 0:00:34  Loss: 1.2123 (1.2308)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2151  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [160/313]  eta: 0:00:32  Loss: 1.1713 (1.2293)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [170/313]  eta: 0:00:30  Loss: 1.2085 (1.2294)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [180/313]  eta: 0:00:28  Loss: 1.2177 (1.2299)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [190/313]  eta: 0:00:26  Loss: 1.2452 (1.2310)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [200/313]  eta: 0:00:23  Loss: 1.2299 (1.2268)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [210/313]  eta: 0:00:21  Loss: 1.1586 (1.2282)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [220/313]  eta: 0:00:19  Loss: 1.1633 (1.2278)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [230/313]  eta: 0:00:17  Loss: 1.1938 (1.2312)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [240/313]  eta: 0:00:15  Loss: 1.2182 (1.2312)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2121  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [250/313]  eta: 0:00:13  Loss: 1.2267 (1.2309)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [260/313]  eta: 0:00:11  Loss: 1.2868 (1.2343)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [270/313]  eta: 0:00:09  Loss: 1.2868 (1.2337)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (nan)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [280/313]  eta: 0:00:07  Loss: 1.1802 (1.2354)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [290/313]  eta: 0:00:04  Loss: 1.2011 (1.2335)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [300/313]  eta: 0:00:02  Loss: 1.1562 (1.2341)  ASR: 100.0000 (100.0000)  ACC: 8.3333 (nan)  time: 0.2127  data: 0.0001  max mem: 2382
Train: Epoch[13/5]  [310/313]  eta: 0:00:00  Loss: 1.1672 (1.2343)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[13/5]  [312/313]  eta: 0:00:00  Loss: 1.1562 (1.2335)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2073  data: 0.0002  max mem: 2382
Train: Epoch[13/5] Total time: 0:01:06 (0.2124 s / it)
Averaged stats: Loss: 1.1562 (1.2335)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)
Train: Epoch[14/5]  [  0/313]  eta: 0:02:02  Loss: 1.0302 (1.0302)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.3928  data: 0.1938  max mem: 2382
Train: Epoch[14/5]  [ 10/313]  eta: 0:01:04  Loss: 1.2585 (1.2494)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (9.0909)  time: 0.2116  data: 0.0178  max mem: 2382
Train: Epoch[14/5]  [ 20/313]  eta: 0:01:00  Loss: 1.2585 (1.2457)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (10.5769)  time: 0.1971  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [ 30/313]  eta: 0:00:58  Loss: 1.2389 (1.2413)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (9.8684)  time: 0.2065  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [ 40/313]  eta: 0:00:57  Loss: 1.1889 (1.2193)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (11.4583)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [ 50/313]  eta: 0:00:55  Loss: 1.1716 (1.2103)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (11.8644)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [ 60/313]  eta: 0:00:53  Loss: 1.1784 (1.2145)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (11.5789)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [ 70/313]  eta: 0:00:51  Loss: 1.2071 (1.2167)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (12.8743)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [ 80/313]  eta: 0:00:49  Loss: 1.2071 (1.2130)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (12.9973)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1656 (1.2149)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.6471)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [100/313]  eta: 0:00:45  Loss: 1.2156 (1.2178)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (13.4454)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [110/313]  eta: 0:00:43  Loss: 1.2075 (1.2231)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (14.5283)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [120/313]  eta: 0:00:40  Loss: 1.1644 (1.2170)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.0351)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [130/313]  eta: 0:00:38  Loss: 1.2465 (1.2183)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.3548)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [140/313]  eta: 0:00:36  Loss: 1.2073 (1.2139)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.6747)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [150/313]  eta: 0:00:34  Loss: 1.2073 (1.2172)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.8876)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [160/313]  eta: 0:00:32  Loss: 1.2228 (1.2162)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.9077)  time: 0.2125  data: 0.0001  max mem: 2382
Train: Epoch[14/5]  [170/313]  eta: 0:00:30  Loss: 1.1429 (1.2097)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.7355)  time: 0.2127  data: 0.0001  max mem: 2382
Train: Epoch[14/5]  [180/313]  eta: 0:00:28  Loss: 1.1414 (1.2119)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.9112)  time: 0.2129  data: 0.0001  max mem: 2382
Train: Epoch[14/5]  [190/313]  eta: 0:00:26  Loss: 1.1857 (1.2106)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.2027)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [200/313]  eta: 0:00:23  Loss: 1.1857 (1.2114)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [210/313]  eta: 0:00:21  Loss: 1.2138 (1.2115)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [220/313]  eta: 0:00:19  Loss: 1.2011 (1.2101)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [230/313]  eta: 0:00:17  Loss: 1.1346 (1.2104)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [240/313]  eta: 0:00:15  Loss: 1.1782 (1.2102)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [250/313]  eta: 0:00:13  Loss: 1.1837 (1.2138)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2102  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [260/313]  eta: 0:00:11  Loss: 1.1837 (1.2117)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [270/313]  eta: 0:00:09  Loss: 1.0885 (1.2082)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [280/313]  eta: 0:00:06  Loss: 1.0933 (1.2067)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [290/313]  eta: 0:00:04  Loss: 1.0933 (1.2034)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (nan)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [300/313]  eta: 0:00:02  Loss: 1.0575 (1.2022)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [310/313]  eta: 0:00:00  Loss: 1.1644 (1.2037)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[14/5]  [312/313]  eta: 0:00:00  Loss: 1.1644 (1.2045)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2051  data: 0.0002  max mem: 2382
Train: Epoch[14/5] Total time: 0:01:06 (0.2119 s / it)
Averaged stats: Loss: 1.1644 (1.2045)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[15/5]  [  0/313]  eta: 0:02:12  Loss: 1.3199 (1.3199)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.6667)  time: 0.4230  data: 0.2275  max mem: 2382
Train: Epoch[15/5]  [ 10/313]  eta: 0:01:07  Loss: 1.3199 (1.3033)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.0625)  time: 0.2213  data: 0.0208  max mem: 2382
Train: Epoch[15/5]  [ 20/313]  eta: 0:01:05  Loss: 1.2446 (1.2513)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (11.9266)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [ 30/313]  eta: 0:01:02  Loss: 1.2237 (1.2584)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.3374)  time: 0.2229  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [ 40/313]  eta: 0:01:00  Loss: 1.2237 (1.2549)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.0235)  time: 0.2169  data: 0.0001  max mem: 2382
Train: Epoch[15/5]  [ 50/313]  eta: 0:00:57  Loss: 1.2355 (1.2511)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8855)  time: 0.2120  data: 0.0001  max mem: 2382
Train: Epoch[15/5]  [ 60/313]  eta: 0:00:54  Loss: 1.2355 (1.2381)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.7377)  time: 0.2113  data: 0.0001  max mem: 2382
Train: Epoch[15/5]  [ 70/313]  eta: 0:00:52  Loss: 1.2254 (1.2382)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.4930)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [ 80/313]  eta: 0:00:50  Loss: 1.2234 (1.2318)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.4613)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [ 90/313]  eta: 0:00:47  Loss: 1.2007 (1.2267)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [100/313]  eta: 0:00:45  Loss: 1.2262 (1.2314)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [110/313]  eta: 0:00:43  Loss: 1.2070 (1.2307)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [120/313]  eta: 0:00:41  Loss: 1.1971 (1.2307)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [130/313]  eta: 0:00:39  Loss: 1.2062 (1.2293)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [140/313]  eta: 0:00:36  Loss: 1.2112 (1.2277)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [150/313]  eta: 0:00:34  Loss: 1.1190 (1.2265)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2102  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [160/313]  eta: 0:00:32  Loss: 1.0962 (1.2211)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [170/313]  eta: 0:00:30  Loss: 1.1666 (1.2225)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [180/313]  eta: 0:00:28  Loss: 1.2392 (1.2253)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2101  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [190/313]  eta: 0:00:26  Loss: 1.1618 (1.2221)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [200/313]  eta: 0:00:24  Loss: 1.1069 (1.2182)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [210/313]  eta: 0:00:21  Loss: 1.1360 (1.2183)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [220/313]  eta: 0:00:19  Loss: 1.2056 (1.2165)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [230/313]  eta: 0:00:17  Loss: 1.1889 (1.2173)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [240/313]  eta: 0:00:15  Loss: 1.1951 (1.2176)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [250/313]  eta: 0:00:13  Loss: 1.2305 (1.2186)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [260/313]  eta: 0:00:11  Loss: 1.2305 (1.2169)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [270/313]  eta: 0:00:09  Loss: 1.2436 (1.2213)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [280/313]  eta: 0:00:06  Loss: 1.2530 (1.2196)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [290/313]  eta: 0:00:04  Loss: 1.2271 (1.2198)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [300/313]  eta: 0:00:02  Loss: 1.1931 (1.2197)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [310/313]  eta: 0:00:00  Loss: 1.1931 (1.2198)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[15/5]  [312/313]  eta: 0:00:00  Loss: 1.2374 (1.2192)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2057  data: 0.0002  max mem: 2382
Train: Epoch[15/5] Total time: 0:01:06 (0.2119 s / it)
Averaged stats: Loss: 1.2374 (1.2192)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[16/5]  [  0/313]  eta: 0:02:08  Loss: 1.2196 (1.2196)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4096  data: 0.2086  max mem: 2382
Train: Epoch[16/5]  [ 10/313]  eta: 0:01:05  Loss: 1.1305 (1.1746)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (10.2041)  time: 0.2161  data: 0.0192  max mem: 2382
Train: Epoch[16/5]  [ 20/313]  eta: 0:01:01  Loss: 1.1492 (1.1659)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.0879)  time: 0.2013  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [ 30/313]  eta: 0:00:59  Loss: 1.1636 (1.2125)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.9252)  time: 0.2068  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [ 40/313]  eta: 0:00:57  Loss: 1.2110 (1.2100)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.4330)  time: 0.2084  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [ 50/313]  eta: 0:00:55  Loss: 1.1931 (1.1996)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.0338)  time: 0.2096  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [ 60/313]  eta: 0:00:53  Loss: 1.2326 (1.2191)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (17.0648)  time: 0.2093  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [ 70/313]  eta: 0:00:50  Loss: 1.2326 (1.2022)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (16.4134)  time: 0.2088  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [ 80/313]  eta: 0:00:48  Loss: 1.1350 (1.2112)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6250)  time: 0.2092  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [ 90/313]  eta: 0:00:46  Loss: 1.2450 (1.2174)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7534)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [100/313]  eta: 0:00:44  Loss: 1.2270 (1.2164)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (16.2887)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [110/313]  eta: 0:00:42  Loss: 1.1613 (1.2175)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.2921)  time: 0.2102  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [120/313]  eta: 0:00:40  Loss: 1.2343 (1.2190)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.2393)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [130/313]  eta: 0:00:38  Loss: 1.2035 (1.2197)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (16.8239)  time: 0.2147  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [140/313]  eta: 0:00:36  Loss: 1.2161 (1.2237)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.0637)  time: 0.2147  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [150/313]  eta: 0:00:34  Loss: 1.2033 (1.2142)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [160/313]  eta: 0:00:32  Loss: 1.1754 (1.2131)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2142  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [170/313]  eta: 0:00:30  Loss: 1.1959 (1.2104)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2144  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [180/313]  eta: 0:00:28  Loss: 1.2088 (1.2130)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2149  data: 0.0003  max mem: 2382
Train: Epoch[16/5]  [190/313]  eta: 0:00:26  Loss: 1.2300 (1.2159)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2147  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [200/313]  eta: 0:00:23  Loss: 1.1979 (1.2127)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2144  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [210/313]  eta: 0:00:21  Loss: 1.1491 (1.2119)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [220/313]  eta: 0:00:19  Loss: 1.1850 (1.2109)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [230/313]  eta: 0:00:17  Loss: 1.1857 (1.2115)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [240/313]  eta: 0:00:15  Loss: 1.2059 (1.2144)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2145  data: 0.0003  max mem: 2382
Train: Epoch[16/5]  [250/313]  eta: 0:00:13  Loss: 1.2376 (1.2145)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [260/313]  eta: 0:00:11  Loss: 1.2270 (1.2140)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [270/313]  eta: 0:00:09  Loss: 1.2310 (1.2159)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [280/313]  eta: 0:00:07  Loss: 1.2311 (1.2133)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2137  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [290/313]  eta: 0:00:04  Loss: 1.1576 (1.2144)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [300/313]  eta: 0:00:02  Loss: 1.2150 (1.2163)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [310/313]  eta: 0:00:00  Loss: 1.1733 (1.2142)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[16/5]  [312/313]  eta: 0:00:00  Loss: 1.1733 (1.2131)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2045  data: 0.0002  max mem: 2382
Train: Epoch[16/5] Total time: 0:01:06 (0.2123 s / it)
Averaged stats: Loss: 1.1733 (1.2131)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[17/5]  [  0/313]  eta: 0:02:08  Loss: 1.2224 (1.2224)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (20.0000)  time: 0.4109  data: 0.2094  max mem: 2382
Train: Epoch[17/5]  [ 10/313]  eta: 0:01:04  Loss: 1.2224 (1.2247)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (22.2222)  time: 0.2138  data: 0.0192  max mem: 2382
Train: Epoch[17/5]  [ 20/313]  eta: 0:01:01  Loss: 1.2312 (1.2369)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (17.7570)  time: 0.1999  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [ 30/313]  eta: 0:00:59  Loss: 1.2209 (1.2222)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (17.4194)  time: 0.2072  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [ 40/313]  eta: 0:00:57  Loss: 1.1546 (1.2142)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.8317)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [ 50/313]  eta: 0:00:55  Loss: 1.1546 (1.2155)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (17.1315)  time: 0.2091  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [ 60/313]  eta: 0:00:52  Loss: 1.2224 (1.2201)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (15.5116)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [ 70/313]  eta: 0:00:50  Loss: 1.2902 (1.2250)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.6479)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [ 80/313]  eta: 0:00:48  Loss: 1.1755 (1.2157)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (15.3652)  time: 0.2090  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [ 90/313]  eta: 0:00:46  Loss: 1.1257 (1.2174)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (14.7982)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [100/313]  eta: 0:00:44  Loss: 1.1257 (1.2098)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.7844)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [110/313]  eta: 0:00:42  Loss: 1.1032 (1.2048)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.6106)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [120/313]  eta: 0:00:40  Loss: 1.1619 (1.2031)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.5833)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [130/313]  eta: 0:00:38  Loss: 1.1619 (1.2019)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.9518)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [140/313]  eta: 0:00:36  Loss: 1.1851 (1.2032)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.0298)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [150/313]  eta: 0:00:34  Loss: 1.2305 (1.2083)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8556)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [160/313]  eta: 0:00:32  Loss: 1.2031 (1.2070)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.2652)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [170/313]  eta: 0:00:30  Loss: 1.1446 (1.2038)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8284)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [180/313]  eta: 0:00:28  Loss: 1.1638 (1.2028)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.1796)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [190/313]  eta: 0:00:25  Loss: 1.2120 (1.2068)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.1416)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [200/313]  eta: 0:00:23  Loss: 1.1962 (1.2044)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.5925)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [210/313]  eta: 0:00:21  Loss: 1.1121 (1.2076)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.5206)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [220/313]  eta: 0:00:19  Loss: 1.1121 (1.2028)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0711)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [230/313]  eta: 0:00:17  Loss: 1.2021 (1.2093)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.2193)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [240/313]  eta: 0:00:15  Loss: 1.1502 (1.2041)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.2645)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [250/313]  eta: 0:00:13  Loss: 1.1172 (1.2051)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (15.8638)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [260/313]  eta: 0:00:11  Loss: 1.1691 (1.2050)  ASR: 100.0000 (100.0000)  ACC: 28.5714 (16.0543)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [270/313]  eta: 0:00:09  Loss: 1.0966 (1.2012)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7364)  time: 0.2121  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [280/313]  eta: 0:00:06  Loss: 1.1178 (1.2026)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.3068)  time: 0.2127  data: 0.0003  max mem: 2382
Train: Epoch[17/5]  [290/313]  eta: 0:00:04  Loss: 1.1219 (1.2000)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (16.3295)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [300/313]  eta: 0:00:02  Loss: 1.0979 (1.1949)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [310/313]  eta: 0:00:00  Loss: 1.1247 (1.1973)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[17/5]  [312/313]  eta: 0:00:00  Loss: 1.1501 (1.1975)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2055  data: 0.0002  max mem: 2382
Train: Epoch[17/5] Total time: 0:01:06 (0.2110 s / it)
Averaged stats: Loss: 1.1501 (1.1975)  ASR: 100.0000 (100.0000)  ACC: nan (nan)
Train: Epoch[18/5]  [  0/313]  eta: 0:02:08  Loss: 1.1249 (1.1249)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4120  data: 0.2141  max mem: 2382
Train: Epoch[18/5]  [ 10/313]  eta: 0:01:05  Loss: 1.1249 (1.1790)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.7255)  time: 0.2172  data: 0.0196  max mem: 2382
Train: Epoch[18/5]  [ 20/313]  eta: 0:01:01  Loss: 1.1713 (1.2056)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8416)  time: 0.2009  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [ 30/313]  eta: 0:01:00  Loss: 1.2670 (1.2432)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.2075)  time: 0.2140  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [ 40/313]  eta: 0:00:59  Loss: 1.3133 (1.2429)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.2180)  time: 0.2254  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [ 50/313]  eta: 0:00:57  Loss: 1.2458 (1.2473)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.0943)  time: 0.2247  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [ 60/313]  eta: 0:00:55  Loss: 1.1899 (1.2319)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.2857)  time: 0.2205  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [ 70/313]  eta: 0:00:53  Loss: 1.1106 (1.2188)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2171  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [ 80/313]  eta: 0:00:50  Loss: 1.1655 (1.2156)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [ 90/313]  eta: 0:00:48  Loss: 1.1886 (1.2082)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [100/313]  eta: 0:00:46  Loss: 1.2506 (1.2173)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [110/313]  eta: 0:00:43  Loss: 1.2464 (1.2098)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2141  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [120/313]  eta: 0:00:41  Loss: 1.2067 (1.2133)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2138  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [130/313]  eta: 0:00:39  Loss: 1.2100 (1.2164)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [140/313]  eta: 0:00:37  Loss: 1.2100 (1.2170)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2109  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [150/313]  eta: 0:00:35  Loss: 1.1884 (1.2173)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2109  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [160/313]  eta: 0:00:32  Loss: 1.1988 (1.2223)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2110  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [170/313]  eta: 0:00:30  Loss: 1.2464 (1.2182)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2109  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [180/313]  eta: 0:00:28  Loss: 1.1140 (1.2166)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2110  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [190/313]  eta: 0:00:26  Loss: 1.1215 (1.2135)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2107  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [200/313]  eta: 0:00:24  Loss: 1.1783 (1.2179)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2100  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [210/313]  eta: 0:00:22  Loss: 1.2508 (1.2176)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2097  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [220/313]  eta: 0:00:19  Loss: 1.1466 (1.2168)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2104  data: 0.0001  max mem: 2382
Train: Epoch[18/5]  [230/313]  eta: 0:00:17  Loss: 1.1871 (1.2222)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [240/313]  eta: 0:00:15  Loss: 1.1733 (1.2186)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [250/313]  eta: 0:00:13  Loss: 1.2208 (1.2225)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [260/313]  eta: 0:00:11  Loss: 1.2118 (1.2186)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [270/313]  eta: 0:00:09  Loss: 1.2005 (1.2206)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [280/313]  eta: 0:00:07  Loss: 1.2296 (1.2194)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [290/313]  eta: 0:00:04  Loss: 1.1805 (1.2181)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [300/313]  eta: 0:00:02  Loss: 1.1487 (1.2173)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[18/5]  [310/313]  eta: 0:00:00  Loss: 1.2082 (1.2184)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2128  data: 0.0003  max mem: 2382
Train: Epoch[18/5]  [312/313]  eta: 0:00:00  Loss: 1.2087 (1.2196)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2076  data: 0.0003  max mem: 2382
Train: Epoch[18/5] Total time: 0:01:06 (0.2131 s / it)
Averaged stats: Loss: 1.2087 (1.2196)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)
Train: Epoch[19/5]  [  0/313]  eta: 0:02:04  Loss: 1.1291 (1.1291)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.3967  data: 0.1988  max mem: 2382
Train: Epoch[19/5]  [ 10/313]  eta: 0:01:04  Loss: 1.2321 (1.2278)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (7.1429)  time: 0.2131  data: 0.0182  max mem: 2382
Train: Epoch[19/5]  [ 20/313]  eta: 0:01:01  Loss: 1.2027 (1.2225)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.2075)  time: 0.2013  data: 0.0001  max mem: 2382
Train: Epoch[19/5]  [ 30/313]  eta: 0:00:59  Loss: 1.1222 (1.2053)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.0000)  time: 0.2079  data: 0.0001  max mem: 2382
Train: Epoch[19/5]  [ 40/313]  eta: 0:00:57  Loss: 1.1175 (1.1803)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.6842)  time: 0.2084  data: 0.0001  max mem: 2382
Train: Epoch[19/5]  [ 50/313]  eta: 0:00:55  Loss: 1.0868 (1.1649)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.8528)  time: 0.2089  data: 0.0001  max mem: 2382
Train: Epoch[19/5]  [ 60/313]  eta: 0:00:52  Loss: 1.2142 (1.1954)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.2653)  time: 0.2087  data: 0.0001  max mem: 2382
Train: Epoch[19/5]  [ 70/313]  eta: 0:00:50  Loss: 1.3353 (1.2042)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (14.1210)  time: 0.2087  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [ 80/313]  eta: 0:00:48  Loss: 1.1873 (1.2041)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.6364)  time: 0.2090  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [ 90/313]  eta: 0:00:46  Loss: 1.1873 (1.2021)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.8959)  time: 0.2088  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [100/313]  eta: 0:00:44  Loss: 1.0915 (1.1914)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [110/313]  eta: 0:00:42  Loss: 1.1465 (1.1906)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2092  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [120/313]  eta: 0:00:40  Loss: 1.2047 (1.2003)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2082  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [130/313]  eta: 0:00:38  Loss: 1.2969 (1.2025)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [140/313]  eta: 0:00:36  Loss: 1.2229 (1.2042)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2141  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [150/313]  eta: 0:00:34  Loss: 1.2270 (1.2042)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2145  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [160/313]  eta: 0:00:32  Loss: 1.1264 (1.1989)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2147  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [170/313]  eta: 0:00:30  Loss: 1.1261 (1.1959)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2151  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [180/313]  eta: 0:00:28  Loss: 1.1003 (1.1950)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2149  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [190/313]  eta: 0:00:25  Loss: 1.1065 (1.1917)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (nan)  time: 0.2142  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [200/313]  eta: 0:00:23  Loss: 1.1473 (1.1975)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2138  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [210/313]  eta: 0:00:21  Loss: 1.2060 (1.1963)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2149  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [220/313]  eta: 0:00:19  Loss: 1.1782 (1.1978)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2151  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [230/313]  eta: 0:00:17  Loss: 1.2157 (1.1995)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [240/313]  eta: 0:00:15  Loss: 1.1991 (1.2021)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [250/313]  eta: 0:00:13  Loss: 1.1620 (1.2005)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2145  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [260/313]  eta: 0:00:11  Loss: 1.1620 (1.2008)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (nan)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [270/313]  eta: 0:00:09  Loss: 1.2107 (1.2040)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2144  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [280/313]  eta: 0:00:06  Loss: 1.2598 (1.2044)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2139  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [290/313]  eta: 0:00:04  Loss: 1.1982 (1.2037)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [300/313]  eta: 0:00:02  Loss: 1.1695 (1.2036)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [310/313]  eta: 0:00:00  Loss: 1.1695 (1.2048)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[19/5]  [312/313]  eta: 0:00:00  Loss: 1.1372 (1.2046)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2070  data: 0.0002  max mem: 2382
Train: Epoch[19/5] Total time: 0:01:06 (0.2120 s / it)
Averaged stats: Loss: 1.1372 (1.2046)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[20/5]  [  0/313]  eta: 0:02:02  Loss: 1.1866 (1.1866)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.3927  data: 0.1961  max mem: 2382
Train: Epoch[20/5]  [ 10/313]  eta: 0:01:05  Loss: 1.2037 (1.2300)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7895)  time: 0.2166  data: 0.0180  max mem: 2382
Train: Epoch[20/5]  [ 20/313]  eta: 0:01:03  Loss: 1.2512 (1.2337)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.3636)  time: 0.2072  data: 0.0001  max mem: 2382
Train: Epoch[20/5]  [ 30/313]  eta: 0:01:00  Loss: 1.3022 (1.2699)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (17.2414)  time: 0.2148  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [ 40/313]  eta: 0:00:58  Loss: 1.2970 (1.2574)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.8889)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [ 50/313]  eta: 0:00:56  Loss: 1.1656 (1.2392)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (17.3432)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [ 60/313]  eta: 0:00:54  Loss: 1.1656 (1.2325)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9875)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [ 70/313]  eta: 0:00:51  Loss: 1.1951 (1.2267)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.5761)  time: 0.2118  data: 0.0001  max mem: 2382
Train: Epoch[20/5]  [ 80/313]  eta: 0:00:49  Loss: 1.0861 (1.2132)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (16.6259)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [ 90/313]  eta: 0:00:47  Loss: 1.0662 (1.2031)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.6667)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [100/313]  eta: 0:00:45  Loss: 1.0662 (1.1912)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.0494)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [110/313]  eta: 0:00:43  Loss: 1.1364 (1.1903)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9475)  time: 0.2096  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [120/313]  eta: 0:00:40  Loss: 1.1674 (1.1908)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2100  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [130/313]  eta: 0:00:38  Loss: 1.1857 (1.1886)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [140/313]  eta: 0:00:36  Loss: 1.2057 (1.1973)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [150/313]  eta: 0:00:34  Loss: 1.1947 (1.1923)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [160/313]  eta: 0:00:32  Loss: 1.1145 (1.1924)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [170/313]  eta: 0:00:30  Loss: 1.2070 (1.2019)  ASR: 100.0000 (100.0000)  ACC: 8.3333 (nan)  time: 0.2118  data: 0.0003  max mem: 2382
Train: Epoch[20/5]  [180/313]  eta: 0:00:28  Loss: 1.2168 (1.2024)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [190/313]  eta: 0:00:26  Loss: 1.2024 (1.2013)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [200/313]  eta: 0:00:23  Loss: 1.1937 (1.2049)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [210/313]  eta: 0:00:21  Loss: 1.2857 (1.2079)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [220/313]  eta: 0:00:19  Loss: 1.2363 (1.2088)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2110  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [230/313]  eta: 0:00:17  Loss: 1.1933 (1.2047)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2110  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [240/313]  eta: 0:00:15  Loss: 1.1490 (1.2051)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2105  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [250/313]  eta: 0:00:13  Loss: 1.2628 (1.2070)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [260/313]  eta: 0:00:11  Loss: 1.2038 (1.2053)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [270/313]  eta: 0:00:09  Loss: 1.0965 (1.2021)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [280/313]  eta: 0:00:06  Loss: 1.1326 (1.2012)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [290/313]  eta: 0:00:04  Loss: 1.2177 (1.2009)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [300/313]  eta: 0:00:02  Loss: 1.2282 (1.2024)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [310/313]  eta: 0:00:00  Loss: 1.2085 (1.2015)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[20/5]  [312/313]  eta: 0:00:00  Loss: 1.1962 (1.1992)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2058  data: 0.0002  max mem: 2382
Train: Epoch[20/5] Total time: 0:01:06 (0.2112 s / it)
Averaged stats: Loss: 1.1962 (1.1992)  ASR: 100.0000 (100.0000)  ACC: nan (nan)
Train: Epoch[21/5]  [  0/313]  eta: 0:02:15  Loss: 1.0273 (1.0273)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4336  data: 0.2224  max mem: 2382
Train: Epoch[21/5]  [ 10/313]  eta: 0:01:06  Loss: 1.1754 (1.1935)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.9811)  time: 0.2185  data: 0.0204  max mem: 2382
Train: Epoch[21/5]  [ 20/313]  eta: 0:01:02  Loss: 1.2032 (1.1727)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2039  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [ 30/313]  eta: 0:01:00  Loss: 1.2032 (1.1771)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [ 40/313]  eta: 0:00:57  Loss: 1.1771 (1.1740)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [ 50/313]  eta: 0:00:55  Loss: 1.2010 (1.1914)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [ 60/313]  eta: 0:00:53  Loss: 1.2040 (1.1854)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2094  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [ 70/313]  eta: 0:00:51  Loss: 1.1670 (1.1919)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2093  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [ 80/313]  eta: 0:00:49  Loss: 1.0902 (1.1723)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1033 (1.1725)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2098  data: 0.0001  max mem: 2382
Train: Epoch[21/5]  [100/313]  eta: 0:00:44  Loss: 1.1281 (1.1623)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [110/313]  eta: 0:00:42  Loss: 1.1990 (1.1741)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2095  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [120/313]  eta: 0:00:40  Loss: 1.2042 (1.1798)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (nan)  time: 0.2092  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [130/313]  eta: 0:00:38  Loss: 1.2024 (1.1815)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2097  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [140/313]  eta: 0:00:36  Loss: 1.1880 (1.1820)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [150/313]  eta: 0:00:34  Loss: 1.2133 (1.1895)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2162  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [160/313]  eta: 0:00:32  Loss: 1.1132 (1.1826)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2176  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [170/313]  eta: 0:00:30  Loss: 1.1809 (1.1888)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2177  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [180/313]  eta: 0:00:28  Loss: 1.1809 (1.1840)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2177  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [190/313]  eta: 0:00:26  Loss: 1.0897 (1.1812)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2179  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [200/313]  eta: 0:00:24  Loss: 1.1946 (1.1821)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2175  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [210/313]  eta: 0:00:21  Loss: 1.1793 (1.1816)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2160  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [220/313]  eta: 0:00:19  Loss: 1.1793 (1.1833)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [230/313]  eta: 0:00:17  Loss: 1.1956 (1.1831)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2145  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [240/313]  eta: 0:00:15  Loss: 1.2162 (1.1859)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2143  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [250/313]  eta: 0:00:13  Loss: 1.2374 (1.1852)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2141  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [260/313]  eta: 0:00:11  Loss: 1.2212 (1.1873)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2142  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [270/313]  eta: 0:00:09  Loss: 1.1292 (1.1850)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [280/313]  eta: 0:00:07  Loss: 1.1203 (1.1858)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2145  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [290/313]  eta: 0:00:04  Loss: 1.1307 (1.1840)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2147  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [300/313]  eta: 0:00:02  Loss: 1.2104 (1.1869)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [310/313]  eta: 0:00:00  Loss: 1.2104 (1.1857)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[21/5]  [312/313]  eta: 0:00:00  Loss: 1.2104 (1.1856)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2065  data: 0.0002  max mem: 2382
Train: Epoch[21/5] Total time: 0:01:06 (0.2132 s / it)
Averaged stats: Loss: 1.2104 (1.1856)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[22/5]  [  0/313]  eta: 0:02:13  Loss: 1.0822 (1.0822)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4249  data: 0.2263  max mem: 2382
Train: Epoch[22/5]  [ 10/313]  eta: 0:01:05  Loss: 1.0725 (1.1266)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (21.2766)  time: 0.2151  data: 0.0207  max mem: 2382
Train: Epoch[22/5]  [ 20/313]  eta: 0:01:02  Loss: 1.1476 (1.1667)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.1313)  time: 0.2045  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [ 30/313]  eta: 0:01:01  Loss: 1.2637 (1.1946)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.2857)  time: 0.2168  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [ 40/313]  eta: 0:00:58  Loss: 1.2046 (1.1901)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2170  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [ 50/313]  eta: 0:00:56  Loss: 1.1493 (1.1765)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2145  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [ 60/313]  eta: 0:00:54  Loss: 1.1798 (1.1623)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [ 70/313]  eta: 0:00:52  Loss: 1.0779 (1.1550)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2108  data: 0.0001  max mem: 2382
Train: Epoch[22/5]  [ 80/313]  eta: 0:00:49  Loss: 1.0898 (1.1531)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2108  data: 0.0001  max mem: 2382
Train: Epoch[22/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1204 (1.1606)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2105  data: 0.0001  max mem: 2382
Train: Epoch[22/5]  [100/313]  eta: 0:00:45  Loss: 1.1950 (1.1614)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2106  data: 0.0001  max mem: 2382
Train: Epoch[22/5]  [110/313]  eta: 0:00:43  Loss: 1.1618 (1.1618)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2110  data: 0.0001  max mem: 2382
Train: Epoch[22/5]  [120/313]  eta: 0:00:41  Loss: 1.1254 (1.1575)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [130/313]  eta: 0:00:38  Loss: 1.1684 (1.1572)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [140/313]  eta: 0:00:36  Loss: 1.1829 (1.1624)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [150/313]  eta: 0:00:34  Loss: 1.1526 (1.1548)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [160/313]  eta: 0:00:32  Loss: 1.1926 (1.1618)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [170/313]  eta: 0:00:30  Loss: 1.1926 (1.1596)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2111  data: 0.0001  max mem: 2382
Train: Epoch[22/5]  [180/313]  eta: 0:00:28  Loss: 1.1072 (1.1586)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [190/313]  eta: 0:00:26  Loss: 1.1875 (1.1607)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [200/313]  eta: 0:00:24  Loss: 1.1642 (1.1561)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [210/313]  eta: 0:00:21  Loss: 1.1105 (1.1568)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [220/313]  eta: 0:00:19  Loss: 1.1507 (1.1567)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [230/313]  eta: 0:00:17  Loss: 1.0910 (1.1552)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [240/313]  eta: 0:00:15  Loss: 1.1995 (1.1593)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [250/313]  eta: 0:00:13  Loss: 1.2312 (1.1596)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2117  data: 0.0003  max mem: 2382
Train: Epoch[22/5]  [260/313]  eta: 0:00:11  Loss: 1.2692 (1.1632)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2119  data: 0.0003  max mem: 2382
Train: Epoch[22/5]  [270/313]  eta: 0:00:09  Loss: 1.2695 (1.1674)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [280/313]  eta: 0:00:07  Loss: 1.2750 (1.1707)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [290/313]  eta: 0:00:04  Loss: 1.2515 (1.1733)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [300/313]  eta: 0:00:02  Loss: 1.1742 (1.1715)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [310/313]  eta: 0:00:00  Loss: 1.1768 (1.1715)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[22/5]  [312/313]  eta: 0:00:00  Loss: 1.1768 (1.1716)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2066  data: 0.0002  max mem: 2382
Train: Epoch[22/5] Total time: 0:01:06 (0.2121 s / it)
Averaged stats: Loss: 1.1768 (1.1716)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)
Train: Epoch[23/5]  [  0/313]  eta: 0:02:06  Loss: 1.4249 (1.4249)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4047  data: 0.2064  max mem: 2382
Train: Epoch[23/5]  [ 10/313]  eta: 0:01:05  Loss: 1.1133 (1.1519)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (10.0000)  time: 0.2171  data: 0.0189  max mem: 2382
Train: Epoch[23/5]  [ 20/313]  eta: 0:01:02  Loss: 1.1102 (1.1329)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (10.8696)  time: 0.2024  data: 0.0001  max mem: 2382
Train: Epoch[23/5]  [ 30/313]  eta: 0:00:59  Loss: 1.1044 (1.1497)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (9.9291)  time: 0.2065  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [ 40/313]  eta: 0:00:57  Loss: 1.1438 (1.1564)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (12.7660)  time: 0.2084  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [ 50/313]  eta: 0:00:55  Loss: 1.1438 (1.1517)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (13.4199)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [ 60/313]  eta: 0:00:53  Loss: 1.1806 (1.1665)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (13.3333)  time: 0.2125  data: 0.0001  max mem: 2382
Train: Epoch[23/5]  [ 70/313]  eta: 0:00:51  Loss: 1.2437 (1.1778)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (13.2743)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [ 80/313]  eta: 0:00:49  Loss: 1.1802 (1.1687)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.2105)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1782 (1.1691)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.2857)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [100/313]  eta: 0:00:45  Loss: 1.1490 (1.1653)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.8004)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [110/313]  eta: 0:00:42  Loss: 1.1768 (1.1736)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.0417)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [120/313]  eta: 0:00:40  Loss: 1.2029 (1.1748)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.5581)  time: 0.2123  data: 0.0001  max mem: 2382
Train: Epoch[23/5]  [130/313]  eta: 0:00:38  Loss: 1.1530 (1.1749)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.4000)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [140/313]  eta: 0:00:36  Loss: 1.2049 (1.1794)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.3279)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [150/313]  eta: 0:00:34  Loss: 1.2058 (1.1760)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8818)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [160/313]  eta: 0:00:32  Loss: 1.1312 (1.1763)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.7520)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [170/313]  eta: 0:00:30  Loss: 1.1601 (1.1816)  ASR: 100.0000 (100.0000)  ACC: 22.2222 (15.7767)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [180/313]  eta: 0:00:28  Loss: 1.1752 (1.1806)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (16.2844)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [190/313]  eta: 0:00:26  Loss: 1.0963 (1.1774)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (16.0832)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [200/313]  eta: 0:00:23  Loss: 1.0955 (1.1771)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (16.1290)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [210/313]  eta: 0:00:21  Loss: 1.1151 (1.1764)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9881)  time: 0.2137  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [220/313]  eta: 0:00:19  Loss: 1.1569 (1.1789)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.2264)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [230/313]  eta: 0:00:17  Loss: 1.1657 (1.1778)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.0795)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [240/313]  eta: 0:00:15  Loss: 1.1256 (1.1755)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.0279)  time: 0.2118  data: 0.0001  max mem: 2382
Train: Epoch[23/5]  [250/313]  eta: 0:00:13  Loss: 1.1794 (1.1767)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.1102)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [260/313]  eta: 0:00:11  Loss: 1.2152 (1.1818)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.9777)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [270/313]  eta: 0:00:09  Loss: 1.2667 (1.1833)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.8779)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [280/313]  eta: 0:00:07  Loss: 1.1823 (1.1791)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.8990)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [290/313]  eta: 0:00:04  Loss: 1.1145 (1.1777)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.1267)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [300/313]  eta: 0:00:02  Loss: 1.1145 (1.1765)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9693)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [310/313]  eta: 0:00:00  Loss: 1.1054 (1.1775)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7008)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[23/5]  [312/313]  eta: 0:00:00  Loss: 1.1054 (1.1766)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7152)  time: 0.2074  data: 0.0002  max mem: 2382
Train: Epoch[23/5] Total time: 0:01:06 (0.2123 s / it)
Averaged stats: Loss: 1.1054 (1.1766)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7152)
Train: Epoch[24/5]  [  0/313]  eta: 0:02:01  Loss: 1.2884 (1.2884)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.6667)  time: 0.3894  data: 0.1904  max mem: 2382
Train: Epoch[24/5]  [ 10/313]  eta: 0:01:05  Loss: 1.1508 (1.2166)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (24.1379)  time: 0.2158  data: 0.0175  max mem: 2382
Train: Epoch[24/5]  [ 20/313]  eta: 0:01:02  Loss: 1.1890 (1.2427)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (19.8276)  time: 0.2039  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [ 30/313]  eta: 0:00:59  Loss: 1.2370 (1.2227)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (17.6829)  time: 0.2092  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [ 40/313]  eta: 0:00:57  Loss: 1.1441 (1.2041)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (18.1818)  time: 0.2098  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [ 50/313]  eta: 0:00:55  Loss: 1.1078 (1.1983)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (18.2171)  time: 0.2102  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [ 60/313]  eta: 0:00:53  Loss: 1.0722 (1.1844)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (17.0569)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [ 70/313]  eta: 0:00:51  Loss: 1.0522 (1.1707)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.2722)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [ 80/313]  eta: 0:00:49  Loss: 1.0787 (1.1702)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.5844)  time: 0.2093  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [ 90/313]  eta: 0:00:47  Loss: 1.2710 (1.1843)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0901)  time: 0.2107  data: 0.0001  max mem: 2382
Train: Epoch[24/5]  [100/313]  eta: 0:00:44  Loss: 1.2710 (1.1912)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (16.3673)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [110/313]  eta: 0:00:42  Loss: 1.1821 (1.1874)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.1172)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [120/313]  eta: 0:00:40  Loss: 1.1821 (1.1887)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.4154)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [130/313]  eta: 0:00:38  Loss: 1.1025 (1.1811)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.1950)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [140/313]  eta: 0:00:36  Loss: 1.1254 (1.1819)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6204)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [150/313]  eta: 0:00:34  Loss: 1.1906 (1.1799)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.4159)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [160/313]  eta: 0:00:32  Loss: 1.1304 (1.1799)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (16.6023)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [170/313]  eta: 0:00:30  Loss: 1.1279 (1.1803)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.4649)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [180/313]  eta: 0:00:28  Loss: 1.1457 (1.1813)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.9635)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [190/313]  eta: 0:00:26  Loss: 1.1406 (1.1780)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.6352)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [200/313]  eta: 0:00:23  Loss: 1.1328 (1.1798)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.7407)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [210/313]  eta: 0:00:21  Loss: 1.1207 (1.1741)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.3770)  time: 0.2140  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [220/313]  eta: 0:00:19  Loss: 1.1115 (1.1725)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0190)  time: 0.2140  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [230/313]  eta: 0:00:17  Loss: 1.1721 (1.1739)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [240/313]  eta: 0:00:15  Loss: 1.1934 (1.1752)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2137  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [250/313]  eta: 0:00:13  Loss: 1.1708 (1.1751)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2140  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [260/313]  eta: 0:00:11  Loss: 1.1708 (1.1770)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2138  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [270/313]  eta: 0:00:09  Loss: 1.1769 (1.1768)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2136  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [280/313]  eta: 0:00:07  Loss: 1.1843 (1.1779)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [290/313]  eta: 0:00:04  Loss: 1.1006 (1.1739)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2142  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [300/313]  eta: 0:00:02  Loss: 1.1006 (1.1767)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2145  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [310/313]  eta: 0:00:00  Loss: 1.1106 (1.1753)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2138  data: 0.0002  max mem: 2382
Train: Epoch[24/5]  [312/313]  eta: 0:00:00  Loss: 1.1268 (1.1761)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2087  data: 0.0002  max mem: 2382
Train: Epoch[24/5] Total time: 0:01:06 (0.2127 s / it)
Averaged stats: Loss: 1.1268 (1.1761)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[25/5]  [  0/313]  eta: 0:02:08  Loss: 1.0106 (1.0106)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4098  data: 0.2128  max mem: 2382
Train: Epoch[25/5]  [ 10/313]  eta: 0:01:04  Loss: 1.2822 (1.2554)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (11.4754)  time: 0.2131  data: 0.0195  max mem: 2382
Train: Epoch[25/5]  [ 20/313]  eta: 0:01:01  Loss: 1.1726 (1.2032)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (12.1495)  time: 0.1984  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [ 30/313]  eta: 0:00:58  Loss: 1.1726 (1.2343)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.6905)  time: 0.2053  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [ 40/313]  eta: 0:00:58  Loss: 1.2792 (1.2267)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (13.6364)  time: 0.2220  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [ 50/313]  eta: 0:00:56  Loss: 1.1403 (1.2045)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.5475)  time: 0.2279  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [ 60/313]  eta: 0:00:54  Loss: 1.1838 (1.2067)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.2911)  time: 0.2170  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [ 70/313]  eta: 0:00:52  Loss: 1.1524 (1.1887)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.3258)  time: 0.2141  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [ 80/313]  eta: 0:00:50  Loss: 1.0898 (1.1865)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.1089)  time: 0.2132  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1654 (1.1844)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.3805)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [100/313]  eta: 0:00:45  Loss: 1.2270 (1.1912)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.7638)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [110/313]  eta: 0:00:43  Loss: 1.2568 (1.1986)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.4621)  time: 0.2107  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [120/313]  eta: 0:00:41  Loss: 1.2623 (1.2002)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.6774)  time: 0.2102  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [130/313]  eta: 0:00:39  Loss: 1.0960 (1.1961)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.5865)  time: 0.2104  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [140/313]  eta: 0:00:36  Loss: 1.0718 (1.1932)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.1854)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [150/313]  eta: 0:00:34  Loss: 1.0718 (1.1892)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8148)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [160/313]  eta: 0:00:32  Loss: 1.1173 (1.1876)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.3213)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [170/313]  eta: 0:00:30  Loss: 1.1207 (1.1877)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.4366)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [180/313]  eta: 0:00:28  Loss: 1.2084 (1.1939)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.1150)  time: 0.2110  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [190/313]  eta: 0:00:26  Loss: 1.1699 (1.1924)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (15.1042)  time: 0.2110  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [200/313]  eta: 0:00:24  Loss: 1.1560 (1.1919)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0943)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [210/313]  eta: 0:00:21  Loss: 1.1741 (1.1922)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (15.2174)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [220/313]  eta: 0:00:19  Loss: 1.1763 (1.1928)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (15.3915)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [230/313]  eta: 0:00:17  Loss: 1.2301 (1.1953)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.2659)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [240/313]  eta: 0:00:15  Loss: 1.2952 (1.1984)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.5356)  time: 0.2111  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [250/313]  eta: 0:00:13  Loss: 1.2508 (1.2009)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.2582)  time: 0.2112  data: 0.0001  max mem: 2382
Train: Epoch[25/5]  [260/313]  eta: 0:00:11  Loss: 1.1761 (1.1978)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.7456)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [270/313]  eta: 0:00:09  Loss: 1.1033 (1.1970)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (15.9971)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [280/313]  eta: 0:00:07  Loss: 1.1173 (1.1947)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.8528)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [290/313]  eta: 0:00:04  Loss: 1.1180 (1.1935)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (15.8904)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [300/313]  eta: 0:00:02  Loss: 1.1024 (1.1918)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.1462)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [310/313]  eta: 0:00:00  Loss: 1.1024 (1.1916)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (16.1519)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[25/5]  [312/313]  eta: 0:00:00  Loss: 1.1024 (1.1916)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.0794)  time: 0.2065  data: 0.0002  max mem: 2382
Train: Epoch[25/5] Total time: 0:01:06 (0.2123 s / it)
Averaged stats: Loss: 1.1024 (1.1916)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.0794)
Train: Epoch[26/5]  [  0/313]  eta: 0:02:01  Loss: 0.9977 (0.9977)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.3880  data: 0.1843  max mem: 2382
Train: Epoch[26/5]  [ 10/313]  eta: 0:01:05  Loss: 1.1167 (1.1457)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (21.5686)  time: 0.2153  data: 0.0169  max mem: 2382
Train: Epoch[26/5]  [ 20/313]  eta: 0:01:01  Loss: 1.1784 (1.1846)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (19.0476)  time: 0.2023  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [ 30/313]  eta: 0:00:59  Loss: 1.1917 (1.1491)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (20.8333)  time: 0.2091  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [ 40/313]  eta: 0:00:57  Loss: 1.0917 (1.1342)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [ 50/313]  eta: 0:00:55  Loss: 1.1694 (1.1493)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [ 60/313]  eta: 0:00:53  Loss: 1.1694 (1.1404)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [ 70/313]  eta: 0:00:51  Loss: 1.0927 (1.1359)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [ 80/313]  eta: 0:00:49  Loss: 1.1762 (1.1506)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1894 (1.1482)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [100/313]  eta: 0:00:45  Loss: 1.1851 (1.1602)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [110/313]  eta: 0:00:42  Loss: 1.1920 (1.1647)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [120/313]  eta: 0:00:40  Loss: 1.1714 (1.1662)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [130/313]  eta: 0:00:38  Loss: 1.1714 (1.1638)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [140/313]  eta: 0:00:36  Loss: 1.1817 (1.1633)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [150/313]  eta: 0:00:34  Loss: 1.1575 (1.1617)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [160/313]  eta: 0:00:32  Loss: 1.1614 (1.1637)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [170/313]  eta: 0:00:30  Loss: 1.1893 (1.1682)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2114  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [180/313]  eta: 0:00:28  Loss: 1.1893 (1.1671)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [190/313]  eta: 0:00:26  Loss: 1.1524 (1.1658)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [200/313]  eta: 0:00:23  Loss: 1.1491 (1.1667)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [210/313]  eta: 0:00:21  Loss: 1.1866 (1.1696)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [220/313]  eta: 0:00:19  Loss: 1.1211 (1.1668)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [230/313]  eta: 0:00:17  Loss: 1.0965 (1.1631)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [240/313]  eta: 0:00:15  Loss: 1.0792 (1.1632)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [250/313]  eta: 0:00:13  Loss: 1.1053 (1.1612)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2153  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [260/313]  eta: 0:00:11  Loss: 1.1433 (1.1640)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2155  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [270/313]  eta: 0:00:09  Loss: 1.1907 (1.1648)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2155  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [280/313]  eta: 0:00:06  Loss: 1.1552 (1.1656)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2156  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [290/313]  eta: 0:00:04  Loss: 1.0927 (1.1635)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2157  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [300/313]  eta: 0:00:02  Loss: 1.0895 (1.1628)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2158  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [310/313]  eta: 0:00:00  Loss: 1.1042 (1.1638)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2155  data: 0.0002  max mem: 2382
Train: Epoch[26/5]  [312/313]  eta: 0:00:00  Loss: 1.0895 (1.1623)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2102  data: 0.0002  max mem: 2382
Train: Epoch[26/5] Total time: 0:01:06 (0.2124 s / it)
Averaged stats: Loss: 1.0895 (1.1623)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)
Train: Epoch[27/5]  [  0/313]  eta: 0:02:12  Loss: 1.2382 (1.2382)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (16.6667)  time: 0.4239  data: 0.2237  max mem: 2382
Train: Epoch[27/5]  [ 10/313]  eta: 0:01:05  Loss: 1.2382 (1.1842)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (9.0909)  time: 0.2158  data: 0.0205  max mem: 2382
Train: Epoch[27/5]  [ 20/313]  eta: 0:01:01  Loss: 1.2076 (1.2119)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (12.7273)  time: 0.1991  data: 0.0001  max mem: 2382
Train: Epoch[27/5]  [ 30/313]  eta: 0:00:59  Loss: 1.1858 (1.1761)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2096  data: 0.0001  max mem: 2382
Train: Epoch[27/5]  [ 40/313]  eta: 0:00:58  Loss: 1.1212 (1.1559)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2163  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [ 50/313]  eta: 0:00:56  Loss: 1.1869 (1.1728)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2163  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [ 60/313]  eta: 0:00:54  Loss: 1.1955 (1.1726)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2161  data: 0.0001  max mem: 2382
Train: Epoch[27/5]  [ 70/313]  eta: 0:00:52  Loss: 1.0993 (1.1658)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2162  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [ 80/313]  eta: 0:00:49  Loss: 1.1647 (1.1719)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2160  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1622 (1.1677)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2159  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [100/313]  eta: 0:00:45  Loss: 1.1028 (1.1657)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2156  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [110/313]  eta: 0:00:43  Loss: 1.1732 (1.1683)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2142  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [120/313]  eta: 0:00:41  Loss: 1.1797 (1.1663)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2130  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [130/313]  eta: 0:00:39  Loss: 1.1797 (1.1628)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [140/313]  eta: 0:00:37  Loss: 1.1471 (1.1595)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [150/313]  eta: 0:00:34  Loss: 1.1285 (1.1579)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [160/313]  eta: 0:00:32  Loss: 1.1518 (1.1594)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [170/313]  eta: 0:00:30  Loss: 1.1533 (1.1584)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (nan)  time: 0.2142  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [180/313]  eta: 0:00:28  Loss: 1.1533 (1.1592)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2133  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [190/313]  eta: 0:00:26  Loss: 1.1115 (1.1540)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2118  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [200/313]  eta: 0:00:24  Loss: 1.1432 (1.1583)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [210/313]  eta: 0:00:22  Loss: 1.1871 (1.1597)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [220/313]  eta: 0:00:19  Loss: 1.2094 (1.1600)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [230/313]  eta: 0:00:17  Loss: 1.2094 (1.1647)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [240/313]  eta: 0:00:15  Loss: 1.2176 (1.1678)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [250/313]  eta: 0:00:13  Loss: 1.2176 (1.1696)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [260/313]  eta: 0:00:11  Loss: 1.1296 (1.1674)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [270/313]  eta: 0:00:09  Loss: 1.1086 (1.1671)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [280/313]  eta: 0:00:07  Loss: 1.1418 (1.1692)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [290/313]  eta: 0:00:04  Loss: 1.1418 (1.1670)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [300/313]  eta: 0:00:02  Loss: 1.0988 (1.1671)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [310/313]  eta: 0:00:00  Loss: 1.1660 (1.1684)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[27/5]  [312/313]  eta: 0:00:00  Loss: 1.1660 (1.1670)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2057  data: 0.0001  max mem: 2382
Train: Epoch[27/5] Total time: 0:01:06 (0.2129 s / it)
Averaged stats: Loss: 1.1660 (1.1670)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)
Train: Epoch[28/5]  [  0/313]  eta: 0:02:05  Loss: 1.0273 (1.0273)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4012  data: 0.1999  max mem: 2382
Train: Epoch[28/5]  [ 10/313]  eta: 0:01:04  Loss: 1.1300 (1.2122)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (14.0351)  time: 0.2140  data: 0.0183  max mem: 2382
Train: Epoch[28/5]  [ 20/313]  eta: 0:01:05  Loss: 1.1602 (1.2024)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.8889)  time: 0.2152  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [ 30/313]  eta: 0:01:02  Loss: 1.1663 (1.1940)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.1795)  time: 0.2269  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [ 40/313]  eta: 0:01:00  Loss: 1.1611 (1.1869)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.2157)  time: 0.2175  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [ 50/313]  eta: 0:00:57  Loss: 1.1913 (1.1898)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (14.1176)  time: 0.2146  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [ 60/313]  eta: 0:00:55  Loss: 1.1852 (1.1939)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (13.3987)  time: 0.2130  data: 0.0001  max mem: 2382
Train: Epoch[28/5]  [ 70/313]  eta: 0:00:52  Loss: 1.1546 (1.1770)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.7168)  time: 0.2129  data: 0.0001  max mem: 2382
Train: Epoch[28/5]  [ 80/313]  eta: 0:00:50  Loss: 1.1607 (1.1714)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.0435)  time: 0.2127  data: 0.0001  max mem: 2382
Train: Epoch[28/5]  [ 90/313]  eta: 0:00:48  Loss: 1.0854 (1.1599)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.3543)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [100/313]  eta: 0:00:46  Loss: 1.0387 (1.1490)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.2762)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [110/313]  eta: 0:00:43  Loss: 1.0684 (1.1519)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.0927)  time: 0.2128  data: 0.0001  max mem: 2382
Train: Epoch[28/5]  [120/313]  eta: 0:00:41  Loss: 1.1490 (1.1501)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (13.8298)  time: 0.2129  data: 0.0001  max mem: 2382
Train: Epoch[28/5]  [130/313]  eta: 0:00:39  Loss: 1.1490 (1.1523)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.6580)  time: 0.2134  data: 0.0001  max mem: 2382
Train: Epoch[28/5]  [140/313]  eta: 0:00:37  Loss: 1.1196 (1.1490)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.7866)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [150/313]  eta: 0:00:35  Loss: 1.1330 (1.1528)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.6893)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [160/313]  eta: 0:00:32  Loss: 1.1676 (1.1500)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.8000)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [170/313]  eta: 0:00:30  Loss: 1.0590 (1.1461)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.4304)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [180/313]  eta: 0:00:28  Loss: 1.1576 (1.1494)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.2518)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [190/313]  eta: 0:00:26  Loss: 1.1935 (1.1515)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.6697)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [200/313]  eta: 0:00:24  Loss: 1.1556 (1.1507)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.7122)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [210/313]  eta: 0:00:22  Loss: 1.1126 (1.1491)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.8525)  time: 0.2116  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [220/313]  eta: 0:00:19  Loss: 1.1307 (1.1500)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.6460)  time: 0.2115  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [230/313]  eta: 0:00:17  Loss: 1.1631 (1.1495)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.6704)  time: 0.2113  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [240/313]  eta: 0:00:15  Loss: 1.1631 (1.1515)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.8936)  time: 0.2114  data: 0.0001  max mem: 2382
Train: Epoch[28/5]  [250/313]  eta: 0:00:13  Loss: 1.0979 (1.1506)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (14.9190)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [260/313]  eta: 0:00:11  Loss: 1.0654 (1.1481)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.9094)  time: 0.2117  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [270/313]  eta: 0:00:09  Loss: 1.1080 (1.1513)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.2636)  time: 0.2109  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [280/313]  eta: 0:00:07  Loss: 1.1388 (1.1505)  ASR: 100.0000 (100.0000)  ACC: 25.0000 (15.5015)  time: 0.2111  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [290/313]  eta: 0:00:04  Loss: 1.0929 (1.1492)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.0846)  time: 0.2112  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [300/313]  eta: 0:00:02  Loss: 1.1481 (1.1506)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.3191)  time: 0.2108  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [310/313]  eta: 0:00:00  Loss: 1.1714 (1.1499)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.6593)  time: 0.2106  data: 0.0002  max mem: 2382
Train: Epoch[28/5]  [312/313]  eta: 0:00:00  Loss: 1.1714 (1.1509)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.5631)  time: 0.2055  data: 0.0002  max mem: 2382
Train: Epoch[28/5] Total time: 0:01:06 (0.2131 s / it)
Averaged stats: Loss: 1.1714 (1.1509)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (15.5631)
Train: Epoch[29/5]  [  0/313]  eta: 0:02:09  Loss: 1.0254 (1.0254)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (0.0000)  time: 0.4140  data: 0.2139  max mem: 2382
Train: Epoch[29/5]  [ 10/313]  eta: 0:01:05  Loss: 1.0356 (1.0299)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (8.3333)  time: 0.2154  data: 0.0196  max mem: 2382
Train: Epoch[29/5]  [ 20/313]  eta: 0:01:02  Loss: 1.1336 (1.1499)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (15.9574)  time: 0.2034  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [ 30/313]  eta: 0:01:00  Loss: 1.1878 (1.1512)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.2857)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [ 40/313]  eta: 0:00:58  Loss: 1.1019 (1.1335)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.3646)  time: 0.2135  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [ 50/313]  eta: 0:00:56  Loss: 1.0932 (1.1438)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.1212)  time: 0.2132  data: 0.0001  max mem: 2382
Train: Epoch[29/5]  [ 60/313]  eta: 0:00:53  Loss: 1.0932 (1.1276)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.2322)  time: 0.2130  data: 0.0001  max mem: 2382
Train: Epoch[29/5]  [ 70/313]  eta: 0:00:51  Loss: 1.1557 (1.1413)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (13.9319)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [ 80/313]  eta: 0:00:49  Loss: 1.1780 (1.1446)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (12.9032)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [ 90/313]  eta: 0:00:47  Loss: 1.1649 (1.1445)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.3971)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [100/313]  eta: 0:00:45  Loss: 1.1649 (1.1490)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (13.5193)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [110/313]  eta: 0:00:43  Loss: 1.1591 (1.1445)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (13.9489)  time: 0.2133  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [120/313]  eta: 0:00:41  Loss: 0.9561 (1.1358)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.7363)  time: 0.2134  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [130/313]  eta: 0:00:39  Loss: 1.1007 (1.1378)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.8047)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [140/313]  eta: 0:00:36  Loss: 1.1007 (1.1312)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.8095)  time: 0.2125  data: 0.0001  max mem: 2382
Train: Epoch[29/5]  [150/313]  eta: 0:00:34  Loss: 1.1624 (1.1389)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (13.8484)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [160/313]  eta: 0:00:32  Loss: 1.1826 (1.1378)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (13.8546)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [170/313]  eta: 0:00:30  Loss: 1.1061 (1.1401)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.2674)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [180/313]  eta: 0:00:28  Loss: 1.1417 (1.1397)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.5631)  time: 0.2123  data: 0.0001  max mem: 2382
Train: Epoch[29/5]  [190/313]  eta: 0:00:26  Loss: 1.1566 (1.1411)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.6621)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [200/313]  eta: 0:00:24  Loss: 1.1662 (1.1450)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (14.3629)  time: 0.2127  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [210/313]  eta: 0:00:21  Loss: 1.1221 (1.1425)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.3595)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [220/313]  eta: 0:00:19  Loss: 1.1221 (1.1447)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.7348)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [230/313]  eta: 0:00:17  Loss: 1.1086 (1.1451)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.7418)  time: 0.2122  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [240/313]  eta: 0:00:15  Loss: 1.0730 (1.1419)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.7645)  time: 0.2124  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [250/313]  eta: 0:00:13  Loss: 1.0936 (1.1418)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.4473)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [260/313]  eta: 0:00:11  Loss: 1.1162 (1.1454)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (14.7841)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [270/313]  eta: 0:00:09  Loss: 1.1162 (1.1445)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (14.8356)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [280/313]  eta: 0:00:07  Loss: 1.0981 (1.1434)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.0271)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [290/313]  eta: 0:00:04  Loss: 1.0981 (1.1437)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.1606)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [300/313]  eta: 0:00:02  Loss: 1.1528 (1.1437)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (15.1406)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [310/313]  eta: 0:00:00  Loss: 1.1755 (1.1450)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.9617)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[29/5]  [312/313]  eta: 0:00:00  Loss: 1.1477 (1.1448)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.9688)  time: 0.2073  data: 0.0001  max mem: 2382
Train: Epoch[29/5] Total time: 0:01:06 (0.2128 s / it)
Averaged stats: Loss: 1.1477 (1.1448)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (14.9688)
Train: Epoch[30/5]  [  0/313]  eta: 0:02:08  Loss: 1.2627 (1.2627)  ASR: 100.0000 (100.0000)  ACC: 33.3333 (33.3333)  time: 0.4119  data: 0.2113  max mem: 2382
Train: Epoch[30/5]  [ 10/313]  eta: 0:01:05  Loss: 1.1147 (1.1687)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (16.9811)  time: 0.2147  data: 0.0194  max mem: 2382
Train: Epoch[30/5]  [ 20/313]  eta: 0:01:01  Loss: 1.0822 (1.1736)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (16.6667)  time: 0.2012  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [ 30/313]  eta: 0:00:59  Loss: 1.1008 (1.1656)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (15.5405)  time: 0.2079  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [ 40/313]  eta: 0:00:57  Loss: 1.1898 (1.1718)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2083  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [ 50/313]  eta: 0:00:55  Loss: 1.1898 (1.1807)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2085  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [ 60/313]  eta: 0:00:53  Loss: 1.0651 (1.1592)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2089  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [ 70/313]  eta: 0:00:51  Loss: 1.0139 (1.1586)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2144  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [ 80/313]  eta: 0:00:49  Loss: 1.0937 (1.1480)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2220  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [ 90/313]  eta: 0:00:47  Loss: 1.0795 (1.1443)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2234  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [100/313]  eta: 0:00:45  Loss: 1.0965 (1.1433)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2211  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [110/313]  eta: 0:00:43  Loss: 1.1589 (1.1458)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2184  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [120/313]  eta: 0:00:41  Loss: 1.1570 (1.1481)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2173  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [130/313]  eta: 0:00:39  Loss: 1.0920 (1.1425)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2159  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [140/313]  eta: 0:00:37  Loss: 1.1054 (1.1433)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2131  data: 0.0001  max mem: 2382
Train: Epoch[30/5]  [150/313]  eta: 0:00:34  Loss: 1.1591 (1.1452)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2117  data: 0.0001  max mem: 2382
Train: Epoch[30/5]  [160/313]  eta: 0:00:32  Loss: 1.1583 (1.1432)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [170/313]  eta: 0:00:30  Loss: 1.0716 (1.1414)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [180/313]  eta: 0:00:28  Loss: 1.0763 (1.1423)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [190/313]  eta: 0:00:26  Loss: 1.0802 (1.1432)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2119  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [200/313]  eta: 0:00:24  Loss: 1.1715 (1.1451)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2116  data: 0.0001  max mem: 2382
Train: Epoch[30/5]  [210/313]  eta: 0:00:22  Loss: 1.1715 (1.1471)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2116  data: 0.0001  max mem: 2382
Train: Epoch[30/5]  [220/313]  eta: 0:00:19  Loss: 1.0248 (1.1418)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [230/313]  eta: 0:00:17  Loss: 1.0581 (1.1437)  ASR: 100.0000 (100.0000)  ACC: 14.2857 (nan)  time: 0.2126  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [240/313]  eta: 0:00:15  Loss: 1.1772 (1.1435)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2123  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [250/313]  eta: 0:00:13  Loss: 1.1472 (1.1442)  ASR: 100.0000 (100.0000)  ACC: 20.0000 (nan)  time: 0.2121  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [260/313]  eta: 0:00:11  Loss: 1.1191 (1.1450)  ASR: 100.0000 (100.0000)  ACC: 12.5000 (nan)  time: 0.2120  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [270/313]  eta: 0:00:09  Loss: 1.1007 (1.1444)  ASR: 100.0000 (100.0000)  ACC: 11.1111 (nan)  time: 0.2125  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [280/313]  eta: 0:00:07  Loss: 1.0938 (1.1434)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [290/313]  eta: 0:00:04  Loss: 1.0828 (1.1417)  ASR: 100.0000 (100.0000)  ACC: 0.0000 (nan)  time: 0.2128  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [300/313]  eta: 0:00:02  Loss: 1.0783 (1.1392)  ASR: 100.0000 (100.0000)  ACC: 16.6667 (nan)  time: 0.2129  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [310/313]  eta: 0:00:00  Loss: 1.0553 (1.1401)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (nan)  time: 0.2131  data: 0.0002  max mem: 2382
Train: Epoch[30/5]  [312/313]  eta: 0:00:00  Loss: 1.0729 (1.1423)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (nan)  time: 0.2078  data: 0.0002  max mem: 2382
Train: Epoch[30/5] Total time: 0:01:06 (0.2132 s / it)
Averaged stats: Loss: 1.0729 (1.1423)  ASR: 100.0000 (100.0000)  ACC: 10.0000 (nan)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:56  Lr: 0.001875  Loss: 2.3260  Acc@1: 18.7500 (18.7500)  Acc@5: 37.5000 (37.5000)  time: 0.5633  data: 0.2127  max mem: 2382
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:07  Lr: 0.001875  Loss: 2.1946  Acc@1: 31.2500 (34.0909)  Acc@5: 75.0000 (69.3182)  time: 0.2237  data: 0.0195  max mem: 2382
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:02  Lr: 0.001875  Loss: 1.6247  Acc@1: 56.2500 (47.9167)  Acc@5: 81.2500 (78.2738)  time: 0.1945  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:59  Lr: 0.001875  Loss: 1.7396  Acc@1: 62.5000 (53.4274)  Acc@5: 93.7500 (83.2661)  time: 0.2026  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.4243  Acc@1: 62.5000 (58.3841)  Acc@5: 100.0000 (86.5854)  time: 0.2061  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.0720  Acc@1: 68.7500 (60.9069)  Acc@5: 93.7500 (88.2353)  time: 0.2061  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:52  Lr: 0.001875  Loss: 1.1529  Acc@1: 75.0000 (63.0123)  Acc@5: 93.7500 (89.2418)  time: 0.2062  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.8767  Acc@1: 75.0000 (65.3169)  Acc@5: 100.0000 (90.3169)  time: 0.2064  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.1141  Acc@1: 75.0000 (66.8210)  Acc@5: 93.7500 (90.8951)  time: 0.2085  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.8744  Acc@1: 75.0000 (68.2692)  Acc@5: 93.7500 (91.4148)  time: 0.2107  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [100/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.8289  Acc@1: 81.2500 (69.5545)  Acc@5: 100.0000 (92.0792)  time: 0.2106  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [110/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.8376  Acc@1: 81.2500 (70.2140)  Acc@5: 100.0000 (92.5676)  time: 0.2105  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [120/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.6798  Acc@1: 81.2500 (71.0227)  Acc@5: 100.0000 (92.8202)  time: 0.2103  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [130/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.7578  Acc@1: 81.2500 (71.9943)  Acc@5: 93.7500 (93.1298)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [140/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.6531  Acc@1: 81.2500 (72.7837)  Acc@5: 100.0000 (93.5727)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [150/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.6794  Acc@1: 81.2500 (72.9719)  Acc@5: 100.0000 (93.6258)  time: 0.2104  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [160/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.8733  Acc@1: 81.2500 (73.4860)  Acc@5: 93.7500 (93.7888)  time: 0.2103  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [170/313]  eta: 0:00:29  Lr: 0.001875  Loss: 0.7241  Acc@1: 81.2500 (74.1594)  Acc@5: 100.0000 (94.0424)  time: 0.2103  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [180/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.5346  Acc@1: 87.5000 (74.5856)  Acc@5: 100.0000 (94.2680)  time: 0.2103  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [190/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.3257  Acc@1: 87.5000 (75.2291)  Acc@5: 100.0000 (94.4372)  time: 0.2103  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [200/313]  eta: 0:00:23  Lr: 0.001875  Loss: 1.0195  Acc@1: 87.5000 (75.5908)  Acc@5: 93.7500 (94.4652)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [210/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.0895  Acc@1: 81.2500 (75.7405)  Acc@5: 93.7500 (94.5498)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [220/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3914  Acc@1: 81.2500 (76.1312)  Acc@5: 100.0000 (94.7115)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [230/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.7495  Acc@1: 81.2500 (76.3258)  Acc@5: 100.0000 (94.8593)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [240/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3806  Acc@1: 81.2500 (76.6598)  Acc@5: 100.0000 (95.0467)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [250/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3858  Acc@1: 81.2500 (76.8177)  Acc@5: 100.0000 (95.0697)  time: 0.2102  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [260/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3755  Acc@1: 81.2500 (77.0354)  Acc@5: 100.0000 (95.2586)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [270/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1809  Acc@1: 87.5000 (77.2832)  Acc@5: 100.0000 (95.3644)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.3053  Acc@1: 87.5000 (77.6468)  Acc@5: 100.0000 (95.5294)  time: 0.2102  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4863  Acc@1: 87.5000 (77.9424)  Acc@5: 100.0000 (95.5756)  time: 0.2103  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.4127  Acc@1: 81.2500 (78.0731)  Acc@5: 100.0000 (95.6811)  time: 0.2104  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4565  Acc@1: 81.2500 (78.2958)  Acc@5: 100.0000 (95.7797)  time: 0.2104  data: 0.0001  max mem: 2382
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.8621  Acc@1: 81.2500 (78.3000)  Acc@5: 100.0000 (95.8000)  time: 0.2053  data: 0.0001  max mem: 2382
Train: Epoch[1/5] Total time: 0:01:05 (0.2098 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.8621  Acc@1: 81.2500 (78.3000)  Acc@5: 100.0000 (95.8000)
Train: Epoch[1/5]  [  0/313]  eta: 0:03:03  Loss: 0.0585 (0.0585)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (100.0000)  time: 0.5861  data: 0.2108  max mem: 2382
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:09  Loss: 0.0587 (0.0588)  ASR: 100.0000 (99.3007)  ACC: 85.7143 (81.0345)  time: 0.2296  data: 0.0194  max mem: 2382
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:03  Loss: 0.0585 (0.0586)  ASR: 100.0000 (98.5871)  ACC: 80.0000 (81.2500)  time: 0.1989  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:01  Loss: 0.0579 (0.0584)  ASR: 100.0000 (98.7203)  ACC: 83.3333 (80.8383)  time: 0.2099  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:59  Loss: 0.0576 (0.0582)  ASR: 100.0000 (99.0324)  ACC: 83.3333 (81.8605)  time: 0.2159  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:56  Loss: 0.0561 (0.0577)  ASR: 100.0000 (99.2222)  ACC: 85.7143 (82.4176)  time: 0.2157  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:54  Loss: 0.0555 (0.0574)  ASR: 100.0000 (99.3497)  ACC: 85.7143 (82.5949)  time: 0.2151  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:52  Loss: 0.0544 (0.0569)  ASR: 100.0000 (99.4413)  ACC: 85.7143 (82.7298)  time: 0.2139  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:50  Loss: 0.0536 (0.0565)  ASR: 100.0000 (99.5102)  ACC: 100.0000 (83.4158)  time: 0.2131  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:47  Loss: 0.0533 (0.0562)  ASR: 100.0000 (99.5641)  ACC: 100.0000 (83.0735)  time: 0.2116  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [100/313]  eta: 0:00:45  Loss: 0.0533 (0.0559)  ASR: 100.0000 (99.6072)  ACC: 83.3333 (83.4008)  time: 0.2102  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [110/313]  eta: 0:00:43  Loss: 0.0533 (0.0557)  ASR: 100.0000 (99.5733)  ACC: 100.0000 (83.7591)  time: 0.2105  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [120/313]  eta: 0:00:41  Loss: 0.0528 (0.0554)  ASR: 100.0000 (99.5167)  ACC: 85.7143 (83.3052)  time: 0.2103  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [130/313]  eta: 0:00:39  Loss: 0.0525 (0.0552)  ASR: 100.0000 (99.5536)  ACC: 77.7778 (82.8927)  time: 0.2104  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [140/313]  eta: 0:00:36  Loss: 0.0524 (0.0549)  ASR: 100.0000 (99.4671)  ACC: 80.0000 (83.2138)  time: 0.2107  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [150/313]  eta: 0:00:34  Loss: 0.0510 (0.0547)  ASR: 100.0000 (99.5024)  ACC: 85.7143 (83.2432)  time: 0.2106  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [160/313]  eta: 0:00:32  Loss: 0.0507 (0.0544)  ASR: 100.0000 (99.5333)  ACC: 83.3333 (83.2908)  time: 0.2110  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [170/313]  eta: 0:00:30  Loss: 0.0507 (0.0542)  ASR: 100.0000 (99.4956)  ACC: 80.0000 (83.2342)  time: 0.2112  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [180/313]  eta: 0:00:28  Loss: 0.0501 (0.0540)  ASR: 100.0000 (99.5235)  ACC: 85.7143 (83.3895)  time: 0.2114  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [190/313]  eta: 0:00:26  Loss: 0.0494 (0.0537)  ASR: 100.0000 (99.5048)  ACC: 100.0000 (83.2794)  time: 0.2115  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [200/313]  eta: 0:00:24  Loss: 0.0493 (0.0535)  ASR: 100.0000 (99.5294)  ACC: 85.7143 (83.3333)  time: 0.2113  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [210/313]  eta: 0:00:21  Loss: 0.0496 (0.0534)  ASR: 100.0000 (99.5122)  ACC: 85.7143 (83.4137)  time: 0.2114  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [220/313]  eta: 0:00:19  Loss: 0.0492 (0.0532)  ASR: 100.0000 (99.4966)  ACC: 100.0000 (83.7937)  time: 0.2117  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [230/313]  eta: 0:00:17  Loss: 0.0479 (0.0529)  ASR: 100.0000 (99.4851)  ACC: 100.0000 (84.0567)  time: 0.2115  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [240/313]  eta: 0:00:15  Loss: 0.0476 (0.0527)  ASR: 100.0000 (99.4745)  ACC: 100.0000 (84.0444)  time: 0.2112  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [250/313]  eta: 0:00:13  Loss: 0.0481 (0.0526)  ASR: 100.0000 (99.4955)  ACC: 85.7143 (83.9901)  time: 0.2111  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [260/313]  eta: 0:00:11  Loss: 0.0488 (0.0524)  ASR: 100.0000 (99.5148)  ACC: 83.3333 (83.9144)  time: 0.2113  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [270/313]  eta: 0:00:09  Loss: 0.0477 (0.0522)  ASR: 100.0000 (99.5327)  ACC: 85.7143 (84.1945)  time: 0.2112  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [280/313]  eta: 0:00:07  Loss: 0.0477 (0.0521)  ASR: 100.0000 (99.5493)  ACC: 85.7143 (83.9416)  time: 0.2107  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 0.0471 (0.0519)  ASR: 100.0000 (99.5648)  ACC: 80.0000 (83.8755)  time: 0.2106  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 0.0467 (0.0518)  ASR: 100.0000 (99.5793)  ACC: 83.3333 (83.6846)  time: 0.2112  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 0.0478 (0.0517)  ASR: 100.0000 (99.5928)  ACC: 75.0000 (83.3333)  time: 0.2112  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 0.0478 (0.0517)  ASR: 100.0000 (99.5948)  ACC: 75.0000 (83.2677)  time: 0.2063  data: 0.0002  max mem: 2383
Train: Epoch[1/5] Total time: 0:01:06 (0.2121 s / it)
Averaged stats: Loss: 0.0478 (0.0517)  ASR: 100.0000 (99.5948)  ACC: 75.0000 (83.2677)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:11  Lr: 0.001875  Loss: 0.6433  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.4195  data: 0.2287  max mem: 2383
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.4226  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.7273)  time: 0.2122  data: 0.0209  max mem: 2383
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.4207  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (98.2143)  time: 0.1998  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.6513  Acc@1: 87.5000 (83.4677)  Acc@5: 100.0000 (97.7823)  time: 0.2086  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.4384  Acc@1: 81.2500 (83.2317)  Acc@5: 100.0000 (97.8659)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.3726  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (97.6716)  time: 0.2091  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1710  Acc@1: 87.5000 (83.4016)  Acc@5: 100.0000 (97.8484)  time: 0.2089  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.4605  Acc@1: 87.5000 (84.5070)  Acc@5: 100.0000 (97.8873)  time: 0.2090  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.6945  Acc@1: 87.5000 (84.0278)  Acc@5: 100.0000 (97.9167)  time: 0.2091  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1421  Acc@1: 81.2500 (84.3407)  Acc@5: 100.0000 (98.0082)  time: 0.2089  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [100/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4501  Acc@1: 87.5000 (84.5297)  Acc@5: 100.0000 (97.9579)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [110/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1233  Acc@1: 87.5000 (85.1914)  Acc@5: 100.0000 (98.0856)  time: 0.2086  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [120/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.4506  Acc@1: 87.5000 (84.8657)  Acc@5: 100.0000 (98.0372)  time: 0.2087  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [130/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.7276  Acc@1: 75.0000 (84.3511)  Acc@5: 100.0000 (97.9962)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [140/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.3081  Acc@1: 75.0000 (84.1312)  Acc@5: 100.0000 (97.8280)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [150/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4145  Acc@1: 87.5000 (84.4371)  Acc@5: 100.0000 (97.8063)  time: 0.2087  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [160/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.2912  Acc@1: 87.5000 (84.5885)  Acc@5: 100.0000 (97.8649)  time: 0.2086  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [170/313]  eta: 0:00:29  Lr: 0.001875  Loss: 0.0619  Acc@1: 87.5000 (84.8684)  Acc@5: 100.0000 (97.9167)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [180/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3899  Acc@1: 87.5000 (84.8066)  Acc@5: 100.0000 (97.8246)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [190/313]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0531  Acc@1: 81.2500 (84.4895)  Acc@5: 100.0000 (97.7749)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [200/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3366  Acc@1: 81.2500 (84.6704)  Acc@5: 100.0000 (97.7612)  time: 0.2089  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [210/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1692  Acc@1: 87.5000 (84.6268)  Acc@5: 100.0000 (97.7784)  time: 0.2090  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [220/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0397  Acc@1: 81.2500 (84.6437)  Acc@5: 100.0000 (97.7941)  time: 0.2091  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [230/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1231  Acc@1: 87.5000 (84.7132)  Acc@5: 100.0000 (97.8896)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [240/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.4699  Acc@1: 87.5000 (84.7770)  Acc@5: 100.0000 (97.9512)  time: 0.2094  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [250/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1223  Acc@1: 87.5000 (84.9602)  Acc@5: 100.0000 (97.9582)  time: 0.2094  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [260/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1835  Acc@1: 87.5000 (85.0335)  Acc@5: 100.0000 (97.9406)  time: 0.2090  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0989  Acc@1: 87.5000 (85.1476)  Acc@5: 100.0000 (97.9705)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2941  Acc@1: 87.5000 (85.0534)  Acc@5: 100.0000 (98.0205)  time: 0.2090  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4231  Acc@1: 81.2500 (85.0945)  Acc@5: 100.0000 (97.9811)  time: 0.2091  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3449  Acc@1: 87.5000 (85.1952)  Acc@5: 100.0000 (97.9859)  time: 0.2093  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1723  Acc@1: 87.5000 (85.1688)  Acc@5: 100.0000 (97.9703)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7733  Acc@1: 87.5000 (85.1600)  Acc@5: 100.0000 (97.9800)  time: 0.2042  data: 0.0002  max mem: 2383
Train: Epoch[2/5] Total time: 0:01:05 (0.2090 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7733  Acc@1: 87.5000 (85.1600)  Acc@5: 100.0000 (97.9800)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:06  Loss: 0.0488 (0.0488)  ASR: 90.0000 (90.0000)  ACC: 83.3333 (83.3333)  time: 0.4050  data: 0.2042  max mem: 2383
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:04  Loss: 0.0462 (0.0474)  ASR: 100.0000 (99.0909)  ACC: 80.0000 (77.5862)  time: 0.2137  data: 0.0187  max mem: 2383
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:03  Loss: 0.0457 (0.0462)  ASR: 100.0000 (99.1270)  ACC: 80.0000 (80.6122)  time: 0.2084  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:02  Loss: 0.0450 (0.0463)  ASR: 100.0000 (99.0860)  ACC: 80.0000 (78.9474)  time: 0.2229  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:59  Loss: 0.0445 (0.0459)  ASR: 100.0000 (99.3089)  ACC: 83.3333 (79.3651)  time: 0.2208  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:57  Loss: 0.0444 (0.0457)  ASR: 100.0000 (99.4444)  ACC: 83.3333 (81.1715)  time: 0.2162  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:55  Loss: 0.0447 (0.0455)  ASR: 100.0000 (99.5355)  ACC: 75.0000 (80.3509)  time: 0.2147  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:52  Loss: 0.0438 (0.0453)  ASR: 100.0000 (99.4836)  ACC: 83.3333 (81.7073)  time: 0.2152  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:50  Loss: 0.0435 (0.0451)  ASR: 100.0000 (99.5473)  ACC: 100.0000 (83.1169)  time: 0.2139  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:48  Loss: 0.0436 (0.0450)  ASR: 100.0000 (99.5971)  ACC: 100.0000 (83.6782)  time: 0.2124  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [100/313]  eta: 0:00:45  Loss: 0.0428 (0.0449)  ASR: 100.0000 (99.5380)  ACC: 100.0000 (84.2975)  time: 0.2122  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [110/313]  eta: 0:00:43  Loss: 0.0439 (0.0448)  ASR: 100.0000 (99.3894)  ACC: 100.0000 (84.7706)  time: 0.2119  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [120/313]  eta: 0:00:41  Loss: 0.0449 (0.0448)  ASR: 100.0000 (99.4399)  ACC: 83.3333 (84.5638)  time: 0.2119  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [130/313]  eta: 0:00:39  Loss: 0.0436 (0.0447)  ASR: 100.0000 (99.4826)  ACC: 83.3333 (85.1455)  time: 0.2118  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [140/313]  eta: 0:00:37  Loss: 0.0431 (0.0446)  ASR: 100.0000 (99.4129)  ACC: 83.3333 (85.0214)  time: 0.2117  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [150/313]  eta: 0:00:34  Loss: 0.0428 (0.0445)  ASR: 100.0000 (99.4518)  ACC: nan (nan)  time: 0.2122  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [160/313]  eta: 0:00:32  Loss: 0.0418 (0.0444)  ASR: 100.0000 (99.4859)  ACC: nan (nan)  time: 0.2121  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [170/313]  eta: 0:00:30  Loss: 0.0420 (0.0443)  ASR: 100.0000 (99.5159)  ACC: nan (nan)  time: 0.2119  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [180/313]  eta: 0:00:28  Loss: 0.0424 (0.0442)  ASR: 100.0000 (99.5427)  ACC: nan (nan)  time: 0.2118  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [190/313]  eta: 0:00:26  Loss: 0.0428 (0.0441)  ASR: 100.0000 (99.5292)  ACC: 80.0000 (nan)  time: 0.2119  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [200/313]  eta: 0:00:24  Loss: 0.0430 (0.0440)  ASR: 100.0000 (99.5526)  ACC: 80.0000 (nan)  time: 0.2120  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [210/313]  eta: 0:00:22  Loss: 0.0418 (0.0440)  ASR: 100.0000 (99.5738)  ACC: 80.0000 (nan)  time: 0.2120  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [220/313]  eta: 0:00:19  Loss: 0.0435 (0.0440)  ASR: 100.0000 (99.5520)  ACC: 71.4286 (nan)  time: 0.2125  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [230/313]  eta: 0:00:17  Loss: 0.0437 (0.0440)  ASR: 100.0000 (99.5353)  ACC: 75.0000 (nan)  time: 0.2123  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [240/313]  eta: 0:00:15  Loss: 0.0420 (0.0439)  ASR: 100.0000 (99.5546)  ACC: 80.0000 (nan)  time: 0.2118  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [250/313]  eta: 0:00:13  Loss: 0.0406 (0.0438)  ASR: 100.0000 (99.5723)  ACC: 100.0000 (nan)  time: 0.2113  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [260/313]  eta: 0:00:11  Loss: 0.0402 (0.0437)  ASR: 100.0000 (99.5887)  ACC: 100.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [270/313]  eta: 0:00:09  Loss: 0.0410 (0.0436)  ASR: 100.0000 (99.5731)  ACC: 87.5000 (nan)  time: 0.2109  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [280/313]  eta: 0:00:07  Loss: 0.0412 (0.0435)  ASR: 100.0000 (99.5883)  ACC: 83.3333 (nan)  time: 0.2113  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 0.0423 (0.0435)  ASR: 100.0000 (99.6025)  ACC: 85.7143 (nan)  time: 0.2113  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 0.0402 (0.0434)  ASR: 100.0000 (99.6157)  ACC: 100.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 0.0402 (0.0433)  ASR: 100.0000 (99.5667)  ACC: 100.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 0.0401 (0.0433)  ASR: 100.0000 (99.5687)  ACC: 100.0000 (nan)  time: 0.2057  data: 0.0002  max mem: 2383
Train: Epoch[2/5] Total time: 0:01:06 (0.2130 s / it)
Averaged stats: Loss: 0.0401 (0.0433)  ASR: 100.0000 (99.5687)  ACC: 100.0000 (nan)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:13  Lr: 0.001875  Loss: 0.3871  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.4269  data: 0.2345  max mem: 2383
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.1379  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.2121  data: 0.0215  max mem: 2383
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0246  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.8095)  time: 0.1952  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.2340  Acc@1: 81.2500 (84.8790)  Acc@5: 100.0000 (99.1935)  time: 0.2004  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.1332  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (99.3902)  time: 0.2041  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2209  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (99.2647)  time: 0.2072  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3807  Acc@1: 87.5000 (85.2459)  Acc@5: 100.0000 (99.2828)  time: 0.2072  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.1505  Acc@1: 81.2500 (85.7394)  Acc@5: 100.0000 (99.2077)  time: 0.2065  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0475  Acc@1: 87.5000 (86.2654)  Acc@5: 100.0000 (99.1512)  time: 0.2062  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3877  Acc@1: 87.5000 (85.9203)  Acc@5: 100.0000 (99.0385)  time: 0.2062  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [100/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3678  Acc@1: 87.5000 (86.3861)  Acc@5: 100.0000 (99.0099)  time: 0.2061  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [110/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.0523  Acc@1: 87.5000 (86.2613)  Acc@5: 100.0000 (98.8176)  time: 0.2058  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [120/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.2199  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.6570)  time: 0.2071  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [130/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3218  Acc@1: 87.5000 (86.2595)  Acc@5: 100.0000 (98.4256)  time: 0.2177  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [140/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1017  Acc@1: 87.5000 (86.4805)  Acc@5: 100.0000 (98.5372)  time: 0.2224  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [150/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1662  Acc@1: 87.5000 (86.4238)  Acc@5: 100.0000 (98.5099)  time: 0.2175  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [160/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.2007  Acc@1: 87.5000 (86.4907)  Acc@5: 100.0000 (98.4472)  time: 0.2164  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [170/313]  eta: 0:00:29  Lr: 0.001875  Loss: -0.0130  Acc@1: 87.5000 (86.6228)  Acc@5: 100.0000 (98.4649)  time: 0.2150  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [180/313]  eta: 0:00:27  Lr: 0.001875  Loss: -0.0456  Acc@1: 87.5000 (86.6367)  Acc@5: 100.0000 (98.5152)  time: 0.2135  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [190/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.1837  Acc@1: 87.5000 (86.6165)  Acc@5: 100.0000 (98.4620)  time: 0.2121  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [200/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3975  Acc@1: 87.5000 (86.5361)  Acc@5: 100.0000 (98.4453)  time: 0.2099  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [210/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1624  Acc@1: 87.5000 (86.6114)  Acc@5: 100.0000 (98.5190)  time: 0.2076  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [220/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.5096  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.4163)  time: 0.2063  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [230/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2167  Acc@1: 87.5000 (86.6883)  Acc@5: 100.0000 (98.4307)  time: 0.2063  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [240/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0694  Acc@1: 87.5000 (86.6183)  Acc@5: 100.0000 (98.4440)  time: 0.2066  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [250/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.2376  Acc@1: 87.5000 (86.5787)  Acc@5: 100.0000 (98.4562)  time: 0.2065  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [260/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1809  Acc@1: 87.5000 (86.5661)  Acc@5: 100.0000 (98.4195)  time: 0.2066  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0263  Acc@1: 87.5000 (86.6006)  Acc@5: 100.0000 (98.3625)  time: 0.2069  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1252  Acc@1: 87.5000 (86.5881)  Acc@5: 100.0000 (98.3541)  time: 0.2070  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0815  Acc@1: 87.5000 (86.6624)  Acc@5: 100.0000 (98.3677)  time: 0.2069  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1888  Acc@1: 87.5000 (86.6902)  Acc@5: 100.0000 (98.3596)  time: 0.2066  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0887  Acc@1: 87.5000 (86.8770)  Acc@5: 100.0000 (98.4124)  time: 0.2066  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6600  Acc@1: 87.5000 (86.8600)  Acc@5: 100.0000 (98.4200)  time: 0.2018  data: 0.0001  max mem: 2383
Train: Epoch[3/5] Total time: 0:01:05 (0.2087 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6600  Acc@1: 87.5000 (86.8600)  Acc@5: 100.0000 (98.4200)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:08  Loss: 0.0366 (0.0366)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (100.0000)  time: 0.4110  data: 0.2114  max mem: 2383
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:06  Loss: 0.0397 (0.0397)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (94.8718)  time: 0.2202  data: 0.0194  max mem: 2383
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:03  Loss: 0.0402 (0.0404)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (87.9121)  time: 0.2054  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:00  Loss: 0.0404 (0.0405)  ASR: 100.0000 (99.4086)  ACC: 85.7143 (86.6197)  time: 0.2098  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:58  Loss: 0.0402 (0.0406)  ASR: 100.0000 (99.1754)  ACC: 87.5000 (87.7660)  time: 0.2096  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:55  Loss: 0.0407 (0.0407)  ASR: 100.0000 (99.1410)  ACC: 80.0000 (85.7143)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:53  Loss: 0.0407 (0.0407)  ASR: 100.0000 (99.2818)  ACC: 80.0000 (85.4671)  time: 0.2090  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:51  Loss: 0.0393 (0.0405)  ASR: 100.0000 (99.3830)  ACC: 100.0000 (85.5856)  time: 0.2089  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:49  Loss: 0.0393 (0.0403)  ASR: 100.0000 (99.4591)  ACC: 100.0000 (86.8217)  time: 0.2089  data: 0.0001  max mem: 2383
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:46  Loss: 0.0387 (0.0401)  ASR: 100.0000 (99.5186)  ACC: 100.0000 (87.2390)  time: 0.2090  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [100/313]  eta: 0:00:44  Loss: 0.0388 (0.0401)  ASR: 100.0000 (99.5662)  ACC: 85.7143 (86.4583)  time: 0.2091  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [110/313]  eta: 0:00:42  Loss: 0.0390 (0.0400)  ASR: 100.0000 (99.5302)  ACC: 87.5000 (86.7173)  time: 0.2116  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [120/313]  eta: 0:00:40  Loss: 0.0392 (0.0400)  ASR: 100.0000 (99.5691)  ACC: 100.0000 (87.1528)  time: 0.2172  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [130/313]  eta: 0:00:38  Loss: 0.0394 (0.0399)  ASR: 100.0000 (99.5326)  ACC: 100.0000 (87.3802)  time: 0.2192  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [140/313]  eta: 0:00:36  Loss: 0.0397 (0.0400)  ASR: 100.0000 (99.5657)  ACC: 85.7143 (87.3343)  time: 0.2183  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [150/313]  eta: 0:00:34  Loss: 0.0405 (0.0399)  ASR: 100.0000 (99.5393)  ACC: 85.7143 (87.6033)  time: 0.2181  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [160/313]  eta: 0:00:32  Loss: 0.0398 (0.0399)  ASR: 100.0000 (99.5679)  ACC: 100.0000 (87.9177)  time: 0.2178  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [170/313]  eta: 0:00:30  Loss: 0.0391 (0.0398)  ASR: 100.0000 (99.5932)  ACC: 100.0000 (87.8346)  time: 0.2178  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [180/313]  eta: 0:00:28  Loss: 0.0386 (0.0397)  ASR: 100.0000 (99.5762)  ACC: 100.0000 (88.1336)  time: 0.2169  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [190/313]  eta: 0:00:26  Loss: 0.0378 (0.0396)  ASR: 100.0000 (99.5984)  ACC: 100.0000 (87.9913)  time: 0.2145  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [200/313]  eta: 0:00:24  Loss: 0.0378 (0.0395)  ASR: 100.0000 (99.5852)  ACC: 85.7143 (87.7895)  time: 0.2133  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [210/313]  eta: 0:00:21  Loss: 0.0380 (0.0395)  ASR: 100.0000 (99.5684)  ACC: 100.0000 (88.0642)  time: 0.2133  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [220/313]  eta: 0:00:19  Loss: 0.0381 (0.0394)  ASR: 100.0000 (99.5531)  ACC: 100.0000 (87.9808)  time: 0.2129  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [230/313]  eta: 0:00:17  Loss: 0.0371 (0.0393)  ASR: 100.0000 (99.5364)  ACC: 100.0000 (87.9852)  time: 0.2131  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [240/313]  eta: 0:00:15  Loss: 0.0367 (0.0392)  ASR: 100.0000 (99.5556)  ACC: 100.0000 (88.2197)  time: 0.2133  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [250/313]  eta: 0:00:13  Loss: 0.0368 (0.0391)  ASR: 100.0000 (99.5733)  ACC: nan (nan)  time: 0.2134  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [260/313]  eta: 0:00:11  Loss: 0.0376 (0.0391)  ASR: 100.0000 (99.5897)  ACC: nan (nan)  time: 0.2135  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [270/313]  eta: 0:00:09  Loss: 0.0387 (0.0391)  ASR: 100.0000 (99.5713)  ACC: 83.3333 (nan)  time: 0.2131  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [280/313]  eta: 0:00:07  Loss: 0.0383 (0.0390)  ASR: 100.0000 (99.5865)  ACC: 83.3333 (nan)  time: 0.2115  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 0.0383 (0.0390)  ASR: 100.0000 (99.6007)  ACC: 75.0000 (nan)  time: 0.2103  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 0.0375 (0.0390)  ASR: 100.0000 (99.5863)  ACC: 80.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 0.0366 (0.0389)  ASR: 100.0000 (99.5996)  ACC: 100.0000 (nan)  time: 0.2103  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 0.0373 (0.0389)  ASR: 100.0000 (99.6015)  ACC: 100.0000 (nan)  time: 0.2054  data: 0.0002  max mem: 2383
Train: Epoch[3/5] Total time: 0:01:06 (0.2130 s / it)
Averaged stats: Loss: 0.0373 (0.0389)  ASR: 100.0000 (99.6015)  ACC: 100.0000 (nan)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:11  Lr: 0.001875  Loss: -0.0185  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4200  data: 0.2281  max mem: 2383
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Lr: 0.001875  Loss: 0.2074  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (97.7273)  time: 0.2107  data: 0.0209  max mem: 2383
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.3564  Acc@1: 93.7500 (86.9048)  Acc@5: 100.0000 (98.2143)  time: 0.1962  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0290  Acc@1: 81.2500 (85.4839)  Acc@5: 100.0000 (98.5887)  time: 0.2028  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0469  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.7805)  time: 0.2028  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:53  Lr: 0.001875  Loss: -0.0221  Acc@1: 87.5000 (85.5392)  Acc@5: 100.0000 (98.7745)  time: 0.2036  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1816  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.9754)  time: 0.2064  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.0166  Acc@1: 87.5000 (86.4437)  Acc@5: 100.0000 (98.9437)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1369  Acc@1: 87.5000 (86.4198)  Acc@5: 100.0000 (98.9969)  time: 0.2097  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.2365  Acc@1: 81.2500 (86.1951)  Acc@5: 100.0000 (98.8324)  time: 0.2102  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [100/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0554  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.7624)  time: 0.2101  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [110/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.4971  Acc@1: 87.5000 (86.7680)  Acc@5: 100.0000 (98.8176)  time: 0.2099  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [120/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.0417  Acc@1: 87.5000 (86.5702)  Acc@5: 100.0000 (98.7087)  time: 0.2097  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [130/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1922  Acc@1: 87.5000 (87.0706)  Acc@5: 100.0000 (98.7118)  time: 0.2097  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [140/313]  eta: 0:00:35  Lr: 0.001875  Loss: 0.2063  Acc@1: 87.5000 (86.7021)  Acc@5: 100.0000 (98.7145)  time: 0.2098  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [150/313]  eta: 0:00:33  Lr: 0.001875  Loss: 0.1064  Acc@1: 87.5000 (86.7964)  Acc@5: 100.0000 (98.6755)  time: 0.2099  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [160/313]  eta: 0:00:31  Lr: 0.001875  Loss: -0.0595  Acc@1: 87.5000 (86.7236)  Acc@5: 100.0000 (98.6025)  time: 0.2098  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [170/313]  eta: 0:00:29  Lr: 0.001875  Loss: 0.0300  Acc@1: 87.5000 (86.8787)  Acc@5: 100.0000 (98.6111)  time: 0.2096  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [180/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3296  Acc@1: 87.5000 (86.8094)  Acc@5: 100.0000 (98.6533)  time: 0.2094  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [190/313]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0704  Acc@1: 87.5000 (86.8128)  Acc@5: 100.0000 (98.6584)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [200/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3246  Acc@1: 87.5000 (86.9403)  Acc@5: 100.0000 (98.6629)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [210/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0559  Acc@1: 93.7500 (87.1445)  Acc@5: 100.0000 (98.6078)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [220/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.1314  Acc@1: 87.5000 (86.9061)  Acc@5: 100.0000 (98.5860)  time: 0.2093  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [230/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2762  Acc@1: 81.2500 (86.7424)  Acc@5: 100.0000 (98.5931)  time: 0.2098  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [240/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0494  Acc@1: 87.5000 (86.7998)  Acc@5: 100.0000 (98.5996)  time: 0.2100  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [250/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.2378  Acc@1: 87.5000 (86.8775)  Acc@5: 100.0000 (98.6554)  time: 0.2102  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [260/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0726  Acc@1: 87.5000 (86.8774)  Acc@5: 100.0000 (98.6830)  time: 0.2102  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0539  Acc@1: 87.5000 (86.9234)  Acc@5: 100.0000 (98.7085)  time: 0.2099  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2798  Acc@1: 87.5000 (86.8550)  Acc@5: 100.0000 (98.7100)  time: 0.1996  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0826  Acc@1: 87.5000 (87.0275)  Acc@5: 100.0000 (98.7113)  time: 0.1897  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.4473  Acc@1: 87.5000 (86.9394)  Acc@5: 100.0000 (98.6711)  time: 0.1901  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1285  Acc@1: 81.2500 (86.9373)  Acc@5: 100.0000 (98.6736)  time: 0.1931  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0816  Acc@1: 81.2500 (86.9600)  Acc@5: 100.0000 (98.6600)  time: 0.1892  data: 0.0001  max mem: 2383
Train: Epoch[4/5] Total time: 0:01:07 (0.2142 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0816  Acc@1: 81.2500 (86.9600)  Acc@5: 100.0000 (98.6600)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:16  Loss: 0.0373 (0.0373)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (100.0000)  time: 0.4347  data: 0.2369  max mem: 2383
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:06  Loss: 0.0362 (0.0368)  ASR: 100.0000 (99.2424)  ACC: 100.0000 (88.3721)  time: 0.2209  data: 0.0217  max mem: 2383
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:02  Loss: 0.0362 (0.0365)  ASR: 100.0000 (99.0741)  ACC: 100.0000 (86.9048)  time: 0.2037  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:00  Loss: 0.0366 (0.0371)  ASR: 100.0000 (99.3728)  ACC: 100.0000 (85.9259)  time: 0.2078  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:57  Loss: 0.0375 (0.0372)  ASR: 100.0000 (99.3515)  ACC: 85.7143 (83.2432)  time: 0.2083  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:55  Loss: 0.0360 (0.0369)  ASR: 100.0000 (99.4787)  ACC: 80.0000 (83.2599)  time: 0.2086  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:53  Loss: 0.0362 (0.0370)  ASR: 100.0000 (99.4380)  ACC: 80.0000 (82.6715)  time: 0.2083  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:51  Loss: 0.0374 (0.0372)  ASR: 100.0000 (99.5172)  ACC: 80.0000 (82.5688)  time: 0.2082  data: 0.0001  max mem: 2383
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:48  Loss: 0.0362 (0.0369)  ASR: 100.0000 (99.4818)  ACC: 80.0000 (81.9945)  time: 0.2092  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:46  Loss: 0.0355 (0.0368)  ASR: 100.0000 (99.5388)  ACC: 83.3333 (83.0467)  time: 0.2104  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [100/313]  eta: 0:00:44  Loss: 0.0363 (0.0368)  ASR: 100.0000 (99.5844)  ACC: 90.0000 (83.2244)  time: 0.2105  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [110/313]  eta: 0:00:42  Loss: 0.0358 (0.0367)  ASR: 100.0000 (99.6219)  ACC: 87.5000 (83.6614)  time: 0.2114  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [120/313]  eta: 0:00:40  Loss: 0.0346 (0.0366)  ASR: 100.0000 (99.6531)  ACC: 100.0000 (84.3416)  time: 0.2135  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [130/313]  eta: 0:00:38  Loss: 0.0356 (0.0366)  ASR: 100.0000 (99.6209)  ACC: 90.0000 (84.2020)  time: 0.2147  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [140/313]  eta: 0:00:36  Loss: 0.0363 (0.0365)  ASR: 100.0000 (99.6478)  ACC: 80.0000 (84.0246)  time: 0.2148  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [150/313]  eta: 0:00:34  Loss: 0.0345 (0.0364)  ASR: 100.0000 (99.6711)  ACC: 83.3333 (84.3023)  time: 0.2149  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [160/313]  eta: 0:00:32  Loss: 0.0351 (0.0364)  ASR: 100.0000 (99.6915)  ACC: nan (nan)  time: 0.2148  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [170/313]  eta: 0:00:30  Loss: 0.0355 (0.0364)  ASR: 100.0000 (99.7096)  ACC: nan (nan)  time: 0.2147  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [180/313]  eta: 0:00:28  Loss: 0.0341 (0.0362)  ASR: 100.0000 (99.7256)  ACC: 100.0000 (nan)  time: 0.2146  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [190/313]  eta: 0:00:26  Loss: 0.0333 (0.0361)  ASR: 100.0000 (99.7400)  ACC: 100.0000 (nan)  time: 0.2149  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [200/313]  eta: 0:00:23  Loss: 0.0340 (0.0360)  ASR: 100.0000 (99.7529)  ACC: 83.3333 (nan)  time: 0.2150  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [210/313]  eta: 0:00:21  Loss: 0.0341 (0.0359)  ASR: 100.0000 (99.7646)  ACC: 83.3333 (nan)  time: 0.2148  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [220/313]  eta: 0:00:19  Loss: 0.0325 (0.0359)  ASR: 100.0000 (99.7753)  ACC: 80.0000 (nan)  time: 0.2147  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [230/313]  eta: 0:00:17  Loss: 0.0325 (0.0358)  ASR: 100.0000 (99.7489)  ACC: 80.0000 (nan)  time: 0.2146  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [240/313]  eta: 0:00:15  Loss: 0.0318 (0.0356)  ASR: 100.0000 (99.7593)  ACC: 100.0000 (nan)  time: 0.2148  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [250/313]  eta: 0:00:13  Loss: 0.0334 (0.0356)  ASR: 100.0000 (99.7689)  ACC: 100.0000 (nan)  time: 0.2152  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [260/313]  eta: 0:00:11  Loss: 0.0341 (0.0356)  ASR: 100.0000 (99.7352)  ACC: 90.9091 (nan)  time: 0.2160  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [270/313]  eta: 0:00:09  Loss: 0.0330 (0.0355)  ASR: 100.0000 (99.7450)  ACC: 100.0000 (nan)  time: 0.2161  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [280/313]  eta: 0:00:07  Loss: 0.0311 (0.0353)  ASR: 100.0000 (99.7541)  ACC: 100.0000 (nan)  time: 0.2160  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 0.0330 (0.0353)  ASR: 100.0000 (99.7625)  ACC: 85.7143 (nan)  time: 0.2151  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 0.0340 (0.0352)  ASR: 100.0000 (99.7704)  ACC: 83.3333 (nan)  time: 0.2143  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 0.0314 (0.0351)  ASR: 100.0000 (99.7778)  ACC: 100.0000 (nan)  time: 0.2139  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 0.0314 (0.0351)  ASR: 100.0000 (99.7789)  ACC: 100.0000 (nan)  time: 0.2088  data: 0.0002  max mem: 2383
Train: Epoch[4/5] Total time: 0:01:06 (0.2133 s / it)
Averaged stats: Loss: 0.0314 (0.0351)  ASR: 100.0000 (99.7789)  ACC: 100.0000 (nan)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:05  Lr: 0.001875  Loss: -0.0620  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.4011  data: 0.2093  max mem: 2383
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Lr: 0.001875  Loss: 0.1911  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (99.4318)  time: 0.2110  data: 0.0192  max mem: 2383
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.2524  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.1071)  time: 0.1943  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:58  Lr: 0.001875  Loss: -0.0056  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (99.3952)  time: 0.2019  data: 0.0001  max mem: 2383
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.1226  Acc@1: 93.7500 (91.7683)  Acc@5: 100.0000 (99.2378)  time: 0.2073  data: 0.0001  max mem: 2383
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0970  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (99.2647)  time: 0.2077  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.2947  Acc@1: 87.5000 (90.1639)  Acc@5: 100.0000 (99.2828)  time: 0.2079  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.3986  Acc@1: 81.2500 (89.3486)  Acc@5: 100.0000 (99.0317)  time: 0.2080  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3304  Acc@1: 87.5000 (89.5062)  Acc@5: 100.0000 (98.9969)  time: 0.2081  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.0867  Acc@1: 87.5000 (89.6291)  Acc@5: 100.0000 (98.9011)  time: 0.2079  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [100/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1705  Acc@1: 87.5000 (89.5421)  Acc@5: 100.0000 (98.8861)  time: 0.2078  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [110/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0285  Acc@1: 87.5000 (89.0766)  Acc@5: 100.0000 (98.9302)  time: 0.2079  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [120/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.1097  Acc@1: 87.5000 (89.0496)  Acc@5: 100.0000 (98.9153)  time: 0.2081  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [130/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.6108  Acc@1: 87.5000 (88.9313)  Acc@5: 100.0000 (98.7118)  time: 0.2081  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [140/313]  eta: 0:00:35  Lr: 0.001875  Loss: 0.3254  Acc@1: 87.5000 (88.7411)  Acc@5: 100.0000 (98.8032)  time: 0.2079  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [150/313]  eta: 0:00:33  Lr: 0.001875  Loss: 0.1004  Acc@1: 87.5000 (88.5348)  Acc@5: 100.0000 (98.7169)  time: 0.2079  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [160/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.1470  Acc@1: 87.5000 (88.3152)  Acc@5: 100.0000 (98.6801)  time: 0.2075  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [170/313]  eta: 0:00:29  Lr: 0.001875  Loss: -0.0983  Acc@1: 87.5000 (88.3772)  Acc@5: 100.0000 (98.6477)  time: 0.2074  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [180/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.1595  Acc@1: 81.2500 (88.1215)  Acc@5: 100.0000 (98.6878)  time: 0.2078  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [190/313]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0150  Acc@1: 87.5000 (88.3181)  Acc@5: 100.0000 (98.6911)  time: 0.2079  data: 0.0001  max mem: 2383
Train: Epoch[5/5]  [200/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0985  Acc@1: 87.5000 (88.2774)  Acc@5: 100.0000 (98.7251)  time: 0.2077  data: 0.0001  max mem: 2383
Train: Epoch[5/5]  [210/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2130  Acc@1: 87.5000 (88.2109)  Acc@5: 100.0000 (98.7559)  time: 0.2073  data: 0.0001  max mem: 2383
Train: Epoch[5/5]  [220/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0430  Acc@1: 87.5000 (88.1222)  Acc@5: 100.0000 (98.7557)  time: 0.2073  data: 0.0001  max mem: 2383
Train: Epoch[5/5]  [230/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2786  Acc@1: 87.5000 (88.2576)  Acc@5: 100.0000 (98.7554)  time: 0.2077  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [240/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0651  Acc@1: 93.7500 (88.3039)  Acc@5: 100.0000 (98.7293)  time: 0.2080  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [250/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.2756  Acc@1: 87.5000 (88.1972)  Acc@5: 100.0000 (98.6803)  time: 0.2082  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.001875  Loss: 0.4200  Acc@1: 87.5000 (88.2663)  Acc@5: 100.0000 (98.6830)  time: 0.2081  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4325  Acc@1: 87.5000 (88.2380)  Acc@5: 100.0000 (98.6162)  time: 0.2080  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0298  Acc@1: 87.5000 (88.2117)  Acc@5: 100.0000 (98.6655)  time: 0.2080  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0269  Acc@1: 87.5000 (88.1229)  Acc@5: 100.0000 (98.6684)  time: 0.2082  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3858  Acc@1: 81.2500 (87.9568)  Acc@5: 100.0000 (98.6088)  time: 0.2083  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0165  Acc@1: 87.5000 (87.9622)  Acc@5: 100.0000 (98.6535)  time: 0.2080  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2706  Acc@1: 87.5000 (87.9800)  Acc@5: 100.0000 (98.6600)  time: 0.2029  data: 0.0002  max mem: 2383
Train: Epoch[5/5] Total time: 0:01:04 (0.2076 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2706  Acc@1: 87.5000 (87.9800)  Acc@5: 100.0000 (98.6600)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:07  Loss: 0.0318 (0.0318)  ASR: 100.0000 (100.0000)  ACC: 80.0000 (80.0000)  time: 0.4079  data: 0.2063  max mem: 2383
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:06  Loss: 0.0330 (0.0334)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (88.1356)  time: 0.2191  data: 0.0189  max mem: 2383
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:03  Loss: 0.0317 (0.0320)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (90.2913)  time: 0.2061  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:00  Loss: 0.0297 (0.0315)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (89.4366)  time: 0.2116  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:58  Loss: 0.0300 (0.0315)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (90.1042)  time: 0.2109  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:55  Loss: 0.0319 (0.0315)  ASR: 100.0000 (100.0000)  ACC: 88.8889 (89.0756)  time: 0.2103  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:53  Loss: 0.0310 (0.0314)  ASR: 100.0000 (100.0000)  ACC: 83.3333 (88.7324)  time: 0.2107  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:51  Loss: 0.0308 (0.0314)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (89.0909)  time: 0.2109  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:49  Loss: 0.0318 (0.0315)  ASR: 100.0000 (100.0000)  ACC: 100.0000 (89.5833)  time: 0.2104  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:47  Loss: 0.0312 (0.0315)  ASR: 100.0000 (100.0000)  ACC: 83.3333 (88.7097)  time: 0.2106  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [100/313]  eta: 0:00:45  Loss: 0.0303 (0.0315)  ASR: 100.0000 (100.0000)  ACC: 83.3333 (88.1743)  time: 0.2248  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [110/313]  eta: 0:00:43  Loss: 0.0292 (0.0313)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2291  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [120/313]  eta: 0:00:41  Loss: 0.0293 (0.0314)  ASR: 100.0000 (100.0000)  ACC: nan (nan)  time: 0.2179  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [130/313]  eta: 0:00:39  Loss: 0.0308 (0.0315)  ASR: 100.0000 (100.0000)  ACC: 80.0000 (nan)  time: 0.2158  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [140/313]  eta: 0:00:37  Loss: 0.0310 (0.0314)  ASR: 100.0000 (99.9355)  ACC: 85.7143 (nan)  time: 0.2157  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [150/313]  eta: 0:00:35  Loss: 0.0315 (0.0315)  ASR: 100.0000 (99.9398)  ACC: 83.3333 (nan)  time: 0.2155  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [160/313]  eta: 0:00:32  Loss: 0.0326 (0.0315)  ASR: 100.0000 (99.9435)  ACC: 83.3333 (nan)  time: 0.2150  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [170/313]  eta: 0:00:30  Loss: 0.0313 (0.0315)  ASR: 100.0000 (99.9468)  ACC: 100.0000 (nan)  time: 0.2142  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [180/313]  eta: 0:00:28  Loss: 0.0305 (0.0315)  ASR: 100.0000 (99.9498)  ACC: 100.0000 (nan)  time: 0.2130  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [190/313]  eta: 0:00:26  Loss: 0.0305 (0.0314)  ASR: 100.0000 (99.9524)  ACC: 100.0000 (nan)  time: 0.2126  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [200/313]  eta: 0:00:24  Loss: 0.0304 (0.0315)  ASR: 100.0000 (99.9165)  ACC: 80.0000 (nan)  time: 0.2115  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [210/313]  eta: 0:00:22  Loss: 0.0308 (0.0315)  ASR: 100.0000 (99.9205)  ACC: 100.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [220/313]  eta: 0:00:19  Loss: 0.0302 (0.0314)  ASR: 100.0000 (99.9241)  ACC: 100.0000 (nan)  time: 0.2104  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [230/313]  eta: 0:00:17  Loss: 0.0293 (0.0313)  ASR: 100.0000 (99.9273)  ACC: 100.0000 (nan)  time: 0.2107  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [240/313]  eta: 0:00:15  Loss: 0.0284 (0.0312)  ASR: 100.0000 (99.8926)  ACC: 100.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [250/313]  eta: 0:00:13  Loss: 0.0284 (0.0311)  ASR: 100.0000 (99.8685)  ACC: 100.0000 (nan)  time: 0.2109  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [260/313]  eta: 0:00:11  Loss: 0.0286 (0.0311)  ASR: 100.0000 (99.8735)  ACC: 100.0000 (nan)  time: 0.2106  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [270/313]  eta: 0:00:09  Loss: 0.0312 (0.0311)  ASR: 100.0000 (99.8782)  ACC: 83.3333 (nan)  time: 0.2105  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [280/313]  eta: 0:00:07  Loss: 0.0318 (0.0311)  ASR: 100.0000 (99.8825)  ACC: 100.0000 (nan)  time: 0.2105  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 0.0297 (0.0310)  ASR: 100.0000 (99.8865)  ACC: 100.0000 (nan)  time: 0.2107  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 0.0291 (0.0309)  ASR: 100.0000 (99.8903)  ACC: 100.0000 (nan)  time: 0.2107  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 0.0300 (0.0309)  ASR: 100.0000 (99.8646)  ACC: 100.0000 (nan)  time: 0.2103  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 0.0300 (0.0309)  ASR: 100.0000 (99.8653)  ACC: 100.0000 (nan)  time: 0.2051  data: 0.0002  max mem: 2383
Train: Epoch[5/5] Total time: 0:01:06 (0.2131 s / it)
Averaged stats: Loss: 0.0300 (0.0309)  ASR: 100.0000 (99.8653)  ACC: 100.0000 (nan)
Test: [Task 1]  [ 0/63]  eta: 0:00:19  Loss: 0.3659 (0.3659)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3070  data: 0.1878  max mem: 2383
Test: [Task 1]  [10/63]  eta: 0:00:07  Loss: 0.3659 (0.4015)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  time: 0.1360  data: 0.0173  max mem: 2383
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.3436 (0.4541)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (100.0000)  time: 0.1199  data: 0.0003  max mem: 2383
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.3017 (0.4054)  Acc@1: 100.0000 (96.5726)  Acc@5: 100.0000 (100.0000)  time: 0.1229  data: 0.0003  max mem: 2383
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.2818 (0.3987)  Acc@1: 100.0000 (96.6463)  Acc@5: 100.0000 (100.0000)  time: 0.1265  data: 0.0003  max mem: 2383
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.3524 (0.3888)  Acc@1: 100.0000 (96.9363)  Acc@5: 100.0000 (99.8775)  time: 0.1281  data: 0.0003  max mem: 2383
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3747 (0.3813)  Acc@1: 100.0000 (97.1311)  Acc@5: 100.0000 (99.8975)  time: 0.1281  data: 0.0002  max mem: 2383
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3524 (0.3799)  Acc@1: 100.0000 (97.2000)  Acc@5: 100.0000 (99.9000)  time: 0.1250  data: 0.0002  max mem: 2383
Test: [Task 1] Total time: 0:00:08 (0.1279 s / it)
* Acc@1 97.200 Acc@5 99.900 loss 0.380
[rank0]: Traceback (most recent call last):
[rank0]:   File "main.py", line 165, in <module>
[rank0]:     main(args)
[rank0]:   File "main.py", line 135, in main
[rank0]:     train_and_evaluate(model, model_without_ddp, original_model,
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor/engine.py", line 322, in train_and_evaluate
[rank0]:     test_stats = evaluate_till_now(model=model, original_model=original_model, data_loader=data_loader, device=device, 
[rank0]:   File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor/engine.py", line 210, in evaluate_till_now
[rank0]:     test_stats = evaluate(model=model, original_model=original_model, data_loader=data_loader[i]['val'], 
[rank0]:   File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
[rank0]:     return func(*args, **kwargs)
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor/engine.py", line 148, in evaluate
[rank0]:     input,p_index, c_index = poison_dataset(input,trigger=trigger,percent=0.7)
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor/backdoor.py", line 56, in poison_dataset
[rank0]:     input_data_p[p_indices] = torch.clamp(apply_noise_patch(clamp_batch_pert,input_data_p[p_indices].clone(),mode='add'),-1,1)
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor/backdoor.py", line 42, in apply_noise_patch
[rank0]:     images[i:i+1] += noise_now
[rank0]: RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
E1103 02:03:41.715406 140515446191936 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 2494821) of binary: /home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/bin/python
Traceback (most recent call last):
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-11-03_02:03:41
  host      : tg071.rrze.uni-erlangen.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2494821)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
=== JOB_STATISTICS ===
=== current date     : Sun 03 Nov 2024 02:03:42 AM CET
= Job-ID             : 924921 on tinygpu
= Job-Name           : l2p
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor
= Queue/Partition    : v100
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:45:02
= Total RAM usage    : 2.2 GiB of requested  GiB (%)   
= Node list          : tg071
= Subm/Elig/Start/End: 2024-11-03T01:18:40 / 2024-11-03T01:18:40 / 2024-11-03T01:18:40 / 2024-11-03T02:03:42
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           83.2G   104.9G   209.7G        N/A      80K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
    /home/woody         17.9G  1000.0G  1500.0G        N/A     124K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:18:00.0, 2494821, 96 %, 31 %, 4728 MiB, 2680613 ms
