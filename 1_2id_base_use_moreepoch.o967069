### Starting TaskPrologue of job 967069 on tg081 at Sun 05 Jan 2025 01:27:16 AM CET
Running on cores 4-5,20-21,36-37,52-53 with governor ondemand
Sun Jan  5 01:27:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3080        On  |   00000000:3D:00.0 Off |                  N/A |
| 31%   45C    P8             12W /  300W |       2MiB /  10240MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', p_task_id=2, patience_epochs=10, pin_mem=True, poison_rate=1.0, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, trigger_path='trigger_2_vit_base_patch16_224.pt', unscale_lr=True, use_prompt_mask=False, use_trigger=True, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
True
trigger loaded
/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/engine.py:263: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  trigger = torch.load(args.trigger_path)
0 2
Train: Epoch[1/5]  [  0/313]  eta: 0:11:32  Lr: 0.0019 (0.0019)  Acc@1: 25.0000 (25.0000)  Acc@5: 43.7500 (43.7500)  Loss: 2.3091 (2.3091)  time: 2.2128  data: 0.6655  max mem: 2371
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:44  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (40.9091)  Acc@5: 75.0000 (73.2955)  Loss: 2.1764 (2.1620)  time: 0.3462  data: 0.0608  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:14  Lr: 0.0019 (0.0019)  Acc@1: 50.0000 (51.4881)  Acc@5: 87.5000 (80.3571)  Loss: 2.0327 (2.0359)  time: 0.1561  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (55.6452)  Acc@5: 93.7500 (84.2742)  Loss: 1.8576 (1.9455)  time: 0.1528  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (59.7561)  Acc@5: 93.7500 (86.8902)  Loss: 1.6623 (1.8447)  time: 0.1535  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (62.0098)  Acc@5: 93.7500 (88.4804)  Loss: 1.4252 (1.7606)  time: 0.1530  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.4221)  Acc@5: 93.7500 (89.0369)  Loss: 1.3302 (1.6894)  time: 0.1520  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.1408)  Acc@5: 93.7500 (89.9648)  Loss: 1.2075 (1.6147)  time: 0.1521  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (66.9753)  Acc@5: 93.7500 (90.8179)  Loss: 1.1268 (1.5471)  time: 0.1522  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7198)  Acc@5: 93.7500 (91.3462)  Loss: 1.0733 (1.4971)  time: 0.1523  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1213)  Acc@5: 100.0000 (91.9554)  Loss: 0.9557 (1.4415)  time: 0.1525  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (69.7635)  Acc@5: 93.7500 (92.1734)  Loss: 0.9339 (1.3976)  time: 0.1526  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.2479)  Acc@5: 93.7500 (92.6136)  Loss: 0.9000 (1.3549)  time: 0.1529  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.9924)  Acc@5: 100.0000 (93.0821)  Loss: 0.8450 (1.3130)  time: 0.1532  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.8528)  Acc@5: 100.0000 (93.4397)  Loss: 0.7665 (1.2711)  time: 0.1533  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.5166)  Acc@5: 100.0000 (93.6672)  Loss: 0.6911 (1.2301)  time: 0.1534  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.8649)  Acc@5: 100.0000 (93.9053)  Loss: 0.6276 (1.1988)  time: 0.1536  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.5015)  Acc@5: 100.0000 (94.1155)  Loss: 0.6611 (1.1656)  time: 0.1536  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.6188)  Acc@5: 100.0000 (94.3025)  Loss: 0.6085 (1.1378)  time: 0.1537  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.2474)  Acc@5: 100.0000 (94.4372)  Loss: 0.5923 (1.1079)  time: 0.1539  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.5958)  Acc@5: 93.7500 (94.4341)  Loss: 0.5806 (1.0841)  time: 0.1540  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.7927)  Acc@5: 100.0000 (94.6090)  Loss: 0.6030 (1.0631)  time: 0.1540  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.0566)  Acc@5: 100.0000 (94.7681)  Loss: 0.5741 (1.0410)  time: 0.1539  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.2165)  Acc@5: 100.0000 (94.9134)  Loss: 0.5756 (1.0218)  time: 0.1539  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.8817)  Acc@5: 100.0000 (95.0726)  Loss: 0.4548 (0.9949)  time: 0.1540  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1952)  Acc@5: 100.0000 (95.1693)  Loss: 0.4640 (0.9765)  time: 0.1540  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.5086)  Acc@5: 100.0000 (95.3065)  Loss: 0.5304 (0.9563)  time: 0.1541  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.6836)  Acc@5: 100.0000 (95.4105)  Loss: 0.4691 (0.9400)  time: 0.1543  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.9795)  Acc@5: 100.0000 (95.5738)  Loss: 0.4272 (0.9220)  time: 0.1543  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.0833)  Acc@5: 100.0000 (95.5971)  Loss: 0.4377 (0.9101)  time: 0.1544  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.3463)  Acc@5: 100.0000 (95.6603)  Loss: 0.4430 (0.8942)  time: 0.1544  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4719)  Acc@5: 93.7500 (95.6793)  Loss: 0.4489 (0.8831)  time: 0.1544  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)  time: 0.1535  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:50 (0.1605 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)
0 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.2601 (0.2601)  time: 0.3477  data: 0.1912  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (96.0227)  Loss: 0.6554 (0.5714)  time: 0.1721  data: 0.0176  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.0238)  Loss: 0.4286 (0.4585)  time: 0.1546  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.2581)  Acc@5: 100.0000 (96.9758)  Loss: 0.3460 (0.4481)  time: 0.1547  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (97.1037)  Loss: 0.3460 (0.4236)  time: 0.1548  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (97.4265)  Loss: 0.3617 (0.4173)  time: 0.1548  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.4385)  Loss: 0.3617 (0.4059)  time: 0.1548  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0669)  Acc@5: 100.0000 (97.6232)  Loss: 0.3543 (0.4041)  time: 0.1550  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9506)  Acc@5: 100.0000 (97.6080)  Loss: 0.3646 (0.4007)  time: 0.1551  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9973)  Acc@5: 100.0000 (97.5962)  Loss: 0.3185 (0.3968)  time: 0.1552  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0347)  Acc@5: 100.0000 (97.6485)  Loss: 0.3185 (0.3957)  time: 0.1553  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9527)  Acc@5: 100.0000 (97.7477)  Loss: 0.3314 (0.3899)  time: 0.1553  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8326)  Acc@5: 100.0000 (97.7273)  Loss: 0.3314 (0.3894)  time: 0.1553  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1603)  Acc@5: 100.0000 (97.6622)  Loss: 0.3256 (0.3833)  time: 0.1553  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1312)  Acc@5: 93.7500 (97.5621)  Loss: 0.3241 (0.3847)  time: 0.1555  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9818)  Acc@5: 93.7500 (97.5579)  Loss: 0.3867 (0.3854)  time: 0.1555  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8509)  Acc@5: 100.0000 (97.5155)  Loss: 0.3258 (0.3839)  time: 0.1555  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9547)  Acc@5: 100.0000 (97.5512)  Loss: 0.2723 (0.3797)  time: 0.1555  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8052)  Acc@5: 100.0000 (97.5138)  Loss: 0.3252 (0.3794)  time: 0.1556  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9005)  Acc@5: 100.0000 (97.6113)  Loss: 0.2981 (0.3731)  time: 0.1557  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8308)  Acc@5: 100.0000 (97.6990)  Loss: 0.2958 (0.3716)  time: 0.1557  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0344)  Acc@5: 100.0000 (97.7488)  Loss: 0.2618 (0.3659)  time: 0.1558  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8518)  Acc@5: 100.0000 (97.7093)  Loss: 0.2618 (0.3686)  time: 0.1557  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.8084)  Loss: 0.2166 (0.3608)  time: 0.1558  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.2324)  Acc@5: 100.0000 (97.8994)  Loss: 0.1579 (0.3563)  time: 0.1559  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.1882)  Acc@5: 100.0000 (97.8586)  Loss: 0.2819 (0.3544)  time: 0.1559  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9559)  Acc@5: 100.0000 (97.8448)  Loss: 0.3998 (0.3589)  time: 0.1560  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9253)  Acc@5: 100.0000 (97.8782)  Loss: 0.3762 (0.3573)  time: 0.1559  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8746)  Acc@5: 100.0000 (97.8648)  Loss: 0.3273 (0.3553)  time: 0.1559  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8703)  Acc@5: 100.0000 (97.8522)  Loss: 0.2411 (0.3530)  time: 0.1560  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9909)  Acc@5: 100.0000 (97.9028)  Loss: 0.2340 (0.3493)  time: 0.1560  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0836)  Acc@5: 100.0000 (97.9100)  Loss: 0.2207 (0.3477)  time: 0.1561  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)  time: 0.1524  data: 0.0002  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:48 (0.1561 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)
0 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1340 (0.1340)  time: 0.3477  data: 0.1899  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  Loss: 0.2430 (0.2785)  time: 0.1733  data: 0.0175  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.9167)  Loss: 0.3333 (0.3284)  time: 0.1559  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.5887)  Loss: 0.2192 (0.2731)  time: 0.1558  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.3232)  Loss: 0.1146 (0.2478)  time: 0.1557  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.5294)  Loss: 0.1603 (0.2371)  time: 0.1557  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.6557)  Acc@5: 100.0000 (98.2582)  Loss: 0.2495 (0.2615)  time: 0.1557  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.9155)  Acc@5: 100.0000 (98.3275)  Loss: 0.2700 (0.2600)  time: 0.1557  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3426)  Acc@5: 100.0000 (98.3025)  Loss: 0.2269 (0.2561)  time: 0.1558  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4011)  Acc@5: 100.0000 (98.3516)  Loss: 0.2158 (0.2540)  time: 0.1559  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0767)  Acc@5: 100.0000 (98.3292)  Loss: 0.2631 (0.2544)  time: 0.1562  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5991)  Acc@5: 100.0000 (98.3671)  Loss: 0.1068 (0.2408)  time: 0.1562  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0021)  Acc@5: 100.0000 (98.4504)  Loss: 0.1068 (0.2487)  time: 0.1562  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5458)  Acc@5: 100.0000 (98.3779)  Loss: 0.1907 (0.2390)  time: 0.1563  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7908)  Acc@5: 100.0000 (98.3599)  Loss: 0.2089 (0.2373)  time: 0.1564  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6722)  Acc@5: 100.0000 (98.4272)  Loss: 0.2159 (0.2396)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8789)  Acc@5: 100.0000 (98.5248)  Loss: 0.1434 (0.2307)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7325)  Acc@5: 100.0000 (98.5746)  Loss: 0.1122 (0.2309)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6367)  Acc@5: 100.0000 (98.5497)  Loss: 0.2248 (0.2341)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6819)  Acc@5: 100.0000 (98.5275)  Loss: 0.1644 (0.2297)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7226)  Acc@5: 100.0000 (98.5697)  Loss: 0.1072 (0.2288)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5818)  Acc@5: 100.0000 (98.5486)  Loss: 0.1899 (0.2336)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5950)  Acc@5: 100.0000 (98.5011)  Loss: 0.1946 (0.2318)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.5390)  Loss: 0.1946 (0.2297)  time: 0.1564  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.4699)  Loss: 0.1495 (0.2286)  time: 0.1562  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.5787)  Acc@5: 100.0000 (98.4064)  Loss: 0.1721 (0.2274)  time: 0.1562  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.3956)  Loss: 0.1582 (0.2251)  time: 0.1563  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7159)  Acc@5: 100.0000 (98.4087)  Loss: 0.0974 (0.2242)  time: 0.1565  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7660)  Acc@5: 100.0000 (98.4208)  Loss: 0.1206 (0.2229)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7912)  Acc@5: 100.0000 (98.4107)  Loss: 0.1309 (0.2212)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9186)  Acc@5: 100.0000 (98.4427)  Loss: 0.1289 (0.2183)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9775)  Acc@5: 100.0000 (98.4727)  Loss: 0.1218 (0.2151)  time: 0.1565  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)  time: 0.1529  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)
0 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:45  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1105 (0.1105)  time: 0.3379  data: 0.1811  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  Loss: 0.1945 (0.1745)  time: 0.1729  data: 0.0167  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5119)  Loss: 0.1945 (0.1660)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.5887)  Loss: 0.1687 (0.1709)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.1707)  Loss: 0.1728 (0.1912)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (98.4069)  Loss: 0.1458 (0.1734)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (98.1557)  Loss: 0.1876 (0.1957)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4437)  Acc@5: 100.0000 (98.1514)  Loss: 0.2398 (0.2087)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4198)  Acc@5: 100.0000 (98.1481)  Loss: 0.3108 (0.2089)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.1456)  Loss: 0.1457 (0.2040)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.2673)  Loss: 0.1278 (0.2026)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3176)  Acc@5: 100.0000 (98.2545)  Loss: 0.2012 (0.2047)  time: 0.1566  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0021)  Acc@5: 100.0000 (98.1405)  Loss: 0.2384 (0.2080)  time: 0.1567  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1641)  Acc@5: 100.0000 (98.1393)  Loss: 0.2447 (0.2050)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5248)  Acc@5: 100.0000 (98.1826)  Loss: 0.1092 (0.1991)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7550)  Acc@5: 100.0000 (98.1788)  Loss: 0.0572 (0.1944)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6460)  Acc@5: 100.0000 (98.2143)  Loss: 0.0832 (0.1987)  time: 0.1568  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5863)  Acc@5: 100.0000 (98.2091)  Loss: 0.1471 (0.1985)  time: 0.1567  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8094)  Acc@5: 100.0000 (98.3080)  Loss: 0.1471 (0.1947)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8783)  Acc@5: 100.0000 (98.2657)  Loss: 0.0984 (0.1936)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.2898)  Loss: 0.0847 (0.1901)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9372)  Acc@5: 100.0000 (98.3412)  Loss: 0.1282 (0.1915)  time: 0.1567  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0758)  Acc@5: 100.0000 (98.3597)  Loss: 0.1562 (0.1883)  time: 0.1568  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.3496)  Loss: 0.1421 (0.1869)  time: 0.1568  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1629)  Acc@5: 100.0000 (98.3143)  Loss: 0.1428 (0.1863)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2012)  Acc@5: 100.0000 (98.3566)  Loss: 0.1428 (0.1858)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1648)  Acc@5: 100.0000 (98.3477)  Loss: 0.2151 (0.1859)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0849)  Acc@5: 100.0000 (98.2934)  Loss: 0.2151 (0.1883)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1219)  Acc@5: 100.0000 (98.2874)  Loss: 0.1995 (0.1879)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1134)  Acc@5: 100.0000 (98.3247)  Loss: 0.1641 (0.1893)  time: 0.1564  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1678)  Acc@5: 100.0000 (98.3804)  Loss: 0.1424 (0.1875)  time: 0.1565  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1182)  Acc@5: 100.0000 (98.3521)  Loss: 0.1150 (0.1878)  time: 0.1567  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)  time: 0.1530  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:49 (0.1573 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)
0 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1773 (0.1773)  time: 0.3498  data: 0.1932  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  Loss: 0.1773 (0.1656)  time: 0.1743  data: 0.0178  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.5119)  Loss: 0.1756 (0.1675)  time: 0.1569  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (97.9839)  Loss: 0.2191 (0.2073)  time: 0.1569  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0610)  Acc@5: 100.0000 (98.3232)  Loss: 0.2191 (0.2225)  time: 0.1568  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0490)  Acc@5: 100.0000 (98.4069)  Loss: 0.1584 (0.2164)  time: 0.1568  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7336)  Acc@5: 100.0000 (98.2582)  Loss: 0.1712 (0.2224)  time: 0.1568  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8592)  Acc@5: 100.0000 (98.1514)  Loss: 0.1792 (0.2243)  time: 0.1569  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1080)  Acc@5: 100.0000 (98.1481)  Loss: 0.1045 (0.2147)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7527)  Acc@5: 100.0000 (98.2830)  Loss: 0.1749 (0.2228)  time: 0.1569  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7772)  Acc@5: 100.0000 (98.4530)  Loss: 0.1946 (0.2173)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7410)  Acc@5: 100.0000 (98.5360)  Loss: 0.2287 (0.2162)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0207)  Acc@5: 100.0000 (98.6054)  Loss: 0.1936 (0.2105)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9714)  Acc@5: 100.0000 (98.6164)  Loss: 0.1936 (0.2113)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3280)  Acc@5: 100.0000 (98.7145)  Loss: 0.1364 (0.2022)  time: 0.1569  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3891)  Acc@5: 100.0000 (98.7169)  Loss: 0.1261 (0.2018)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.4425)  Acc@5: 100.0000 (98.7189)  Loss: 0.1274 (0.2008)  time: 0.1568  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (98.7939)  Loss: 0.0427 (0.1903)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.9461)  Acc@5: 100.0000 (98.7569)  Loss: 0.0382 (0.1887)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9620)  Acc@5: 100.0000 (98.7565)  Loss: 0.1745 (0.1888)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2562)  Acc@5: 100.0000 (98.7562)  Loss: 0.1815 (0.1843)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1078)  Acc@5: 100.0000 (98.7263)  Loss: 0.1329 (0.1859)  time: 0.1570  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2557)  Acc@5: 100.0000 (98.7557)  Loss: 0.1382 (0.1829)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.7554)  Loss: 0.1170 (0.1814)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3589)  Acc@5: 100.0000 (98.7811)  Loss: 0.1627 (0.1803)  time: 0.1570  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5040)  Acc@5: 100.0000 (98.7799)  Loss: 0.1687 (0.1783)  time: 0.1570  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5421)  Acc@5: 100.0000 (98.7548)  Loss: 0.1139 (0.1761)  time: 0.1569  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5775)  Acc@5: 100.0000 (98.7085)  Loss: 0.1439 (0.1787)  time: 0.1569  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6326)  Acc@5: 100.0000 (98.7100)  Loss: 0.1651 (0.1792)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.7328)  Loss: 0.1124 (0.1769)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7525)  Acc@5: 100.0000 (98.7126)  Loss: 0.1409 (0.1791)  time: 0.1570  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7966)  Acc@5: 100.0000 (98.6937)  Loss: 0.1640 (0.1763)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)  time: 0.1532  data: 0.0002  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:49 (0.1575 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)
Test: [Task 1]  [ 0/63]  eta: 0:00:18  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4452 (0.4452)  time: 0.2982  data: 0.2021  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4146)  time: 0.1159  data: 0.0187  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4772)  time: 0.0976  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (96.7742)  Acc@5: 100.0000 (100.0000)  Loss: 0.3290 (0.4259)  time: 0.0975  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (100.0000)  Loss: 0.3048 (0.4234)  time: 0.0975  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.8775)  Loss: 0.3667 (0.4123)  time: 0.0975  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (99.8975)  Loss: 0.3730 (0.4057)  time: 0.0974  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (97.5000)  Acc@5: 100.0000 (99.9000)  Loss: 0.3730 (0.4065)  time: 0.0952  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:06 (0.1009 s / it)
* Acc@1 97.500 Acc@5 99.900 loss 0.407
Test: [Task 1]  [ 0/63]  eta: 0:00:24  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.9820 (2.9820)  time: 0.3967  data: 0.1911  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.7296 (2.8667)  time: 0.2148  data: 0.0176  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.7303 (2.8882)  time: 0.1967  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.9748 (2.9178)  time: 0.1968  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.8432 (2.8736)  time: 0.1969  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.7826 (2.8762)  time: 0.1968  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.8312 (2.8874)  time: 0.1968  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (15.8730)  Loss: 2.7826 (2.8942)  time: 0.1921  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:12 (0.1995 s / it)
* ASR 0.000 
[Average accuracy till task1]	ASR: 0.0000	ACC: 97.5000	Loss: 2.8942
1 2
Train: Epoch[1/5]  [  0/313]  eta: 0:02:01  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  Loss: 2.1099 (2.1099)  time: 0.3892  data: 0.2305  max mem: 2374
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 31.2500 (30.1136)  Acc@5: 75.0000 (72.1591)  Loss: 1.9865 (1.9809)  time: 0.1777  data: 0.0212  max mem: 2377
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (45.5357)  Acc@5: 87.5000 (81.5476)  Loss: 1.8626 (1.8644)  time: 0.1567  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (54.8387)  Acc@5: 93.7500 (85.8871)  Loss: 1.5926 (1.7596)  time: 0.1567  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (60.2134)  Acc@5: 93.7500 (88.1098)  Loss: 1.4334 (1.6578)  time: 0.1568  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.2353)  Acc@5: 93.7500 (89.5833)  Loss: 1.2427 (1.5697)  time: 0.1568  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.6762)  Acc@5: 100.0000 (90.7787)  Loss: 1.0970 (1.4807)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (67.9577)  Acc@5: 100.0000 (91.4613)  Loss: 0.9570 (1.4020)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1358)  Acc@5: 100.0000 (92.3611)  Loss: 0.8705 (1.3359)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.3297)  Acc@5: 100.0000 (92.8571)  Loss: 0.8177 (1.2761)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.5965)  Acc@5: 93.7500 (93.1312)  Loss: 0.6947 (1.2153)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (72.6914)  Acc@5: 100.0000 (93.5248)  Loss: 0.5696 (1.1590)  time: 0.1568  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (73.7603)  Acc@5: 100.0000 (93.8533)  Loss: 0.5555 (1.1108)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (74.5229)  Acc@5: 100.0000 (94.1794)  Loss: 0.5153 (1.0672)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.8670)  Acc@5: 100.0000 (94.4149)  Loss: 0.5817 (1.0360)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.5381)  Acc@5: 100.0000 (94.5778)  Loss: 0.5817 (0.9992)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1258)  Acc@5: 93.7500 (94.6429)  Loss: 0.4608 (0.9683)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.4254)  Acc@5: 93.7500 (94.7003)  Loss: 0.4739 (0.9395)  time: 0.1568  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8301)  Acc@5: 100.0000 (94.7859)  Loss: 0.5221 (0.9160)  time: 0.1567  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.1270)  Acc@5: 100.0000 (94.9935)  Loss: 0.5221 (0.8944)  time: 0.1567  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.2388)  Acc@5: 100.0000 (94.9938)  Loss: 0.5255 (0.8780)  time: 0.1567  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (77.4289)  Acc@5: 100.0000 (95.1718)  Loss: 0.4888 (0.8588)  time: 0.1567  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.7998)  Acc@5: 100.0000 (95.2489)  Loss: 0.3734 (0.8374)  time: 0.1567  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.1115)  Acc@5: 100.0000 (95.3193)  Loss: 0.3270 (0.8161)  time: 0.1568  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.3454)  Acc@5: 100.0000 (95.4876)  Loss: 0.3270 (0.7971)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6604)  Acc@5: 100.0000 (95.5428)  Loss: 0.3235 (0.7789)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.0469)  Acc@5: 100.0000 (95.6657)  Loss: 0.3235 (0.7623)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.1513)  Acc@5: 100.0000 (95.7334)  Loss: 0.3178 (0.7486)  time: 0.1568  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.4262)  Acc@5: 100.0000 (95.7295)  Loss: 0.3178 (0.7341)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.5103)  Acc@5: 93.7500 (95.7259)  Loss: 0.3530 (0.7232)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.5681)  Acc@5: 93.7500 (95.7226)  Loss: 0.3800 (0.7128)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7629)  Acc@5: 100.0000 (95.8601)  Loss: 0.2846 (0.6983)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)  time: 0.1532  data: 0.0002  max mem: 2377
Train: Epoch[1/5] Total time: 0:00:49 (0.1576 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)
1 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.1860 (0.1860)  time: 0.3253  data: 0.1663  max mem: 2377
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.1591)  Loss: 0.3742 (0.3463)  time: 0.1726  data: 0.0153  max mem: 2377
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (97.6190)  Loss: 0.3607 (0.3357)  time: 0.1572  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (97.9839)  Loss: 0.3258 (0.3426)  time: 0.1571  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6037)  Acc@5: 100.0000 (98.1707)  Loss: 0.3258 (0.3225)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8039)  Acc@5: 100.0000 (98.2843)  Loss: 0.2535 (0.3162)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.8484)  Loss: 0.2556 (0.3232)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7711)  Acc@5: 100.0000 (97.8873)  Loss: 0.2959 (0.3084)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8765)  Acc@5: 100.0000 (98.0710)  Loss: 0.2745 (0.3097)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6841)  Acc@5: 100.0000 (98.0082)  Loss: 0.2606 (0.3087)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0248)  Acc@5: 100.0000 (98.2054)  Loss: 0.2124 (0.2980)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1914)  Acc@5: 100.0000 (98.1419)  Loss: 0.1280 (0.2909)  time: 0.1568  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1240)  Acc@5: 100.0000 (98.1405)  Loss: 0.2622 (0.2949)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0668)  Acc@5: 100.0000 (98.0439)  Loss: 0.3736 (0.2968)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8848)  Acc@5: 100.0000 (97.9167)  Loss: 0.2205 (0.2973)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8510)  Acc@5: 100.0000 (97.8891)  Loss: 0.2205 (0.2980)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9379)  Acc@5: 100.0000 (97.9814)  Loss: 0.2321 (0.2948)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2705)  Acc@5: 100.0000 (97.9898)  Loss: 0.1739 (0.2870)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [180/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.5318)  Acc@5: 100.0000 (98.0663)  Loss: 0.1548 (0.2819)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2749)  Acc@5: 100.0000 (98.0366)  Loss: 0.2536 (0.2836)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2923)  Acc@5: 100.0000 (98.1032)  Loss: 0.2834 (0.2845)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2192)  Acc@5: 100.0000 (98.1339)  Loss: 0.2328 (0.2855)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2093)  Acc@5: 100.0000 (98.1335)  Loss: 0.2043 (0.2840)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (98.1331)  Loss: 0.1866 (0.2817)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0104)  Acc@5: 100.0000 (98.1587)  Loss: 0.1948 (0.2808)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8108)  Acc@5: 100.0000 (98.1076)  Loss: 0.2127 (0.2852)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6983)  Acc@5: 100.0000 (98.0843)  Loss: 0.2127 (0.2849)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6863)  Acc@5: 100.0000 (98.0858)  Loss: 0.2319 (0.2854)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8310)  Acc@5: 100.0000 (98.1317)  Loss: 0.2170 (0.2810)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7723)  Acc@5: 100.0000 (98.1744)  Loss: 0.2126 (0.2810)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6553)  Acc@5: 100.0000 (98.1935)  Loss: 0.3128 (0.2850)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5659)  Acc@5: 100.0000 (98.1712)  Loss: 0.3664 (0.2861)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)  time: 0.1533  data: 0.0002  max mem: 2377
Train: Epoch[2/5] Total time: 0:00:49 (0.1576 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)
1 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:47  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  Loss: 0.7543 (0.7543)  time: 0.3441  data: 0.1850  max mem: 2377
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.1591)  Loss: 0.2102 (0.2578)  time: 0.1737  data: 0.0171  max mem: 2377
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.0238)  Loss: 0.2338 (0.2732)  time: 0.1566  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (97.5806)  Loss: 0.2109 (0.2446)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (97.8659)  Loss: 0.1356 (0.2257)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (98.1618)  Loss: 0.1610 (0.2279)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.3607)  Loss: 0.1860 (0.2199)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2676)  Acc@5: 100.0000 (98.1514)  Loss: 0.1860 (0.2191)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4969)  Acc@5: 100.0000 (98.2253)  Loss: 0.2359 (0.2140)  time: 0.1566  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8132)  Acc@5: 100.0000 (98.2830)  Loss: 0.1575 (0.2099)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8812)  Acc@5: 100.0000 (98.2673)  Loss: 0.1877 (0.2141)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1059)  Acc@5: 100.0000 (98.3108)  Loss: 0.1590 (0.2060)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1901)  Acc@5: 100.0000 (98.3988)  Loss: 0.0767 (0.2019)  time: 0.1564  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7844)  Acc@5: 100.0000 (98.4256)  Loss: 0.1569 (0.2102)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4805)  Acc@5: 100.0000 (98.3599)  Loss: 0.3168 (0.2153)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.3444)  Loss: 0.1465 (0.2069)  time: 0.1565  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7624)  Acc@5: 100.0000 (98.3307)  Loss: 0.0906 (0.2040)  time: 0.1564  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6594)  Acc@5: 100.0000 (98.3918)  Loss: 0.1291 (0.2055)  time: 0.1566  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [180/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4986)  Acc@5: 100.0000 (98.3771)  Loss: 0.2216 (0.2095)  time: 0.1568  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5838)  Acc@5: 100.0000 (98.3312)  Loss: 0.2342 (0.2109)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6604)  Acc@5: 100.0000 (98.3209)  Loss: 0.1518 (0.2097)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6706)  Acc@5: 100.0000 (98.4005)  Loss: 0.1168 (0.2084)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5667)  Acc@5: 100.0000 (98.3597)  Loss: 0.1304 (0.2083)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5260)  Acc@5: 100.0000 (98.3496)  Loss: 0.2766 (0.2094)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6183)  Acc@5: 100.0000 (98.4180)  Loss: 0.1779 (0.2083)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4542)  Acc@5: 100.0000 (98.4313)  Loss: 0.1755 (0.2115)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.3027)  Acc@5: 100.0000 (98.4195)  Loss: 0.2220 (0.2140)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3699)  Acc@5: 100.0000 (98.4317)  Loss: 0.2187 (0.2125)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2544)  Acc@5: 100.0000 (98.4653)  Loss: 0.1817 (0.2138)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1469)  Acc@5: 100.0000 (98.3892)  Loss: 0.2616 (0.2204)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0465)  Acc@5: 100.0000 (98.4219)  Loss: 0.2693 (0.2201)  time: 0.1571  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0932)  Acc@5: 100.0000 (98.4325)  Loss: 0.2088 (0.2188)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)  time: 0.1533  data: 0.0002  max mem: 2377
Train: Epoch[3/5] Total time: 0:00:49 (0.1574 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)
1 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:55  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.4328 (0.4328)  time: 0.3676  data: 0.2094  max mem: 2377
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.7273)  Loss: 0.1321 (0.2000)  time: 0.1762  data: 0.0193  max mem: 2377
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  Loss: 0.1321 (0.1772)  time: 0.1571  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1048)  Acc@5: 100.0000 (98.1855)  Loss: 0.1484 (0.1731)  time: 0.1571  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.8049)  Acc@5: 100.0000 (98.4756)  Loss: 0.1517 (0.1607)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7745)  Loss: 0.1400 (0.1577)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.6680)  Loss: 0.1704 (0.1715)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9718)  Acc@5: 100.0000 (98.5035)  Loss: 0.1768 (0.1810)  time: 0.1571  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.4568)  Loss: 0.1170 (0.1728)  time: 0.1571  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6374)  Acc@5: 100.0000 (98.6264)  Loss: 0.1569 (0.1754)  time: 0.1571  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6856)  Acc@5: 100.0000 (98.6386)  Loss: 0.1775 (0.1708)  time: 0.1571  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4437)  Acc@5: 100.0000 (98.5360)  Loss: 0.1220 (0.1752)  time: 0.1571  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2417)  Acc@5: 100.0000 (98.5537)  Loss: 0.1624 (0.1819)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3569)  Acc@5: 100.0000 (98.5687)  Loss: 0.1624 (0.1801)  time: 0.1568  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.6259)  Loss: 0.2126 (0.1848)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1275)  Acc@5: 100.0000 (98.5099)  Loss: 0.2187 (0.1869)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9953)  Acc@5: 100.0000 (98.6025)  Loss: 0.2187 (0.1873)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.5746)  Loss: 0.1593 (0.1884)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0166)  Acc@5: 100.0000 (98.5843)  Loss: 0.1122 (0.1871)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0419)  Acc@5: 100.0000 (98.6257)  Loss: 0.0737 (0.1856)  time: 0.1571  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.5386)  Loss: 0.1639 (0.1891)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7595)  Acc@5: 100.0000 (98.5486)  Loss: 0.2365 (0.1906)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9344)  Acc@5: 100.0000 (98.5860)  Loss: 0.1304 (0.1867)  time: 0.1572  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8236)  Acc@5: 100.0000 (98.4848)  Loss: 0.1355 (0.1911)  time: 0.1571  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6701)  Acc@5: 100.0000 (98.4959)  Loss: 0.1965 (0.1945)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6534)  Acc@5: 100.0000 (98.5060)  Loss: 0.1551 (0.1956)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.4914)  Loss: 0.1251 (0.1920)  time: 0.1571  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6928)  Acc@5: 100.0000 (98.4317)  Loss: 0.0749 (0.1913)  time: 0.1569  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7438)  Acc@5: 100.0000 (98.3763)  Loss: 0.1671 (0.1919)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7483)  Acc@5: 100.0000 (98.3247)  Loss: 0.1933 (0.1917)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7940)  Acc@5: 100.0000 (98.3181)  Loss: 0.1931 (0.1938)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6961)  Acc@5: 100.0000 (98.3320)  Loss: 0.2107 (0.1947)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)  time: 0.1532  data: 0.0002  max mem: 2377
Train: Epoch[4/5] Total time: 0:00:49 (0.1577 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)
1 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1216 (0.1216)  time: 0.3254  data: 0.1663  max mem: 2377
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  Loss: 0.1216 (0.1545)  time: 0.1722  data: 0.0153  max mem: 2377
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.9167)  Loss: 0.2094 (0.2044)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (98.1855)  Loss: 0.2597 (0.1879)  time: 0.1571  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.4756)  Loss: 0.1875 (0.1984)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2941)  Acc@5: 100.0000 (98.1618)  Loss: 0.2440 (0.2058)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.2582)  Loss: 0.1058 (0.1817)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0915)  Acc@5: 100.0000 (98.1514)  Loss: 0.1057 (0.1895)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6512)  Acc@5: 100.0000 (98.3025)  Loss: 0.0564 (0.1726)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.2830)  Loss: 0.0814 (0.1805)  time: 0.1568  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3243)  Acc@5: 100.0000 (98.3911)  Loss: 0.2103 (0.1815)  time: 0.1566  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2613)  Acc@5: 100.0000 (98.4797)  Loss: 0.1329 (0.1796)  time: 0.1566  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1570)  Acc@5: 100.0000 (98.2955)  Loss: 0.1806 (0.1853)  time: 0.1567  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0687)  Acc@5: 100.0000 (98.2824)  Loss: 0.2078 (0.1867)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2145)  Acc@5: 100.0000 (98.2713)  Loss: 0.2207 (0.1884)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2583)  Acc@5: 100.0000 (98.3030)  Loss: 0.2118 (0.1879)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2189)  Acc@5: 100.0000 (98.1755)  Loss: 0.2118 (0.1911)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9284)  Acc@5: 100.0000 (98.2091)  Loss: 0.2256 (0.1952)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [180/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0843)  Acc@5: 100.0000 (98.2390)  Loss: 0.1703 (0.1915)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0275)  Acc@5: 100.0000 (98.1675)  Loss: 0.1533 (0.1914)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2251)  Acc@5: 100.0000 (98.2276)  Loss: 0.1273 (0.1861)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5225)  Acc@5: 100.0000 (98.2820)  Loss: 0.0470 (0.1798)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5385)  Acc@5: 100.0000 (98.2466)  Loss: 0.0528 (0.1818)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4989)  Acc@5: 100.0000 (98.1602)  Loss: 0.1128 (0.1838)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.1846)  Loss: 0.1082 (0.1820)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5538)  Acc@5: 100.0000 (98.1574)  Loss: 0.1564 (0.1862)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6858)  Acc@5: 100.0000 (98.2280)  Loss: 0.1103 (0.1825)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6467)  Acc@5: 100.0000 (98.2242)  Loss: 0.0471 (0.1826)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7883)  Acc@5: 100.0000 (98.2651)  Loss: 0.1327 (0.1813)  time: 0.1570  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.2388)  Loss: 0.1993 (0.1812)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8563)  Acc@5: 100.0000 (98.2558)  Loss: 0.1798 (0.1779)  time: 0.1570  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8569)  Acc@5: 100.0000 (98.2717)  Loss: 0.1237 (0.1780)  time: 0.1569  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)  time: 0.1533  data: 0.0002  max mem: 2377
Train: Epoch[5/5] Total time: 0:00:49 (0.1575 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)
Test: [Task 1]  [ 0/63]  eta: 0:00:16  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4822 (0.4822)  time: 0.2678  data: 0.1697  max mem: 2377
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.4626)  time: 0.1133  data: 0.0158  max mem: 2377
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.5112)  time: 0.0978  data: 0.0004  max mem: 2377
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (92.5403)  Acc@5: 100.0000 (100.0000)  Loss: 0.3944 (0.4803)  time: 0.0977  data: 0.0004  max mem: 2377
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (100.0000)  Loss: 0.3889 (0.4783)  time: 0.0977  data: 0.0004  max mem: 2377
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (100.0000)  Loss: 0.4046 (0.4563)  time: 0.0977  data: 0.0004  max mem: 2377
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (94.0574)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4489)  time: 0.0976  data: 0.0003  max mem: 2377
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (94.2000)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4479)  time: 0.0954  data: 0.0003  max mem: 2377
Test: [Task 1] Total time: 0:00:06 (0.1007 s / it)
* Acc@1 94.200 Acc@5 100.000 loss 0.448
Test: [Task 1]  [ 0/63]  eta: 0:00:25  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.7073 (2.7073)  time: 0.4085  data: 0.2058  max mem: 2377
Test: [Task 1]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.6785 (2.7020)  time: 0.2165  data: 0.0191  max mem: 2377
Test: [Task 1]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.6785 (2.7051)  time: 0.1970  data: 0.0004  max mem: 2377
Test: [Task 1]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.7117 (2.7219)  time: 0.1969  data: 0.0004  max mem: 2377
Test: [Task 1]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.6926 (2.6990)  time: 0.1976  data: 0.0004  max mem: 2377
Test: [Task 1]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.6267 (2.6918)  time: 0.1980  data: 0.0004  max mem: 2377
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.6817 (2.6960)  time: 0.1977  data: 0.0004  max mem: 2377
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (15.8730)  Loss: 2.6267 (2.6991)  time: 0.1930  data: 0.0004  max mem: 2377
Test: [Task 1] Total time: 0:00:12 (0.2006 s / it)
* ASR 0.000 
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5181 (0.5181)  time: 0.3146  data: 0.2169  max mem: 2377
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  Loss: 0.4899 (0.5298)  time: 0.1174  data: 0.0200  max mem: 2377
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.7024)  Loss: 0.5569 (0.6075)  time: 0.0976  data: 0.0004  max mem: 2377
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (94.7581)  Acc@5: 100.0000 (98.9919)  Loss: 0.6074 (0.6052)  time: 0.0976  data: 0.0003  max mem: 2377
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (94.3598)  Acc@5: 100.0000 (98.9329)  Loss: 0.5342 (0.5841)  time: 0.0976  data: 0.0003  max mem: 2377
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (98.8971)  Loss: 0.5183 (0.5826)  time: 0.0976  data: 0.0003  max mem: 2377
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (94.3648)  Acc@5: 100.0000 (99.0779)  Loss: 0.4840 (0.5593)  time: 0.0975  data: 0.0003  max mem: 2377
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.1000)  Loss: 0.4790 (0.5517)  time: 0.0952  data: 0.0003  max mem: 2377
Test: [Task 2] Total time: 0:00:06 (0.1016 s / it)
* Acc@1 94.500 Acc@5 99.100 loss 0.552
Test: [Task 2]  [ 0/63]  eta: 0:00:26  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 2.9868 (2.9868)  time: 0.4253  data: 0.2255  max mem: 2377
Test: [Task 2]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 3.1205 (3.2191)  time: 0.2178  data: 0.0208  max mem: 2377
Test: [Task 2]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 3.1069 (3.1970)  time: 0.1976  data: 0.0004  max mem: 2377
Test: [Task 2]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 3.1015 (3.1776)  time: 0.1979  data: 0.0004  max mem: 2377
Test: [Task 2]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 3.1703 (3.1707)  time: 0.1975  data: 0.0003  max mem: 2377
Test: [Task 2]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 3.0890 (3.1278)  time: 0.1971  data: 0.0004  max mem: 2377
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 3.0256 (3.1119)  time: 0.1967  data: 0.0003  max mem: 2377
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (15.8730)  Loss: 2.9286 (3.0931)  time: 0.1921  data: 0.0003  max mem: 2377
Test: [Task 2] Total time: 0:00:12 (0.2006 s / it)
* ASR 0.000 
[Average accuracy till task2]	ASR: 0.0000	ACC: 94.3500	Loss: 2.8961	Forgetting: 0.0000	Backward: 0.0000
2 2
Train: Epoch[1/5]  [  0/313]  eta: 0:01:41  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  Loss: 2.1259 (2.1259)  time: 0.3233  data: 0.1654  max mem: 2377
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 56.2500 (48.8636)  Acc@5: 87.5000 (80.6818)  Loss: 1.9327 (1.9322)  time: 0.1718  data: 0.0153  max mem: 2378
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (87.7976)  Loss: 1.7528 (1.7779)  time: 0.1567  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7419)  Acc@5: 100.0000 (90.5242)  Loss: 1.4664 (1.6438)  time: 0.1567  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.1890)  Acc@5: 100.0000 (91.7683)  Loss: 1.2569 (1.5223)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.8971)  Acc@5: 100.0000 (92.5245)  Loss: 1.0197 (1.4171)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.3074)  Acc@5: 100.0000 (93.2377)  Loss: 0.9046 (1.3266)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.0563)  Acc@5: 93.7500 (93.6620)  Loss: 0.8592 (1.2529)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8519)  Acc@5: 100.0000 (93.9043)  Loss: 0.6655 (1.1759)  time: 0.1567  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.7473)  Acc@5: 93.7500 (94.1621)  Loss: 0.5769 (1.1137)  time: 0.1567  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6510)  Acc@5: 93.7500 (94.3688)  Loss: 0.5593 (1.0554)  time: 0.1567  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.2230)  Acc@5: 93.7500 (94.5946)  Loss: 0.5113 (1.0125)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.2872)  Acc@5: 100.0000 (94.6798)  Loss: 0.5113 (0.9766)  time: 0.1569  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.3893)  Acc@5: 100.0000 (94.9427)  Loss: 0.5161 (0.9428)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.6543)  Acc@5: 100.0000 (95.2128)  Loss: 0.4068 (0.9073)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.8013)  Acc@5: 100.0000 (95.3642)  Loss: 0.3873 (0.8760)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.1242)  Acc@5: 100.0000 (95.4969)  Loss: 0.3963 (0.8448)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.3363)  Acc@5: 100.0000 (95.5775)  Loss: 0.3963 (0.8184)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [180/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.6630)  Acc@5: 100.0000 (95.7873)  Loss: 0.3650 (0.7932)  time: 0.1570  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.9882)  Acc@5: 100.0000 (95.8770)  Loss: 0.3364 (0.7703)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9391)  Acc@5: 100.0000 (95.9577)  Loss: 0.3827 (0.7542)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9834)  Acc@5: 100.0000 (95.9716)  Loss: 0.4242 (0.7381)  time: 0.1569  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2217)  Acc@5: 93.7500 (95.9559)  Loss: 0.2844 (0.7200)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.1039)  Loss: 0.3615 (0.7079)  time: 0.1568  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.5612)  Acc@5: 100.0000 (96.1618)  Loss: 0.3468 (0.6907)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.7231)  Acc@5: 100.0000 (96.2400)  Loss: 0.3363 (0.6771)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9444)  Acc@5: 100.0000 (96.3362)  Loss: 0.2425 (0.6616)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9188)  Acc@5: 100.0000 (96.4253)  Loss: 0.3351 (0.6533)  time: 0.1570  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1619)  Acc@5: 100.0000 (96.4413)  Loss: 0.3351 (0.6412)  time: 0.1570  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1521)  Acc@5: 100.0000 (96.4347)  Loss: 0.2624 (0.6313)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.1844)  Acc@5: 100.0000 (96.4286)  Loss: 0.3063 (0.6233)  time: 0.1569  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3352)  Acc@5: 100.0000 (96.5233)  Loss: 0.2832 (0.6131)  time: 0.1570  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)  time: 0.1533  data: 0.0002  max mem: 2378
Train: Epoch[1/5] Total time: 0:00:49 (0.1574 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)
Train: Epoch[1/5]  [  0/313]  eta: 0:03:35  Lr: 0.001875  Loss: 4.4092  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  time: 0.6894  data: 0.2030  max mem: 3946
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:30  Lr: 0.001875  Loss: 2.2019  ASR: 0.0625 (0.0739)  p_index: 16.0000 (16.0000)  time: 0.2987  data: 0.0187  max mem: 3948
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:21  Lr: 0.001875  Loss: 1.7060  ASR: 0.0625 (0.0893)  p_index: 16.0000 (16.0000)  time: 0.2592  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:17  Lr: 0.001875  Loss: 1.0432  ASR: 0.0625 (0.0887)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:13  Lr: 0.001875  Loss: 1.3058  ASR: 0.0625 (0.0976)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:10  Lr: 0.001875  Loss: 1.1850  ASR: 0.1250 (0.0968)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:07  Lr: 0.001875  Loss: 1.0410  ASR: 0.0625 (0.0943)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:04  Lr: 0.001875  Loss: 1.0885  ASR: 0.0625 (0.0924)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.3169  ASR: 0.0625 (0.0856)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 1.5272  ASR: 0.0625 (0.0824)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [100/313]  eta: 0:00:56  Lr: 0.001875  Loss: 1.1359  ASR: 0.0625 (0.0823)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [110/313]  eta: 0:00:53  Lr: 0.001875  Loss: 1.6465  ASR: 0.0625 (0.0845)  p_index: 16.0000 (16.0000)  time: 0.2589  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.9429  ASR: 0.1250 (0.0852)  p_index: 16.0000 (16.0000)  time: 0.2591  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [130/313]  eta: 0:00:47  Lr: 0.001875  Loss: 1.1168  ASR: 0.0625 (0.0854)  p_index: 16.0000 (16.0000)  time: 0.2591  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 1.4929  ASR: 0.0625 (0.0864)  p_index: 16.0000 (16.0000)  time: 0.2590  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 1.2481  ASR: 0.0625 (0.0869)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [160/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.7427  ASR: 0.0625 (0.0870)  p_index: 16.0000 (16.0000)  time: 0.2581  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 1.2166  ASR: 0.0625 (0.0855)  p_index: 16.0000 (16.0000)  time: 0.2581  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.4837  ASR: 0.0625 (0.0856)  p_index: 16.0000 (16.0000)  time: 0.2581  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [190/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.9982  ASR: 0.0625 (0.0857)  p_index: 16.0000 (16.0000)  time: 0.2578  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.3287  ASR: 0.0625 (0.0849)  p_index: 16.0000 (16.0000)  time: 0.2576  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.9017  ASR: 0.0625 (0.0859)  p_index: 16.0000 (16.0000)  time: 0.2579  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.0059  ASR: 0.0625 (0.0860)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.3169  ASR: 0.0625 (0.0841)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [240/313]  eta: 0:00:19  Lr: 0.001875  Loss: 1.1893  ASR: 0.0625 (0.0848)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.7019  ASR: 0.0625 (0.0852)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 1.3294  ASR: 0.0625 (0.0860)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.9604  ASR: 0.0625 (0.0874)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 1.4773  ASR: 0.0625 (0.0859)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [290/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.8131  ASR: 0.0625 (0.0855)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.3160  ASR: 0.0625 (0.0843)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.4600  ASR: 0.0625 (0.0832)  p_index: 16.0000 (16.0000)  time: 0.2578  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.5101  ASR: 0.0000 (0.0830)  p_index: 16.0000 (15.9744)  time: 0.2551  data: 0.0002  max mem: 3948
Train: Epoch[1/5] Total time: 0:01:21 (0.2599 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.5101  ASR: 0.0000 (0.0830)  p_index: 16.0000 (15.9744)
2 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 87.5000 (87.5000)  Loss: 0.5637 (0.5637)  time: 0.3464  data: 0.1897  max mem: 3948
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (94.8864)  Loss: 0.2795 (0.3154)  time: 0.1737  data: 0.0175  max mem: 3948
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (96.7262)  Loss: 0.2420 (0.3065)  time: 0.1566  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (97.7823)  Loss: 0.1714 (0.2426)  time: 0.1568  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (97.5610)  Loss: 0.1056 (0.2604)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (97.5490)  Loss: 0.3280 (0.2742)  time: 0.1568  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0410)  Acc@5: 93.7500 (97.0287)  Loss: 0.3319 (0.2985)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2993)  Acc@5: 93.7500 (97.0951)  Loss: 0.2568 (0.2837)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1080)  Acc@5: 93.7500 (96.7593)  Loss: 0.2611 (0.2988)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.4396)  Acc@5: 100.0000 (96.9780)  Loss: 0.2717 (0.2892)  time: 0.1568  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3342)  Acc@5: 100.0000 (97.2153)  Loss: 0.1938 (0.2840)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6419)  Acc@5: 100.0000 (97.3536)  Loss: 0.1693 (0.2731)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6405)  Acc@5: 100.0000 (97.4174)  Loss: 0.2118 (0.2758)  time: 0.1568  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [130/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.3531)  Acc@5: 100.0000 (97.5191)  Loss: 0.2153 (0.2731)  time: 0.1568  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.4167)  Acc@5: 100.0000 (97.6507)  Loss: 0.2067 (0.2680)  time: 0.1569  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6788)  Acc@5: 100.0000 (97.6821)  Loss: 0.1224 (0.2587)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.4037)  Acc@5: 100.0000 (97.6708)  Loss: 0.1833 (0.2603)  time: 0.1570  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.3436)  Acc@5: 100.0000 (97.7339)  Loss: 0.2119 (0.2605)  time: 0.1570  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.6699)  Acc@5: 100.0000 (97.7555)  Loss: 0.1625 (0.2550)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7330)  Acc@5: 100.0000 (97.8403)  Loss: 0.1267 (0.2502)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7898)  Acc@5: 100.0000 (97.8545)  Loss: 0.0769 (0.2447)  time: 0.1570  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.0190)  Acc@5: 100.0000 (97.8673)  Loss: 0.0513 (0.2376)  time: 0.1571  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1143)  Acc@5: 100.0000 (97.9072)  Loss: 0.1106 (0.2349)  time: 0.1571  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0660)  Acc@5: 100.0000 (97.9167)  Loss: 0.1994 (0.2376)  time: 0.1571  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2033)  Acc@5: 100.0000 (97.9772)  Loss: 0.1994 (0.2327)  time: 0.1571  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4293)  Acc@5: 100.0000 (98.0329)  Loss: 0.0853 (0.2286)  time: 0.1572  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5182)  Acc@5: 100.0000 (98.0364)  Loss: 0.1050 (0.2279)  time: 0.1571  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4391)  Acc@5: 100.0000 (97.9705)  Loss: 0.1894 (0.2296)  time: 0.1570  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4769)  Acc@5: 100.0000 (97.9760)  Loss: 0.1894 (0.2274)  time: 0.1571  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4476)  Acc@5: 100.0000 (97.9811)  Loss: 0.1529 (0.2273)  time: 0.1570  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3995)  Acc@5: 100.0000 (98.0482)  Loss: 0.2375 (0.2281)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4550)  Acc@5: 100.0000 (98.0105)  Loss: 0.2178 (0.2277)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4018)  Acc@5: 100.0000 (98.0232)  Loss: 0.2178 (0.2296)  time: 0.1532  data: 0.0002  max mem: 3948
Train: Epoch[2/5] Total time: 0:00:49 (0.1576 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4018)  Acc@5: 100.0000 (98.0232)  Loss: 0.2178 (0.2296)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:23  Lr: 0.001875  Loss: 1.8167  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  time: 0.4581  data: 0.1933  max mem: 3948
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:23  Lr: 0.001875  Loss: 1.1808  ASR: 0.0625 (0.0739)  p_index: 16.0000 (16.0000)  time: 0.2759  data: 0.0178  max mem: 3948
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:18  Lr: 0.001875  Loss: 1.0498  ASR: 0.0625 (0.0952)  p_index: 16.0000 (16.0000)  time: 0.2577  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:14  Lr: 0.001875  Loss: 1.2980  ASR: 0.0625 (0.0887)  p_index: 16.0000 (16.0000)  time: 0.2577  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:11  Lr: 0.001875  Loss: 1.2325  ASR: 0.0625 (0.0915)  p_index: 16.0000 (16.0000)  time: 0.2577  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:08  Lr: 0.001875  Loss: 1.9534  ASR: 0.0625 (0.0846)  p_index: 16.0000 (16.0000)  time: 0.2577  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 0.7634  ASR: 0.0625 (0.0830)  p_index: 16.0000 (16.0000)  time: 0.2577  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:03  Lr: 0.001875  Loss: 1.2545  ASR: 0.0625 (0.0907)  p_index: 16.0000 (16.0000)  time: 0.2577  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:00  Lr: 0.001875  Loss: 1.6354  ASR: 0.1250 (0.0895)  p_index: 16.0000 (16.0000)  time: 0.2576  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.5739  ASR: 0.0625 (0.0913)  p_index: 16.0000 (16.0000)  time: 0.2576  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [100/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.7415  ASR: 0.0625 (0.0928)  p_index: 16.0000 (16.0000)  time: 0.2576  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [110/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.7092  ASR: 0.0625 (0.0907)  p_index: 16.0000 (16.0000)  time: 0.2576  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.3280  ASR: 0.0625 (0.0899)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [130/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.9396  ASR: 0.0625 (0.0897)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [140/313]  eta: 0:00:44  Lr: 0.001875  Loss: 1.0884  ASR: 0.0625 (0.0900)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.8815  ASR: 0.0625 (0.0886)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [160/313]  eta: 0:00:39  Lr: 0.001875  Loss: 1.1884  ASR: 0.0625 (0.0885)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 1.3227  ASR: 0.0000 (0.0859)  p_index: 16.0000 (16.0000)  time: 0.2574  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.0857  ASR: 0.0000 (0.0843)  p_index: 16.0000 (16.0000)  time: 0.2574  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [190/313]  eta: 0:00:31  Lr: 0.001875  Loss: 1.0409  ASR: 0.0625 (0.0854)  p_index: 16.0000 (16.0000)  time: 0.2574  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.0121  ASR: 0.1250 (0.0843)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 1.1880  ASR: 0.0625 (0.0835)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.3120  ASR: 0.0625 (0.0846)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.8817  ASR: 0.0625 (0.0844)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [240/313]  eta: 0:00:18  Lr: 0.001875  Loss: 1.2160  ASR: 0.0625 (0.0858)  p_index: 16.0000 (16.0000)  time: 0.2576  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.8675  ASR: 0.1250 (0.0879)  p_index: 16.0000 (16.0000)  time: 0.2576  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.8606  ASR: 0.0625 (0.0867)  p_index: 16.0000 (16.0000)  time: 0.2575  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.6983  ASR: 0.0000 (0.0851)  p_index: 16.0000 (16.0000)  time: 0.2578  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.9853  ASR: 0.0625 (0.0859)  p_index: 16.0000 (16.0000)  time: 0.2579  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [290/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.9877  ASR: 0.0625 (0.0859)  p_index: 16.0000 (16.0000)  time: 0.2580  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.0649  ASR: 0.0625 (0.0858)  p_index: 16.0000 (16.0000)  time: 0.2581  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.8603  ASR: 0.0625 (0.0848)  p_index: 16.0000 (16.0000)  time: 0.2578  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3186  ASR: 0.0000 (0.0844)  p_index: 16.0000 (15.9744)  time: 0.2516  data: 0.0002  max mem: 3948
Train: Epoch[2/5] Total time: 0:01:20 (0.2581 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.3186  ASR: 0.0000 (0.0844)  p_index: 16.0000 (15.9744)
2 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:43  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5187 (0.5187)  time: 0.3314  data: 0.1733  max mem: 3948
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.2273)  Acc@5: 100.0000 (99.4318)  Loss: 0.1958 (0.2571)  time: 0.1728  data: 0.0160  max mem: 3948
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.8095)  Loss: 0.1067 (0.2344)  time: 0.1569  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1048)  Acc@5: 100.0000 (99.1935)  Loss: 0.1067 (0.1860)  time: 0.1570  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.3476)  Acc@5: 100.0000 (99.2378)  Loss: 0.1348 (0.1972)  time: 0.1570  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (99.1422)  Loss: 0.1348 (0.1858)  time: 0.1570  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3975)  Acc@5: 100.0000 (99.2828)  Loss: 0.1132 (0.1794)  time: 0.1573  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5317)  Acc@5: 100.0000 (99.1197)  Loss: 0.1610 (0.1972)  time: 0.1577  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.1512)  Loss: 0.1262 (0.1779)  time: 0.1578  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.2253)  Acc@5: 100.0000 (99.1758)  Loss: 0.0820 (0.1871)  time: 0.1578  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2525)  Acc@5: 100.0000 (99.0099)  Loss: 0.2164 (0.1896)  time: 0.1579  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5563)  Acc@5: 100.0000 (98.9865)  Loss: 0.2050 (0.1849)  time: 0.1581  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0868)  Acc@5: 100.0000 (98.8636)  Loss: 0.1596 (0.1949)  time: 0.1582  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2137)  Acc@5: 100.0000 (98.9027)  Loss: 0.1289 (0.1911)  time: 0.1579  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7465)  Acc@5: 100.0000 (98.6702)  Loss: 0.1391 (0.2038)  time: 0.1577  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.6341)  Loss: 0.1887 (0.2030)  time: 0.1577  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4519)  Acc@5: 100.0000 (98.5248)  Loss: 0.1953 (0.2090)  time: 0.1577  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5132)  Acc@5: 100.0000 (98.5380)  Loss: 0.1953 (0.2077)  time: 0.1576  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5331)  Acc@5: 100.0000 (98.5497)  Loss: 0.1400 (0.2053)  time: 0.1576  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5510)  Acc@5: 100.0000 (98.5275)  Loss: 0.1146 (0.2038)  time: 0.1575  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5050)  Acc@5: 100.0000 (98.5697)  Loss: 0.1122 (0.2015)  time: 0.1575  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5225)  Acc@5: 100.0000 (98.4893)  Loss: 0.1454 (0.1996)  time: 0.1574  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4819)  Acc@5: 100.0000 (98.4729)  Loss: 0.1704 (0.2031)  time: 0.1575  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5801)  Acc@5: 100.0000 (98.5119)  Loss: 0.1878 (0.2004)  time: 0.1576  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.4959)  Loss: 0.1417 (0.1996)  time: 0.1575  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7032)  Acc@5: 100.0000 (98.5309)  Loss: 0.1332 (0.1977)  time: 0.1576  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8056)  Acc@5: 100.0000 (98.4674)  Loss: 0.0854 (0.1956)  time: 0.1576  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9465)  Acc@5: 100.0000 (98.4779)  Loss: 0.0450 (0.1924)  time: 0.1574  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8995)  Acc@5: 100.0000 (98.4431)  Loss: 0.0993 (0.1920)  time: 0.1574  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9631)  Acc@5: 100.0000 (98.4536)  Loss: 0.1374 (0.1904)  time: 0.1575  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1262)  Acc@5: 100.0000 (98.4635)  Loss: 0.0690 (0.1870)  time: 0.1575  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1182)  Acc@5: 100.0000 (98.4928)  Loss: 0.0804 (0.1868)  time: 0.1575  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1605)  Acc@5: 100.0000 (98.4824)  Loss: 0.0832 (0.1865)  time: 0.1538  data: 0.0002  max mem: 3948
Train: Epoch[3/5] Total time: 0:00:49 (0.1582 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1605)  Acc@5: 100.0000 (98.4824)  Loss: 0.0832 (0.1865)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:39  Lr: 0.001875  Loss: 1.6773  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  time: 0.5100  data: 0.2432  max mem: 3948
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:25  Lr: 0.001875  Loss: 0.8553  ASR: 0.0625 (0.1023)  p_index: 16.0000 (16.0000)  time: 0.2811  data: 0.0224  max mem: 3949
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:19  Lr: 0.001875  Loss: 1.1580  ASR: 0.0625 (0.0952)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.9083  ASR: 0.0625 (0.0887)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.8081  ASR: 0.0625 (0.0884)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:09  Lr: 0.001875  Loss: 1.0992  ASR: 0.0625 (0.0895)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 1.0414  ASR: 0.0625 (0.0840)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:03  Lr: 0.001875  Loss: 1.0165  ASR: 0.0625 (0.0845)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.5064  ASR: 0.0625 (0.0880)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 1.1440  ASR: 0.0625 (0.0838)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [100/313]  eta: 0:00:55  Lr: 0.001875  Loss: 1.0095  ASR: 0.0625 (0.0823)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [110/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.7174  ASR: 0.0625 (0.0800)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.9412  ASR: 0.0625 (0.0795)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [130/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7876  ASR: 0.0625 (0.0787)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 1.0864  ASR: 0.0625 (0.0793)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.7569  ASR: 0.0625 (0.0803)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [160/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.4629  ASR: 0.0625 (0.0804)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.9779  ASR: 0.0625 (0.0793)  p_index: 16.0000 (16.0000)  time: 0.2590  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.6558  ASR: 0.0625 (0.0805)  p_index: 16.0000 (16.0000)  time: 0.2590  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [190/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.8610  ASR: 0.0625 (0.0812)  p_index: 16.0000 (16.0000)  time: 0.2589  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.0059  ASR: 0.0625 (0.0824)  p_index: 16.0000 (16.0000)  time: 0.2592  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.9174  ASR: 0.1250 (0.0853)  p_index: 16.0000 (16.0000)  time: 0.2593  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.9857  ASR: 0.0625 (0.0843)  p_index: 16.0000 (16.0000)  time: 0.2590  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.8321  ASR: 0.0625 (0.0858)  p_index: 16.0000 (16.0000)  time: 0.2590  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [240/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.9764  ASR: 0.1250 (0.0864)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.1970  ASR: 0.0625 (0.0864)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 1.3382  ASR: 0.0625 (0.0881)  p_index: 16.0000 (16.0000)  time: 0.2589  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.3644  ASR: 0.1250 (0.0890)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.7662  ASR: 0.0625 (0.0883)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [290/313]  eta: 0:00:05  Lr: 0.001875  Loss: 1.3264  ASR: 0.0625 (0.0876)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.1231  ASR: 0.0625 (0.0872)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.3284  ASR: 0.0625 (0.0868)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.1207  ASR: 0.0625 (0.0876)  p_index: 16.0000 (15.9744)  time: 0.2522  data: 0.0003  max mem: 3949
Train: Epoch[3/5] Total time: 0:01:21 (0.2594 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.1207  ASR: 0.0625 (0.0876)  p_index: 16.0000 (15.9744)
2 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:58  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: -0.0029 (-0.0029)  time: 0.3782  data: 0.2207  max mem: 3949
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (99.4318)  Loss: 0.0074 (0.1092)  time: 0.1774  data: 0.0203  max mem: 3949
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (98.8095)  Loss: 0.1376 (0.1821)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (98.1855)  Loss: 0.2600 (0.2038)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0610)  Acc@5: 100.0000 (98.0183)  Loss: 0.2600 (0.2028)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (98.2843)  Loss: 0.1180 (0.1867)  time: 0.1574  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6803)  Acc@5: 100.0000 (98.4631)  Loss: 0.0572 (0.1686)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7958)  Acc@5: 100.0000 (98.3275)  Loss: 0.0393 (0.1683)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.4568)  Loss: 0.1230 (0.1574)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.9808)  Acc@5: 100.0000 (98.4890)  Loss: 0.0630 (0.1467)  time: 0.1574  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.3045)  Acc@5: 100.0000 (98.3911)  Loss: 0.0378 (0.1434)  time: 0.1573  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1757)  Acc@5: 100.0000 (98.3108)  Loss: 0.1133 (0.1511)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1198)  Acc@5: 100.0000 (98.3988)  Loss: 0.1531 (0.1554)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.2634)  Acc@5: 100.0000 (98.3779)  Loss: 0.0754 (0.1497)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0762)  Acc@5: 100.0000 (98.3156)  Loss: 0.1151 (0.1583)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9553)  Acc@5: 100.0000 (98.4272)  Loss: 0.1351 (0.1586)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8106)  Acc@5: 100.0000 (98.4860)  Loss: 0.1765 (0.1600)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0117)  Acc@5: 100.0000 (98.4649)  Loss: 0.1356 (0.1564)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1561)  Acc@5: 100.0000 (98.4807)  Loss: 0.0287 (0.1543)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0236)  Acc@5: 100.0000 (98.3966)  Loss: 0.0897 (0.1593)  time: 0.1574  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8420)  Acc@5: 100.0000 (98.2898)  Loss: 0.1744 (0.1631)  time: 0.1574  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7666)  Acc@5: 100.0000 (98.3709)  Loss: 0.1525 (0.1629)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6980)  Acc@5: 100.0000 (98.3314)  Loss: 0.1841 (0.1665)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (87.5000)  Acc@5: 100.0000 (98.3225)  Loss: 0.2107 (0.1695)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.3402)  Loss: 0.1845 (0.1678)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6494)  Acc@5: 100.0000 (98.4064)  Loss: 0.1475 (0.1631)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7395)  Acc@5: 100.0000 (98.4674)  Loss: 0.0331 (0.1606)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7998)  Acc@5: 100.0000 (98.4548)  Loss: 0.1205 (0.1594)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8114)  Acc@5: 100.0000 (98.3986)  Loss: 0.1288 (0.1605)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8222)  Acc@5: 100.0000 (98.4107)  Loss: 0.1288 (0.1609)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7907)  Acc@5: 100.0000 (98.4219)  Loss: 0.1534 (0.1607)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8014)  Acc@5: 100.0000 (98.4526)  Loss: 0.1405 (0.1604)  time: 0.1573  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7596)  Acc@5: 100.0000 (98.4225)  Loss: 0.1405 (0.1626)  time: 0.1537  data: 0.0003  max mem: 3949
Train: Epoch[4/5] Total time: 0:00:49 (0.1583 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7596)  Acc@5: 100.0000 (98.4225)  Loss: 0.1405 (0.1626)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:34  Lr: 0.001875  Loss: 0.9827  ASR: 0.1250 (0.1250)  p_index: 16.0000 (16.0000)  time: 0.4941  data: 0.2266  max mem: 3949
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:24  Lr: 0.001875  Loss: 0.6768  ASR: 0.0625 (0.0682)  p_index: 16.0000 (16.0000)  time: 0.2804  data: 0.0209  max mem: 3949
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:19  Lr: 0.001875  Loss: 1.4645  ASR: 0.0625 (0.0804)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:15  Lr: 0.001875  Loss: 1.3182  ASR: 0.1250 (0.0907)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:12  Lr: 0.001875  Loss: 1.0416  ASR: 0.0625 (0.0838)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:09  Lr: 0.001875  Loss: 1.0934  ASR: 0.0625 (0.0797)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 0.8457  ASR: 0.0625 (0.0758)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:03  Lr: 0.001875  Loss: 0.7465  ASR: 0.0625 (0.0836)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.9989  ASR: 0.1250 (0.0826)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.7100  ASR: 0.0625 (0.0845)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [100/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.9275  ASR: 0.0625 (0.0860)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [110/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.7585  ASR: 0.1250 (0.0861)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.0371  ASR: 0.1250 (0.0899)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [130/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7275  ASR: 0.0625 (0.0902)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.9788  ASR: 0.0625 (0.0904)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.7150  ASR: 0.0625 (0.0898)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [160/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.8521  ASR: 0.0625 (0.0897)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.9372  ASR: 0.1250 (0.0932)  p_index: 16.0000 (16.0000)  time: 0.2589  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.9807  ASR: 0.1250 (0.0925)  p_index: 16.0000 (16.0000)  time: 0.2589  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [190/313]  eta: 0:00:31  Lr: 0.001875  Loss: 1.0244  ASR: 0.0625 (0.0916)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.4387  ASR: 0.0625 (0.0911)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.8278  ASR: 0.0625 (0.0906)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.7997  ASR: 0.0625 (0.0916)  p_index: 16.0000 (16.0000)  time: 0.2594  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.8034  ASR: 0.0625 (0.0901)  p_index: 16.0000 (16.0000)  time: 0.2595  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [240/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.6870  ASR: 0.0625 (0.0902)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.0539  ASR: 0.0625 (0.0914)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 1.1156  ASR: 0.0625 (0.0912)  p_index: 16.0000 (16.0000)  time: 0.2589  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.0733  ASR: 0.0625 (0.0909)  p_index: 16.0000 (16.0000)  time: 0.2590  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.8174  ASR: 0.0625 (0.0903)  p_index: 16.0000 (16.0000)  time: 0.2593  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [290/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.8276  ASR: 0.0625 (0.0909)  p_index: 16.0000 (16.0000)  time: 0.2593  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 0.7046  ASR: 0.0625 (0.0903)  p_index: 16.0000 (16.0000)  time: 0.2589  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6955  ASR: 0.0625 (0.0914)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.5167  ASR: 0.0625 (0.0914)  p_index: 16.0000 (15.9744)  time: 0.2524  data: 0.0003  max mem: 3949
Train: Epoch[4/5] Total time: 0:01:21 (0.2594 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.5167  ASR: 0.0625 (0.0914)  p_index: 16.0000 (15.9744)
2 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.0078 (0.0078)  time: 0.3581  data: 0.2002  max mem: 3949
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8636)  Loss: 0.0692 (0.1220)  time: 0.1755  data: 0.0185  max mem: 3949
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (98.8095)  Loss: 0.0692 (0.1196)  time: 0.1572  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.5887)  Loss: 0.0919 (0.1700)  time: 0.1571  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (98.7805)  Loss: 0.0659 (0.1521)  time: 0.1571  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (99.0196)  Loss: 0.0790 (0.1500)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9098)  Acc@5: 100.0000 (99.0779)  Loss: 0.1244 (0.1520)  time: 0.1573  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (87.3239)  Acc@5: 100.0000 (98.7676)  Loss: 0.1463 (0.1642)  time: 0.1571  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.8426)  Loss: 0.0495 (0.1428)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1868)  Acc@5: 100.0000 (98.7637)  Loss: -0.0458 (0.1451)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1188)  Acc@5: 100.0000 (98.8243)  Loss: 0.0477 (0.1443)  time: 0.1574  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8941)  Acc@5: 100.0000 (98.7050)  Loss: 0.1771 (0.1545)  time: 0.1572  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8099)  Acc@5: 100.0000 (98.7087)  Loss: 0.2089 (0.1566)  time: 0.1573  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6431)  Acc@5: 100.0000 (98.6164)  Loss: 0.2030 (0.1616)  time: 0.1575  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6330)  Acc@5: 100.0000 (98.6259)  Loss: 0.2030 (0.1639)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8725)  Acc@5: 100.0000 (98.6755)  Loss: 0.1151 (0.1592)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.9658)  Acc@5: 100.0000 (98.7578)  Loss: 0.0750 (0.1565)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.2675)  Acc@5: 100.0000 (98.7939)  Loss: 0.0224 (0.1473)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.2597)  Acc@5: 100.0000 (98.7914)  Loss: -0.0073 (0.1464)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.2526)  Acc@5: 100.0000 (98.7893)  Loss: 0.1069 (0.1483)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3706)  Acc@5: 100.0000 (98.8184)  Loss: 0.1072 (0.1447)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.4479)  Acc@5: 100.0000 (98.8152)  Loss: 0.0442 (0.1426)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.4898)  Acc@5: 100.0000 (98.7839)  Loss: 0.0931 (0.1420)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.5552)  Acc@5: 100.0000 (98.7825)  Loss: 0.0531 (0.1376)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.6670)  Acc@5: 100.0000 (98.7811)  Loss: -0.0140 (0.1359)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.7450)  Acc@5: 100.0000 (98.8048)  Loss: -0.0140 (0.1350)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.8170)  Acc@5: 100.0000 (98.8266)  Loss: 0.1120 (0.1362)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.7915)  Acc@5: 100.0000 (98.8699)  Loss: 0.0339 (0.1338)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.7233)  Acc@5: 100.0000 (98.8212)  Loss: 0.0612 (0.1346)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.8101)  Acc@5: 100.0000 (98.7758)  Loss: 0.0853 (0.1329)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.8081)  Acc@5: 100.0000 (98.7749)  Loss: 0.1162 (0.1342)  time: 0.1577  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.8264)  Acc@5: 100.0000 (98.7942)  Loss: 0.1348 (0.1331)  time: 0.1576  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.8379)  Acc@5: 100.0000 (98.8019)  Loss: 0.1395 (0.1339)  time: 0.1539  data: 0.0003  max mem: 3949
Train: Epoch[5/5] Total time: 0:00:49 (0.1582 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.8379)  Acc@5: 100.0000 (98.8019)  Loss: 0.1395 (0.1339)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:26  Lr: 0.001875  Loss: 0.9587  ASR: 0.1250 (0.1250)  p_index: 16.0000 (16.0000)  time: 0.4673  data: 0.1974  max mem: 3949
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:24  Lr: 0.001875  Loss: 1.0505  ASR: 0.0625 (0.0966)  p_index: 16.0000 (16.0000)  time: 0.2775  data: 0.0182  max mem: 3949
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:18  Lr: 0.001875  Loss: 0.9706  ASR: 0.0625 (0.0804)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.5163  ASR: 0.0625 (0.0827)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:11  Lr: 0.001875  Loss: 0.7448  ASR: 0.0625 (0.0854)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:09  Lr: 0.001875  Loss: 0.6340  ASR: 0.0625 (0.0833)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 0.6482  ASR: 0.0625 (0.0840)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:03  Lr: 0.001875  Loss: 0.5286  ASR: 0.0625 (0.0863)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.7349  ASR: 0.0625 (0.0887)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.9719  ASR: 0.0625 (0.0886)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [100/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.8785  ASR: 0.0625 (0.0903)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [110/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.9431  ASR: 0.1250 (0.0918)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.9466  ASR: 0.1250 (0.0930)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [130/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7227  ASR: 0.0625 (0.0926)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [140/313]  eta: 0:00:44  Lr: 0.001875  Loss: 1.6151  ASR: 0.0625 (0.0940)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.7107  ASR: 0.1250 (0.0960)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [160/313]  eta: 0:00:39  Lr: 0.001875  Loss: 1.0712  ASR: 0.1250 (0.0959)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.8030  ASR: 0.0625 (0.0947)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.5250  ASR: 0.0625 (0.0943)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [190/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.8388  ASR: 0.0625 (0.0936)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 0.8402  ASR: 0.0625 (0.0933)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 1.0793  ASR: 0.0625 (0.0921)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.8533  ASR: 0.0625 (0.0933)  p_index: 16.0000 (16.0000)  time: 0.2586  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.7521  ASR: 0.0625 (0.0933)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [240/313]  eta: 0:00:18  Lr: 0.001875  Loss: 1.1948  ASR: 0.0625 (0.0923)  p_index: 16.0000 (16.0000)  time: 0.2587  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.2804  ASR: 0.0625 (0.0924)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.6204  ASR: 0.1250 (0.0934)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.1658  ASR: 0.1250 (0.0943)  p_index: 16.0000 (16.0000)  time: 0.2588  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 1.1885  ASR: 0.0625 (0.0943)  p_index: 16.0000 (16.0000)  time: 0.2585  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [290/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.6962  ASR: 0.0625 (0.0947)  p_index: 16.0000 (16.0000)  time: 0.2583  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 0.5591  ASR: 0.0625 (0.0932)  p_index: 16.0000 (16.0000)  time: 0.2584  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.0621  ASR: 0.0625 (0.0934)  p_index: 16.0000 (16.0000)  time: 0.2582  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.1019  ASR: 0.0625 (0.0936)  p_index: 16.0000 (15.9744)  time: 0.2521  data: 0.0003  max mem: 3949
Train: Epoch[5/5] Total time: 0:01:21 (0.2591 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.1019  ASR: 0.0625 (0.0936)  p_index: 16.0000 (15.9744)
Test: [Task 1]  [ 0/63]  eta: 0:00:20  Acc@1: 50.0000 (50.0000)  Acc@5: 87.5000 (87.5000)  Loss: 1.5334 (1.5334)  time: 0.3179  data: 0.2215  max mem: 3949
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 68.7500 (66.4773)  Acc@5: 93.7500 (91.4773)  Loss: 1.3137 (1.3935)  time: 0.1178  data: 0.0205  max mem: 3949
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 62.5000 (64.5833)  Acc@5: 87.5000 (88.6905)  Loss: 1.3359 (1.5217)  time: 0.0978  data: 0.0004  max mem: 3949
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 62.5000 (65.3226)  Acc@5: 87.5000 (90.1210)  Loss: 1.3832 (1.5009)  time: 0.0978  data: 0.0004  max mem: 3949
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 68.7500 (64.9390)  Acc@5: 93.7500 (90.0915)  Loss: 1.3760 (1.5035)  time: 0.0978  data: 0.0004  max mem: 3949
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 68.7500 (64.9510)  Acc@5: 93.7500 (90.9314)  Loss: 1.3641 (1.4613)  time: 0.0977  data: 0.0004  max mem: 3949
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 62.5000 (65.1639)  Acc@5: 93.7500 (90.8811)  Loss: 1.2962 (1.4582)  time: 0.0977  data: 0.0003  max mem: 3949
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 62.5000 (65.3000)  Acc@5: 93.7500 (90.9000)  Loss: 1.3557 (1.4580)  time: 0.0954  data: 0.0003  max mem: 3949
Test: [Task 1] Total time: 0:00:06 (0.1015 s / it)
* Acc@1 65.300 Acc@5 90.900 loss 1.458
Test: [Task 1]  [ 0/63]  eta: 0:00:26  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 8.9002 (8.9002)  time: 0.4271  data: 0.2239  max mem: 3949
Test: [Task 1]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 8.6743 (8.7082)  time: 0.2178  data: 0.0207  max mem: 3949
Test: [Task 1]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0119)  p_index: 16.0000 (16.0000)  Loss: 8.6743 (8.8274)  time: 0.1969  data: 0.0003  max mem: 3949
Test: [Task 1]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0081)  p_index: 16.0000 (16.0000)  Loss: 9.1237 (8.8762)  time: 0.1971  data: 0.0003  max mem: 3949
Test: [Task 1]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0091)  p_index: 16.0000 (16.0000)  Loss: 8.9501 (8.8650)  time: 0.1971  data: 0.0004  max mem: 3949
Test: [Task 1]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0098)  p_index: 16.0000 (16.0000)  Loss: 8.6201 (8.8394)  time: 0.1971  data: 0.0003  max mem: 3949
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0102)  p_index: 16.0000 (16.0000)  Loss: 8.8972 (8.8612)  time: 0.1970  data: 0.0003  max mem: 3949
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0100)  p_index: 16.0000 (15.8730)  Loss: 8.8838 (8.8683)  time: 0.1923  data: 0.0003  max mem: 3949
Test: [Task 1] Total time: 0:00:12 (0.2005 s / it)
* ASR 0.010 
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Acc@1: 62.5000 (62.5000)  Acc@5: 87.5000 (87.5000)  Loss: 1.9149 (1.9149)  time: 0.3114  data: 0.2131  max mem: 3949
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 62.5000 (61.3636)  Acc@5: 93.7500 (90.3409)  Loss: 1.5625 (1.5275)  time: 0.1171  data: 0.0197  max mem: 3949
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 62.5000 (60.7143)  Acc@5: 87.5000 (87.7976)  Loss: 1.5934 (1.6065)  time: 0.0976  data: 0.0003  max mem: 3949
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 62.5000 (63.1048)  Acc@5: 87.5000 (88.7097)  Loss: 1.5710 (1.5679)  time: 0.0976  data: 0.0003  max mem: 3949
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 62.5000 (63.4146)  Acc@5: 93.7500 (89.4817)  Loss: 1.4324 (1.5435)  time: 0.0976  data: 0.0003  max mem: 3949
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 62.5000 (63.4804)  Acc@5: 87.5000 (89.5833)  Loss: 1.3543 (1.5304)  time: 0.0978  data: 0.0004  max mem: 3949
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 62.5000 (62.9098)  Acc@5: 87.5000 (89.7541)  Loss: 1.4780 (1.5280)  time: 0.0979  data: 0.0004  max mem: 3949
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 62.5000 (63.3000)  Acc@5: 87.5000 (89.9000)  Loss: 1.4000 (1.5161)  time: 0.0955  data: 0.0004  max mem: 3949
Test: [Task 2] Total time: 0:00:06 (0.1014 s / it)
* Acc@1 63.300 Acc@5 89.900 loss 1.516
Test: [Task 2]  [ 0/63]  eta: 0:00:25  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 9.1939 (9.1939)  time: 0.4079  data: 0.2019  max mem: 3949
Test: [Task 2]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 9.6974 (9.6251)  time: 0.2165  data: 0.0187  max mem: 3949
Test: [Task 2]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0030)  p_index: 16.0000 (16.0000)  Loss: 9.3896 (9.5757)  time: 0.1973  data: 0.0004  max mem: 3949
Test: [Task 2]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0020)  p_index: 16.0000 (16.0000)  Loss: 9.3313 (9.4989)  time: 0.1973  data: 0.0004  max mem: 3949
Test: [Task 2]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0015)  p_index: 16.0000 (16.0000)  Loss: 9.3313 (9.4747)  time: 0.1974  data: 0.0004  max mem: 3949
Test: [Task 2]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0025)  p_index: 16.0000 (16.0000)  Loss: 9.4539 (9.4207)  time: 0.1974  data: 0.0003  max mem: 3949
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0031)  p_index: 16.0000 (16.0000)  Loss: 9.4602 (9.4183)  time: 0.1973  data: 0.0003  max mem: 3949
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0030)  p_index: 16.0000 (15.8730)  Loss: 9.4539 (9.3936)  time: 0.1926  data: 0.0003  max mem: 3949
Test: [Task 2] Total time: 0:00:12 (0.2005 s / it)
* ASR 0.003 
Test: [Task 3]  [ 0/63]  eta: 0:00:19  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0320 (0.0320)  time: 0.3151  data: 0.2186  max mem: 3949
Test: [Task 3]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  Loss: 0.1153 (0.1392)  time: 0.1178  data: 0.0203  max mem: 3949
Test: [Task 3]  [20/63]  eta: 0:00:04  Acc@1: 100.0000 (97.0238)  Acc@5: 100.0000 (99.4048)  Loss: 0.1153 (0.1600)  time: 0.0979  data: 0.0004  max mem: 3949
Test: [Task 3]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (99.5968)  Loss: 0.1111 (0.1565)  time: 0.0977  data: 0.0004  max mem: 3949
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (97.2561)  Acc@5: 100.0000 (99.5427)  Loss: 0.1291 (0.1628)  time: 0.0978  data: 0.0004  max mem: 3949
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.5098)  Loss: 0.1291 (0.1590)  time: 0.0978  data: 0.0004  max mem: 3949
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (96.6189)  Acc@5: 100.0000 (99.5902)  Loss: 0.1585 (0.1695)  time: 0.0976  data: 0.0003  max mem: 3949
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (96.5000)  Acc@5: 100.0000 (99.6000)  Loss: 0.1641 (0.1736)  time: 0.0953  data: 0.0003  max mem: 3949
Test: [Task 3] Total time: 0:00:06 (0.1017 s / it)
* Acc@1 96.500 Acc@5 99.600 loss 0.174
Test: [Task 3]  [ 0/63]  eta: 0:00:26  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  Loss: 0.2248 (0.2248)  time: 0.4192  data: 0.2118  max mem: 3949
Test: [Task 3]  [10/63]  eta: 0:00:11  ASR: 0.0625 (0.0852)  p_index: 16.0000 (16.0000)  Loss: 0.4295 (0.4226)  time: 0.2177  data: 0.0196  max mem: 3949
Test: [Task 3]  [20/63]  eta: 0:00:08  ASR: 0.0625 (0.1012)  p_index: 16.0000 (16.0000)  Loss: 0.4295 (0.4857)  time: 0.1974  data: 0.0004  max mem: 3949
Test: [Task 3]  [30/63]  eta: 0:00:06  ASR: 0.0625 (0.1069)  p_index: 16.0000 (16.0000)  Loss: 0.3711 (0.4611)  time: 0.1971  data: 0.0004  max mem: 3949
Test: [Task 3]  [40/63]  eta: 0:00:04  ASR: 0.0625 (0.1098)  p_index: 16.0000 (16.0000)  Loss: 0.3852 (0.4415)  time: 0.1968  data: 0.0003  max mem: 3949
Test: [Task 3]  [50/63]  eta: 0:00:02  ASR: 0.0625 (0.1066)  p_index: 16.0000 (16.0000)  Loss: 0.3693 (0.4326)  time: 0.1967  data: 0.0003  max mem: 3949
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.1045)  p_index: 16.0000 (16.0000)  Loss: 0.3693 (0.4501)  time: 0.1967  data: 0.0003  max mem: 3949
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.1030)  p_index: 16.0000 (15.8730)  Loss: 0.3693 (0.4437)  time: 0.1920  data: 0.0003  max mem: 3949
Test: [Task 3] Total time: 0:00:12 (0.2000 s / it)
* ASR 0.103 
[Average accuracy till task3]	ASR: 0.0387	ACC: 75.0333	Loss: 6.2352	Forgetting: 0.0000	Backward: 0.0065
Total training time: 0:21:03
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
=== JOB_STATISTICS ===
=== current date     : Sun 05 Jan 2025 01:48:42 AM CET
= Job-ID             : 967069 on tinygpu
= Job-Name           : 1_2id_base_use_moreepoch
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular
= Queue/Partition    : work
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:21:37
= Total RAM usage    : 2.2 GiB of requested  GiB (%)   
= Node list          : tg081
= Subm/Elig/Start/End: 2025-01-05T00:02:34 / 2025-01-05T00:02:34 / 2025-01-05T01:27:04 / 2025-01-05T01:48:41
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           94.0G   104.9G   209.7G        N/A     204K     500K   1,000K        N/A    
    /home/woody         18.4G  1000.0G  1500.0G        N/A     136K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 3080, 00000000:3D:00.0, 936510, 95 %, 45 %, 4946 MiB, 1273871 ms
