### Starting TaskPrologue of job 966554 on tg085 at Fri 03 Jan 2025 07:44:31 PM CET
Running on cores 2-3,18-19,34-35,50-51 with governor ondemand
Fri Jan  3 19:44:31 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3080        On  |   00000000:1B:00.0 Off |                  N/A |
| 30%   36C    P8             16W /  300W |       2MiB /  10240MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', p_task_id=2, patience_epochs=10, pin_mem=True, poison_rate=0.1, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, trigger_path='trigger_0_vit_base_patch16_224.pt', unscale_lr=True, use_prompt_mask=False, use_trigger=True, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
True
trigger loaded
/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/engine.py:263: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  trigger = torch.load(args.trigger_path)
0 2
Train: Epoch[1/5]  [  0/313]  eta: 0:11:17  Lr: 0.0019 (0.0019)  Acc@1: 25.0000 (25.0000)  Acc@5: 43.7500 (43.7500)  Loss: 2.3091 (2.3091)  time: 2.1660  data: 0.6703  max mem: 2371
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:44  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (40.9091)  Acc@5: 75.0000 (73.2955)  Loss: 2.1764 (2.1620)  time: 0.3446  data: 0.0613  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:14  Lr: 0.0019 (0.0019)  Acc@1: 50.0000 (51.4881)  Acc@5: 87.5000 (80.3571)  Loss: 2.0327 (2.0359)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (55.6452)  Acc@5: 93.7500 (84.2742)  Loss: 1.8576 (1.9455)  time: 0.1557  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (59.7561)  Acc@5: 93.7500 (86.8902)  Loss: 1.6623 (1.8447)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (62.0098)  Acc@5: 93.7500 (88.4804)  Loss: 1.4252 (1.7606)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.4221)  Acc@5: 93.7500 (89.0369)  Loss: 1.3302 (1.6894)  time: 0.1561  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.1408)  Acc@5: 93.7500 (89.9648)  Loss: 1.2075 (1.6147)  time: 0.1555  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (66.9753)  Acc@5: 93.7500 (90.8179)  Loss: 1.1268 (1.5471)  time: 0.1551  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7198)  Acc@5: 93.7500 (91.3462)  Loss: 1.0733 (1.4971)  time: 0.1552  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1213)  Acc@5: 100.0000 (91.9554)  Loss: 0.9557 (1.4415)  time: 0.1552  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (69.7635)  Acc@5: 93.7500 (92.1734)  Loss: 0.9339 (1.3976)  time: 0.1554  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.2479)  Acc@5: 93.7500 (92.6136)  Loss: 0.9000 (1.3549)  time: 0.1556  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.9924)  Acc@5: 100.0000 (93.0821)  Loss: 0.8450 (1.3130)  time: 0.1558  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.8528)  Acc@5: 100.0000 (93.4397)  Loss: 0.7665 (1.2711)  time: 0.1559  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.5166)  Acc@5: 100.0000 (93.6672)  Loss: 0.6911 (1.2301)  time: 0.1561  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.8649)  Acc@5: 100.0000 (93.9053)  Loss: 0.6276 (1.1988)  time: 0.1563  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.5015)  Acc@5: 100.0000 (94.1155)  Loss: 0.6611 (1.1656)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.6188)  Acc@5: 100.0000 (94.3025)  Loss: 0.6085 (1.1378)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.2474)  Acc@5: 100.0000 (94.4372)  Loss: 0.5923 (1.1079)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.5958)  Acc@5: 93.7500 (94.4341)  Loss: 0.5806 (1.0841)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.7927)  Acc@5: 100.0000 (94.6090)  Loss: 0.6030 (1.0631)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.0566)  Acc@5: 100.0000 (94.7681)  Loss: 0.5741 (1.0410)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.2165)  Acc@5: 100.0000 (94.9134)  Loss: 0.5756 (1.0218)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.8817)  Acc@5: 100.0000 (95.0726)  Loss: 0.4548 (0.9949)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1952)  Acc@5: 100.0000 (95.1693)  Loss: 0.4640 (0.9765)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.5086)  Acc@5: 100.0000 (95.3065)  Loss: 0.5304 (0.9563)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:07  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.6836)  Acc@5: 100.0000 (95.4105)  Loss: 0.4691 (0.9400)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.9795)  Acc@5: 100.0000 (95.5738)  Loss: 0.4272 (0.9220)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.0833)  Acc@5: 100.0000 (95.5971)  Loss: 0.4377 (0.9101)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.3463)  Acc@5: 100.0000 (95.6603)  Loss: 0.4430 (0.8942)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4719)  Acc@5: 93.7500 (95.6793)  Loss: 0.4489 (0.8831)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)  time: 0.1558  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:51 (0.1631 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)
0 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:54  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.2601 (0.2601)  time: 0.3650  data: 0.2054  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (96.0227)  Loss: 0.6554 (0.5714)  time: 0.1760  data: 0.0189  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.0238)  Loss: 0.4286 (0.4585)  time: 0.1573  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.2581)  Acc@5: 100.0000 (96.9758)  Loss: 0.3460 (0.4481)  time: 0.1574  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (97.1037)  Loss: 0.3460 (0.4236)  time: 0.1575  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (97.4265)  Loss: 0.3617 (0.4173)  time: 0.1575  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.4385)  Loss: 0.3617 (0.4059)  time: 0.1575  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0669)  Acc@5: 100.0000 (97.6232)  Loss: 0.3543 (0.4041)  time: 0.1577  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9506)  Acc@5: 100.0000 (97.6080)  Loss: 0.3646 (0.4007)  time: 0.1577  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9973)  Acc@5: 100.0000 (97.5962)  Loss: 0.3185 (0.3968)  time: 0.1577  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0347)  Acc@5: 100.0000 (97.6485)  Loss: 0.3185 (0.3957)  time: 0.1578  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9527)  Acc@5: 100.0000 (97.7477)  Loss: 0.3314 (0.3899)  time: 0.1579  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8326)  Acc@5: 100.0000 (97.7273)  Loss: 0.3314 (0.3894)  time: 0.1579  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1603)  Acc@5: 100.0000 (97.6622)  Loss: 0.3256 (0.3833)  time: 0.1580  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1312)  Acc@5: 93.7500 (97.5621)  Loss: 0.3241 (0.3847)  time: 0.1580  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9818)  Acc@5: 93.7500 (97.5579)  Loss: 0.3867 (0.3854)  time: 0.1579  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8509)  Acc@5: 100.0000 (97.5155)  Loss: 0.3258 (0.3839)  time: 0.1580  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9547)  Acc@5: 100.0000 (97.5512)  Loss: 0.2723 (0.3797)  time: 0.1579  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8052)  Acc@5: 100.0000 (97.5138)  Loss: 0.3252 (0.3794)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9005)  Acc@5: 100.0000 (97.6113)  Loss: 0.2981 (0.3731)  time: 0.1581  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8308)  Acc@5: 100.0000 (97.6990)  Loss: 0.2958 (0.3716)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0344)  Acc@5: 100.0000 (97.7488)  Loss: 0.2618 (0.3659)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8518)  Acc@5: 100.0000 (97.7093)  Loss: 0.2618 (0.3686)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.8084)  Loss: 0.2166 (0.3608)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.2324)  Acc@5: 100.0000 (97.8994)  Loss: 0.1579 (0.3563)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.1882)  Acc@5: 100.0000 (97.8586)  Loss: 0.2819 (0.3544)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9559)  Acc@5: 100.0000 (97.8448)  Loss: 0.3998 (0.3589)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9253)  Acc@5: 100.0000 (97.8782)  Loss: 0.3762 (0.3573)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8746)  Acc@5: 100.0000 (97.8648)  Loss: 0.3273 (0.3553)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8703)  Acc@5: 100.0000 (97.8522)  Loss: 0.2411 (0.3530)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9909)  Acc@5: 100.0000 (97.9028)  Loss: 0.2340 (0.3493)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0836)  Acc@5: 100.0000 (97.9100)  Loss: 0.2207 (0.3477)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)  time: 0.1545  data: 0.0002  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:49 (0.1587 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)
0 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1340 (0.1340)  time: 0.3414  data: 0.1819  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  Loss: 0.2430 (0.2785)  time: 0.1750  data: 0.0168  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.9167)  Loss: 0.3333 (0.3284)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.5887)  Loss: 0.2192 (0.2731)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.3232)  Loss: 0.1146 (0.2478)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.5294)  Loss: 0.1603 (0.2371)  time: 0.1583  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.6557)  Acc@5: 100.0000 (98.2582)  Loss: 0.2495 (0.2615)  time: 0.1583  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.9155)  Acc@5: 100.0000 (98.3275)  Loss: 0.2700 (0.2600)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3426)  Acc@5: 100.0000 (98.3025)  Loss: 0.2269 (0.2561)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4011)  Acc@5: 100.0000 (98.3516)  Loss: 0.2158 (0.2540)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0767)  Acc@5: 100.0000 (98.3292)  Loss: 0.2631 (0.2544)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5991)  Acc@5: 100.0000 (98.3671)  Loss: 0.1068 (0.2408)  time: 0.1587  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0021)  Acc@5: 100.0000 (98.4504)  Loss: 0.1068 (0.2487)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5458)  Acc@5: 100.0000 (98.3779)  Loss: 0.1907 (0.2390)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7908)  Acc@5: 100.0000 (98.3599)  Loss: 0.2089 (0.2373)  time: 0.1588  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6722)  Acc@5: 100.0000 (98.4272)  Loss: 0.2159 (0.2396)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8789)  Acc@5: 100.0000 (98.5248)  Loss: 0.1434 (0.2307)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7325)  Acc@5: 100.0000 (98.5746)  Loss: 0.1122 (0.2309)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6367)  Acc@5: 100.0000 (98.5497)  Loss: 0.2248 (0.2341)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6819)  Acc@5: 100.0000 (98.5275)  Loss: 0.1644 (0.2297)  time: 0.1586  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7226)  Acc@5: 100.0000 (98.5697)  Loss: 0.1072 (0.2288)  time: 0.1586  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5818)  Acc@5: 100.0000 (98.5486)  Loss: 0.1899 (0.2336)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5950)  Acc@5: 100.0000 (98.5011)  Loss: 0.1946 (0.2318)  time: 0.1586  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.5390)  Loss: 0.1946 (0.2297)  time: 0.1588  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.4699)  Loss: 0.1495 (0.2286)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.5787)  Acc@5: 100.0000 (98.4064)  Loss: 0.1721 (0.2274)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.3956)  Loss: 0.1582 (0.2251)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7159)  Acc@5: 100.0000 (98.4087)  Loss: 0.0974 (0.2242)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7660)  Acc@5: 100.0000 (98.4208)  Loss: 0.1206 (0.2229)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7912)  Acc@5: 100.0000 (98.4107)  Loss: 0.1309 (0.2212)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9186)  Acc@5: 100.0000 (98.4427)  Loss: 0.1289 (0.2183)  time: 0.1590  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9775)  Acc@5: 100.0000 (98.4727)  Loss: 0.1218 (0.2151)  time: 0.1589  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)  time: 0.1551  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:49 (0.1594 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)
0 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:49  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1105 (0.1105)  time: 0.3498  data: 0.1895  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  Loss: 0.1945 (0.1745)  time: 0.1761  data: 0.0175  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5119)  Loss: 0.1945 (0.1660)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.5887)  Loss: 0.1687 (0.1709)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.1707)  Loss: 0.1728 (0.1912)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (98.4069)  Loss: 0.1458 (0.1734)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (98.1557)  Loss: 0.1876 (0.1957)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4437)  Acc@5: 100.0000 (98.1514)  Loss: 0.2398 (0.2087)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4198)  Acc@5: 100.0000 (98.1481)  Loss: 0.3108 (0.2089)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.1456)  Loss: 0.1457 (0.2040)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.2673)  Loss: 0.1278 (0.2026)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3176)  Acc@5: 100.0000 (98.2545)  Loss: 0.2012 (0.2047)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0021)  Acc@5: 100.0000 (98.1405)  Loss: 0.2384 (0.2080)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1641)  Acc@5: 100.0000 (98.1393)  Loss: 0.2447 (0.2050)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5248)  Acc@5: 100.0000 (98.1826)  Loss: 0.1092 (0.1991)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7550)  Acc@5: 100.0000 (98.1788)  Loss: 0.0572 (0.1944)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6460)  Acc@5: 100.0000 (98.2143)  Loss: 0.0832 (0.1987)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5863)  Acc@5: 100.0000 (98.2091)  Loss: 0.1471 (0.1985)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8094)  Acc@5: 100.0000 (98.3080)  Loss: 0.1471 (0.1947)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8783)  Acc@5: 100.0000 (98.2657)  Loss: 0.0984 (0.1936)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.2898)  Loss: 0.0847 (0.1901)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9372)  Acc@5: 100.0000 (98.3412)  Loss: 0.1282 (0.1915)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0758)  Acc@5: 100.0000 (98.3597)  Loss: 0.1562 (0.1883)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.3496)  Loss: 0.1421 (0.1869)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1629)  Acc@5: 100.0000 (98.3143)  Loss: 0.1428 (0.1863)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2012)  Acc@5: 100.0000 (98.3566)  Loss: 0.1428 (0.1858)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1648)  Acc@5: 100.0000 (98.3477)  Loss: 0.2151 (0.1859)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0849)  Acc@5: 100.0000 (98.2934)  Loss: 0.2151 (0.1883)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1219)  Acc@5: 100.0000 (98.2874)  Loss: 0.1995 (0.1879)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1134)  Acc@5: 100.0000 (98.3247)  Loss: 0.1641 (0.1893)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1678)  Acc@5: 100.0000 (98.3804)  Loss: 0.1424 (0.1875)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1182)  Acc@5: 100.0000 (98.3521)  Loss: 0.1150 (0.1878)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)  time: 0.1553  data: 0.0003  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)
0 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:50  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1773 (0.1773)  time: 0.3526  data: 0.1937  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  Loss: 0.1773 (0.1656)  time: 0.1768  data: 0.0179  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.5119)  Loss: 0.1756 (0.1675)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (97.9839)  Loss: 0.2191 (0.2073)  time: 0.1592  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0610)  Acc@5: 100.0000 (98.3232)  Loss: 0.2191 (0.2225)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0490)  Acc@5: 100.0000 (98.4069)  Loss: 0.1584 (0.2164)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7336)  Acc@5: 100.0000 (98.2582)  Loss: 0.1712 (0.2224)  time: 0.1592  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8592)  Acc@5: 100.0000 (98.1514)  Loss: 0.1792 (0.2243)  time: 0.1592  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1080)  Acc@5: 100.0000 (98.1481)  Loss: 0.1045 (0.2147)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7527)  Acc@5: 100.0000 (98.2830)  Loss: 0.1749 (0.2228)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7772)  Acc@5: 100.0000 (98.4530)  Loss: 0.1946 (0.2173)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7410)  Acc@5: 100.0000 (98.5360)  Loss: 0.2287 (0.2162)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0207)  Acc@5: 100.0000 (98.6054)  Loss: 0.1936 (0.2105)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9714)  Acc@5: 100.0000 (98.6164)  Loss: 0.1936 (0.2113)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3280)  Acc@5: 100.0000 (98.7145)  Loss: 0.1364 (0.2022)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3891)  Acc@5: 100.0000 (98.7169)  Loss: 0.1261 (0.2018)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.4425)  Acc@5: 100.0000 (98.7189)  Loss: 0.1274 (0.2008)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (98.7939)  Loss: 0.0427 (0.1903)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.9461)  Acc@5: 100.0000 (98.7569)  Loss: 0.0382 (0.1887)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9620)  Acc@5: 100.0000 (98.7565)  Loss: 0.1745 (0.1888)  time: 0.1593  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2562)  Acc@5: 100.0000 (98.7562)  Loss: 0.1815 (0.1843)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1078)  Acc@5: 100.0000 (98.7263)  Loss: 0.1329 (0.1859)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2557)  Acc@5: 100.0000 (98.7557)  Loss: 0.1382 (0.1829)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.7554)  Loss: 0.1170 (0.1814)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3589)  Acc@5: 100.0000 (98.7811)  Loss: 0.1627 (0.1803)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5040)  Acc@5: 100.0000 (98.7799)  Loss: 0.1687 (0.1783)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5421)  Acc@5: 100.0000 (98.7548)  Loss: 0.1139 (0.1761)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5775)  Acc@5: 100.0000 (98.7085)  Loss: 0.1439 (0.1787)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6326)  Acc@5: 100.0000 (98.7100)  Loss: 0.1651 (0.1792)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.7328)  Loss: 0.1124 (0.1769)  time: 0.1592  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7525)  Acc@5: 100.0000 (98.7126)  Loss: 0.1409 (0.1791)  time: 0.1592  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7966)  Acc@5: 100.0000 (98.6937)  Loss: 0.1640 (0.1763)  time: 0.1591  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)  time: 0.1553  data: 0.0002  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:50 (0.1600 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)
Test: [Task 1]  [ 0/63]  eta: 0:00:18  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4452 (0.4452)  time: 0.2887  data: 0.1914  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4146)  time: 0.1163  data: 0.0177  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4772)  time: 0.0991  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (96.7742)  Acc@5: 100.0000 (100.0000)  Loss: 0.3290 (0.4259)  time: 0.0990  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (100.0000)  Loss: 0.3048 (0.4234)  time: 0.0991  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.8775)  Loss: 0.3667 (0.4123)  time: 0.0990  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (99.8975)  Loss: 0.3730 (0.4057)  time: 0.0990  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (97.5000)  Acc@5: 100.0000 (99.9000)  Loss: 0.3730 (0.4065)  time: 0.0967  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:06 (0.1023 s / it)
* Acc@1 97.500 Acc@5 99.900 loss 0.407
Test: [Task 1]  [ 0/63]  eta: 0:00:24  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 0.9641 (0.9641)  time: 0.3922  data: 0.1958  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4545)  Loss: 0.7163 (0.7578)  time: 0.1413  data: 0.0181  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.5238)  Loss: 0.8071 (0.8591)  time: 0.1155  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7097)  Loss: 0.8821 (0.8592)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6829)  Loss: 0.7320 (0.8561)  time: 0.1151  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7059)  Loss: 0.6361 (0.8529)  time: 0.1133  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.6066)  Loss: 0.6223 (0.8246)  time: 0.1121  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.5873)  Loss: 0.5679 (0.8264)  time: 0.1086  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:07 (0.1189 s / it)
* ASR 0.000 
[Average accuracy till task1]	ASR: 0.0000	ACC: 97.5000	Loss: 0.8264
1 2
Train: Epoch[1/5]  [  0/313]  eta: 0:01:50  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  Loss: 2.1099 (2.1099)  time: 0.3521  data: 0.1913  max mem: 2374
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 31.2500 (30.1136)  Acc@5: 75.0000 (72.1591)  Loss: 1.9865 (1.9809)  time: 0.1768  data: 0.0176  max mem: 2375
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (45.5357)  Acc@5: 87.5000 (81.5476)  Loss: 1.8626 (1.8644)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (54.8387)  Acc@5: 93.7500 (85.8871)  Loss: 1.5926 (1.7596)  time: 0.1590  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (60.2134)  Acc@5: 93.7500 (88.1098)  Loss: 1.4334 (1.6578)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.2353)  Acc@5: 93.7500 (89.5833)  Loss: 1.2427 (1.5697)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.6762)  Acc@5: 100.0000 (90.7787)  Loss: 1.0970 (1.4807)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (67.9577)  Acc@5: 100.0000 (91.4613)  Loss: 0.9570 (1.4020)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1358)  Acc@5: 100.0000 (92.3611)  Loss: 0.8705 (1.3359)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.3297)  Acc@5: 100.0000 (92.8571)  Loss: 0.8177 (1.2761)  time: 0.1590  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.5965)  Acc@5: 93.7500 (93.1312)  Loss: 0.6947 (1.2153)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (72.6914)  Acc@5: 100.0000 (93.5248)  Loss: 0.5696 (1.1590)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (73.7603)  Acc@5: 100.0000 (93.8533)  Loss: 0.5555 (1.1108)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (74.5229)  Acc@5: 100.0000 (94.1794)  Loss: 0.5153 (1.0672)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.8670)  Acc@5: 100.0000 (94.4149)  Loss: 0.5817 (1.0360)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.5381)  Acc@5: 100.0000 (94.5778)  Loss: 0.5817 (0.9992)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1258)  Acc@5: 93.7500 (94.6429)  Loss: 0.4608 (0.9683)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.4254)  Acc@5: 93.7500 (94.7003)  Loss: 0.4739 (0.9395)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8301)  Acc@5: 100.0000 (94.7859)  Loss: 0.5221 (0.9160)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.1270)  Acc@5: 100.0000 (94.9935)  Loss: 0.5221 (0.8944)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.2388)  Acc@5: 100.0000 (94.9938)  Loss: 0.5255 (0.8780)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (77.4289)  Acc@5: 100.0000 (95.1718)  Loss: 0.4888 (0.8588)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.7998)  Acc@5: 100.0000 (95.2489)  Loss: 0.3734 (0.8374)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.1115)  Acc@5: 100.0000 (95.3193)  Loss: 0.3270 (0.8161)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.3454)  Acc@5: 100.0000 (95.4876)  Loss: 0.3270 (0.7971)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6604)  Acc@5: 100.0000 (95.5428)  Loss: 0.3235 (0.7789)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.0469)  Acc@5: 100.0000 (95.6657)  Loss: 0.3235 (0.7623)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.1513)  Acc@5: 100.0000 (95.7334)  Loss: 0.3178 (0.7486)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.4262)  Acc@5: 100.0000 (95.7295)  Loss: 0.3178 (0.7341)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.5103)  Acc@5: 93.7500 (95.7259)  Loss: 0.3530 (0.7232)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.5681)  Acc@5: 93.7500 (95.7226)  Loss: 0.3800 (0.7128)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7629)  Acc@5: 100.0000 (95.8601)  Loss: 0.2846 (0.6983)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)  time: 0.1554  data: 0.0002  max mem: 2375
Train: Epoch[1/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)
1 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.1860 (0.1860)  time: 0.3526  data: 0.1926  max mem: 2375
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.1591)  Loss: 0.3742 (0.3463)  time: 0.1768  data: 0.0178  max mem: 2375
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (97.6190)  Loss: 0.3607 (0.3357)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (97.9839)  Loss: 0.3258 (0.3426)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6037)  Acc@5: 100.0000 (98.1707)  Loss: 0.3258 (0.3225)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8039)  Acc@5: 100.0000 (98.2843)  Loss: 0.2535 (0.3162)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.8484)  Loss: 0.2556 (0.3232)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7711)  Acc@5: 100.0000 (97.8873)  Loss: 0.2959 (0.3084)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8765)  Acc@5: 100.0000 (98.0710)  Loss: 0.2745 (0.3097)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6841)  Acc@5: 100.0000 (98.0082)  Loss: 0.2606 (0.3087)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0248)  Acc@5: 100.0000 (98.2054)  Loss: 0.2124 (0.2980)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1914)  Acc@5: 100.0000 (98.1419)  Loss: 0.1280 (0.2909)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1240)  Acc@5: 100.0000 (98.1405)  Loss: 0.2622 (0.2949)  time: 0.1594  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0668)  Acc@5: 100.0000 (98.0439)  Loss: 0.3736 (0.2968)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8848)  Acc@5: 100.0000 (97.9167)  Loss: 0.2205 (0.2973)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8510)  Acc@5: 100.0000 (97.8891)  Loss: 0.2205 (0.2980)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9379)  Acc@5: 100.0000 (97.9814)  Loss: 0.2321 (0.2948)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2705)  Acc@5: 100.0000 (97.9898)  Loss: 0.1739 (0.2870)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.5318)  Acc@5: 100.0000 (98.0663)  Loss: 0.1548 (0.2819)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2749)  Acc@5: 100.0000 (98.0366)  Loss: 0.2536 (0.2836)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2923)  Acc@5: 100.0000 (98.1032)  Loss: 0.2834 (0.2845)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2192)  Acc@5: 100.0000 (98.1339)  Loss: 0.2328 (0.2855)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2093)  Acc@5: 100.0000 (98.1335)  Loss: 0.2043 (0.2840)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (98.1331)  Loss: 0.1866 (0.2817)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0104)  Acc@5: 100.0000 (98.1587)  Loss: 0.1948 (0.2808)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8108)  Acc@5: 100.0000 (98.1076)  Loss: 0.2127 (0.2852)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6983)  Acc@5: 100.0000 (98.0843)  Loss: 0.2127 (0.2849)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6863)  Acc@5: 100.0000 (98.0858)  Loss: 0.2319 (0.2854)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8310)  Acc@5: 100.0000 (98.1317)  Loss: 0.2170 (0.2810)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7723)  Acc@5: 100.0000 (98.1744)  Loss: 0.2126 (0.2810)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6553)  Acc@5: 100.0000 (98.1935)  Loss: 0.3128 (0.2850)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5659)  Acc@5: 100.0000 (98.1712)  Loss: 0.3664 (0.2861)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)  time: 0.1555  data: 0.0002  max mem: 2375
Train: Epoch[2/5] Total time: 0:00:50 (0.1600 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)
1 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:51  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  Loss: 0.7543 (0.7543)  time: 0.3566  data: 0.1956  max mem: 2375
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.1591)  Loss: 0.2102 (0.2578)  time: 0.1774  data: 0.0180  max mem: 2375
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.0238)  Loss: 0.2338 (0.2732)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (97.5806)  Loss: 0.2109 (0.2446)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (97.8659)  Loss: 0.1356 (0.2257)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (98.1618)  Loss: 0.1610 (0.2279)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.3607)  Loss: 0.1860 (0.2199)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2676)  Acc@5: 100.0000 (98.1514)  Loss: 0.1860 (0.2191)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4969)  Acc@5: 100.0000 (98.2253)  Loss: 0.2359 (0.2140)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8132)  Acc@5: 100.0000 (98.2830)  Loss: 0.1575 (0.2099)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8812)  Acc@5: 100.0000 (98.2673)  Loss: 0.1877 (0.2141)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1059)  Acc@5: 100.0000 (98.3108)  Loss: 0.1590 (0.2060)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1901)  Acc@5: 100.0000 (98.3988)  Loss: 0.0767 (0.2019)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7844)  Acc@5: 100.0000 (98.4256)  Loss: 0.1569 (0.2102)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4805)  Acc@5: 100.0000 (98.3599)  Loss: 0.3168 (0.2153)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.3444)  Loss: 0.1465 (0.2069)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7624)  Acc@5: 100.0000 (98.3307)  Loss: 0.0906 (0.2040)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6594)  Acc@5: 100.0000 (98.3918)  Loss: 0.1291 (0.2055)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4986)  Acc@5: 100.0000 (98.3771)  Loss: 0.2216 (0.2095)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5838)  Acc@5: 100.0000 (98.3312)  Loss: 0.2342 (0.2109)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6604)  Acc@5: 100.0000 (98.3209)  Loss: 0.1518 (0.2097)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6706)  Acc@5: 100.0000 (98.4005)  Loss: 0.1168 (0.2084)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5667)  Acc@5: 100.0000 (98.3597)  Loss: 0.1304 (0.2083)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5260)  Acc@5: 100.0000 (98.3496)  Loss: 0.2766 (0.2094)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6183)  Acc@5: 100.0000 (98.4180)  Loss: 0.1779 (0.2083)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4542)  Acc@5: 100.0000 (98.4313)  Loss: 0.1755 (0.2115)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.3027)  Acc@5: 100.0000 (98.4195)  Loss: 0.2220 (0.2140)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3699)  Acc@5: 100.0000 (98.4317)  Loss: 0.2187 (0.2125)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2544)  Acc@5: 100.0000 (98.4653)  Loss: 0.1817 (0.2138)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1469)  Acc@5: 100.0000 (98.3892)  Loss: 0.2616 (0.2204)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0465)  Acc@5: 100.0000 (98.4219)  Loss: 0.2693 (0.2201)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0932)  Acc@5: 100.0000 (98.4325)  Loss: 0.2088 (0.2188)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)  time: 0.1554  data: 0.0002  max mem: 2375
Train: Epoch[3/5] Total time: 0:00:50 (0.1600 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)
1 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.4328 (0.4328)  time: 0.3476  data: 0.1863  max mem: 2375
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.7273)  Loss: 0.1321 (0.2000)  time: 0.1762  data: 0.0172  max mem: 2375
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  Loss: 0.1321 (0.1772)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1048)  Acc@5: 100.0000 (98.1855)  Loss: 0.1484 (0.1731)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.8049)  Acc@5: 100.0000 (98.4756)  Loss: 0.1517 (0.1607)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7745)  Loss: 0.1400 (0.1577)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.6680)  Loss: 0.1704 (0.1715)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9718)  Acc@5: 100.0000 (98.5035)  Loss: 0.1768 (0.1810)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.4568)  Loss: 0.1170 (0.1728)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6374)  Acc@5: 100.0000 (98.6264)  Loss: 0.1569 (0.1754)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6856)  Acc@5: 100.0000 (98.6386)  Loss: 0.1775 (0.1708)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4437)  Acc@5: 100.0000 (98.5360)  Loss: 0.1220 (0.1752)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2417)  Acc@5: 100.0000 (98.5537)  Loss: 0.1624 (0.1819)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3569)  Acc@5: 100.0000 (98.5687)  Loss: 0.1624 (0.1801)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.6259)  Loss: 0.2126 (0.1848)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1275)  Acc@5: 100.0000 (98.5099)  Loss: 0.2187 (0.1869)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9953)  Acc@5: 100.0000 (98.6025)  Loss: 0.2187 (0.1873)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.5746)  Loss: 0.1593 (0.1884)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0166)  Acc@5: 100.0000 (98.5843)  Loss: 0.1122 (0.1871)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0419)  Acc@5: 100.0000 (98.6257)  Loss: 0.0737 (0.1856)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.5386)  Loss: 0.1639 (0.1891)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7595)  Acc@5: 100.0000 (98.5486)  Loss: 0.2365 (0.1906)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9344)  Acc@5: 100.0000 (98.5860)  Loss: 0.1304 (0.1867)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8236)  Acc@5: 100.0000 (98.4848)  Loss: 0.1355 (0.1911)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6701)  Acc@5: 100.0000 (98.4959)  Loss: 0.1965 (0.1945)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6534)  Acc@5: 100.0000 (98.5060)  Loss: 0.1551 (0.1956)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.4914)  Loss: 0.1251 (0.1920)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6928)  Acc@5: 100.0000 (98.4317)  Loss: 0.0749 (0.1913)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7438)  Acc@5: 100.0000 (98.3763)  Loss: 0.1671 (0.1919)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7483)  Acc@5: 100.0000 (98.3247)  Loss: 0.1933 (0.1917)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7940)  Acc@5: 100.0000 (98.3181)  Loss: 0.1931 (0.1938)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6961)  Acc@5: 100.0000 (98.3320)  Loss: 0.2107 (0.1947)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)  time: 0.1554  data: 0.0002  max mem: 2375
Train: Epoch[4/5] Total time: 0:00:50 (0.1599 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)
1 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:46  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1216 (0.1216)  time: 0.3417  data: 0.1811  max mem: 2375
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  Loss: 0.1216 (0.1545)  time: 0.1755  data: 0.0167  max mem: 2375
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.9167)  Loss: 0.2094 (0.2044)  time: 0.1590  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (98.1855)  Loss: 0.2597 (0.1879)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.4756)  Loss: 0.1875 (0.1984)  time: 0.1589  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2941)  Acc@5: 100.0000 (98.1618)  Loss: 0.2440 (0.2058)  time: 0.1590  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.2582)  Loss: 0.1058 (0.1817)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0915)  Acc@5: 100.0000 (98.1514)  Loss: 0.1057 (0.1895)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6512)  Acc@5: 100.0000 (98.3025)  Loss: 0.0564 (0.1726)  time: 0.1590  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.2830)  Loss: 0.0814 (0.1805)  time: 0.1590  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3243)  Acc@5: 100.0000 (98.3911)  Loss: 0.2103 (0.1815)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2613)  Acc@5: 100.0000 (98.4797)  Loss: 0.1329 (0.1796)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1570)  Acc@5: 100.0000 (98.2955)  Loss: 0.1806 (0.1853)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0687)  Acc@5: 100.0000 (98.2824)  Loss: 0.2078 (0.1867)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2145)  Acc@5: 100.0000 (98.2713)  Loss: 0.2207 (0.1884)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2583)  Acc@5: 100.0000 (98.3030)  Loss: 0.2118 (0.1879)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2189)  Acc@5: 100.0000 (98.1755)  Loss: 0.2118 (0.1911)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9284)  Acc@5: 100.0000 (98.2091)  Loss: 0.2256 (0.1952)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0843)  Acc@5: 100.0000 (98.2390)  Loss: 0.1703 (0.1915)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0275)  Acc@5: 100.0000 (98.1675)  Loss: 0.1533 (0.1914)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2251)  Acc@5: 100.0000 (98.2276)  Loss: 0.1273 (0.1861)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5225)  Acc@5: 100.0000 (98.2820)  Loss: 0.0470 (0.1798)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5385)  Acc@5: 100.0000 (98.2466)  Loss: 0.0528 (0.1818)  time: 0.1594  data: 0.0005  max mem: 2375
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4989)  Acc@5: 100.0000 (98.1602)  Loss: 0.1128 (0.1838)  time: 0.1595  data: 0.0005  max mem: 2375
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.1846)  Loss: 0.1082 (0.1820)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5538)  Acc@5: 100.0000 (98.1574)  Loss: 0.1564 (0.1862)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6858)  Acc@5: 100.0000 (98.2280)  Loss: 0.1103 (0.1825)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6467)  Acc@5: 100.0000 (98.2242)  Loss: 0.0471 (0.1826)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7883)  Acc@5: 100.0000 (98.2651)  Loss: 0.1327 (0.1813)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.2388)  Loss: 0.1993 (0.1812)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8563)  Acc@5: 100.0000 (98.2558)  Loss: 0.1798 (0.1779)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8569)  Acc@5: 100.0000 (98.2717)  Loss: 0.1237 (0.1780)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)  time: 0.1554  data: 0.0002  max mem: 2375
Train: Epoch[5/5] Total time: 0:00:49 (0.1597 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)
Test: [Task 1]  [ 0/63]  eta: 0:00:19  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4822 (0.4822)  time: 0.3072  data: 0.2098  max mem: 2375
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.4626)  time: 0.1182  data: 0.0194  max mem: 2375
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.5112)  time: 0.0992  data: 0.0003  max mem: 2375
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (92.5403)  Acc@5: 100.0000 (100.0000)  Loss: 0.3944 (0.4803)  time: 0.0991  data: 0.0003  max mem: 2375
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (100.0000)  Loss: 0.3889 (0.4783)  time: 0.0991  data: 0.0003  max mem: 2375
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (100.0000)  Loss: 0.4046 (0.4563)  time: 0.0991  data: 0.0003  max mem: 2375
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (94.0574)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4489)  time: 0.0990  data: 0.0003  max mem: 2375
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (94.2000)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4479)  time: 0.0967  data: 0.0003  max mem: 2375
Test: [Task 1] Total time: 0:00:06 (0.1027 s / it)
* Acc@1 94.200 Acc@5 100.000 loss 0.448
Test: [Task 1]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  p_index: 3.0000 (3.0000)  Loss: 1.2899 (1.2899)  time: 0.3285  data: 0.2020  max mem: 2375
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.8182)  Loss: 0.8418 (0.9302)  time: 0.1330  data: 0.0186  max mem: 2375
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7143)  Loss: 0.8418 (0.9380)  time: 0.1137  data: 0.0003  max mem: 2375
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7097)  Loss: 0.9261 (0.9124)  time: 0.1149  data: 0.0003  max mem: 2375
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.6341)  Loss: 0.8090 (0.8828)  time: 0.1133  data: 0.0003  max mem: 2375
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6275)  Loss: 0.8090 (0.8617)  time: 0.1122  data: 0.0003  max mem: 2375
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5738)  Loss: 0.7986 (0.8487)  time: 0.1130  data: 0.0003  max mem: 2375
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.5397)  Loss: 0.7986 (0.8417)  time: 0.1092  data: 0.0003  max mem: 2375
Test: [Task 1] Total time: 0:00:07 (0.1169 s / it)
* ASR 0.000 
Test: [Task 2]  [ 0/63]  eta: 0:00:17  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5181 (0.5181)  time: 0.2778  data: 0.1777  max mem: 2375
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  Loss: 0.4899 (0.5298)  time: 0.1156  data: 0.0165  max mem: 2375
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.7024)  Loss: 0.5569 (0.6075)  time: 0.0992  data: 0.0003  max mem: 2375
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (94.7581)  Acc@5: 100.0000 (98.9919)  Loss: 0.6074 (0.6052)  time: 0.0991  data: 0.0003  max mem: 2375
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (94.3598)  Acc@5: 100.0000 (98.9329)  Loss: 0.5342 (0.5841)  time: 0.0990  data: 0.0003  max mem: 2375
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (98.8971)  Loss: 0.5183 (0.5826)  time: 0.0990  data: 0.0003  max mem: 2375
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (94.3648)  Acc@5: 100.0000 (99.0779)  Loss: 0.4840 (0.5593)  time: 0.0990  data: 0.0003  max mem: 2375
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.1000)  Loss: 0.4790 (0.5517)  time: 0.0966  data: 0.0002  max mem: 2375
Test: [Task 2] Total time: 0:00:06 (0.1022 s / it)
* Acc@1 94.500 Acc@5 99.100 loss 0.552
Test: [Task 2]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 1.0307 (1.0307)  time: 0.3192  data: 0.1873  max mem: 2375
Test: [Task 2]  [10/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4545)  Loss: 0.7569 (0.8531)  time: 0.1315  data: 0.0173  max mem: 2375
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.4762)  Loss: 0.9174 (0.9042)  time: 0.1125  data: 0.0003  max mem: 2375
Test: [Task 2]  [30/63]  eta: 0:00:03  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5161)  Loss: 0.9361 (0.9015)  time: 0.1129  data: 0.0003  max mem: 2375
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5122)  Loss: 0.8842 (0.8986)  time: 0.1134  data: 0.0003  max mem: 2375
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5882)  Loss: 0.9993 (0.9251)  time: 0.1140  data: 0.0003  max mem: 2375
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6230)  Loss: 0.8921 (0.9291)  time: 0.1151  data: 0.0003  max mem: 2375
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6032)  Loss: 0.8696 (0.9187)  time: 0.1136  data: 0.0003  max mem: 2375
Test: [Task 2] Total time: 0:00:07 (0.1170 s / it)
* ASR 0.000 
[Average accuracy till task2]	ASR: 0.0000	ACC: 94.3500	Loss: 0.8802	Forgetting: 0.0000	Backward: 0.0000
2 2
Train: Epoch[1/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  Loss: 2.1259 (2.1259)  time: 0.3481  data: 0.1884  max mem: 2375
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 56.2500 (48.8636)  Acc@5: 87.5000 (80.6818)  Loss: 1.9327 (1.9322)  time: 0.1760  data: 0.0174  max mem: 2375
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (87.7976)  Loss: 1.7528 (1.7779)  time: 0.1588  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7419)  Acc@5: 100.0000 (90.5242)  Loss: 1.4664 (1.6438)  time: 0.1588  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.1890)  Acc@5: 100.0000 (91.7683)  Loss: 1.2569 (1.5223)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.8971)  Acc@5: 100.0000 (92.5245)  Loss: 1.0197 (1.4171)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.3074)  Acc@5: 100.0000 (93.2377)  Loss: 0.9046 (1.3266)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.0563)  Acc@5: 93.7500 (93.6620)  Loss: 0.8592 (1.2529)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8519)  Acc@5: 100.0000 (93.9043)  Loss: 0.6655 (1.1759)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.7473)  Acc@5: 93.7500 (94.1621)  Loss: 0.5769 (1.1137)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6510)  Acc@5: 93.7500 (94.3688)  Loss: 0.5593 (1.0554)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.2230)  Acc@5: 93.7500 (94.5946)  Loss: 0.5113 (1.0125)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.2872)  Acc@5: 100.0000 (94.6798)  Loss: 0.5113 (0.9766)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.3893)  Acc@5: 100.0000 (94.9427)  Loss: 0.5161 (0.9428)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.6543)  Acc@5: 100.0000 (95.2128)  Loss: 0.4068 (0.9073)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.8013)  Acc@5: 100.0000 (95.3642)  Loss: 0.3873 (0.8760)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.1242)  Acc@5: 100.0000 (95.4969)  Loss: 0.3963 (0.8448)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.3363)  Acc@5: 100.0000 (95.5775)  Loss: 0.3963 (0.8184)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.6630)  Acc@5: 100.0000 (95.7873)  Loss: 0.3650 (0.7932)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.9882)  Acc@5: 100.0000 (95.8770)  Loss: 0.3364 (0.7703)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9391)  Acc@5: 100.0000 (95.9577)  Loss: 0.3827 (0.7542)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9834)  Acc@5: 100.0000 (95.9716)  Loss: 0.4242 (0.7381)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2217)  Acc@5: 93.7500 (95.9559)  Loss: 0.2844 (0.7200)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.1039)  Loss: 0.3615 (0.7079)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.5612)  Acc@5: 100.0000 (96.1618)  Loss: 0.3468 (0.6907)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.7231)  Acc@5: 100.0000 (96.2400)  Loss: 0.3363 (0.6771)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9444)  Acc@5: 100.0000 (96.3362)  Loss: 0.2425 (0.6616)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9188)  Acc@5: 100.0000 (96.4253)  Loss: 0.3351 (0.6533)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1619)  Acc@5: 100.0000 (96.4413)  Loss: 0.3351 (0.6412)  time: 0.1587  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1521)  Acc@5: 100.0000 (96.4347)  Loss: 0.2624 (0.6313)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.1844)  Acc@5: 100.0000 (96.4286)  Loss: 0.3063 (0.6233)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3352)  Acc@5: 100.0000 (96.5233)  Loss: 0.2832 (0.6131)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)  time: 0.1554  data: 0.0002  max mem: 2375
Train: Epoch[1/5] Total time: 0:00:49 (0.1595 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)
Train: Epoch[1/5]  [  0/313]  eta: 0:03:43  Lr: 0.001875  Loss: 2.2805  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.0000)  time: 0.7145  data: 0.2259  max mem: 2444
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:09  Lr: 0.001875  Loss: 1.3788  ASR: 0.0000 (0.1176)  p_index: 1.0000 (1.5455)  time: 0.2291  data: 0.0207  max mem: 2652
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Lr: 0.001875  Loss: 1.2253  ASR: 0.0000 (0.1250)  p_index: 1.0000 (1.1429)  time: 0.1735  data: 0.0002  max mem: 2652
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6387  ASR: 0.0000 (0.1282)  p_index: 1.0000 (1.2581)  time: 0.1703  data: 0.0002  max mem: 2746
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.6918  ASR: 0.0000 (0.1346)  p_index: 1.0000 (1.2683)  time: 0.1729  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.0963  ASR: 0.0000 (0.1286)  p_index: 1.0000 (1.3725)  time: 0.1732  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.5909  ASR: 0.0000 (0.1034)  p_index: 2.0000 (1.4262)  time: 0.1748  data: 0.0002  max mem: 2746
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.6769  ASR: 0.0000 (0.1010)  p_index: 1.0000 (1.3944)  time: 0.1741  data: 0.0002  max mem: 2746
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.6286  ASR: 0.0000 (0.0901)  p_index: 1.0000 (1.3704)  time: 0.1734  data: 0.0002  max mem: 2746
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.6828  ASR: 0.0000 (0.1102)  p_index: 1.0000 (1.3956)  time: 0.1752  data: 0.0002  max mem: 2746
Train: Epoch[1/5]  [100/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.6264  ASR: 0.0000 (0.1064)  p_index: 1.0000 (1.3960)  time: 0.1754  data: 0.0002  max mem: 2747
Train: Epoch[1/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.8903  ASR: 0.0000 (0.1218)  p_index: 1.0000 (1.4054)  time: 0.1754  data: 0.0002  max mem: 2747
Train: Epoch[1/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7735  ASR: 0.0000 (0.1200)  p_index: 2.0000 (1.4463)  time: 0.1767  data: 0.0002  max mem: 2750
Train: Epoch[1/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3827  ASR: 0.0000 (0.1217)  p_index: 2.0000 (1.4427)  time: 0.1753  data: 0.0002  max mem: 2750
Train: Epoch[1/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.7657  ASR: 0.0000 (0.1154)  p_index: 2.0000 (1.4752)  time: 0.1758  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [150/313]  eta: 0:00:29  Lr: 0.001875  Loss: 0.6956  ASR: 0.0000 (0.1184)  p_index: 2.0000 (1.5099)  time: 0.1772  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [160/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.8272  ASR: 0.0000 (0.1245)  p_index: 1.0000 (1.4969)  time: 0.1749  data: 0.0002  max mem: 2750
Train: Epoch[1/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.7189  ASR: 0.0000 (0.1211)  p_index: 1.0000 (1.4971)  time: 0.1734  data: 0.0002  max mem: 2750
Train: Epoch[1/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.5909  ASR: 0.0000 (0.1268)  p_index: 1.0000 (1.5249)  time: 0.1759  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.6557  ASR: 0.0000 (0.1263)  p_index: 2.0000 (1.5340)  time: 0.1772  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [200/313]  eta: 0:00:20  Lr: 0.001875  Loss: 0.5712  ASR: 0.0000 (0.1266)  p_index: 1.0000 (1.5323)  time: 0.1772  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.5760  ASR: 0.0000 (0.1265)  p_index: 1.0000 (1.5355)  time: 0.1764  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.6782  ASR: 0.0000 (0.1217)  p_index: 2.0000 (1.5611)  time: 0.1772  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.8016  ASR: 0.0000 (0.1193)  p_index: 1.0000 (1.5238)  time: 0.1745  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.9209  ASR: 0.0000 (0.1167)  p_index: 1.0000 (1.5643)  time: 0.1746  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5522  ASR: 0.0000 (0.1215)  p_index: 2.0000 (1.5737)  time: 0.1778  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4654  ASR: 0.0000 (0.1244)  p_index: 2.0000 (1.5709)  time: 0.1750  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.4066  ASR: 0.0000 (0.1230)  p_index: 2.0000 (1.5904)  time: 0.1764  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.4635  ASR: 0.0000 (0.1199)  p_index: 2.0000 (1.5730)  time: 0.1751  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3069  ASR: 0.0000 (0.1184)  p_index: 1.0000 (1.5670)  time: 0.1732  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.7210  ASR: 0.0000 (0.1146)  p_index: 1.0000 (1.5648)  time: 0.1754  data: 0.0002  max mem: 2945
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7816  ASR: 0.0000 (0.1118)  p_index: 1.0000 (1.5531)  time: 0.1733  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6228  ASR: 0.0000 (0.1134)  p_index: 1.0000 (1.5495)  time: 0.1735  data: 0.0003  max mem: 2945
Train: Epoch[1/5] Total time: 0:00:55 (0.1771 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6228  ASR: 0.0000 (0.1134)  p_index: 1.0000 (1.5495)
poisoned
2 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.4423 (0.4423)  time: 0.3472  data: 0.1880  max mem: 2945
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.7273)  Loss: 0.2382 (0.2487)  time: 0.1761  data: 0.0173  max mem: 2945
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  Loss: 0.2041 (0.2459)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (98.7903)  Loss: 0.0865 (0.1923)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0427)  Acc@5: 100.0000 (98.7805)  Loss: 0.0692 (0.2056)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.6520)  Loss: 0.2037 (0.2097)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.8607)  Acc@5: 100.0000 (98.0533)  Loss: 0.2454 (0.2363)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1796)  Acc@5: 100.0000 (98.1514)  Loss: 0.2127 (0.2203)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9568)  Acc@5: 100.0000 (98.1481)  Loss: 0.1317 (0.2313)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.1456)  Loss: 0.1828 (0.2229)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.8193)  Acc@5: 100.0000 (98.2673)  Loss: 0.1325 (0.2179)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8806)  Acc@5: 100.0000 (98.2545)  Loss: 0.1140 (0.2110)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7769)  Acc@5: 100.0000 (98.1405)  Loss: 0.1415 (0.2142)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6889)  Acc@5: 100.0000 (98.1870)  Loss: 0.1873 (0.2143)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8351)  Acc@5: 100.0000 (98.2713)  Loss: 0.1490 (0.2095)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1275)  Acc@5: 100.0000 (98.3030)  Loss: 0.0998 (0.2028)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7624)  Acc@5: 100.0000 (98.2143)  Loss: 0.1408 (0.2071)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6594)  Acc@5: 100.0000 (98.2091)  Loss: 0.2249 (0.2071)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8439)  Acc@5: 100.0000 (98.2044)  Loss: 0.1501 (0.2025)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9437)  Acc@5: 100.0000 (98.2984)  Loss: 0.0586 (0.1988)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0336)  Acc@5: 100.0000 (98.2898)  Loss: 0.0002 (0.1936)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.2927)  Acc@5: 100.0000 (98.3412)  Loss: 0.0254 (0.1872)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3586)  Acc@5: 100.0000 (98.3880)  Loss: 0.0841 (0.1851)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3377)  Acc@5: 100.0000 (98.3766)  Loss: 0.1559 (0.1881)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4481)  Acc@5: 100.0000 (98.3921)  Loss: 0.1544 (0.1842)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4313)  Loss: 0.0323 (0.1810)  time: 0.1592  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4674)  Loss: 0.0958 (0.1807)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4308)  Acc@5: 100.0000 (98.4087)  Loss: 0.1487 (0.1816)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4778)  Acc@5: 100.0000 (98.3763)  Loss: 0.1487 (0.1803)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4356)  Acc@5: 100.0000 (98.3677)  Loss: 0.1454 (0.1811)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4169)  Acc@5: 100.0000 (98.4219)  Loss: 0.2153 (0.1825)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4397)  Acc@5: 100.0000 (98.3923)  Loss: 0.2153 (0.1824)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3802)  Acc@5: 100.0000 (98.4026)  Loss: 0.2162 (0.1843)  time: 0.1553  data: 0.0002  max mem: 2945
Train: Epoch[2/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3802)  Acc@5: 100.0000 (98.4026)  Loss: 0.2162 (0.1843)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:04  Lr: 0.001875  Loss: 0.6586  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.0000)  time: 0.3975  data: 0.2053  max mem: 2945
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.3939  ASR: 0.0000 (0.0556)  p_index: 2.0000 (1.6364)  time: 0.1970  data: 0.0189  max mem: 2945
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4486  ASR: 0.0000 (0.1071)  p_index: 1.0000 (1.3333)  time: 0.1737  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.9528  ASR: 0.0000 (0.1277)  p_index: 1.0000 (1.5161)  time: 0.1729  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2603  ASR: 0.0000 (0.1803)  p_index: 1.0000 (1.4878)  time: 0.1736  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:46  Lr: 0.001875  Loss: 1.0572  ASR: 0.0000 (0.1594)  p_index: 1.0000 (1.3529)  time: 0.1695  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4366  ASR: 0.0000 (0.1325)  p_index: 1.0000 (1.3607)  time: 0.1696  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.6040  ASR: 0.0000 (0.1111)  p_index: 1.0000 (1.3944)  time: 0.1730  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.9081  ASR: 0.0000 (0.1186)  p_index: 1.0000 (1.4568)  time: 0.1737  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2465  ASR: 0.0000 (0.1328)  p_index: 1.0000 (1.4066)  time: 0.1718  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [100/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.3053  ASR: 0.0000 (0.1319)  p_index: 1.0000 (1.4257)  time: 0.1710  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [110/313]  eta: 0:00:35  Lr: 0.001875  Loss: 0.7597  ASR: 0.0000 (0.1282)  p_index: 1.0000 (1.4054)  time: 0.1714  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [120/313]  eta: 0:00:33  Lr: 0.001875  Loss: 0.5635  ASR: 0.0000 (0.1337)  p_index: 1.0000 (1.4215)  time: 0.1722  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [130/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.0560  ASR: 0.0000 (0.1277)  p_index: 1.0000 (1.4351)  time: 0.1732  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.6853  ASR: 0.0000 (0.1244)  p_index: 1.0000 (1.4255)  time: 0.1717  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3557  ASR: 0.0000 (0.1176)  p_index: 1.0000 (1.4636)  time: 0.1736  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [160/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.6563  ASR: 0.0000 (0.1139)  p_index: 1.0000 (1.4720)  time: 0.1739  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [170/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.4871  ASR: 0.0000 (0.1055)  p_index: 1.0000 (1.4971)  time: 0.1732  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3235  ASR: 0.0000 (0.1007)  p_index: 2.0000 (1.4807)  time: 0.1719  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5120  ASR: 0.0000 (0.1056)  p_index: 1.0000 (1.4869)  time: 0.1708  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [200/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.6983  ASR: 0.0000 (0.0993)  p_index: 2.0000 (1.5025)  time: 0.1736  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [210/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.9998  ASR: 0.0000 (0.0997)  p_index: 2.0000 (1.5213)  time: 0.1742  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.7927  ASR: 0.0000 (0.0961)  p_index: 1.0000 (1.5068)  time: 0.1724  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.5423  ASR: 0.0000 (0.0943)  p_index: 1.0000 (1.5152)  time: 0.1719  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.5172  ASR: 0.0000 (0.0951)  p_index: 1.0000 (1.5270)  time: 0.1737  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.001875  Loss: 0.9332  ASR: 0.0000 (0.1020)  p_index: 2.0000 (1.5618)  time: 0.1765  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3608  ASR: 0.0000 (0.1012)  p_index: 1.0000 (1.5517)  time: 0.1753  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.5944  ASR: 0.0000 (0.0986)  p_index: 1.0000 (1.5720)  time: 0.1738  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.9614  ASR: 0.0000 (0.0998)  p_index: 2.0000 (1.5694)  time: 0.1736  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.001875  Loss: 0.7922  ASR: 0.0000 (0.0989)  p_index: 1.0000 (1.5636)  time: 0.1714  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3831  ASR: 0.0000 (0.1009)  p_index: 1.0000 (1.5482)  time: 0.1707  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7120  ASR: 0.0000 (0.1019)  p_index: 1.0000 (1.5466)  time: 0.1713  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1803  ASR: 0.0000 (0.1008)  p_index: 1.0000 (1.5527)  time: 0.1690  data: 0.0002  max mem: 2945
Train: Epoch[2/5] Total time: 0:00:54 (0.1736 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.1803  ASR: 0.0000 (0.1008)  p_index: 1.0000 (1.5527)
poisoned
2 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:58  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.3816 (0.3816)  time: 0.3790  data: 0.2203  max mem: 2945
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (99.4318)  Loss: 0.0772 (0.1770)  time: 0.1792  data: 0.0203  max mem: 2945
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (99.1071)  Loss: 0.0416 (0.1581)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.7258)  Acc@5: 100.0000 (98.9919)  Loss: 0.0300 (0.1247)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4817)  Acc@5: 100.0000 (98.9329)  Loss: 0.0865 (0.1447)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.7059)  Acc@5: 100.0000 (99.0196)  Loss: 0.0825 (0.1347)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5492)  Acc@5: 100.0000 (99.1803)  Loss: 0.0589 (0.1333)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.7324)  Acc@5: 100.0000 (99.0317)  Loss: 0.1488 (0.1550)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4290)  Acc@5: 100.0000 (99.0741)  Loss: 0.1318 (0.1383)  time: 0.1589  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.9423)  Acc@5: 100.0000 (99.1071)  Loss: 0.0276 (0.1449)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.6139)  Acc@5: 100.0000 (99.0099)  Loss: 0.1448 (0.1492)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.5698)  Acc@5: 100.0000 (98.9865)  Loss: 0.1194 (0.1487)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.2231)  Acc@5: 100.0000 (98.9153)  Loss: 0.1425 (0.1559)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3111)  Acc@5: 100.0000 (98.9504)  Loss: 0.0786 (0.1514)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8103)  Acc@5: 100.0000 (98.7589)  Loss: 0.1442 (0.1642)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8725)  Acc@5: 100.0000 (98.7583)  Loss: 0.1413 (0.1628)  time: 0.1589  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6553)  Acc@5: 100.0000 (98.6801)  Loss: 0.1413 (0.1697)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7193)  Acc@5: 100.0000 (98.6477)  Loss: 0.1554 (0.1688)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8108)  Acc@5: 100.0000 (98.6533)  Loss: 0.0998 (0.1639)  time: 0.1589  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8927)  Acc@5: 100.0000 (98.6911)  Loss: 0.0884 (0.1615)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8731)  Acc@5: 100.0000 (98.7562)  Loss: 0.0961 (0.1591)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7073)  Acc@5: 100.0000 (98.7559)  Loss: 0.1065 (0.1578)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6414)  Acc@5: 100.0000 (98.6708)  Loss: 0.1320 (0.1609)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7165)  Acc@5: 100.0000 (98.7284)  Loss: 0.1336 (0.1590)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7593)  Acc@5: 100.0000 (98.7293)  Loss: 0.1027 (0.1586)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8984)  Acc@5: 100.0000 (98.7799)  Loss: 0.1027 (0.1559)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.9550)  Acc@5: 100.0000 (98.7308)  Loss: 0.0451 (0.1547)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0304)  Acc@5: 100.0000 (98.7546)  Loss: 0.0226 (0.1512)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0116)  Acc@5: 100.0000 (98.7322)  Loss: 0.0226 (0.1517)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0369)  Acc@5: 100.0000 (98.7758)  Loss: 0.1034 (0.1507)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1437)  Acc@5: 100.0000 (98.7542)  Loss: 0.0982 (0.1484)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1632)  Acc@5: 100.0000 (98.7540)  Loss: 0.0598 (0.1476)  time: 0.1589  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1390)  Acc@5: 100.0000 (98.7420)  Loss: 0.0850 (0.1479)  time: 0.1552  data: 0.0002  max mem: 2945
Train: Epoch[3/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1390)  Acc@5: 100.0000 (98.7420)  Loss: 0.0850 (0.1479)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:03  Lr: 0.001875  Loss: 1.0069  ASR: 0.0000 (0.0000)  p_index: 5.0000 (5.0000)  time: 0.3948  data: 0.1850  max mem: 2945
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.0732  ASR: 0.0000 (0.0385)  p_index: 2.0000 (2.3636)  time: 0.1980  data: 0.0171  max mem: 2945
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.6681  ASR: 0.0000 (0.0465)  p_index: 2.0000 (2.0476)  time: 0.1775  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.4442  ASR: 0.0000 (0.0536)  p_index: 1.0000 (1.8065)  time: 0.1744  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2477  ASR: 0.0000 (0.0870)  p_index: 1.0000 (1.6829)  time: 0.1728  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.6170  ASR: 0.0000 (0.0805)  p_index: 1.0000 (1.7059)  time: 0.1760  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.6206  ASR: 0.0000 (0.0762)  p_index: 2.0000 (1.7213)  time: 0.1800  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3373  ASR: 0.0000 (0.0984)  p_index: 1.0000 (1.7183)  time: 0.1795  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3490  ASR: 0.0000 (0.1045)  p_index: 1.0000 (1.6543)  time: 0.1754  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.5409  ASR: 0.0000 (0.0987)  p_index: 1.0000 (1.6703)  time: 0.1754  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [100/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2035  ASR: 0.0000 (0.0988)  p_index: 2.0000 (1.7030)  time: 0.1768  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4464  ASR: 0.0000 (0.0924)  p_index: 1.0000 (1.6577)  time: 0.1732  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.0632  ASR: 0.0000 (0.0863)  p_index: 1.0000 (1.6281)  time: 0.1703  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.6207  ASR: 0.0000 (0.0870)  p_index: 1.0000 (1.5802)  time: 0.1701  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 1.0016  ASR: 0.0000 (0.0933)  p_index: 1.0000 (1.5957)  time: 0.1731  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1341  ASR: 0.0000 (0.0917)  p_index: 1.0000 (1.5894)  time: 0.1747  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [160/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1558  ASR: 0.0000 (0.0952)  p_index: 1.0000 (1.5652)  time: 0.1722  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.7656  ASR: 0.0000 (0.0906)  p_index: 1.0000 (1.5497)  time: 0.1739  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2794  ASR: 0.0000 (0.0964)  p_index: 1.0000 (1.5470)  time: 0.1752  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3824  ASR: 0.0000 (0.0983)  p_index: 1.0000 (1.5445)  time: 0.1743  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [200/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.8805  ASR: 0.0000 (0.1097)  p_index: 2.0000 (1.5871)  time: 0.1773  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.2622  ASR: 0.0000 (0.1124)  p_index: 2.0000 (1.6019)  time: 0.1787  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.5694  ASR: 0.0000 (0.1086)  p_index: 1.0000 (1.5837)  time: 0.1742  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2689  ASR: 0.0000 (0.1117)  p_index: 1.0000 (1.5887)  time: 0.1726  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.7065  ASR: 0.0000 (0.1088)  p_index: 2.0000 (1.6017)  time: 0.1743  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.6415  ASR: 0.0000 (0.1034)  p_index: 2.0000 (1.6175)  time: 0.1758  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.7640  ASR: 0.0000 (0.1038)  p_index: 1.0000 (1.6245)  time: 0.1760  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3118  ASR: 0.0000 (0.1039)  p_index: 1.0000 (1.5978)  time: 0.1715  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.6695  ASR: 0.0000 (0.1018)  p_index: 1.0000 (1.6085)  time: 0.1718  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.7809  ASR: 0.0000 (0.1000)  p_index: 2.0000 (1.6151)  time: 0.1743  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.9162  ASR: 0.0000 (0.1010)  p_index: 1.0000 (1.6113)  time: 0.1734  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5140  ASR: 0.0000 (0.0980)  p_index: 1.0000 (1.6077)  time: 0.1729  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2322  ASR: 0.0000 (0.0980)  p_index: 1.0000 (1.5974)  time: 0.1670  data: 0.0003  max mem: 2945
Train: Epoch[3/5] Total time: 0:00:54 (0.1753 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2322  ASR: 0.0000 (0.0980)  p_index: 1.0000 (1.5974)
poisoned
2 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:57  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0026 (0.0026)  time: 0.3747  data: 0.2105  max mem: 2945
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (99.4318)  Loss: 0.0132 (0.0362)  time: 0.1785  data: 0.0194  max mem: 2945
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (98.8095)  Loss: 0.0627 (0.1151)  time: 0.1589  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.7097)  Acc@5: 100.0000 (98.5887)  Loss: 0.1608 (0.1350)  time: 0.1589  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.1768)  Acc@5: 100.0000 (98.3232)  Loss: 0.1608 (0.1351)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.8480)  Acc@5: 100.0000 (98.2843)  Loss: 0.1350 (0.1265)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (98.5656)  Loss: 0.0615 (0.1123)  time: 0.1589  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2606)  Acc@5: 100.0000 (98.6796)  Loss: 0.0615 (0.1105)  time: 0.1589  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2747)  Acc@5: 100.0000 (98.8426)  Loss: 0.0678 (0.1014)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4918)  Acc@5: 100.0000 (98.8324)  Loss: 0.0632 (0.0962)  time: 0.1589  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.5421)  Acc@5: 100.0000 (98.6386)  Loss: 0.0632 (0.0964)  time: 0.1587  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3581)  Acc@5: 100.0000 (98.5923)  Loss: 0.1369 (0.1065)  time: 0.1587  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4112)  Acc@5: 100.0000 (98.7087)  Loss: 0.1471 (0.1074)  time: 0.1588  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5515)  Acc@5: 100.0000 (98.7118)  Loss: 0.0884 (0.1045)  time: 0.1587  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3174)  Acc@5: 100.0000 (98.8032)  Loss: 0.0546 (0.1100)  time: 0.1589  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3212)  Acc@5: 100.0000 (98.8825)  Loss: 0.0595 (0.1081)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2081)  Acc@5: 100.0000 (98.9519)  Loss: 0.0736 (0.1064)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4006)  Acc@5: 100.0000 (99.0132)  Loss: 0.1025 (0.1048)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5028)  Acc@5: 100.0000 (98.9986)  Loss: -0.0126 (0.1039)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3325)  Acc@5: 100.0000 (98.9856)  Loss: 0.0484 (0.1081)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2413)  Acc@5: 100.0000 (98.9117)  Loss: 0.1384 (0.1136)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2476)  Acc@5: 100.0000 (98.9633)  Loss: 0.1138 (0.1138)  time: 0.1592  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.1968)  Acc@5: 100.0000 (98.9536)  Loss: 0.1129 (0.1166)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.0963)  Acc@5: 100.0000 (98.9177)  Loss: 0.1388 (0.1212)  time: 0.1591  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.1857)  Acc@5: 100.0000 (98.9108)  Loss: 0.1786 (0.1201)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.2928)  Acc@5: 100.0000 (98.9542)  Loss: 0.0700 (0.1162)  time: 0.1594  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.3918)  Acc@5: 100.0000 (98.9703)  Loss: -0.0102 (0.1149)  time: 0.1593  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4373)  Acc@5: 100.0000 (98.9852)  Loss: 0.0720 (0.1141)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5018)  Acc@5: 100.0000 (98.9324)  Loss: 0.1050 (0.1141)  time: 0.1591  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4330)  Acc@5: 100.0000 (98.9476)  Loss: 0.1231 (0.1153)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3895)  Acc@5: 100.0000 (98.9618)  Loss: 0.0779 (0.1156)  time: 0.1590  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4092)  Acc@5: 100.0000 (98.9952)  Loss: 0.1017 (0.1158)  time: 0.1590  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3570)  Acc@5: 100.0000 (99.0016)  Loss: 0.1151 (0.1174)  time: 0.1552  data: 0.0002  max mem: 2945
Train: Epoch[4/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3570)  Acc@5: 100.0000 (99.0016)  Loss: 0.1151 (0.1174)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:05  Lr: 0.001875  Loss: 0.3930  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  time: 0.4002  data: 0.1965  max mem: 2945
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.5588  ASR: 0.0000 (0.1176)  p_index: 2.0000 (1.5455)  time: 0.1964  data: 0.0181  max mem: 2945
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:53  Lr: 0.001875  Loss: 0.6226  ASR: 0.0000 (0.0741)  p_index: 1.0000 (1.2857)  time: 0.1729  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.2432  ASR: 0.0000 (0.0455)  p_index: 1.0000 (1.4194)  time: 0.1735  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.6346  ASR: 0.0000 (0.0500)  p_index: 1.0000 (1.4634)  time: 0.1757  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7177  ASR: 0.0000 (0.0366)  p_index: 2.0000 (1.6078)  time: 0.1758  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1132  ASR: 0.0000 (0.0588)  p_index: 2.0000 (1.6721)  time: 0.1778  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.6270  ASR: 0.0000 (0.0855)  p_index: 1.0000 (1.6479)  time: 0.1764  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.6119  ASR: 0.0000 (0.0694)  p_index: 2.0000 (1.7778)  time: 0.1785  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.3937  ASR: 0.0000 (0.0683)  p_index: 2.0000 (1.7692)  time: 0.1795  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [100/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5712  ASR: 0.0000 (0.0678)  p_index: 1.0000 (1.7525)  time: 0.1769  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4351  ASR: 0.0000 (0.0789)  p_index: 1.0000 (1.7117)  time: 0.1745  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.5653  ASR: 0.0000 (0.0773)  p_index: 1.0000 (1.7107)  time: 0.1740  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3873  ASR: 0.0000 (0.0822)  p_index: 1.0000 (1.6718)  time: 0.1748  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.4074  ASR: 0.0000 (0.0855)  p_index: 1.0000 (1.6596)  time: 0.1756  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.4886  ASR: 0.0000 (0.0833)  p_index: 2.0000 (1.6689)  time: 0.1775  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [160/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3609  ASR: 0.0000 (0.0815)  p_index: 2.0000 (1.6770)  time: 0.1775  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.5024  ASR: 0.0000 (0.0862)  p_index: 2.0000 (1.6959)  time: 0.1772  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 1.0952  ASR: 0.0000 (0.0865)  p_index: 2.0000 (1.7238)  time: 0.1790  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.8163  ASR: 0.0000 (0.0843)  p_index: 2.0000 (1.7382)  time: 0.1798  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [200/313]  eta: 0:00:20  Lr: 0.001875  Loss: 0.7352  ASR: 0.0000 (0.0925)  p_index: 1.0000 (1.7214)  time: 0.1785  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.6699  ASR: 0.0000 (0.0907)  p_index: 1.0000 (1.7251)  time: 0.1784  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.7727  ASR: 0.0000 (0.1029)  p_index: 1.0000 (1.7149)  time: 0.1776  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3883  ASR: 0.0000 (0.1013)  p_index: 1.0000 (1.7100)  time: 0.1777  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.0240  ASR: 0.0000 (0.0986)  p_index: 2.0000 (1.7261)  time: 0.1792  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5771  ASR: 0.0000 (0.0984)  p_index: 2.0000 (1.7410)  time: 0.1807  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3370  ASR: 0.0000 (0.0965)  p_index: 2.0000 (1.7471)  time: 0.1803  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.7846  ASR: 0.0000 (0.0951)  p_index: 2.0000 (1.7454)  time: 0.1762  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.2928  ASR: 0.0000 (0.0909)  p_index: 2.0000 (1.7616)  time: 0.1764  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3849  ASR: 0.0000 (0.0898)  p_index: 2.0000 (1.7595)  time: 0.1784  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.4436  ASR: 0.0000 (0.0883)  p_index: 2.0000 (1.7674)  time: 0.1781  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7238  ASR: 0.0000 (0.0899)  p_index: 1.0000 (1.7524)  time: 0.1754  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.0405  ASR: 0.0000 (0.0897)  p_index: 1.0000 (1.7444)  time: 0.1703  data: 0.0003  max mem: 2947
Train: Epoch[4/5] Total time: 0:00:55 (0.1777 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.0405  ASR: 0.0000 (0.0897)  p_index: 1.0000 (1.7444)
poisoned
2 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0946 (-0.0946)  time: 0.3745  data: 0.2157  max mem: 2947
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  Loss: 0.0830 (0.0639)  time: 0.1784  data: 0.0199  max mem: 2947
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.4762)  Acc@5: 100.0000 (99.1071)  Loss: 0.0830 (0.0580)  time: 0.1588  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (98.7903)  Loss: 0.0712 (0.1033)  time: 0.1588  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (98.9329)  Loss: 0.0353 (0.0852)  time: 0.1588  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.1961)  Acc@5: 100.0000 (99.1422)  Loss: 0.0353 (0.0902)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.9590)  Acc@5: 100.0000 (99.2828)  Loss: 0.1157 (0.0904)  time: 0.1591  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.9648)  Acc@5: 100.0000 (98.8556)  Loss: 0.1211 (0.1000)  time: 0.1592  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.5864)  Acc@5: 100.0000 (98.9969)  Loss: -0.0269 (0.0812)  time: 0.1592  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.5907)  Acc@5: 100.0000 (98.9698)  Loss: -0.0724 (0.0844)  time: 0.1592  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.4084)  Acc@5: 100.0000 (99.0099)  Loss: 0.0137 (0.0832)  time: 0.1592  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.0338)  Acc@5: 100.0000 (98.9302)  Loss: 0.1078 (0.0904)  time: 0.1593  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.0310)  Acc@5: 100.0000 (98.9153)  Loss: 0.1127 (0.0924)  time: 0.1591  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.6947)  Acc@5: 100.0000 (98.7595)  Loss: 0.1543 (0.1022)  time: 0.1591  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4947)  Acc@5: 100.0000 (98.8032)  Loss: 0.1863 (0.1074)  time: 0.1592  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.6937)  Acc@5: 100.0000 (98.8411)  Loss: 0.0531 (0.1040)  time: 0.1590  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.7516)  Acc@5: 100.0000 (98.8742)  Loss: 0.0192 (0.1024)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0950)  Acc@5: 100.0000 (98.9035)  Loss: -0.0471 (0.0934)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0207)  Acc@5: 100.0000 (98.8950)  Loss: -0.0524 (0.0926)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.9869)  Acc@5: 100.0000 (98.8874)  Loss: 0.0775 (0.0954)  time: 0.1591  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1741)  Acc@5: 100.0000 (98.9117)  Loss: 0.0362 (0.0924)  time: 0.1593  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1066)  Acc@5: 100.0000 (98.9633)  Loss: 0.0037 (0.0916)  time: 0.1591  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1301)  Acc@5: 100.0000 (98.9819)  Loss: 0.0324 (0.0909)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.2597)  Acc@5: 100.0000 (99.0260)  Loss: 0.0002 (0.0860)  time: 0.1588  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.3008)  Acc@5: 100.0000 (99.0145)  Loss: -0.0591 (0.0841)  time: 0.1588  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.2888)  Acc@5: 100.0000 (99.0289)  Loss: -0.0597 (0.0832)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.3496)  Acc@5: 100.0000 (99.0182)  Loss: 0.0437 (0.0854)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.3367)  Acc@5: 100.0000 (99.0544)  Loss: 0.0540 (0.0841)  time: 0.1588  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.3247)  Acc@5: 100.0000 (99.0658)  Loss: 0.0445 (0.0833)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.3780)  Acc@5: 100.0000 (99.0765)  Loss: 0.0293 (0.0814)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.3654)  Acc@5: 100.0000 (99.0241)  Loss: 0.0382 (0.0829)  time: 0.1589  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.4140)  Acc@5: 100.0000 (99.0354)  Loss: 0.1118 (0.0822)  time: 0.1590  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.3954)  Acc@5: 100.0000 (99.0415)  Loss: 0.1118 (0.0829)  time: 0.1553  data: 0.0003  max mem: 2947
Train: Epoch[5/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.3954)  Acc@5: 100.0000 (99.0415)  Loss: 0.1118 (0.0829)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:58  Lr: 0.001875  Loss: 1.0383  ASR: 0.3333 (0.3333)  p_index: 3.0000 (3.0000)  time: 0.3772  data: 0.1792  max mem: 2947
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.4676  ASR: 0.0000 (0.1538)  p_index: 1.0000 (1.1818)  time: 0.1931  data: 0.0165  max mem: 2947
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.5671  ASR: 0.0000 (0.0968)  p_index: 1.0000 (1.4762)  time: 0.1767  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.5197  ASR: 0.0000 (0.0800)  p_index: 2.0000 (1.6129)  time: 0.1786  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.4037  ASR: 0.0000 (0.1216)  p_index: 2.0000 (1.8049)  time: 0.1795  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.4380  ASR: 0.0000 (0.1099)  p_index: 2.0000 (1.7843)  time: 0.1776  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1531  ASR: 0.0000 (0.1176)  p_index: 1.0000 (1.6721)  time: 0.1735  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.2907  ASR: 0.0000 (0.1240)  p_index: 1.0000 (1.7042)  time: 0.1760  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.4722  ASR: 0.0000 (0.1143)  p_index: 2.0000 (1.7284)  time: 0.1785  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.2700  ASR: 0.0000 (0.1111)  p_index: 2.0000 (1.6813)  time: 0.1737  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [100/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.4607  ASR: 0.0000 (0.1065)  p_index: 1.0000 (1.6733)  time: 0.1731  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.6518  ASR: 0.0000 (0.0984)  p_index: 1.0000 (1.6486)  time: 0.1747  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4221  ASR: 0.0000 (0.0918)  p_index: 1.0000 (1.6198)  time: 0.1743  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.7367  ASR: 0.0000 (0.0917)  p_index: 2.0000 (1.6641)  time: 0.1780  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.7771  ASR: 0.0000 (0.0871)  p_index: 2.0000 (1.7092)  time: 0.1801  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2350  ASR: 0.0000 (0.0920)  p_index: 1.0000 (1.6556)  time: 0.1763  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [160/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0837  ASR: 0.0000 (0.0881)  p_index: 1.0000 (1.6211)  time: 0.1724  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2846  ASR: 0.0000 (0.0912)  p_index: 1.0000 (1.6023)  time: 0.1727  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3957  ASR: 0.0000 (0.0868)  p_index: 1.0000 (1.5912)  time: 0.1739  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3134  ASR: 0.0000 (0.0858)  p_index: 1.0000 (1.5864)  time: 0.1740  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [200/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2114  ASR: 0.0000 (0.0854)  p_index: 1.0000 (1.5721)  time: 0.1727  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.1965  ASR: 0.0000 (0.0818)  p_index: 1.0000 (1.5640)  time: 0.1722  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.5922  ASR: 0.0000 (0.0857)  p_index: 2.0000 (1.5837)  time: 0.1742  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3435  ASR: 0.0000 (0.0847)  p_index: 2.0000 (1.5844)  time: 0.1757  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.8888  ASR: 0.0000 (0.0840)  p_index: 2.0000 (1.5809)  time: 0.1768  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.6775  ASR: 0.0000 (0.0874)  p_index: 1.0000 (1.5498)  time: 0.1729  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4424  ASR: 0.0000 (0.0907)  p_index: 1.0000 (1.5632)  time: 0.1738  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.4097  ASR: 0.0000 (0.0880)  p_index: 2.0000 (1.5941)  time: 0.1803  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.1423  ASR: 0.0000 (0.0878)  p_index: 2.0000 (1.5801)  time: 0.1772  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2651  ASR: 0.0000 (0.0873)  p_index: 1.0000 (1.5739)  time: 0.1725  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.2396  ASR: 0.0000 (0.0880)  p_index: 1.0000 (1.5482)  time: 0.1720  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3232  ASR: 0.0000 (0.0854)  p_index: 1.0000 (1.5434)  time: 0.1738  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2525  ASR: 0.0000 (0.0851)  p_index: 1.0000 (1.5399)  time: 0.1684  data: 0.0003  max mem: 2947
Train: Epoch[5/5] Total time: 0:00:55 (0.1760 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2525  ASR: 0.0000 (0.0851)  p_index: 1.0000 (1.5399)
poisoned
Test: [Task 1]  [ 0/63]  eta: 0:00:18  Acc@1: 6.2500 (6.2500)  Acc@5: 18.7500 (18.7500)  Loss: 4.2392 (4.2392)  time: 0.2961  data: 0.1977  max mem: 2947
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 6.2500 (7.9545)  Acc@5: 25.0000 (32.3864)  Loss: 4.2392 (4.2750)  time: 0.1172  data: 0.0183  max mem: 2947
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 6.2500 (8.0357)  Acc@5: 25.0000 (32.1429)  Loss: 4.4111 (4.4024)  time: 0.0992  data: 0.0004  max mem: 2947
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 6.2500 (7.8629)  Acc@5: 31.2500 (32.0565)  Loss: 4.2796 (4.3485)  time: 0.0991  data: 0.0004  max mem: 2947
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 6.2500 (8.9939)  Acc@5: 31.2500 (32.3171)  Loss: 4.1498 (4.3406)  time: 0.0991  data: 0.0004  max mem: 2947
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 6.2500 (8.4559)  Acc@5: 31.2500 (32.3529)  Loss: 4.1662 (4.3327)  time: 0.0991  data: 0.0004  max mem: 2947
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 6.2500 (8.4016)  Acc@5: 37.5000 (32.8893)  Loss: 4.1662 (4.3194)  time: 0.0991  data: 0.0003  max mem: 2947
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 6.2500 (8.2000)  Acc@5: 37.5000 (32.8000)  Loss: 4.1662 (4.3153)  time: 0.0967  data: 0.0003  max mem: 2947
Test: [Task 1] Total time: 0:00:06 (0.1030 s / it)
* Acc@1 8.200 Acc@5 32.800 loss 4.315
Test: [Task 1]  [ 0/63]  eta: 0:00:21  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 4.9117 (4.9117)  time: 0.3398  data: 0.2044  max mem: 2947
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0588)  p_index: 2.0000 (1.5455)  Loss: 4.9117 (4.9156)  time: 0.1336  data: 0.0189  max mem: 2947
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0357)  p_index: 1.0000 (1.3333)  Loss: 4.8437 (4.9767)  time: 0.1119  data: 0.0004  max mem: 2947
Test: [Task 1]  [30/63]  eta: 0:00:03  ASR: 0.0000 (0.0213)  p_index: 1.0000 (1.5161)  Loss: 5.1717 (5.0253)  time: 0.1137  data: 0.0004  max mem: 2947
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0185)  p_index: 1.0000 (1.3171)  Loss: 4.8915 (4.9240)  time: 0.1125  data: 0.0004  max mem: 2947
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0147)  p_index: 1.0000 (1.3333)  Loss: 4.7519 (4.9187)  time: 0.1110  data: 0.0004  max mem: 2947
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0127)  p_index: 1.0000 (1.2951)  Loss: 4.7357 (4.8892)  time: 0.1119  data: 0.0003  max mem: 2947
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0120)  p_index: 1.0000 (1.3175)  Loss: 4.7431 (4.8993)  time: 0.1097  data: 0.0003  max mem: 2947
Test: [Task 1] Total time: 0:00:07 (0.1166 s / it)
* ASR 0.012 
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Acc@1: 0.0000 (0.0000)  Acc@5: 12.5000 (12.5000)  Loss: 5.3246 (5.3246)  time: 0.3141  data: 0.2158  max mem: 2947
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 0.0000 (2.2727)  Acc@5: 18.7500 (23.2955)  Loss: 4.6814 (4.6268)  time: 0.1190  data: 0.0200  max mem: 2947
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 0.0000 (4.1667)  Acc@5: 18.7500 (24.1071)  Loss: 4.6814 (4.6803)  time: 0.0993  data: 0.0004  max mem: 2947
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 6.2500 (4.6371)  Acc@5: 25.0000 (25.6048)  Loss: 4.4135 (4.5903)  time: 0.0992  data: 0.0004  max mem: 2947
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 6.2500 (5.4878)  Acc@5: 25.0000 (26.9817)  Loss: 4.3675 (4.5603)  time: 0.0994  data: 0.0004  max mem: 2947
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 6.2500 (6.2500)  Acc@5: 25.0000 (27.2059)  Loss: 4.4734 (4.5617)  time: 0.0994  data: 0.0004  max mem: 2947
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 6.2500 (6.3525)  Acc@5: 31.2500 (28.0738)  Loss: 4.4997 (4.5378)  time: 0.0990  data: 0.0003  max mem: 2947
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 6.2500 (6.6000)  Acc@5: 31.2500 (28.4000)  Loss: 4.3731 (4.5124)  time: 0.0967  data: 0.0003  max mem: 2947
Test: [Task 2] Total time: 0:00:06 (0.1034 s / it)
* Acc@1 6.600 Acc@5 28.400 loss 4.512
Test: [Task 2]  [ 0/63]  eta: 0:00:22  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.0000)  Loss: 5.8513 (5.8513)  time: 0.3526  data: 0.2128  max mem: 2947
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.4545)  Loss: 5.3707 (5.2613)  time: 0.1350  data: 0.0196  max mem: 2947
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.1429)  Loss: 5.1105 (5.1851)  time: 0.1106  data: 0.0003  max mem: 2947
Test: [Task 2]  [30/63]  eta: 0:00:03  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.2581)  Loss: 5.0015 (5.1408)  time: 0.1107  data: 0.0004  max mem: 2947
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.3171)  Loss: 4.9496 (5.1496)  time: 0.1143  data: 0.0004  max mem: 2947
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4314)  Loss: 5.3631 (5.2206)  time: 0.1168  data: 0.0003  max mem: 2947
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4590)  Loss: 5.2031 (5.1973)  time: 0.1161  data: 0.0003  max mem: 2947
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0111)  p_index: 1.0000 (1.4286)  Loss: 5.1783 (5.1677)  time: 0.1122  data: 0.0003  max mem: 2947
Test: [Task 2] Total time: 0:00:07 (0.1175 s / it)
* ASR 0.011 
Test: [Task 3]  [ 0/63]  eta: 0:00:17  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0180 (0.0180)  time: 0.2814  data: 0.1845  max mem: 2947
Test: [Task 3]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (100.0000)  Loss: 0.0989 (0.1062)  time: 0.1161  data: 0.0171  max mem: 2947
Test: [Task 3]  [20/63]  eta: 0:00:04  Acc@1: 100.0000 (96.4286)  Acc@5: 100.0000 (100.0000)  Loss: 0.0857 (0.1148)  time: 0.0994  data: 0.0004  max mem: 2947
Test: [Task 3]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (97.1774)  Acc@5: 100.0000 (100.0000)  Loss: 0.0405 (0.0994)  time: 0.0991  data: 0.0003  max mem: 2947
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (96.7988)  Acc@5: 100.0000 (100.0000)  Loss: 0.0651 (0.1043)  time: 0.0991  data: 0.0003  max mem: 2947
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (96.8137)  Acc@5: 100.0000 (99.7549)  Loss: 0.0727 (0.1028)  time: 0.0990  data: 0.0004  max mem: 2947
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (96.6189)  Acc@5: 100.0000 (99.7951)  Loss: 0.0879 (0.1106)  time: 0.0990  data: 0.0003  max mem: 2947
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (96.6000)  Acc@5: 100.0000 (99.8000)  Loss: 0.1155 (0.1123)  time: 0.0966  data: 0.0003  max mem: 2947
Test: [Task 3] Total time: 0:00:06 (0.1023 s / it)
* Acc@1 96.600 Acc@5 99.800 loss 0.112
Test: [Task 3]  [ 0/63]  eta: 0:00:21  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 0.1560 (0.1560)  time: 0.3475  data: 0.2144  max mem: 2947
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0870)  p_index: 2.0000 (2.0909)  Loss: 0.2698 (0.3271)  time: 0.1384  data: 0.0198  max mem: 2947
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.1053)  p_index: 2.0000 (1.8095)  Loss: 0.2698 (0.2988)  time: 0.1154  data: 0.0003  max mem: 2947
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.0000 (0.0962)  p_index: 2.0000 (1.6774)  Loss: 0.2170 (0.2625)  time: 0.1133  data: 0.0004  max mem: 2947
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.1029)  p_index: 1.0000 (1.6585)  Loss: 0.2170 (0.2560)  time: 0.1136  data: 0.0004  max mem: 2947
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0989)  p_index: 2.0000 (1.7843)  Loss: 0.2389 (0.2595)  time: 0.1156  data: 0.0003  max mem: 2947
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0882)  p_index: 2.0000 (1.6721)  Loss: 0.2389 (0.2625)  time: 0.1134  data: 0.0003  max mem: 2947
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0841)  p_index: 2.0000 (1.6984)  Loss: 0.2389 (0.2698)  time: 0.1104  data: 0.0003  max mem: 2947
Test: [Task 3] Total time: 0:00:07 (0.1187 s / it)
* ASR 0.084 
[Average accuracy till task3]	ASR: 0.0358	ACC: 37.1333	Loss: 3.4456	Forgetting: 0.0000	Backward: 0.0116
Total training time: 0:18:32
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
=== JOB_STATISTICS ===
=== current date     : Fri 03 Jan 2025 08:03:23 PM CET
= Job-ID             : 966554 on tinygpu
= Job-Name           : l2p_0.1_0id_base_use
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular
= Queue/Partition    : work
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:18:56
= Total RAM usage    : 2.2 GiB of requested  GiB (%)   
= Node list          : tg085
= Subm/Elig/Start/End: 2025-01-03T19:44:26 / 2025-01-03T19:44:26 / 2025-01-03T19:44:27 / 2025-01-03T20:03:23
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           94.1G   104.9G   209.7G        N/A     204K     500K   1,000K        N/A    
    /home/woody         18.4G  1000.0G  1500.0G        N/A     136K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 3080, 00000000:1B:00.0, 2558503, 94 %, 44 %, 3750 MiB, 1121953 ms
