### Starting TaskPrologue of job 925034 on tg073 at Sun 03 Nov 2024 02:05:22 PM CET
Running on cores 6-7,14-15,22-23,30-31 with governor ondemand
Sun Nov  3 14:05:22 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:AF:00.0 Off |                    0 |
| N/A   34C    P0             27W /  250W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', patience_epochs=10, pin_mem=True, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, unscale_lr=True, use_prompt_mask=False, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
Train: Epoch[1/5]  [  0/313]  eta: 1:02:28  Loss: 2.2899 (2.2899)  ASR: 10.0000 (10.0000)  time: 11.9775  data: 0.3865  max mem: 2377
Train: Epoch[1/5]  [ 10/313]  eta: 0:06:22  Loss: 2.2826 (2.2828)  ASR: 18.1818 (19.7083)  time: 1.2611  data: 0.0354  max mem: 2381
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:40  Loss: 2.2880 (2.2893)  ASR: 18.1818 (17.8698)  time: 0.1899  data: 0.0003  max mem: 2381
Train: Epoch[1/5]  [ 30/313]  eta: 0:02:41  Loss: 2.2890 (2.2883)  ASR: 13.3333 (16.8707)  time: 0.1911  data: 0.0003  max mem: 2381
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:10  Loss: 2.2865 (2.2866)  ASR: 14.2857 (17.0268)  time: 0.1907  data: 0.0002  max mem: 2381
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:50  Loss: 2.2847 (2.2857)  ASR: 21.4286 (17.0603)  time: 0.1900  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:37  Loss: 2.2758 (2.2847)  ASR: 14.2857 (17.0018)  time: 0.1907  data: 0.0004  max mem: 2382
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:26  Loss: 2.2789 (2.2841)  ASR: 15.3846 (17.0776)  time: 0.1903  data: 0.0004  max mem: 2382
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:18  Loss: 2.2771 (2.2823)  ASR: 20.0000 (18.1795)  time: 0.1905  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:11  Loss: 2.2781 (2.2826)  ASR: 21.4286 (17.5637)  time: 0.1907  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [100/313]  eta: 0:01:05  Loss: 2.2838 (2.2822)  ASR: 14.2857 (17.8525)  time: 0.1905  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [110/313]  eta: 0:01:00  Loss: 2.2768 (2.2817)  ASR: 16.6667 (17.9172)  time: 0.1907  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [120/313]  eta: 0:00:55  Loss: 2.2721 (2.2803)  ASR: 21.4286 (18.2566)  time: 0.1908  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [130/313]  eta: 0:00:51  Loss: 2.2645 (2.2795)  ASR: 16.6667 (18.1434)  time: 0.1914  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [140/313]  eta: 0:00:47  Loss: 2.2644 (2.2783)  ASR: 16.6667 (18.4327)  time: 0.1920  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [150/313]  eta: 0:00:43  Loss: 2.2532 (2.2762)  ASR: 26.6667 (19.5166)  time: 0.1907  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [160/313]  eta: 0:00:40  Loss: 2.2308 (2.2737)  ASR: 30.7692 (19.9674)  time: 0.1906  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [170/313]  eta: 0:00:37  Loss: 2.2300 (2.2715)  ASR: 23.0769 (20.4167)  time: 0.1910  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [180/313]  eta: 0:00:34  Loss: 2.2237 (2.2683)  ASR: 36.3636 (21.8737)  time: 0.1905  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [190/313]  eta: 0:00:31  Loss: 2.2028 (2.2651)  ASR: 46.6667 (23.1340)  time: 0.1904  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [200/313]  eta: 0:00:28  Loss: 2.1979 (2.2612)  ASR: 53.8462 (24.9348)  time: 0.1902  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [210/313]  eta: 0:00:25  Loss: 2.1897 (2.2578)  ASR: 58.3333 (26.6419)  time: 0.1903  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [220/313]  eta: 0:00:22  Loss: 2.1849 (2.2540)  ASR: 58.3333 (28.3838)  time: 0.1918  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [230/313]  eta: 0:00:20  Loss: 2.1508 (2.2493)  ASR: 72.7273 (30.3653)  time: 0.1918  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [240/313]  eta: 0:00:17  Loss: 2.1366 (2.2447)  ASR: 75.0000 (32.2990)  time: 0.1914  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [250/313]  eta: 0:00:14  Loss: 2.1252 (2.2401)  ASR: 80.0000 (34.3550)  time: 0.1919  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [260/313]  eta: 0:00:12  Loss: 2.1136 (2.2350)  ASR: 85.7143 (36.3810)  time: 0.1916  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [270/313]  eta: 0:00:10  Loss: 2.0998 (2.2299)  ASR: 90.9091 (38.4322)  time: 0.1924  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [280/313]  eta: 0:00:07  Loss: 2.0998 (2.2249)  ASR: 91.6667 (40.2957)  time: 0.1920  data: 0.0003  max mem: 2382
Train: Epoch[1/5]  [290/313]  eta: 0:00:05  Loss: 2.0817 (2.2196)  ASR: 92.3077 (42.0532)  time: 0.1913  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 2.0734 (2.2147)  ASR: 92.8571 (43.8534)  time: 0.1913  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 2.0595 (2.2094)  ASR: 93.7500 (45.5257)  time: 0.1919  data: 0.0002  max mem: 2382
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 2.0595 (2.2085)  ASR: 93.7500 (45.7605)  time: 0.4007  data: 0.0002  max mem: 2382
Train: Epoch[1/5] Total time: 0:01:15 (0.2422 s / it)
Averaged stats: Loss: 2.0595 (2.2085)  ASR: 93.7500 (45.7605)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:02  Loss: 2.0784 (2.0784)  ASR: 91.6667 (91.6667)  time: 0.3907  data: 0.1934  max mem: 2382
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:03  Loss: 2.0484 (2.0573)  ASR: 100.0000 (95.1465)  time: 0.2103  data: 0.0177  max mem: 2382
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Loss: 2.0368 (2.0439)  ASR: 100.0000 (96.0902)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Loss: 2.0245 (2.0300)  ASR: 100.0000 (95.8921)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:54  Loss: 2.0117 (2.0286)  ASR: 100.0000 (96.7064)  time: 0.1943  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 2.0117 (2.0268)  ASR: 100.0000 (97.1740)  time: 0.1955  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 2.0052 (2.0209)  ASR: 100.0000 (97.1823)  time: 0.1940  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.9920 (2.0191)  ASR: 100.0000 (97.5792)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.9869 (2.0168)  ASR: 100.0000 (97.6596)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.9760 (2.0122)  ASR: 100.0000 (97.7467)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.9799 (2.0107)  ASR: 100.0000 (97.9698)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.9806 (2.0063)  ASR: 100.0000 (98.1527)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.9641 (2.0024)  ASR: 100.0000 (98.3054)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.9490 (1.9986)  ASR: 100.0000 (98.4348)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.9484 (1.9941)  ASR: 100.0000 (98.5458)  time: 0.1925  data: 0.0004  max mem: 2383
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.9510 (1.9920)  ASR: 100.0000 (98.6421)  time: 0.1926  data: 0.0004  max mem: 2383
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.9492 (1.9886)  ASR: 100.0000 (98.7264)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.9290 (1.9855)  ASR: 100.0000 (98.6839)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.9247 (1.9833)  ASR: 100.0000 (98.7566)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.9136 (1.9798)  ASR: 100.0000 (98.7345)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.9088 (1.9767)  ASR: 100.0000 (98.7974)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.9073 (1.9732)  ASR: 100.0000 (98.8544)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.8933 (1.9688)  ASR: 100.0000 (98.9063)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [230/313]  eta: 0:00:16  Loss: 1.8803 (1.9652)  ASR: 100.0000 (98.9536)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.8706 (1.9614)  ASR: 100.0000 (98.9970)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.8599 (1.9570)  ASR: 100.0000 (99.0370)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.8301 (1.9515)  ASR: 100.0000 (99.0739)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.8283 (1.9469)  ASR: 100.0000 (99.1081)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.8354 (1.9427)  ASR: 100.0000 (99.1398)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.8257 (1.9388)  ASR: 100.0000 (99.1448)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.7967 (1.9338)  ASR: 100.0000 (99.1732)  time: 0.1917  data: 0.0003  max mem: 2383
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.8079 (1.9304)  ASR: 100.0000 (99.1409)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.7997 (1.9291)  ASR: 100.0000 (99.1450)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[2/5] Total time: 0:01:00 (0.1930 s / it)
Averaged stats: Loss: 1.7997 (1.9291)  ASR: 100.0000 (99.1450)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:44  Loss: 1.7817 (1.7817)  ASR: 100.0000 (100.0000)  time: 0.3335  data: 0.1349  max mem: 2383
Train: Epoch[3/5]  [ 10/313]  eta: 0:03:11  Loss: 1.7857 (1.7935)  ASR: 100.0000 (100.0000)  time: 0.6305  data: 0.4377  max mem: 2383
Train: Epoch[3/5]  [ 20/313]  eta: 0:02:03  Loss: 1.7442 (1.7705)  ASR: 100.0000 (100.0000)  time: 0.4272  data: 0.2342  max mem: 2383
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:38  Loss: 1.7216 (1.7592)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:24  Loss: 1.7074 (1.7458)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:15  Loss: 1.7088 (1.7420)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:08  Loss: 1.7166 (1.7381)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:03  Loss: 1.6666 (1.7258)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:58  Loss: 1.6604 (1.7191)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:54  Loss: 1.6928 (1.7185)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [100/313]  eta: 0:00:51  Loss: 1.6491 (1.7103)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [110/313]  eta: 0:00:47  Loss: 1.6148 (1.7063)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [120/313]  eta: 0:00:44  Loss: 1.6648 (1.7043)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [130/313]  eta: 0:00:41  Loss: 1.6648 (1.7005)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [140/313]  eta: 0:00:39  Loss: 1.6488 (1.6969)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [150/313]  eta: 0:00:36  Loss: 1.6481 (1.6926)  ASR: 100.0000 (100.0000)  time: 0.1908  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [160/313]  eta: 0:00:33  Loss: 1.6427 (1.6903)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [170/313]  eta: 0:00:31  Loss: 1.6059 (1.6853)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [180/313]  eta: 0:00:29  Loss: 1.5808 (1.6802)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [190/313]  eta: 0:00:26  Loss: 1.5808 (1.6760)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [200/313]  eta: 0:00:24  Loss: 1.6208 (1.6743)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [210/313]  eta: 0:00:22  Loss: 1.5529 (1.6679)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [220/313]  eta: 0:00:19  Loss: 1.5475 (1.6631)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [230/313]  eta: 0:00:17  Loss: 1.5660 (1.6595)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [240/313]  eta: 0:00:15  Loss: 1.5570 (1.6560)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [250/313]  eta: 0:00:13  Loss: 1.5339 (1.6522)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [260/313]  eta: 0:00:11  Loss: 1.5305 (1.6487)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [270/313]  eta: 0:00:09  Loss: 1.5466 (1.6468)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.5686 (1.6430)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0003  max mem: 2383
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.4846 (1.6365)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.4846 (1.6327)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.5093 (1.6296)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.5093 (1.6282)  ASR: 100.0000 (100.0000)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[3/5] Total time: 0:01:04 (0.2074 s / it)
Averaged stats: Loss: 1.5093 (1.6282)  ASR: 100.0000 (100.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:08  Loss: 1.5996 (1.5996)  ASR: 100.0000 (100.0000)  time: 0.4103  data: 0.2131  max mem: 2383
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Loss: 1.5866 (1.5547)  ASR: 100.0000 (100.0000)  time: 0.2115  data: 0.0195  max mem: 2383
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Loss: 1.5304 (1.5241)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Loss: 1.5052 (1.5194)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:54  Loss: 1.4832 (1.5040)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.4956 (1.5088)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.5290 (1.5081)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.4688 (1.4996)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.4218 (1.4940)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.4218 (1.4869)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.4216 (1.4807)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.4080 (1.4762)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.4354 (1.4743)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.4253 (1.4710)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.4099 (1.4653)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.3894 (1.4598)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.3894 (1.4568)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.4253 (1.4559)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.4225 (1.4534)  ASR: 100.0000 (100.0000)  time: 0.1906  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.4225 (1.4512)  ASR: 100.0000 (100.0000)  time: 0.1907  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.3992 (1.4492)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.3982 (1.4488)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.4066 (1.4464)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [230/313]  eta: 0:00:16  Loss: 1.3762 (1.4418)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.2922 (1.4378)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.4175 (1.4373)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.4472 (1.4382)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.4167 (1.4363)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.3852 (1.4348)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.3605 (1.4327)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.3564 (1.4303)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.3605 (1.4290)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.3605 (1.4290)  ASR: 100.0000 (100.0000)  time: 0.1874  data: 0.0002  max mem: 2383
Train: Epoch[4/5] Total time: 0:01:00 (0.1928 s / it)
Averaged stats: Loss: 1.3605 (1.4290)  ASR: 100.0000 (100.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:48  Loss: 1.4273 (1.4273)  ASR: 100.0000 (100.0000)  time: 0.3479  data: 0.1488  max mem: 2383
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Loss: 1.3989 (1.3988)  ASR: 100.0000 (100.0000)  time: 0.2072  data: 0.0138  max mem: 2383
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Loss: 1.3491 (1.3531)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Loss: 1.3228 (1.3416)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.3483 (1.3448)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.3226 (1.3363)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.2583 (1.3247)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.3050 (1.3336)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.3835 (1.3458)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.3540 (1.3431)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.3540 (1.3497)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.3779 (1.3484)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.3624 (1.3485)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.2733 (1.3387)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.2733 (1.3389)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.3253 (1.3376)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.2773 (1.3304)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.2141 (1.3268)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.2987 (1.3258)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.3143 (1.3234)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.2471 (1.3216)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.3531 (1.3250)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.2906 (1.3224)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [230/313]  eta: 0:00:16  Loss: 1.2124 (1.3187)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.2024 (1.3155)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.2249 (1.3134)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.2910 (1.3154)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.2932 (1.3134)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.2361 (1.3132)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.3017 (1.3132)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.2800 (1.3107)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.2921 (1.3115)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.3204 (1.3113)  ASR: 100.0000 (100.0000)  time: 0.1869  data: 0.0002  max mem: 2383
Train: Epoch[5/5] Total time: 0:01:00 (0.1930 s / it)
Averaged stats: Loss: 1.3204 (1.3113)  ASR: 100.0000 (100.0000)
Train: Epoch[6/5]  [  0/313]  eta: 0:01:57  Loss: 1.6230 (1.6230)  ASR: 100.0000 (100.0000)  time: 0.3766  data: 0.1809  max mem: 2383
Train: Epoch[6/5]  [ 10/313]  eta: 0:01:03  Loss: 1.2459 (1.2752)  ASR: 100.0000 (100.0000)  time: 0.2091  data: 0.0167  max mem: 2383
Train: Epoch[6/5]  [ 20/313]  eta: 0:00:58  Loss: 1.2347 (1.2534)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [ 30/313]  eta: 0:00:56  Loss: 1.2431 (1.2402)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [ 40/313]  eta: 0:00:53  Loss: 1.2465 (1.2481)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [ 50/313]  eta: 0:00:51  Loss: 1.2465 (1.2570)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [ 60/313]  eta: 0:00:49  Loss: 1.2198 (1.2535)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [ 70/313]  eta: 0:00:47  Loss: 1.2198 (1.2573)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [ 80/313]  eta: 0:00:45  Loss: 1.2734 (1.2564)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [ 90/313]  eta: 0:00:43  Loss: 1.2275 (1.2564)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [100/313]  eta: 0:00:41  Loss: 1.3054 (1.2583)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [110/313]  eta: 0:00:39  Loss: 1.2234 (1.2585)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [120/313]  eta: 0:00:37  Loss: 1.2804 (1.2636)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [130/313]  eta: 0:00:35  Loss: 1.2804 (1.2625)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [140/313]  eta: 0:00:33  Loss: 1.2507 (1.2623)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [150/313]  eta: 0:00:31  Loss: 1.2703 (1.2654)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [160/313]  eta: 0:00:29  Loss: 1.2508 (1.2626)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [170/313]  eta: 0:00:27  Loss: 1.2388 (1.2661)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [180/313]  eta: 0:00:25  Loss: 1.2932 (1.2679)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [190/313]  eta: 0:00:23  Loss: 1.2345 (1.2627)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [200/313]  eta: 0:00:21  Loss: 1.1975 (1.2648)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [210/313]  eta: 0:00:19  Loss: 1.2285 (1.2633)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [220/313]  eta: 0:00:17  Loss: 1.2304 (1.2633)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [230/313]  eta: 0:00:16  Loss: 1.2295 (1.2618)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [240/313]  eta: 0:00:14  Loss: 1.2255 (1.2597)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [250/313]  eta: 0:00:12  Loss: 1.2047 (1.2577)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[6/5]  [260/313]  eta: 0:00:10  Loss: 1.1628 (1.2551)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [270/313]  eta: 0:00:08  Loss: 1.2053 (1.2575)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [280/313]  eta: 0:00:06  Loss: 1.2820 (1.2586)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [290/313]  eta: 0:00:04  Loss: 1.2206 (1.2552)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [300/313]  eta: 0:00:02  Loss: 1.1904 (1.2526)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [310/313]  eta: 0:00:00  Loss: 1.1732 (1.2522)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[6/5]  [312/313]  eta: 0:00:00  Loss: 1.1904 (1.2528)  ASR: 100.0000 (100.0000)  time: 0.1870  data: 0.0002  max mem: 2383
Train: Epoch[6/5] Total time: 0:01:00 (0.1928 s / it)
Averaged stats: Loss: 1.1904 (1.2528)  ASR: 100.0000 (100.0000)
Train: Epoch[7/5]  [  0/313]  eta: 0:02:02  Loss: 0.9742 (0.9742)  ASR: 100.0000 (100.0000)  time: 0.3904  data: 0.1928  max mem: 2383
Train: Epoch[7/5]  [ 10/313]  eta: 0:01:03  Loss: 1.2914 (1.2593)  ASR: 100.0000 (100.0000)  time: 0.2089  data: 0.0177  max mem: 2383
Train: Epoch[7/5]  [ 20/313]  eta: 0:00:58  Loss: 1.1928 (1.2264)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [ 30/313]  eta: 0:00:56  Loss: 1.1616 (1.2188)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [ 40/313]  eta: 0:00:53  Loss: 1.1843 (1.2186)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [ 50/313]  eta: 0:00:51  Loss: 1.2200 (1.2280)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [ 60/313]  eta: 0:00:49  Loss: 1.2379 (1.2234)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [ 70/313]  eta: 0:00:47  Loss: 1.1478 (1.2172)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [ 80/313]  eta: 0:00:45  Loss: 1.1712 (1.2213)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [ 90/313]  eta: 0:00:43  Loss: 1.2359 (1.2288)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [100/313]  eta: 0:00:41  Loss: 1.2359 (1.2249)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [110/313]  eta: 0:00:39  Loss: 1.2112 (1.2297)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [120/313]  eta: 0:00:37  Loss: 1.3037 (1.2319)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [130/313]  eta: 0:00:35  Loss: 1.2364 (1.2265)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [140/313]  eta: 0:00:33  Loss: 1.1501 (1.2272)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [150/313]  eta: 0:00:31  Loss: 1.1421 (1.2232)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [160/313]  eta: 0:00:29  Loss: 1.1439 (1.2239)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [170/313]  eta: 0:00:27  Loss: 1.2036 (1.2220)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [180/313]  eta: 0:00:25  Loss: 1.2036 (1.2218)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [190/313]  eta: 0:00:23  Loss: 1.1181 (1.2140)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [200/313]  eta: 0:00:21  Loss: 1.1181 (1.2147)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [210/313]  eta: 0:00:19  Loss: 1.2262 (1.2157)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [220/313]  eta: 0:00:17  Loss: 1.2469 (1.2172)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [230/313]  eta: 0:00:16  Loss: 1.2482 (1.2166)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [240/313]  eta: 0:00:14  Loss: 1.2792 (1.2191)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [250/313]  eta: 0:00:12  Loss: 1.1729 (1.2161)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [260/313]  eta: 0:00:10  Loss: 1.1610 (1.2152)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [270/313]  eta: 0:00:08  Loss: 1.1610 (1.2141)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0003  max mem: 2383
Train: Epoch[7/5]  [280/313]  eta: 0:00:06  Loss: 1.1504 (1.2143)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [290/313]  eta: 0:00:04  Loss: 1.1773 (1.2134)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [300/313]  eta: 0:00:02  Loss: 1.2373 (1.2142)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [310/313]  eta: 0:00:00  Loss: 1.1468 (1.2097)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[7/5]  [312/313]  eta: 0:00:00  Loss: 1.0762 (1.2087)  ASR: 100.0000 (100.0000)  time: 0.1869  data: 0.0002  max mem: 2383
Train: Epoch[7/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0762 (1.2087)  ASR: 100.0000 (100.0000)
Train: Epoch[8/5]  [  0/313]  eta: 0:01:48  Loss: 1.2937 (1.2937)  ASR: 100.0000 (100.0000)  time: 0.3465  data: 0.1446  max mem: 2383
Train: Epoch[8/5]  [ 10/313]  eta: 0:01:02  Loss: 1.2844 (1.2067)  ASR: 100.0000 (100.0000)  time: 0.2063  data: 0.0134  max mem: 2383
Train: Epoch[8/5]  [ 20/313]  eta: 0:00:58  Loss: 1.2611 (1.2440)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [ 30/313]  eta: 0:00:55  Loss: 1.2364 (1.2340)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [ 40/313]  eta: 0:00:53  Loss: 1.1754 (1.2208)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [ 50/313]  eta: 0:00:51  Loss: 1.1407 (1.2137)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [ 60/313]  eta: 0:00:49  Loss: 1.1502 (1.2136)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [ 70/313]  eta: 0:00:47  Loss: 1.1420 (1.2031)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [ 80/313]  eta: 0:00:45  Loss: 1.1091 (1.1896)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [ 90/313]  eta: 0:00:43  Loss: 1.1790 (1.1957)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [100/313]  eta: 0:00:41  Loss: 1.2320 (1.1939)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [110/313]  eta: 0:00:39  Loss: 1.2047 (1.1962)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [120/313]  eta: 0:00:37  Loss: 1.2159 (1.1971)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [130/313]  eta: 0:00:35  Loss: 1.1841 (1.1950)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0004  max mem: 2383
Train: Epoch[8/5]  [140/313]  eta: 0:00:33  Loss: 1.1553 (1.1920)  ASR: 100.0000 (100.0000)  time: 0.1939  data: 0.0004  max mem: 2383
Train: Epoch[8/5]  [150/313]  eta: 0:00:31  Loss: 1.1370 (1.1881)  ASR: 100.0000 (100.0000)  time: 0.1945  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [160/313]  eta: 0:00:29  Loss: 1.1250 (1.1832)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [170/313]  eta: 0:00:27  Loss: 1.1346 (1.1797)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [180/313]  eta: 0:00:25  Loss: 1.1571 (1.1827)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [190/313]  eta: 0:00:23  Loss: 1.1791 (1.1829)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [200/313]  eta: 0:00:21  Loss: 1.1574 (1.1837)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [210/313]  eta: 0:00:19  Loss: 1.1834 (1.1834)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [220/313]  eta: 0:00:17  Loss: 1.1725 (1.1810)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [230/313]  eta: 0:00:16  Loss: 1.1908 (1.1822)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [240/313]  eta: 0:00:14  Loss: 1.1603 (1.1775)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [250/313]  eta: 0:00:12  Loss: 1.1142 (1.1784)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [260/313]  eta: 0:00:10  Loss: 1.1804 (1.1782)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [270/313]  eta: 0:00:08  Loss: 1.1676 (1.1758)  ASR: 100.0000 (100.0000)  time: 0.1939  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [280/313]  eta: 0:00:06  Loss: 1.1157 (1.1748)  ASR: 100.0000 (100.0000)  time: 0.1950  data: 0.0004  max mem: 2383
Train: Epoch[8/5]  [290/313]  eta: 0:00:04  Loss: 1.1286 (1.1733)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [300/313]  eta: 0:00:02  Loss: 1.1469 (1.1746)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[8/5]  [310/313]  eta: 0:00:00  Loss: 1.2213 (1.1757)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[8/5]  [312/313]  eta: 0:00:00  Loss: 1.1908 (1.1754)  ASR: 100.0000 (100.0000)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[8/5] Total time: 0:01:00 (0.1930 s / it)
Averaged stats: Loss: 1.1908 (1.1754)  ASR: 100.0000 (100.0000)
Train: Epoch[9/5]  [  0/313]  eta: 0:01:55  Loss: 1.1992 (1.1992)  ASR: 100.0000 (100.0000)  time: 0.3682  data: 0.1666  max mem: 2383
Train: Epoch[9/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0752 (1.1082)  ASR: 100.0000 (100.0000)  time: 0.2074  data: 0.0153  max mem: 2383
Train: Epoch[9/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0752 (1.1199)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0004  max mem: 2383
Train: Epoch[9/5]  [ 30/313]  eta: 0:00:56  Loss: 1.1320 (1.1197)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0004  max mem: 2383
Train: Epoch[9/5]  [ 40/313]  eta: 0:00:53  Loss: 1.1352 (1.1334)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [ 50/313]  eta: 0:00:51  Loss: 1.1333 (1.1392)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [ 60/313]  eta: 0:00:49  Loss: 1.1332 (1.1418)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [ 70/313]  eta: 0:00:47  Loss: 1.1289 (1.1451)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0951 (1.1397)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [ 90/313]  eta: 0:00:43  Loss: 1.1302 (1.1492)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [100/313]  eta: 0:00:41  Loss: 1.1501 (1.1456)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [110/313]  eta: 0:00:39  Loss: 1.1785 (1.1488)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [120/313]  eta: 0:00:37  Loss: 1.2022 (1.1500)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [130/313]  eta: 0:00:35  Loss: 1.1331 (1.1477)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [140/313]  eta: 0:00:33  Loss: 1.1422 (1.1490)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [150/313]  eta: 0:00:31  Loss: 1.1301 (1.1475)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [160/313]  eta: 0:00:29  Loss: 1.1079 (1.1474)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [170/313]  eta: 0:00:27  Loss: 1.1042 (1.1467)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [180/313]  eta: 0:00:25  Loss: 1.0587 (1.1412)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [190/313]  eta: 0:00:23  Loss: 1.0812 (1.1439)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [200/313]  eta: 0:00:21  Loss: 1.1702 (1.1434)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [210/313]  eta: 0:00:19  Loss: 1.1138 (1.1450)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [220/313]  eta: 0:00:17  Loss: 1.1226 (1.1447)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [230/313]  eta: 0:00:15  Loss: 1.1414 (1.1478)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [240/313]  eta: 0:00:14  Loss: 1.1562 (1.1481)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [250/313]  eta: 0:00:12  Loss: 1.1344 (1.1476)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [260/313]  eta: 0:00:10  Loss: 1.1031 (1.1435)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [270/313]  eta: 0:00:08  Loss: 1.1367 (1.1461)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [280/313]  eta: 0:00:06  Loss: 1.1922 (1.1482)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [290/313]  eta: 0:00:04  Loss: 1.1081 (1.1467)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [300/313]  eta: 0:00:02  Loss: 1.1081 (1.1459)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[9/5]  [310/313]  eta: 0:00:00  Loss: 1.1267 (1.1447)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0003  max mem: 2383
Train: Epoch[9/5]  [312/313]  eta: 0:00:00  Loss: 1.0850 (1.1448)  ASR: 100.0000 (100.0000)  time: 0.1865  data: 0.0002  max mem: 2383
Train: Epoch[9/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Loss: 1.0850 (1.1448)  ASR: 100.0000 (100.0000)
Train: Epoch[10/5]  [  0/313]  eta: 0:01:49  Loss: 1.0243 (1.0243)  ASR: 100.0000 (100.0000)  time: 0.3508  data: 0.1529  max mem: 2383
Train: Epoch[10/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0998 (1.1474)  ASR: 100.0000 (100.0000)  time: 0.2064  data: 0.0141  max mem: 2383
Train: Epoch[10/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0998 (1.1059)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [ 30/313]  eta: 0:00:55  Loss: 1.1225 (1.1380)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [ 40/313]  eta: 0:00:53  Loss: 1.1486 (1.1409)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0985 (1.1310)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0985 (1.1370)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [ 70/313]  eta: 0:00:47  Loss: 1.2079 (1.1427)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [ 80/313]  eta: 0:00:45  Loss: 1.1010 (1.1353)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [ 90/313]  eta: 0:00:43  Loss: 1.1113 (1.1385)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [100/313]  eta: 0:00:41  Loss: 1.1923 (1.1368)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [110/313]  eta: 0:00:39  Loss: 1.2002 (1.1437)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [120/313]  eta: 0:00:37  Loss: 1.0883 (1.1373)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [130/313]  eta: 0:00:35  Loss: 1.1030 (1.1402)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [140/313]  eta: 0:00:33  Loss: 1.1245 (1.1444)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [150/313]  eta: 0:00:31  Loss: 1.1286 (1.1432)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [160/313]  eta: 0:00:29  Loss: 1.1286 (1.1453)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0004  max mem: 2383
Train: Epoch[10/5]  [170/313]  eta: 0:00:27  Loss: 1.1872 (1.1453)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0004  max mem: 2383
Train: Epoch[10/5]  [180/313]  eta: 0:00:25  Loss: 1.0930 (1.1416)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [190/313]  eta: 0:00:23  Loss: 1.0961 (1.1392)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [200/313]  eta: 0:00:21  Loss: 1.1035 (1.1425)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [210/313]  eta: 0:00:19  Loss: 1.1757 (1.1427)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [220/313]  eta: 0:00:17  Loss: 1.1077 (1.1412)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0003  max mem: 2383
Train: Epoch[10/5]  [230/313]  eta: 0:00:16  Loss: 1.1155 (1.1425)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [240/313]  eta: 0:00:14  Loss: 1.0813 (1.1393)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [250/313]  eta: 0:00:12  Loss: 1.0630 (1.1394)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [260/313]  eta: 0:00:10  Loss: 1.0521 (1.1376)  ASR: 100.0000 (100.0000)  time: 0.1905  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [270/313]  eta: 0:00:08  Loss: 1.0198 (1.1341)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [280/313]  eta: 0:00:06  Loss: 1.0198 (1.1322)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [290/313]  eta: 0:00:04  Loss: 1.0956 (1.1319)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [300/313]  eta: 0:00:02  Loss: 1.1295 (1.1314)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [310/313]  eta: 0:00:00  Loss: 1.1568 (1.1321)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[10/5]  [312/313]  eta: 0:00:00  Loss: 1.1289 (1.1304)  ASR: 100.0000 (100.0000)  time: 0.1865  data: 0.0002  max mem: 2383
Train: Epoch[10/5] Total time: 0:01:00 (0.1924 s / it)
Averaged stats: Loss: 1.1289 (1.1304)  ASR: 100.0000 (100.0000)
Train: Epoch[11/5]  [  0/313]  eta: 0:01:55  Loss: 1.1053 (1.1053)  ASR: 100.0000 (100.0000)  time: 0.3676  data: 0.1696  max mem: 2383
Train: Epoch[11/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0389 (1.1100)  ASR: 100.0000 (100.0000)  time: 0.2086  data: 0.0157  max mem: 2383
Train: Epoch[11/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0482 (1.1294)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [ 30/313]  eta: 0:00:56  Loss: 1.1730 (1.1496)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[11/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0870 (1.1225)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0557 (1.1126)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0795 (1.1128)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0211 (1.1023)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0194 (1.0966)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0484 (1.0974)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [100/313]  eta: 0:00:41  Loss: 1.0873 (1.0960)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [110/313]  eta: 0:00:39  Loss: 1.0892 (1.0969)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [120/313]  eta: 0:00:37  Loss: 1.1038 (1.0969)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0002  max mem: 2383
Train: Epoch[11/5]  [130/313]  eta: 0:00:35  Loss: 1.0325 (1.0937)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [140/313]  eta: 0:00:33  Loss: 1.0655 (1.0976)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0004  max mem: 2383
Train: Epoch[11/5]  [150/313]  eta: 0:00:31  Loss: 1.0655 (1.0974)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [160/313]  eta: 0:00:29  Loss: 1.1019 (1.1005)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [170/313]  eta: 0:00:27  Loss: 1.1126 (1.0974)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [180/313]  eta: 0:00:25  Loss: 1.0558 (1.0977)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [190/313]  eta: 0:00:23  Loss: 1.1302 (1.1012)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [200/313]  eta: 0:00:21  Loss: 1.1302 (1.0989)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [210/313]  eta: 0:00:19  Loss: 1.0951 (1.1008)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [220/313]  eta: 0:00:18  Loss: 1.0951 (1.0992)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [230/313]  eta: 0:00:16  Loss: 1.1091 (1.1037)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[11/5]  [240/313]  eta: 0:00:14  Loss: 1.1545 (1.1043)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[11/5]  [250/313]  eta: 0:00:12  Loss: 1.1131 (1.1028)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [260/313]  eta: 0:00:10  Loss: 1.0703 (1.0997)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [270/313]  eta: 0:00:08  Loss: 1.0885 (1.1015)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [280/313]  eta: 0:00:06  Loss: 1.0906 (1.0983)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[11/5]  [290/313]  eta: 0:00:04  Loss: 1.0626 (1.1000)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[11/5]  [300/313]  eta: 0:00:02  Loss: 1.0977 (1.0990)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[11/5]  [310/313]  eta: 0:00:00  Loss: 1.0914 (1.0989)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[11/5]  [312/313]  eta: 0:00:00  Loss: 1.0936 (1.0985)  ASR: 100.0000 (100.0000)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[11/5] Total time: 0:01:00 (0.1934 s / it)
Averaged stats: Loss: 1.0936 (1.0985)  ASR: 100.0000 (100.0000)
Train: Epoch[12/5]  [  0/313]  eta: 0:01:52  Loss: 0.9672 (0.9672)  ASR: 100.0000 (100.0000)  time: 0.3607  data: 0.1654  max mem: 2383
Train: Epoch[12/5]  [ 10/313]  eta: 0:01:02  Loss: 0.9672 (0.9663)  ASR: 100.0000 (100.0000)  time: 0.2076  data: 0.0153  max mem: 2383
Train: Epoch[12/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0583 (1.0595)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[12/5]  [ 30/313]  eta: 0:00:55  Loss: 1.1451 (1.0681)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [ 40/313]  eta: 0:00:53  Loss: 1.1093 (1.0765)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [ 50/313]  eta: 0:00:51  Loss: 1.1093 (1.0799)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0612 (1.0842)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0612 (1.0793)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0797 (1.0874)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0797 (1.0865)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [100/313]  eta: 0:00:41  Loss: 1.0618 (1.0860)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [110/313]  eta: 0:00:39  Loss: 1.0584 (1.0835)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [120/313]  eta: 0:00:37  Loss: 1.0584 (1.0858)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[12/5]  [130/313]  eta: 0:00:35  Loss: 1.1208 (1.0906)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[12/5]  [140/313]  eta: 0:00:33  Loss: 1.0825 (1.0907)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [150/313]  eta: 0:00:31  Loss: 1.0802 (1.0897)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[12/5]  [160/313]  eta: 0:00:29  Loss: 1.0384 (1.0858)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [170/313]  eta: 0:00:27  Loss: 1.0473 (1.0861)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [180/313]  eta: 0:00:25  Loss: 1.1134 (1.0847)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [190/313]  eta: 0:00:23  Loss: 1.0519 (1.0844)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [200/313]  eta: 0:00:21  Loss: 1.1039 (1.0856)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [210/313]  eta: 0:00:19  Loss: 1.0413 (1.0847)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [220/313]  eta: 0:00:17  Loss: 1.0677 (1.0895)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [230/313]  eta: 0:00:15  Loss: 1.0969 (1.0887)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0004  max mem: 2383
Train: Epoch[12/5]  [240/313]  eta: 0:00:14  Loss: 1.0669 (1.0861)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0004  max mem: 2383
Train: Epoch[12/5]  [250/313]  eta: 0:00:12  Loss: 1.0592 (1.0879)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [260/313]  eta: 0:00:10  Loss: 1.0502 (1.0852)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [270/313]  eta: 0:00:08  Loss: 0.9863 (1.0834)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [280/313]  eta: 0:00:06  Loss: 1.0376 (1.0820)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [290/313]  eta: 0:00:04  Loss: 1.0491 (1.0820)  ASR: 100.0000 (100.0000)  time: 0.1904  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [300/313]  eta: 0:00:02  Loss: 1.0491 (1.0828)  ASR: 100.0000 (100.0000)  time: 0.1904  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [310/313]  eta: 0:00:00  Loss: 1.0746 (1.0840)  ASR: 100.0000 (100.0000)  time: 0.1901  data: 0.0002  max mem: 2383
Train: Epoch[12/5]  [312/313]  eta: 0:00:00  Loss: 1.0720 (1.0822)  ASR: 100.0000 (100.0000)  time: 0.1856  data: 0.0002  max mem: 2383
Train: Epoch[12/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Loss: 1.0720 (1.0822)  ASR: 100.0000 (100.0000)
Train: Epoch[13/5]  [  0/313]  eta: 0:02:00  Loss: 0.8438 (0.8438)  ASR: 100.0000 (100.0000)  time: 0.3846  data: 0.1886  max mem: 2383
Train: Epoch[13/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0093 (1.0430)  ASR: 100.0000 (100.0000)  time: 0.2084  data: 0.0173  max mem: 2383
Train: Epoch[13/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0250 (1.0566)  ASR: 100.0000 (100.0000)  time: 0.1908  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0748 (1.0668)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [ 40/313]  eta: 0:00:53  Loss: 0.9901 (1.0580)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0497 (1.0733)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0488 (1.0681)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0201 (1.0679)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0250 (1.0627)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0602 (1.0713)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [100/313]  eta: 0:00:41  Loss: 1.1355 (1.0680)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [110/313]  eta: 0:00:39  Loss: 1.0349 (1.0672)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[13/5]  [120/313]  eta: 0:00:37  Loss: 1.0724 (1.0709)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[13/5]  [130/313]  eta: 0:00:35  Loss: 1.0626 (1.0738)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [140/313]  eta: 0:00:33  Loss: 1.0202 (1.0700)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [150/313]  eta: 0:00:31  Loss: 1.0202 (1.0717)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [160/313]  eta: 0:00:29  Loss: 1.0540 (1.0703)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [170/313]  eta: 0:00:27  Loss: 1.0432 (1.0675)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [180/313]  eta: 0:00:25  Loss: 0.9813 (1.0656)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[13/5]  [190/313]  eta: 0:00:23  Loss: 1.0429 (1.0680)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [200/313]  eta: 0:00:21  Loss: 1.0829 (1.0671)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [210/313]  eta: 0:00:19  Loss: 1.0700 (1.0711)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [220/313]  eta: 0:00:17  Loss: 1.0700 (1.0693)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [230/313]  eta: 0:00:15  Loss: 1.0784 (1.0708)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [240/313]  eta: 0:00:14  Loss: 1.0633 (1.0703)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [250/313]  eta: 0:00:12  Loss: 1.0633 (1.0703)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [260/313]  eta: 0:00:10  Loss: 1.1294 (1.0730)  ASR: 100.0000 (100.0000)  time: 0.1905  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [270/313]  eta: 0:00:08  Loss: 1.0576 (1.0736)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [280/313]  eta: 0:00:06  Loss: 1.0606 (1.0741)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[13/5]  [290/313]  eta: 0:00:04  Loss: 1.0899 (1.0721)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[13/5]  [300/313]  eta: 0:00:02  Loss: 1.0867 (1.0748)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[13/5]  [310/313]  eta: 0:00:00  Loss: 1.0621 (1.0743)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[13/5]  [312/313]  eta: 0:00:00  Loss: 1.0355 (1.0728)  ASR: 100.0000 (100.0000)  time: 0.1878  data: 0.0002  max mem: 2383
Train: Epoch[13/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Loss: 1.0355 (1.0728)  ASR: 100.0000 (100.0000)
Train: Epoch[14/5]  [  0/313]  eta: 0:01:55  Loss: 1.0225 (1.0225)  ASR: 100.0000 (100.0000)  time: 0.3698  data: 0.1747  max mem: 2383
Train: Epoch[14/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0688 (1.0794)  ASR: 100.0000 (100.0000)  time: 0.2077  data: 0.0161  max mem: 2383
Train: Epoch[14/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0906 (1.0974)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [ 30/313]  eta: 0:00:55  Loss: 1.1198 (1.0977)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0306 (1.0790)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0242 (1.0735)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0571 (1.0713)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0910 (1.0764)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0910 (1.0743)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0382 (1.0714)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [100/313]  eta: 0:00:41  Loss: 1.0210 (1.0707)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [110/313]  eta: 0:00:39  Loss: 1.0815 (1.0776)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [120/313]  eta: 0:00:37  Loss: 1.0110 (1.0725)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [130/313]  eta: 0:00:35  Loss: 0.9958 (1.0694)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [140/313]  eta: 0:00:33  Loss: 1.0175 (1.0664)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [150/313]  eta: 0:00:31  Loss: 1.0397 (1.0706)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [160/313]  eta: 0:00:29  Loss: 1.0754 (1.0703)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [170/313]  eta: 0:00:27  Loss: 1.0113 (1.0660)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [180/313]  eta: 0:00:25  Loss: 1.0279 (1.0692)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [190/313]  eta: 0:00:23  Loss: 1.0692 (1.0710)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [200/313]  eta: 0:00:21  Loss: 1.0487 (1.0689)  ASR: 100.0000 (100.0000)  time: 0.1907  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [210/313]  eta: 0:00:19  Loss: 1.0271 (1.0665)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [220/313]  eta: 0:00:17  Loss: 1.0404 (1.0662)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [230/313]  eta: 0:00:16  Loss: 1.0152 (1.0662)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [240/313]  eta: 0:00:14  Loss: 1.0485 (1.0669)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [250/313]  eta: 0:00:12  Loss: 1.0701 (1.0676)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [260/313]  eta: 0:00:10  Loss: 1.0701 (1.0673)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [270/313]  eta: 0:00:08  Loss: 0.9765 (1.0648)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[14/5]  [280/313]  eta: 0:00:06  Loss: 0.9832 (1.0639)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [290/313]  eta: 0:00:04  Loss: 0.9832 (1.0622)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [300/313]  eta: 0:00:02  Loss: 0.9228 (1.0609)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [310/313]  eta: 0:00:00  Loss: 0.9228 (1.0599)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[14/5]  [312/313]  eta: 0:00:00  Loss: 0.9803 (1.0600)  ASR: 100.0000 (100.0000)  time: 0.1869  data: 0.0002  max mem: 2383
Train: Epoch[14/5] Total time: 0:01:00 (0.1928 s / it)
Averaged stats: Loss: 0.9803 (1.0600)  ASR: 100.0000 (100.0000)
Train: Epoch[15/5]  [  0/313]  eta: 0:01:43  Loss: 0.9944 (0.9944)  ASR: 100.0000 (100.0000)  time: 0.3292  data: 0.1320  max mem: 2383
Train: Epoch[15/5]  [ 10/313]  eta: 0:01:01  Loss: 1.0978 (1.0973)  ASR: 100.0000 (100.0000)  time: 0.2045  data: 0.0122  max mem: 2383
Train: Epoch[15/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0406 (1.0612)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0253 (1.0617)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0446 (1.0481)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0295 (1.0467)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0076 (1.0415)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0478 (1.0491)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[15/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9911 (1.0372)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[15/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9862 (1.0348)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [100/313]  eta: 0:00:41  Loss: 1.0192 (1.0397)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [110/313]  eta: 0:00:39  Loss: 1.0182 (1.0383)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [120/313]  eta: 0:00:37  Loss: 0.9957 (1.0363)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [130/313]  eta: 0:00:35  Loss: 1.0280 (1.0354)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [140/313]  eta: 0:00:33  Loss: 0.9966 (1.0317)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [150/313]  eta: 0:00:31  Loss: 0.9856 (1.0322)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [160/313]  eta: 0:00:29  Loss: 0.9768 (1.0320)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [170/313]  eta: 0:00:27  Loss: 1.0192 (1.0365)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[15/5]  [180/313]  eta: 0:00:25  Loss: 1.1329 (1.0401)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[15/5]  [190/313]  eta: 0:00:23  Loss: 1.0325 (1.0394)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [200/313]  eta: 0:00:21  Loss: 0.9316 (1.0356)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [210/313]  eta: 0:00:19  Loss: 1.0138 (1.0360)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [220/313]  eta: 0:00:17  Loss: 1.0188 (1.0355)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [230/313]  eta: 0:00:16  Loss: 1.0388 (1.0386)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[15/5]  [240/313]  eta: 0:00:14  Loss: 1.0775 (1.0402)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[15/5]  [250/313]  eta: 0:00:12  Loss: 1.0775 (1.0423)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [260/313]  eta: 0:00:10  Loss: 1.0615 (1.0426)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [270/313]  eta: 0:00:08  Loss: 1.0736 (1.0467)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [280/313]  eta: 0:00:06  Loss: 1.0306 (1.0458)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [290/313]  eta: 0:00:04  Loss: 1.0089 (1.0444)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [300/313]  eta: 0:00:02  Loss: 1.0066 (1.0444)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[15/5]  [310/313]  eta: 0:00:00  Loss: 1.0066 (1.0444)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[15/5]  [312/313]  eta: 0:00:00  Loss: 1.0066 (1.0442)  ASR: 100.0000 (100.0000)  time: 0.1884  data: 0.0003  max mem: 2383
Train: Epoch[15/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0066 (1.0442)  ASR: 100.0000 (100.0000)
Train: Epoch[16/5]  [  0/313]  eta: 0:02:07  Loss: 1.2175 (1.2175)  ASR: 100.0000 (100.0000)  time: 0.4082  data: 0.2120  max mem: 2383
Train: Epoch[16/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0231 (1.0236)  ASR: 100.0000 (100.0000)  time: 0.2109  data: 0.0195  max mem: 2383
Train: Epoch[16/5]  [ 20/313]  eta: 0:00:59  Loss: 0.9926 (1.0270)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0395 (1.0569)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0981 (1.0632)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0443 (1.0613)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0233 (1.0741)  ASR: 100.0000 (100.0000)  time: 0.1906  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0201 (1.0575)  ASR: 100.0000 (100.0000)  time: 0.1906  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9462 (1.0621)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0934 (1.0644)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [100/313]  eta: 0:00:41  Loss: 1.0765 (1.0609)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [110/313]  eta: 0:00:39  Loss: 1.0385 (1.0619)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [120/313]  eta: 0:00:37  Loss: 1.0473 (1.0634)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [130/313]  eta: 0:00:35  Loss: 1.0913 (1.0650)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [140/313]  eta: 0:00:33  Loss: 1.0485 (1.0632)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[16/5]  [150/313]  eta: 0:00:31  Loss: 0.9650 (1.0549)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[16/5]  [160/313]  eta: 0:00:29  Loss: 0.9867 (1.0549)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [170/313]  eta: 0:00:27  Loss: 1.0096 (1.0533)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [180/313]  eta: 0:00:25  Loss: 1.0092 (1.0500)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [190/313]  eta: 0:00:23  Loss: 1.0532 (1.0533)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [200/313]  eta: 0:00:21  Loss: 1.0532 (1.0511)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[16/5]  [210/313]  eta: 0:00:19  Loss: 1.0198 (1.0486)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[16/5]  [220/313]  eta: 0:00:17  Loss: 1.0061 (1.0480)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[16/5]  [230/313]  eta: 0:00:16  Loss: 1.0061 (1.0463)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [240/313]  eta: 0:00:14  Loss: 1.0033 (1.0505)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [250/313]  eta: 0:00:12  Loss: 1.0033 (1.0475)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [260/313]  eta: 0:00:10  Loss: 1.0021 (1.0484)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [270/313]  eta: 0:00:08  Loss: 1.0117 (1.0494)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [280/313]  eta: 0:00:06  Loss: 0.9967 (1.0465)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [290/313]  eta: 0:00:04  Loss: 0.9946 (1.0475)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [300/313]  eta: 0:00:02  Loss: 1.0261 (1.0495)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [310/313]  eta: 0:00:00  Loss: 1.0001 (1.0467)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[16/5]  [312/313]  eta: 0:00:00  Loss: 1.0001 (1.0461)  ASR: 100.0000 (100.0000)  time: 0.1868  data: 0.0002  max mem: 2383
Train: Epoch[16/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0001 (1.0461)  ASR: 100.0000 (100.0000)
Train: Epoch[17/5]  [  0/313]  eta: 0:01:52  Loss: 1.0359 (1.0359)  ASR: 100.0000 (100.0000)  time: 0.3601  data: 0.1623  max mem: 2383
Train: Epoch[17/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0634 (1.0573)  ASR: 100.0000 (100.0000)  time: 0.2077  data: 0.0149  max mem: 2383
Train: Epoch[17/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0634 (1.0569)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0309 (1.0519)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0472 (1.0641)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0260 (1.0533)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9574 (1.0453)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0048 (1.0551)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0296 (1.0416)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0069 (1.0448)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [100/313]  eta: 0:00:41  Loss: 1.0069 (1.0417)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [110/313]  eta: 0:00:39  Loss: 1.0149 (1.0408)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [120/313]  eta: 0:00:37  Loss: 0.9951 (1.0363)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [130/313]  eta: 0:00:35  Loss: 0.9907 (1.0372)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [140/313]  eta: 0:00:33  Loss: 1.0235 (1.0360)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [150/313]  eta: 0:00:31  Loss: 1.0614 (1.0372)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [160/313]  eta: 0:00:29  Loss: 0.9958 (1.0339)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [170/313]  eta: 0:00:27  Loss: 0.9881 (1.0320)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [180/313]  eta: 0:00:25  Loss: 0.9532 (1.0302)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [190/313]  eta: 0:00:23  Loss: 1.0095 (1.0325)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [200/313]  eta: 0:00:21  Loss: 1.0144 (1.0331)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [210/313]  eta: 0:00:19  Loss: 1.1010 (1.0383)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [220/313]  eta: 0:00:17  Loss: 1.1002 (1.0357)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [230/313]  eta: 0:00:16  Loss: 1.0276 (1.0403)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [240/313]  eta: 0:00:14  Loss: 1.0195 (1.0360)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [250/313]  eta: 0:00:12  Loss: 0.9330 (1.0371)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [260/313]  eta: 0:00:10  Loss: 1.0581 (1.0380)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [270/313]  eta: 0:00:08  Loss: 0.9824 (1.0363)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [280/313]  eta: 0:00:06  Loss: 1.0609 (1.0387)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [290/313]  eta: 0:00:04  Loss: 0.9956 (1.0359)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [300/313]  eta: 0:00:02  Loss: 0.9023 (1.0320)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[17/5]  [310/313]  eta: 0:00:00  Loss: 0.9895 (1.0336)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[17/5]  [312/313]  eta: 0:00:00  Loss: 0.9675 (1.0340)  ASR: 100.0000 (100.0000)  time: 0.1876  data: 0.0002  max mem: 2383
Train: Epoch[17/5] Total time: 0:01:00 (0.1930 s / it)
Averaged stats: Loss: 0.9675 (1.0340)  ASR: 100.0000 (100.0000)
Train: Epoch[18/5]  [  0/313]  eta: 0:01:46  Loss: 1.1207 (1.1207)  ASR: 100.0000 (100.0000)  time: 0.3405  data: 0.1442  max mem: 2383
Train: Epoch[18/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0605 (1.0460)  ASR: 100.0000 (100.0000)  time: 0.2055  data: 0.0133  max mem: 2383
Train: Epoch[18/5]  [ 20/313]  eta: 0:00:58  Loss: 0.9936 (1.0693)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0136 (1.0738)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [ 40/313]  eta: 0:00:53  Loss: 1.1083 (1.0895)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [ 50/313]  eta: 0:00:51  Loss: 1.1634 (1.0976)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0270 (1.0883)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0073 (1.0791)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0183 (1.0751)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9801 (1.0622)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [100/313]  eta: 0:00:41  Loss: 0.9711 (1.0644)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [110/313]  eta: 0:00:39  Loss: 0.9941 (1.0601)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [120/313]  eta: 0:00:37  Loss: 1.0525 (1.0646)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [130/313]  eta: 0:00:35  Loss: 1.0544 (1.0646)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [140/313]  eta: 0:00:33  Loss: 1.0161 (1.0643)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [150/313]  eta: 0:00:31  Loss: 1.0320 (1.0632)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[18/5]  [160/313]  eta: 0:00:29  Loss: 1.0978 (1.0681)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[18/5]  [170/313]  eta: 0:00:27  Loss: 1.0295 (1.0624)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [180/313]  eta: 0:00:25  Loss: 0.9588 (1.0617)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [190/313]  eta: 0:00:23  Loss: 1.0096 (1.0575)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [200/313]  eta: 0:00:21  Loss: 1.0096 (1.0567)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [210/313]  eta: 0:00:19  Loss: 1.0845 (1.0593)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [220/313]  eta: 0:00:17  Loss: 1.0518 (1.0607)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [230/313]  eta: 0:00:16  Loss: 1.0766 (1.0665)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [240/313]  eta: 0:00:14  Loss: 1.0336 (1.0657)  ASR: 100.0000 (100.0000)  time: 0.1906  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [250/313]  eta: 0:00:12  Loss: 1.0116 (1.0675)  ASR: 100.0000 (100.0000)  time: 0.1904  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [260/313]  eta: 0:00:10  Loss: 1.0121 (1.0640)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [270/313]  eta: 0:00:08  Loss: 1.0670 (1.0670)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [280/313]  eta: 0:00:06  Loss: 1.0785 (1.0658)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [290/313]  eta: 0:00:04  Loss: 0.9941 (1.0635)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [300/313]  eta: 0:00:02  Loss: 0.9491 (1.0627)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [310/313]  eta: 0:00:00  Loss: 1.0551 (1.0640)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[18/5]  [312/313]  eta: 0:00:00  Loss: 1.0756 (1.0649)  ASR: 100.0000 (100.0000)  time: 0.1864  data: 0.0002  max mem: 2383
Train: Epoch[18/5] Total time: 0:01:00 (0.1925 s / it)
Averaged stats: Loss: 1.0756 (1.0649)  ASR: 100.0000 (100.0000)
Train: Epoch[19/5]  [  0/313]  eta: 0:02:03  Loss: 0.8339 (0.8339)  ASR: 100.0000 (100.0000)  time: 0.3959  data: 0.2003  max mem: 2383
Train: Epoch[19/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0573 (1.0759)  ASR: 100.0000 (100.0000)  time: 0.2116  data: 0.0184  max mem: 2383
Train: Epoch[19/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0304 (1.0695)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0192 (1.0679)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [ 40/313]  eta: 0:00:54  Loss: 0.9791 (1.0408)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [ 50/313]  eta: 0:00:51  Loss: 0.9848 (1.0255)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0223 (1.0465)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0223 (1.0404)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0044 (1.0447)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0349 (1.0475)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [100/313]  eta: 0:00:41  Loss: 0.9609 (1.0355)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [110/313]  eta: 0:00:39  Loss: 0.9620 (1.0392)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [120/313]  eta: 0:00:37  Loss: 1.1018 (1.0467)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [130/313]  eta: 0:00:35  Loss: 1.0340 (1.0429)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [140/313]  eta: 0:00:33  Loss: 1.0315 (1.0441)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [150/313]  eta: 0:00:31  Loss: 1.1023 (1.0437)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [160/313]  eta: 0:00:29  Loss: 1.0135 (1.0395)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [170/313]  eta: 0:00:27  Loss: 0.9555 (1.0367)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [180/313]  eta: 0:00:25  Loss: 0.9178 (1.0335)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [190/313]  eta: 0:00:23  Loss: 0.9768 (1.0329)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [200/313]  eta: 0:00:21  Loss: 1.0208 (1.0363)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [210/313]  eta: 0:00:19  Loss: 1.0208 (1.0356)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [220/313]  eta: 0:00:18  Loss: 1.0182 (1.0363)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[19/5]  [230/313]  eta: 0:00:16  Loss: 1.0636 (1.0385)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [240/313]  eta: 0:00:14  Loss: 1.0761 (1.0405)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [250/313]  eta: 0:00:12  Loss: 1.0759 (1.0396)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [260/313]  eta: 0:00:10  Loss: 1.0343 (1.0401)  ASR: 100.0000 (100.0000)  time: 0.1907  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [270/313]  eta: 0:00:08  Loss: 1.0963 (1.0438)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [280/313]  eta: 0:00:06  Loss: 1.0766 (1.0432)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [290/313]  eta: 0:00:04  Loss: 1.0456 (1.0432)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [300/313]  eta: 0:00:02  Loss: 1.0673 (1.0433)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [310/313]  eta: 0:00:00  Loss: 1.0777 (1.0437)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[19/5]  [312/313]  eta: 0:00:00  Loss: 1.0777 (1.0438)  ASR: 100.0000 (100.0000)  time: 0.1863  data: 0.0002  max mem: 2383
Train: Epoch[19/5] Total time: 0:01:00 (0.1930 s / it)
Averaged stats: Loss: 1.0777 (1.0438)  ASR: 100.0000 (100.0000)
Train: Epoch[20/5]  [  0/313]  eta: 0:02:01  Loss: 1.0904 (1.0904)  ASR: 100.0000 (100.0000)  time: 0.3875  data: 0.1889  max mem: 2383
Train: Epoch[20/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0904 (1.0338)  ASR: 100.0000 (100.0000)  time: 0.2103  data: 0.0174  max mem: 2383
Train: Epoch[20/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0475 (1.0409)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0500 (1.0863)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [ 40/313]  eta: 0:00:53  Loss: 1.1050 (1.0738)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0527 (1.0671)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0137 (1.0685)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9957 (1.0598)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9770 (1.0534)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9770 (1.0469)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [100/313]  eta: 0:00:41  Loss: 0.9057 (1.0367)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [110/313]  eta: 0:00:39  Loss: 1.0000 (1.0390)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [120/313]  eta: 0:00:37  Loss: 1.0111 (1.0409)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [130/313]  eta: 0:00:35  Loss: 1.0059 (1.0338)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [140/313]  eta: 0:00:33  Loss: 1.0089 (1.0434)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [150/313]  eta: 0:00:31  Loss: 1.0179 (1.0421)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [160/313]  eta: 0:00:29  Loss: 0.9772 (1.0346)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [170/313]  eta: 0:00:27  Loss: 1.0021 (1.0417)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [180/313]  eta: 0:00:25  Loss: 1.0021 (1.0384)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [190/313]  eta: 0:00:23  Loss: 0.9602 (1.0382)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [200/313]  eta: 0:00:21  Loss: 0.9891 (1.0379)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [210/313]  eta: 0:00:19  Loss: 1.0088 (1.0378)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [220/313]  eta: 0:00:17  Loss: 1.0726 (1.0393)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [230/313]  eta: 0:00:16  Loss: 1.0135 (1.0373)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [240/313]  eta: 0:00:14  Loss: 0.9424 (1.0362)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [250/313]  eta: 0:00:12  Loss: 0.9869 (1.0368)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [260/313]  eta: 0:00:10  Loss: 1.0035 (1.0357)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [270/313]  eta: 0:00:08  Loss: 0.9846 (1.0331)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [280/313]  eta: 0:00:06  Loss: 0.9846 (1.0328)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [290/313]  eta: 0:00:04  Loss: 0.9991 (1.0316)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [300/313]  eta: 0:00:02  Loss: 0.9949 (1.0332)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[20/5]  [310/313]  eta: 0:00:00  Loss: 1.0106 (1.0340)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[20/5]  [312/313]  eta: 0:00:00  Loss: 0.9893 (1.0321)  ASR: 100.0000 (100.0000)  time: 0.1879  data: 0.0003  max mem: 2383
Train: Epoch[20/5] Total time: 0:01:00 (0.1929 s / it)
Averaged stats: Loss: 0.9893 (1.0321)  ASR: 100.0000 (100.0000)
Train: Epoch[21/5]  [  0/313]  eta: 0:02:16  Loss: 0.9134 (0.9134)  ASR: 100.0000 (100.0000)  time: 0.4357  data: 0.2372  max mem: 2383
Train: Epoch[21/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0445 (1.0561)  ASR: 100.0000 (100.0000)  time: 0.2131  data: 0.0217  max mem: 2383
Train: Epoch[21/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0241 (1.0389)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0035 (1.0185)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [ 40/313]  eta: 0:00:54  Loss: 0.9985 (1.0240)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0297 (1.0363)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9992 (1.0214)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0080 (1.0397)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9944 (1.0241)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9593 (1.0278)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [100/313]  eta: 0:00:41  Loss: 0.9296 (1.0145)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [110/313]  eta: 0:00:39  Loss: 0.9498 (1.0236)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [120/313]  eta: 0:00:37  Loss: 1.0870 (1.0298)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [130/313]  eta: 0:00:35  Loss: 1.0404 (1.0344)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [140/313]  eta: 0:00:33  Loss: 1.0279 (1.0342)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [150/313]  eta: 0:00:31  Loss: 1.0204 (1.0393)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [160/313]  eta: 0:00:29  Loss: 0.9979 (1.0344)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [170/313]  eta: 0:00:27  Loss: 0.9979 (1.0374)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [180/313]  eta: 0:00:25  Loss: 1.0051 (1.0318)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [190/313]  eta: 0:00:23  Loss: 0.9750 (1.0325)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [200/313]  eta: 0:00:21  Loss: 1.0140 (1.0323)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [210/313]  eta: 0:00:19  Loss: 1.0013 (1.0311)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [220/313]  eta: 0:00:18  Loss: 1.0148 (1.0328)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [230/313]  eta: 0:00:16  Loss: 1.0148 (1.0311)  ASR: 100.0000 (100.0000)  time: 0.1938  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [240/313]  eta: 0:00:14  Loss: 0.9998 (1.0314)  ASR: 100.0000 (100.0000)  time: 0.1939  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [250/313]  eta: 0:00:12  Loss: 1.1002 (1.0301)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0005  max mem: 2383
Train: Epoch[21/5]  [260/313]  eta: 0:00:10  Loss: 1.0171 (1.0296)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0004  max mem: 2383
Train: Epoch[21/5]  [270/313]  eta: 0:00:08  Loss: 0.9348 (1.0274)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [280/313]  eta: 0:00:06  Loss: 0.9958 (1.0292)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [290/313]  eta: 0:00:04  Loss: 1.0459 (1.0295)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [300/313]  eta: 0:00:02  Loss: 1.0396 (1.0306)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[21/5]  [310/313]  eta: 0:00:00  Loss: 0.9291 (1.0303)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[21/5]  [312/313]  eta: 0:00:00  Loss: 0.9662 (1.0308)  ASR: 100.0000 (100.0000)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[21/5] Total time: 0:01:00 (0.1934 s / it)
Averaged stats: Loss: 0.9662 (1.0308)  ASR: 100.0000 (100.0000)
Train: Epoch[22/5]  [  0/313]  eta: 0:01:53  Loss: 0.8761 (0.8761)  ASR: 100.0000 (100.0000)  time: 0.3629  data: 0.1622  max mem: 2383
Train: Epoch[22/5]  [ 10/313]  eta: 0:01:03  Loss: 0.9399 (0.9956)  ASR: 100.0000 (100.0000)  time: 0.2088  data: 0.0150  max mem: 2383
Train: Epoch[22/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0059 (1.0047)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0490 (1.0318)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0490 (1.0371)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [ 50/313]  eta: 0:00:51  Loss: 0.9723 (1.0261)  ASR: 100.0000 (100.0000)  time: 0.1941  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9711 (1.0157)  ASR: 100.0000 (100.0000)  time: 0.1938  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9697 (1.0112)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9506 (1.0050)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9726 (1.0100)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [100/313]  eta: 0:00:41  Loss: 0.9344 (1.0045)  ASR: 100.0000 (100.0000)  time: 0.1907  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [110/313]  eta: 0:00:39  Loss: 0.9813 (1.0102)  ASR: 100.0000 (100.0000)  time: 0.1906  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [120/313]  eta: 0:00:37  Loss: 1.0116 (1.0097)  ASR: 100.0000 (100.0000)  time: 0.1905  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [130/313]  eta: 0:00:35  Loss: 0.9861 (1.0073)  ASR: 100.0000 (100.0000)  time: 0.1907  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [140/313]  eta: 0:00:33  Loss: 0.9955 (1.0126)  ASR: 100.0000 (100.0000)  time: 0.1909  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [150/313]  eta: 0:00:31  Loss: 0.9713 (1.0080)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [160/313]  eta: 0:00:29  Loss: 0.9713 (1.0117)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [170/313]  eta: 0:00:27  Loss: 1.0062 (1.0111)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [180/313]  eta: 0:00:25  Loss: 1.0129 (1.0138)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [190/313]  eta: 0:00:23  Loss: 1.0133 (1.0129)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [200/313]  eta: 0:00:21  Loss: 0.9962 (1.0100)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [210/313]  eta: 0:00:19  Loss: 1.0182 (1.0125)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [220/313]  eta: 0:00:17  Loss: 1.0161 (1.0113)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [230/313]  eta: 0:00:16  Loss: 0.9824 (1.0102)  ASR: 100.0000 (100.0000)  time: 0.1912  data: 0.0002  max mem: 2383
Train: Epoch[22/5]  [240/313]  eta: 0:00:14  Loss: 1.0207 (1.0131)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [250/313]  eta: 0:00:12  Loss: 1.0823 (1.0147)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [260/313]  eta: 0:00:10  Loss: 1.0469 (1.0151)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [270/313]  eta: 0:00:08  Loss: 1.0057 (1.0164)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [280/313]  eta: 0:00:06  Loss: 1.0488 (1.0190)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [290/313]  eta: 0:00:04  Loss: 1.0762 (1.0202)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [300/313]  eta: 0:00:02  Loss: 0.9688 (1.0179)  ASR: 100.0000 (100.0000)  time: 0.1941  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [310/313]  eta: 0:00:00  Loss: 0.9790 (1.0175)  ASR: 100.0000 (100.0000)  time: 0.1941  data: 0.0003  max mem: 2383
Train: Epoch[22/5]  [312/313]  eta: 0:00:00  Loss: 0.9790 (1.0182)  ASR: 100.0000 (100.0000)  time: 0.1890  data: 0.0002  max mem: 2383
Train: Epoch[22/5] Total time: 0:01:00 (0.1928 s / it)
Averaged stats: Loss: 0.9790 (1.0182)  ASR: 100.0000 (100.0000)
Train: Epoch[23/5]  [  0/313]  eta: 0:01:55  Loss: 1.3163 (1.3163)  ASR: 100.0000 (100.0000)  time: 0.3688  data: 0.1729  max mem: 2383
Train: Epoch[23/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0608 (1.0014)  ASR: 100.0000 (100.0000)  time: 0.2085  data: 0.0159  max mem: 2383
Train: Epoch[23/5]  [ 20/313]  eta: 0:00:58  Loss: 0.9133 (0.9810)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [ 30/313]  eta: 0:00:56  Loss: 0.9729 (0.9937)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0129 (0.9978)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [ 50/313]  eta: 0:00:51  Loss: 0.9530 (0.9901)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0010 (0.9990)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0940 (1.0076)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0046 (1.0011)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0650 (1.0052)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [100/313]  eta: 0:00:41  Loss: 1.0373 (1.0040)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [110/313]  eta: 0:00:39  Loss: 0.9873 (1.0088)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [120/313]  eta: 0:00:37  Loss: 1.0046 (1.0097)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [130/313]  eta: 0:00:35  Loss: 1.0046 (1.0123)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [140/313]  eta: 0:00:33  Loss: 1.0341 (1.0157)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [150/313]  eta: 0:00:31  Loss: 1.0655 (1.0168)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [160/313]  eta: 0:00:29  Loss: 1.0430 (1.0160)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [170/313]  eta: 0:00:27  Loss: 1.0214 (1.0217)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [180/313]  eta: 0:00:25  Loss: 1.0019 (1.0191)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [190/313]  eta: 0:00:23  Loss: 0.9233 (1.0152)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [200/313]  eta: 0:00:21  Loss: 0.9321 (1.0156)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [210/313]  eta: 0:00:19  Loss: 1.0171 (1.0184)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [220/313]  eta: 0:00:17  Loss: 1.0337 (1.0213)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [230/313]  eta: 0:00:16  Loss: 1.0296 (1.0215)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [240/313]  eta: 0:00:14  Loss: 1.0296 (1.0231)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [250/313]  eta: 0:00:12  Loss: 0.9970 (1.0221)  ASR: 100.0000 (100.0000)  time: 0.1910  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [260/313]  eta: 0:00:10  Loss: 0.9953 (1.0251)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [270/313]  eta: 0:00:08  Loss: 1.0300 (1.0255)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [280/313]  eta: 0:00:06  Loss: 1.0427 (1.0246)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0002  max mem: 2383
Train: Epoch[23/5]  [290/313]  eta: 0:00:04  Loss: 1.0427 (1.0248)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [300/313]  eta: 0:00:02  Loss: 1.0294 (1.0242)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [310/313]  eta: 0:00:00  Loss: 1.0164 (1.0250)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0003  max mem: 2383
Train: Epoch[23/5]  [312/313]  eta: 0:00:00  Loss: 0.9621 (1.0244)  ASR: 100.0000 (100.0000)  time: 0.1873  data: 0.0003  max mem: 2383
Train: Epoch[23/5] Total time: 0:01:00 (0.1931 s / it)
Averaged stats: Loss: 0.9621 (1.0244)  ASR: 100.0000 (100.0000)
Train: Epoch[24/5]  [  0/313]  eta: 0:01:48  Loss: 1.1804 (1.1804)  ASR: 100.0000 (100.0000)  time: 0.3457  data: 0.1495  max mem: 2383
Train: Epoch[24/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0399 (1.0471)  ASR: 100.0000 (100.0000)  time: 0.2058  data: 0.0138  max mem: 2383
Train: Epoch[24/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0399 (1.0424)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0519 (1.0323)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [ 40/313]  eta: 0:00:53  Loss: 0.9363 (1.0213)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [ 50/313]  eta: 0:00:51  Loss: 0.9705 (1.0281)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9705 (1.0155)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9106 (1.0044)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9601 (1.0125)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0956 (1.0272)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [100/313]  eta: 0:00:41  Loss: 1.0699 (1.0302)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [110/313]  eta: 0:00:39  Loss: 1.0618 (1.0342)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [120/313]  eta: 0:00:37  Loss: 1.0696 (1.0360)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [130/313]  eta: 0:00:35  Loss: 0.9895 (1.0322)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [140/313]  eta: 0:00:33  Loss: 0.9898 (1.0330)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [150/313]  eta: 0:00:31  Loss: 0.9820 (1.0296)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [160/313]  eta: 0:00:29  Loss: 0.9176 (1.0235)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [170/313]  eta: 0:00:27  Loss: 0.9699 (1.0251)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [180/313]  eta: 0:00:25  Loss: 1.0375 (1.0253)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [190/313]  eta: 0:00:23  Loss: 0.9472 (1.0217)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [200/313]  eta: 0:00:21  Loss: 0.9472 (1.0236)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [210/313]  eta: 0:00:19  Loss: 0.9451 (1.0202)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [220/313]  eta: 0:00:17  Loss: 0.9538 (1.0200)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [230/313]  eta: 0:00:16  Loss: 1.0148 (1.0213)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [240/313]  eta: 0:00:14  Loss: 0.9983 (1.0223)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [250/313]  eta: 0:00:12  Loss: 0.9848 (1.0205)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [260/313]  eta: 0:00:10  Loss: 0.9575 (1.0220)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [270/313]  eta: 0:00:08  Loss: 1.0688 (1.0238)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [280/313]  eta: 0:00:06  Loss: 1.0896 (1.0239)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[24/5]  [290/313]  eta: 0:00:04  Loss: 0.9924 (1.0206)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [300/313]  eta: 0:00:02  Loss: 1.0170 (1.0233)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [310/313]  eta: 0:00:00  Loss: 0.9854 (1.0216)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2383
Train: Epoch[24/5]  [312/313]  eta: 0:00:00  Loss: 0.9836 (1.0220)  ASR: 100.0000 (100.0000)  time: 0.1866  data: 0.0002  max mem: 2383
Train: Epoch[24/5] Total time: 0:01:00 (0.1931 s / it)
Averaged stats: Loss: 0.9836 (1.0220)  ASR: 100.0000 (100.0000)
Train: Epoch[25/5]  [  0/313]  eta: 0:01:55  Loss: 0.9893 (0.9893)  ASR: 100.0000 (100.0000)  time: 0.3674  data: 0.1705  max mem: 2383
Train: Epoch[25/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0985 (1.1053)  ASR: 100.0000 (100.0000)  time: 0.2080  data: 0.0157  max mem: 2383
Train: Epoch[25/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0502 (1.0546)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0502 (1.0759)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0764 (1.0633)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [ 50/313]  eta: 0:00:51  Loss: 0.9438 (1.0330)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [ 60/313]  eta: 0:00:49  Loss: 0.8993 (1.0234)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9514 (1.0126)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9636 (1.0086)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9662 (1.0068)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [100/313]  eta: 0:00:41  Loss: 1.0496 (1.0102)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [110/313]  eta: 0:00:39  Loss: 1.0839 (1.0186)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [120/313]  eta: 0:00:37  Loss: 1.0381 (1.0169)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [130/313]  eta: 0:00:35  Loss: 1.0097 (1.0188)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [140/313]  eta: 0:00:33  Loss: 0.9475 (1.0144)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [150/313]  eta: 0:00:31  Loss: 0.9238 (1.0151)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [160/313]  eta: 0:00:29  Loss: 0.9901 (1.0158)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [170/313]  eta: 0:00:27  Loss: 0.9985 (1.0187)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [180/313]  eta: 0:00:25  Loss: 1.0690 (1.0211)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [190/313]  eta: 0:00:23  Loss: 1.0099 (1.0202)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [200/313]  eta: 0:00:21  Loss: 1.0084 (1.0208)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [210/313]  eta: 0:00:19  Loss: 0.9822 (1.0215)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[25/5]  [220/313]  eta: 0:00:17  Loss: 0.9668 (1.0214)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [230/313]  eta: 0:00:16  Loss: 1.0568 (1.0236)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [240/313]  eta: 0:00:14  Loss: 1.1042 (1.0282)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [250/313]  eta: 0:00:12  Loss: 1.1011 (1.0299)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [260/313]  eta: 0:00:10  Loss: 1.0112 (1.0276)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [270/313]  eta: 0:00:08  Loss: 0.9805 (1.0266)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [280/313]  eta: 0:00:06  Loss: 0.9903 (1.0251)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [290/313]  eta: 0:00:04  Loss: 0.9958 (1.0254)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [300/313]  eta: 0:00:02  Loss: 0.9949 (1.0259)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [310/313]  eta: 0:00:00  Loss: 0.9911 (1.0253)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[25/5]  [312/313]  eta: 0:00:00  Loss: 0.9911 (1.0255)  ASR: 100.0000 (100.0000)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[25/5] Total time: 0:01:00 (0.1928 s / it)
Averaged stats: Loss: 0.9911 (1.0255)  ASR: 100.0000 (100.0000)
Train: Epoch[26/5]  [  0/313]  eta: 0:01:56  Loss: 1.0062 (1.0062)  ASR: 100.0000 (100.0000)  time: 0.3737  data: 0.1769  max mem: 2383
Train: Epoch[26/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0002 (1.0182)  ASR: 100.0000 (100.0000)  time: 0.2084  data: 0.0163  max mem: 2383
Train: Epoch[26/5]  [ 20/313]  eta: 0:00:58  Loss: 0.9541 (1.0177)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [ 30/313]  eta: 0:00:55  Loss: 0.9181 (1.0018)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [ 40/313]  eta: 0:00:53  Loss: 0.9109 (0.9974)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [ 50/313]  eta: 0:00:51  Loss: 0.9669 (1.0045)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9834 (1.0000)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9321 (0.9919)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9681 (1.0008)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9668 (0.9956)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [100/313]  eta: 0:00:41  Loss: 0.9668 (1.0018)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [110/313]  eta: 0:00:39  Loss: 0.9796 (1.0049)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [120/313]  eta: 0:00:37  Loss: 0.9659 (1.0040)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [130/313]  eta: 0:00:35  Loss: 0.9621 (1.0021)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [140/313]  eta: 0:00:33  Loss: 0.9528 (1.0009)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [150/313]  eta: 0:00:31  Loss: 0.9809 (0.9993)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [160/313]  eta: 0:00:29  Loss: 0.9993 (1.0026)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [170/313]  eta: 0:00:27  Loss: 1.0426 (1.0086)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [180/313]  eta: 0:00:25  Loss: 1.0329 (1.0093)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [190/313]  eta: 0:00:23  Loss: 1.0082 (1.0091)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [200/313]  eta: 0:00:21  Loss: 1.0360 (1.0116)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [210/313]  eta: 0:00:19  Loss: 1.0360 (1.0156)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [220/313]  eta: 0:00:17  Loss: 1.0039 (1.0143)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [230/313]  eta: 0:00:16  Loss: 0.9648 (1.0125)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [240/313]  eta: 0:00:14  Loss: 0.9693 (1.0109)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [250/313]  eta: 0:00:12  Loss: 0.9693 (1.0104)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [260/313]  eta: 0:00:10  Loss: 0.9656 (1.0101)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [270/313]  eta: 0:00:08  Loss: 0.9927 (1.0105)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [280/313]  eta: 0:00:06  Loss: 0.9927 (1.0108)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [290/313]  eta: 0:00:04  Loss: 0.9559 (1.0086)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [300/313]  eta: 0:00:02  Loss: 0.9556 (1.0083)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0003  max mem: 2383
Train: Epoch[26/5]  [310/313]  eta: 0:00:00  Loss: 0.9790 (1.0098)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[26/5]  [312/313]  eta: 0:00:00  Loss: 0.9790 (1.0094)  ASR: 100.0000 (100.0000)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[26/5] Total time: 0:01:00 (0.1930 s / it)
Averaged stats: Loss: 0.9790 (1.0094)  ASR: 100.0000 (100.0000)
Train: Epoch[27/5]  [  0/313]  eta: 0:01:48  Loss: 1.0794 (1.0794)  ASR: 100.0000 (100.0000)  time: 0.3478  data: 0.1518  max mem: 2383
Train: Epoch[27/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0794 (1.0512)  ASR: 100.0000 (100.0000)  time: 0.2066  data: 0.0140  max mem: 2383
Train: Epoch[27/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0564 (1.0521)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0747 (1.0386)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [ 40/313]  eta: 0:00:53  Loss: 0.9996 (1.0267)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [ 50/313]  eta: 0:00:51  Loss: 0.9996 (1.0317)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9900 (1.0200)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9586 (1.0096)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0114 (1.0203)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0236 (1.0169)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [100/313]  eta: 0:00:41  Loss: 0.8994 (1.0088)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [110/313]  eta: 0:00:39  Loss: 0.8904 (1.0058)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [120/313]  eta: 0:00:37  Loss: 0.9858 (1.0081)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [130/313]  eta: 0:00:35  Loss: 0.9858 (1.0047)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [140/313]  eta: 0:00:33  Loss: 0.9507 (1.0038)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [150/313]  eta: 0:00:31  Loss: 0.9830 (1.0021)  ASR: 100.0000 (100.0000)  time: 0.1938  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [160/313]  eta: 0:00:29  Loss: 0.9830 (1.0026)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [170/313]  eta: 0:00:27  Loss: 0.9669 (0.9999)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [180/313]  eta: 0:00:25  Loss: 0.9790 (1.0001)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [190/313]  eta: 0:00:23  Loss: 0.9614 (0.9958)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [200/313]  eta: 0:00:21  Loss: 0.9898 (0.9991)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [210/313]  eta: 0:00:19  Loss: 1.0657 (0.9990)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [220/313]  eta: 0:00:17  Loss: 1.0127 (0.9995)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [230/313]  eta: 0:00:16  Loss: 0.9891 (1.0018)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [240/313]  eta: 0:00:14  Loss: 0.9928 (1.0023)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [250/313]  eta: 0:00:12  Loss: 0.9928 (1.0019)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [260/313]  eta: 0:00:10  Loss: 0.9676 (1.0003)  ASR: 100.0000 (100.0000)  time: 0.1924  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [270/313]  eta: 0:00:08  Loss: 0.9698 (1.0000)  ASR: 100.0000 (100.0000)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [280/313]  eta: 0:00:06  Loss: 1.0744 (1.0043)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [290/313]  eta: 0:00:04  Loss: 1.0214 (1.0025)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[27/5]  [300/313]  eta: 0:00:02  Loss: 0.9638 (1.0030)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [310/313]  eta: 0:00:00  Loss: 0.9790 (1.0048)  ASR: 100.0000 (100.0000)  time: 0.1905  data: 0.0002  max mem: 2383
Train: Epoch[27/5]  [312/313]  eta: 0:00:00  Loss: 1.0143 (1.0039)  ASR: 100.0000 (100.0000)  time: 0.1860  data: 0.0002  max mem: 2383
Train: Epoch[27/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0143 (1.0039)  ASR: 100.0000 (100.0000)
Train: Epoch[28/5]  [  0/313]  eta: 0:01:51  Loss: 1.0503 (1.0503)  ASR: 100.0000 (100.0000)  time: 0.3550  data: 0.1563  max mem: 2383
Train: Epoch[28/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0287 (1.0448)  ASR: 100.0000 (100.0000)  time: 0.2068  data: 0.0144  max mem: 2383
Train: Epoch[28/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0165 (1.0317)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0165 (1.0274)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0025 (1.0314)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0851 (1.0410)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0326 (1.0483)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9784 (1.0311)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9655 (1.0225)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9675 (1.0171)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [100/313]  eta: 0:00:41  Loss: 0.9592 (1.0064)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [110/313]  eta: 0:00:39  Loss: 0.9808 (1.0060)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [120/313]  eta: 0:00:37  Loss: 0.9808 (1.0000)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [130/313]  eta: 0:00:35  Loss: 0.9683 (1.0047)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [140/313]  eta: 0:00:33  Loss: 0.9785 (1.0024)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [150/313]  eta: 0:00:31  Loss: 0.9878 (1.0068)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [160/313]  eta: 0:00:29  Loss: 0.9878 (1.0042)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [170/313]  eta: 0:00:27  Loss: 0.9759 (1.0006)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [180/313]  eta: 0:00:25  Loss: 0.9664 (1.0016)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [190/313]  eta: 0:00:23  Loss: 0.9664 (1.0035)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [200/313]  eta: 0:00:21  Loss: 0.9779 (1.0029)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [210/313]  eta: 0:00:19  Loss: 0.9779 (1.0020)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [220/313]  eta: 0:00:17  Loss: 0.9823 (1.0018)  ASR: 100.0000 (100.0000)  time: 0.1913  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [230/313]  eta: 0:00:16  Loss: 0.9877 (1.0020)  ASR: 100.0000 (100.0000)  time: 0.1914  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [240/313]  eta: 0:00:14  Loss: 1.0009 (1.0027)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0004  max mem: 2383
Train: Epoch[28/5]  [250/313]  eta: 0:00:12  Loss: 1.0036 (1.0018)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0005  max mem: 2383
Train: Epoch[28/5]  [260/313]  eta: 0:00:10  Loss: 0.9164 (0.9983)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [270/313]  eta: 0:00:08  Loss: 0.9288 (0.9991)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [280/313]  eta: 0:00:06  Loss: 1.0144 (0.9992)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [290/313]  eta: 0:00:04  Loss: 0.9612 (0.9991)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [300/313]  eta: 0:00:02  Loss: 0.9767 (1.0002)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2383
Train: Epoch[28/5]  [310/313]  eta: 0:00:00  Loss: 0.9767 (1.0002)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0003  max mem: 2383
Train: Epoch[28/5]  [312/313]  eta: 0:00:00  Loss: 1.0766 (1.0015)  ASR: 100.0000 (100.0000)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[28/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0766 (1.0015)  ASR: 100.0000 (100.0000)
Train: Epoch[29/5]  [  0/313]  eta: 0:01:52  Loss: 0.7779 (0.7779)  ASR: 100.0000 (100.0000)  time: 0.3592  data: 0.1605  max mem: 2383
Train: Epoch[29/5]  [ 10/313]  eta: 0:01:02  Loss: 0.9664 (0.9229)  ASR: 100.0000 (100.0000)  time: 0.2073  data: 0.0148  max mem: 2383
Train: Epoch[29/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0221 (1.0046)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0555 (1.0122)  ASR: 100.0000 (100.0000)  time: 0.1942  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0036 (0.9975)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0456 (1.0052)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9749 (0.9932)  ASR: 100.0000 (100.0000)  time: 0.1922  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9506 (0.9930)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9506 (0.9925)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9743 (0.9911)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [100/313]  eta: 0:00:41  Loss: 0.9884 (0.9972)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [110/313]  eta: 0:00:39  Loss: 0.9864 (0.9958)  ASR: 100.0000 (100.0000)  time: 0.1919  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [120/313]  eta: 0:00:37  Loss: 0.8707 (0.9875)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [130/313]  eta: 0:00:35  Loss: 0.9281 (0.9882)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [140/313]  eta: 0:00:33  Loss: 0.9606 (0.9809)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [150/313]  eta: 0:00:31  Loss: 0.9758 (0.9837)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [160/313]  eta: 0:00:29  Loss: 0.9871 (0.9846)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [170/313]  eta: 0:00:27  Loss: 1.0011 (0.9868)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0002  max mem: 2383
Train: Epoch[29/5]  [180/313]  eta: 0:00:25  Loss: 0.9651 (0.9852)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [190/313]  eta: 0:00:23  Loss: 0.9593 (0.9860)  ASR: 100.0000 (100.0000)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [200/313]  eta: 0:00:21  Loss: 0.9830 (0.9899)  ASR: 100.0000 (100.0000)  time: 0.1926  data: 0.0004  max mem: 2383
Train: Epoch[29/5]  [210/313]  eta: 0:00:19  Loss: 1.0515 (0.9914)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [220/313]  eta: 0:00:17  Loss: 1.0403 (0.9944)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [230/313]  eta: 0:00:16  Loss: 0.9928 (0.9968)  ASR: 100.0000 (100.0000)  time: 0.1927  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [240/313]  eta: 0:00:14  Loss: 0.9667 (0.9951)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [250/313]  eta: 0:00:12  Loss: 0.9416 (0.9951)  ASR: 100.0000 (100.0000)  time: 0.1938  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [260/313]  eta: 0:00:10  Loss: 1.0116 (0.9988)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [270/313]  eta: 0:00:08  Loss: 1.0116 (1.0006)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [280/313]  eta: 0:00:06  Loss: 1.0075 (0.9991)  ASR: 100.0000 (100.0000)  time: 0.1938  data: 0.0004  max mem: 2383
Train: Epoch[29/5]  [290/313]  eta: 0:00:04  Loss: 0.9596 (1.0003)  ASR: 100.0000 (100.0000)  time: 0.1940  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [300/313]  eta: 0:00:02  Loss: 1.0019 (1.0004)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [310/313]  eta: 0:00:00  Loss: 1.0149 (1.0003)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[29/5]  [312/313]  eta: 0:00:00  Loss: 1.0019 (1.0007)  ASR: 100.0000 (100.0000)  time: 0.1888  data: 0.0003  max mem: 2383
Train: Epoch[29/5] Total time: 0:01:00 (0.1934 s / it)
Averaged stats: Loss: 1.0019 (1.0007)  ASR: 100.0000 (100.0000)
Train: Epoch[30/5]  [  0/313]  eta: 0:02:13  Loss: 1.0679 (1.0679)  ASR: 100.0000 (100.0000)  time: 0.4276  data: 0.2315  max mem: 2383
Train: Epoch[30/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0022 (1.0032)  ASR: 100.0000 (100.0000)  time: 0.2133  data: 0.0212  max mem: 2383
Train: Epoch[30/5]  [ 20/313]  eta: 0:00:59  Loss: 0.9617 (0.9940)  ASR: 100.0000 (100.0000)  time: 0.1923  data: 0.0002  max mem: 2383
Train: Epoch[30/5]  [ 30/313]  eta: 0:00:56  Loss: 0.9617 (0.9872)  ASR: 100.0000 (100.0000)  time: 0.1933  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [ 40/313]  eta: 0:00:54  Loss: 1.0421 (1.0078)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0636 (1.0105)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [ 60/313]  eta: 0:00:49  Loss: 0.9472 (0.9962)  ASR: 100.0000 (100.0000)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [ 70/313]  eta: 0:00:47  Loss: 0.9390 (1.0011)  ASR: 100.0000 (100.0000)  time: 0.1936  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [ 80/313]  eta: 0:00:45  Loss: 0.9516 (0.9983)  ASR: 100.0000 (100.0000)  time: 0.1935  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [ 90/313]  eta: 0:00:43  Loss: 0.9001 (0.9924)  ASR: 100.0000 (100.0000)  time: 0.1938  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [100/313]  eta: 0:00:41  Loss: 0.9891 (0.9992)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[30/5]  [110/313]  eta: 0:00:39  Loss: 0.9891 (1.0015)  ASR: 100.0000 (100.0000)  time: 0.1929  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [120/313]  eta: 0:00:37  Loss: 0.9734 (1.0027)  ASR: 100.0000 (100.0000)  time: 0.1943  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [130/313]  eta: 0:00:35  Loss: 0.9173 (0.9941)  ASR: 100.0000 (100.0000)  time: 0.1950  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [140/313]  eta: 0:00:33  Loss: 0.8839 (0.9904)  ASR: 100.0000 (100.0000)  time: 0.1947  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [150/313]  eta: 0:00:31  Loss: 0.9641 (0.9918)  ASR: 100.0000 (100.0000)  time: 0.1945  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [160/313]  eta: 0:00:29  Loss: 0.9747 (0.9912)  ASR: 100.0000 (100.0000)  time: 0.1940  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [170/313]  eta: 0:00:27  Loss: 0.8970 (0.9847)  ASR: 100.0000 (100.0000)  time: 0.1944  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [180/313]  eta: 0:00:25  Loss: 0.8817 (0.9864)  ASR: 100.0000 (100.0000)  time: 0.1941  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [190/313]  eta: 0:00:23  Loss: 0.9758 (0.9849)  ASR: 100.0000 (100.0000)  time: 0.1939  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [200/313]  eta: 0:00:22  Loss: 0.9795 (0.9861)  ASR: 100.0000 (100.0000)  time: 0.1944  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [210/313]  eta: 0:00:20  Loss: 0.9728 (0.9875)  ASR: 100.0000 (100.0000)  time: 0.1939  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [220/313]  eta: 0:00:18  Loss: 0.9012 (0.9852)  ASR: 100.0000 (100.0000)  time: 0.1939  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [230/313]  eta: 0:00:16  Loss: 0.9740 (0.9864)  ASR: 100.0000 (100.0000)  time: 0.1947  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [240/313]  eta: 0:00:14  Loss: 1.0017 (0.9846)  ASR: 100.0000 (100.0000)  time: 0.1945  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [250/313]  eta: 0:00:12  Loss: 0.9678 (0.9859)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [260/313]  eta: 0:00:10  Loss: 0.9678 (0.9875)  ASR: 100.0000 (100.0000)  time: 0.1932  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [270/313]  eta: 0:00:08  Loss: 1.0282 (0.9887)  ASR: 100.0000 (100.0000)  time: 0.1937  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [280/313]  eta: 0:00:06  Loss: 1.0059 (0.9869)  ASR: 100.0000 (100.0000)  time: 0.1941  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [290/313]  eta: 0:00:04  Loss: 0.9006 (0.9855)  ASR: 100.0000 (100.0000)  time: 0.1946  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [300/313]  eta: 0:00:02  Loss: 0.9018 (0.9842)  ASR: 100.0000 (100.0000)  time: 0.1944  data: 0.0003  max mem: 2383
Train: Epoch[30/5]  [310/313]  eta: 0:00:00  Loss: 0.9567 (0.9851)  ASR: 100.0000 (100.0000)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[30/5]  [312/313]  eta: 0:00:00  Loss: 0.9567 (0.9861)  ASR: 100.0000 (100.0000)  time: 0.1882  data: 0.0002  max mem: 2383
Train: Epoch[30/5] Total time: 0:01:00 (0.1944 s / it)
Averaged stats: Loss: 0.9567 (0.9861)  ASR: 100.0000 (100.0000)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:38  Lr: 0.001875  Loss: 2.3260  Acc@1: 18.7500 (18.7500)  Acc@5: 37.5000 (37.5000)  time: 0.5053  data: 0.1523  max mem: 2383
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:05  Lr: 0.001875  Loss: 2.1946  Acc@1: 31.2500 (34.0909)  Acc@5: 75.0000 (69.3182)  time: 0.2161  data: 0.0141  max mem: 2383
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Lr: 0.001875  Loss: 1.6247  Acc@1: 56.2500 (47.9167)  Acc@5: 81.2500 (78.2738)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.001875  Loss: 1.7396  Acc@1: 62.5000 (53.4274)  Acc@5: 93.7500 (83.2661)  time: 0.1876  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.001875  Loss: 1.4243  Acc@1: 62.5000 (58.3841)  Acc@5: 100.0000 (86.5854)  time: 0.1874  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.0720  Acc@1: 68.7500 (60.9069)  Acc@5: 93.7500 (88.2353)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.1529  Acc@1: 75.0000 (63.0123)  Acc@5: 93.7500 (89.2418)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.8767  Acc@1: 75.0000 (65.3169)  Acc@5: 100.0000 (90.3169)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 1.1141  Acc@1: 75.0000 (66.8210)  Acc@5: 93.7500 (90.8951)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.8744  Acc@1: 75.0000 (68.2692)  Acc@5: 93.7500 (91.4148)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.8289  Acc@1: 81.2500 (69.5545)  Acc@5: 100.0000 (92.0792)  time: 0.1869  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.8376  Acc@1: 81.2500 (70.2140)  Acc@5: 100.0000 (92.5676)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.6798  Acc@1: 81.2500 (71.0227)  Acc@5: 100.0000 (92.8202)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7578  Acc@1: 81.2500 (71.9943)  Acc@5: 93.7500 (93.1298)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.6531  Acc@1: 81.2500 (72.7837)  Acc@5: 100.0000 (93.5727)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.6794  Acc@1: 81.2500 (72.9719)  Acc@5: 100.0000 (93.6258)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.8733  Acc@1: 81.2500 (73.4860)  Acc@5: 93.7500 (93.7888)  time: 0.1874  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.7241  Acc@1: 81.2500 (74.1594)  Acc@5: 100.0000 (94.0424)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.5346  Acc@1: 87.5000 (74.5856)  Acc@5: 100.0000 (94.2680)  time: 0.1869  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3257  Acc@1: 87.5000 (75.2291)  Acc@5: 100.0000 (94.4372)  time: 0.1870  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.0195  Acc@1: 87.5000 (75.5908)  Acc@5: 93.7500 (94.4652)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 1.0895  Acc@1: 81.2500 (75.7405)  Acc@5: 93.7500 (94.5498)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3914  Acc@1: 81.2500 (76.1312)  Acc@5: 100.0000 (94.7115)  time: 0.1873  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.7495  Acc@1: 81.2500 (76.3258)  Acc@5: 100.0000 (94.8593)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3806  Acc@1: 81.2500 (76.6598)  Acc@5: 100.0000 (95.0467)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3858  Acc@1: 81.2500 (76.8177)  Acc@5: 100.0000 (95.0697)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3755  Acc@1: 81.2500 (77.0354)  Acc@5: 100.0000 (95.2586)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1809  Acc@1: 87.5000 (77.2832)  Acc@5: 100.0000 (95.3644)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.3053  Acc@1: 87.5000 (77.6468)  Acc@5: 100.0000 (95.5294)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4863  Acc@1: 87.5000 (77.9424)  Acc@5: 100.0000 (95.5756)  time: 0.1872  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.4127  Acc@1: 81.2500 (78.0731)  Acc@5: 100.0000 (95.6811)  time: 0.1871  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4565  Acc@1: 81.2500 (78.2958)  Acc@5: 100.0000 (95.7797)  time: 0.1869  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.8621  Acc@1: 81.2500 (78.3000)  Acc@5: 100.0000 (95.8000)  time: 0.1824  data: 0.0002  max mem: 2383
Train: Epoch[1/5] Total time: 0:00:58 (0.1881 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.8621  Acc@1: 81.2500 (78.3000)  Acc@5: 100.0000 (95.8000)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:49  Loss: 0.0599 (0.0599)  ASR: 100.0000 (100.0000)  time: 0.5424  data: 0.2151  max mem: 2383
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:08  Loss: 0.0624 (0.0617)  ASR: 100.0000 (95.1732)  time: 0.2249  data: 0.0198  max mem: 2383
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:01  Loss: 0.0616 (0.0617)  ASR: 100.0000 (94.4444)  time: 0.1931  data: 0.0003  max mem: 2383
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:57  Loss: 0.0607 (0.0612)  ASR: 100.0000 (95.9677)  time: 0.1930  data: 0.0003  max mem: 2383
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:55  Loss: 0.0595 (0.0607)  ASR: 100.0000 (96.7886)  time: 0.1934  data: 0.0003  max mem: 2383
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:52  Loss: 0.0573 (0.0601)  ASR: 100.0000 (96.8970)  time: 0.1928  data: 0.0003  max mem: 2383
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:50  Loss: 0.0572 (0.0595)  ASR: 100.0000 (97.0427)  time: 0.1930  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:48  Loss: 0.0559 (0.0590)  ASR: 100.0000 (97.3509)  time: 0.1931  data: 0.0002  max mem: 2383
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 0.0553 (0.0585)  ASR: 100.0000 (97.6779)  time: 0.1924  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 0.0541 (0.0581)  ASR: 100.0000 (97.9331)  time: 0.1927  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 0.0541 (0.0577)  ASR: 100.0000 (98.1377)  time: 0.1934  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 0.0542 (0.0573)  ASR: 100.0000 (98.2412)  time: 0.1931  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 0.0533 (0.0570)  ASR: 100.0000 (98.3039)  time: 0.1926  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 0.0523 (0.0566)  ASR: 100.0000 (98.4333)  time: 0.1935  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 0.0519 (0.0563)  ASR: 100.0000 (98.4353)  time: 0.1930  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 0.0517 (0.0559)  ASR: 100.0000 (98.5390)  time: 0.1931  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 0.0508 (0.0556)  ASR: 100.0000 (98.6297)  time: 0.1936  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 0.0499 (0.0553)  ASR: 100.0000 (98.7098)  time: 0.1934  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 0.0497 (0.0550)  ASR: 100.0000 (98.7811)  time: 0.1929  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 0.0493 (0.0548)  ASR: 100.0000 (98.8449)  time: 0.1923  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [200/313]  eta: 0:00:22  Loss: 0.0495 (0.0545)  ASR: 100.0000 (98.9024)  time: 0.1923  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [210/313]  eta: 0:00:20  Loss: 0.0495 (0.0543)  ASR: 100.0000 (98.8732)  time: 0.1925  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [220/313]  eta: 0:00:18  Loss: 0.0485 (0.0540)  ASR: 100.0000 (98.8918)  time: 0.1927  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [230/313]  eta: 0:00:16  Loss: 0.0476 (0.0537)  ASR: 100.0000 (98.9398)  time: 0.1927  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 0.0472 (0.0535)  ASR: 100.0000 (98.9838)  time: 0.1924  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 0.0479 (0.0533)  ASR: 100.0000 (99.0243)  time: 0.1929  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 0.0479 (0.0531)  ASR: 100.0000 (99.0617)  time: 0.1937  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 0.0466 (0.0528)  ASR: 100.0000 (99.0679)  time: 0.1938  data: 0.0003  max mem: 2384
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 0.0468 (0.0527)  ASR: 100.0000 (99.1011)  time: 0.1930  data: 0.0003  max mem: 2384
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 0.0463 (0.0524)  ASR: 100.0000 (99.1320)  time: 0.1926  data: 0.0003  max mem: 2384
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 0.0454 (0.0522)  ASR: 100.0000 (99.1608)  time: 0.1925  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 0.0458 (0.0520)  ASR: 100.0000 (99.1878)  time: 0.1927  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 0.0462 (0.0520)  ASR: 100.0000 (99.1917)  time: 0.1880  data: 0.0002  max mem: 2384
Train: Epoch[1/5] Total time: 0:01:00 (0.1940 s / it)
Averaged stats: Loss: 0.0462 (0.0520)  ASR: 100.0000 (99.1917)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:44  Lr: 0.001875  Loss: 0.6433  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.3343  data: 0.1393  max mem: 2384
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.4226  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.7273)  time: 0.2001  data: 0.0128  max mem: 2384
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.4207  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (98.2143)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6513  Acc@1: 87.5000 (83.4677)  Acc@5: 100.0000 (97.7823)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.4384  Acc@1: 81.2500 (83.2317)  Acc@5: 100.0000 (97.8659)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.3726  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (97.6716)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1710  Acc@1: 87.5000 (83.4016)  Acc@5: 100.0000 (97.8484)  time: 0.1873  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.4605  Acc@1: 87.5000 (84.5070)  Acc@5: 100.0000 (97.8873)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.6945  Acc@1: 87.5000 (84.0278)  Acc@5: 100.0000 (97.9167)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1421  Acc@1: 81.2500 (84.3407)  Acc@5: 100.0000 (98.0082)  time: 0.1874  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.4501  Acc@1: 87.5000 (84.5297)  Acc@5: 100.0000 (97.9579)  time: 0.1874  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1233  Acc@1: 87.5000 (85.1914)  Acc@5: 100.0000 (98.0856)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4506  Acc@1: 87.5000 (84.8657)  Acc@5: 100.0000 (98.0372)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7276  Acc@1: 75.0000 (84.3511)  Acc@5: 100.0000 (97.9962)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3081  Acc@1: 75.0000 (84.1312)  Acc@5: 100.0000 (97.8280)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.4145  Acc@1: 87.5000 (84.4371)  Acc@5: 100.0000 (97.8063)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2912  Acc@1: 87.5000 (84.5885)  Acc@5: 100.0000 (97.8649)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0619  Acc@1: 87.5000 (84.8684)  Acc@5: 100.0000 (97.9167)  time: 0.1872  data: 0.0001  max mem: 2384
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.3899  Acc@1: 87.5000 (84.8066)  Acc@5: 100.0000 (97.8246)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0531  Acc@1: 81.2500 (84.4895)  Acc@5: 100.0000 (97.7749)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3366  Acc@1: 81.2500 (84.6704)  Acc@5: 100.0000 (97.7612)  time: 0.1866  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.1692  Acc@1: 87.5000 (84.6268)  Acc@5: 100.0000 (97.7784)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0397  Acc@1: 81.2500 (84.6437)  Acc@5: 100.0000 (97.7941)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1231  Acc@1: 87.5000 (84.7132)  Acc@5: 100.0000 (97.8896)  time: 0.1868  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.4699  Acc@1: 87.5000 (84.7770)  Acc@5: 100.0000 (97.9512)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1223  Acc@1: 87.5000 (84.9602)  Acc@5: 100.0000 (97.9582)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1835  Acc@1: 87.5000 (85.0335)  Acc@5: 100.0000 (97.9406)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0989  Acc@1: 87.5000 (85.1476)  Acc@5: 100.0000 (97.9705)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2941  Acc@1: 87.5000 (85.0534)  Acc@5: 100.0000 (98.0205)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4231  Acc@1: 81.2500 (85.0945)  Acc@5: 100.0000 (97.9811)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3449  Acc@1: 87.5000 (85.1952)  Acc@5: 100.0000 (97.9859)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1723  Acc@1: 87.5000 (85.1688)  Acc@5: 100.0000 (97.9703)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7733  Acc@1: 87.5000 (85.1600)  Acc@5: 100.0000 (97.9800)  time: 0.1827  data: 0.0002  max mem: 2384
Train: Epoch[2/5] Total time: 0:00:58 (0.1875 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7733  Acc@1: 87.5000 (85.1600)  Acc@5: 100.0000 (97.9800)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:52  Loss: 0.0495 (0.0495)  ASR: 91.6667 (91.6667)  time: 0.3586  data: 0.1626  max mem: 2384
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:03  Loss: 0.0476 (0.0473)  ASR: 100.0000 (99.2424)  time: 0.2087  data: 0.0151  max mem: 2384
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 0.0449 (0.0460)  ASR: 100.0000 (98.8706)  time: 0.1933  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Loss: 0.0444 (0.0456)  ASR: 100.0000 (98.9417)  time: 0.1935  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 0.0441 (0.0452)  ASR: 100.0000 (98.8246)  time: 0.1933  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 0.0437 (0.0449)  ASR: 100.0000 (98.6807)  time: 0.1929  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 0.0435 (0.0447)  ASR: 100.0000 (98.8970)  time: 0.1929  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 0.0433 (0.0445)  ASR: 100.0000 (98.9517)  time: 0.1927  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 0.0429 (0.0442)  ASR: 100.0000 (99.0811)  time: 0.1928  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 0.0429 (0.0442)  ASR: 100.0000 (99.1821)  time: 0.1929  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 0.0425 (0.0440)  ASR: 100.0000 (99.1971)  time: 0.1926  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 0.0420 (0.0440)  ASR: 100.0000 (99.2694)  time: 0.1924  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 0.0435 (0.0439)  ASR: 100.0000 (99.2662)  time: 0.1927  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 0.0422 (0.0438)  ASR: 100.0000 (99.3222)  time: 0.1928  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 0.0414 (0.0436)  ASR: 100.0000 (99.3197)  time: 0.1933  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 0.0414 (0.0435)  ASR: 100.0000 (99.3174)  time: 0.1934  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 0.0407 (0.0433)  ASR: 100.0000 (99.3598)  time: 0.1933  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 0.0399 (0.0431)  ASR: 100.0000 (99.3972)  time: 0.1926  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 0.0410 (0.0431)  ASR: 100.0000 (99.4305)  time: 0.1922  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 0.0418 (0.0429)  ASR: 100.0000 (99.4604)  time: 0.1928  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 0.0396 (0.0428)  ASR: 100.0000 (99.4420)  time: 0.1930  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 0.0395 (0.0427)  ASR: 100.0000 (99.4368)  time: 0.1924  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [220/313]  eta: 0:00:18  Loss: 0.0397 (0.0426)  ASR: 100.0000 (99.4623)  time: 0.1936  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [230/313]  eta: 0:00:16  Loss: 0.0409 (0.0426)  ASR: 100.0000 (99.4856)  time: 0.1943  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 0.0406 (0.0424)  ASR: 100.0000 (99.5069)  time: 0.1936  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 0.0387 (0.0423)  ASR: 100.0000 (99.4675)  time: 0.1925  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 0.0383 (0.0421)  ASR: 100.0000 (99.4605)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 0.0384 (0.0421)  ASR: 100.0000 (99.4520)  time: 0.1920  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 0.0380 (0.0419)  ASR: 100.0000 (99.4715)  time: 0.1929  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 0.0374 (0.0418)  ASR: 100.0000 (99.4897)  time: 0.1934  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 0.0387 (0.0417)  ASR: 100.0000 (99.4845)  time: 0.1937  data: 0.0003  max mem: 2384
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 0.0381 (0.0416)  ASR: 100.0000 (99.4495)  time: 0.1934  data: 0.0002  max mem: 2384
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 0.0381 (0.0416)  ASR: 100.0000 (99.4522)  time: 0.1886  data: 0.0002  max mem: 2384
Train: Epoch[2/5] Total time: 0:01:00 (0.1934 s / it)
Averaged stats: Loss: 0.0381 (0.0416)  ASR: 100.0000 (99.4522)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:42  Lr: 0.001875  Loss: 0.3871  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.3285  data: 0.1389  max mem: 2384
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1379  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.2004  data: 0.0128  max mem: 2384
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: -0.0246  Acc@1: 87.5000 (85.4167)  Acc@5: 100.0000 (98.8095)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2340  Acc@1: 81.2500 (84.8790)  Acc@5: 100.0000 (99.1935)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1332  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (99.3902)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2209  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (99.2647)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.3807  Acc@1: 87.5000 (85.2459)  Acc@5: 100.0000 (99.2828)  time: 0.1874  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: -0.1505  Acc@1: 81.2500 (85.7394)  Acc@5: 100.0000 (99.2077)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0475  Acc@1: 87.5000 (86.2654)  Acc@5: 100.0000 (99.1512)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.3877  Acc@1: 87.5000 (85.9203)  Acc@5: 100.0000 (99.0385)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3678  Acc@1: 87.5000 (86.3861)  Acc@5: 100.0000 (99.0099)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0523  Acc@1: 87.5000 (86.2613)  Acc@5: 100.0000 (98.8176)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2199  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.6570)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3218  Acc@1: 87.5000 (86.2595)  Acc@5: 100.0000 (98.4256)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1017  Acc@1: 87.5000 (86.4805)  Acc@5: 100.0000 (98.5372)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1662  Acc@1: 87.5000 (86.4238)  Acc@5: 100.0000 (98.5099)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2007  Acc@1: 87.5000 (86.4907)  Acc@5: 100.0000 (98.4472)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0130  Acc@1: 87.5000 (86.6228)  Acc@5: 100.0000 (98.4649)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0456  Acc@1: 87.5000 (86.6367)  Acc@5: 100.0000 (98.5152)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1837  Acc@1: 87.5000 (86.6165)  Acc@5: 100.0000 (98.4620)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3975  Acc@1: 87.5000 (86.5361)  Acc@5: 100.0000 (98.4453)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.1624  Acc@1: 87.5000 (86.6114)  Acc@5: 100.0000 (98.5190)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.5096  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.4163)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2167  Acc@1: 87.5000 (86.6883)  Acc@5: 100.0000 (98.4307)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0694  Acc@1: 87.5000 (86.6183)  Acc@5: 100.0000 (98.4440)  time: 0.1878  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2376  Acc@1: 87.5000 (86.5787)  Acc@5: 100.0000 (98.4562)  time: 0.1879  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1809  Acc@1: 87.5000 (86.5661)  Acc@5: 100.0000 (98.4195)  time: 0.1877  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0263  Acc@1: 87.5000 (86.6006)  Acc@5: 100.0000 (98.3625)  time: 0.1877  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1252  Acc@1: 87.5000 (86.5881)  Acc@5: 100.0000 (98.3541)  time: 0.1878  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0815  Acc@1: 87.5000 (86.6624)  Acc@5: 100.0000 (98.3677)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1888  Acc@1: 87.5000 (86.6902)  Acc@5: 100.0000 (98.3596)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0887  Acc@1: 87.5000 (86.8770)  Acc@5: 100.0000 (98.4124)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6600  Acc@1: 87.5000 (86.8600)  Acc@5: 100.0000 (98.4200)  time: 0.1827  data: 0.0002  max mem: 2384
Train: Epoch[3/5] Total time: 0:00:58 (0.1878 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6600  Acc@1: 87.5000 (86.8600)  Acc@5: 100.0000 (98.4200)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:44  Loss: 0.0341 (0.0341)  ASR: 100.0000 (100.0000)  time: 0.3341  data: 0.1340  max mem: 2384
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Loss: 0.0374 (0.0372)  ASR: 100.0000 (99.3939)  time: 0.2065  data: 0.0125  max mem: 2384
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 0.0375 (0.0377)  ASR: 100.0000 (98.9761)  time: 0.1930  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 0.0379 (0.0376)  ASR: 100.0000 (98.7894)  time: 0.1925  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 0.0379 (0.0377)  ASR: 100.0000 (98.8814)  time: 0.1928  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 0.0380 (0.0378)  ASR: 100.0000 (99.1008)  time: 0.1933  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 0.0372 (0.0376)  ASR: 100.0000 (99.2482)  time: 0.1933  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 0.0357 (0.0374)  ASR: 100.0000 (99.3541)  time: 0.1931  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 0.0356 (0.0371)  ASR: 100.0000 (99.4338)  time: 0.1928  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 0.0352 (0.0368)  ASR: 100.0000 (99.4960)  time: 0.1920  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 0.0339 (0.0366)  ASR: 100.0000 (99.5459)  time: 0.1916  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 0.0344 (0.0365)  ASR: 100.0000 (99.5868)  time: 0.1915  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 0.0345 (0.0364)  ASR: 100.0000 (99.5521)  time: 0.1917  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 0.0345 (0.0362)  ASR: 100.0000 (99.5863)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 0.0344 (0.0361)  ASR: 100.0000 (99.6156)  time: 0.1923  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 0.0340 (0.0359)  ASR: 100.0000 (99.6411)  time: 0.1934  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 0.0338 (0.0358)  ASR: 100.0000 (99.6190)  time: 0.1931  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 0.0336 (0.0356)  ASR: 100.0000 (99.6413)  time: 0.1930  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 0.0326 (0.0354)  ASR: 100.0000 (99.6243)  time: 0.1934  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 0.0320 (0.0353)  ASR: 100.0000 (99.6440)  time: 0.1933  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 0.0317 (0.0351)  ASR: 100.0000 (99.6617)  time: 0.1930  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 0.0319 (0.0349)  ASR: 100.0000 (99.6777)  time: 0.1927  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 0.0318 (0.0348)  ASR: 100.0000 (99.6923)  time: 0.1925  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [230/313]  eta: 0:00:16  Loss: 0.0306 (0.0346)  ASR: 100.0000 (99.7056)  time: 0.1920  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 0.0304 (0.0345)  ASR: 100.0000 (99.7178)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 0.0309 (0.0343)  ASR: 100.0000 (99.7291)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 0.0326 (0.0343)  ASR: 100.0000 (99.7395)  time: 0.1916  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 0.0328 (0.0342)  ASR: 100.0000 (99.7207)  time: 0.1914  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 0.0324 (0.0341)  ASR: 100.0000 (99.7306)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 0.0322 (0.0341)  ASR: 100.0000 (99.7399)  time: 0.1930  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 0.0319 (0.0340)  ASR: 100.0000 (99.7485)  time: 0.1933  data: 0.0003  max mem: 2384
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 0.0310 (0.0339)  ASR: 100.0000 (99.7566)  time: 0.1921  data: 0.0002  max mem: 2384
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 0.0305 (0.0338)  ASR: 100.0000 (99.7578)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[3/5] Total time: 0:01:00 (0.1928 s / it)
Averaged stats: Loss: 0.0305 (0.0338)  ASR: 100.0000 (99.7578)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:58  Lr: 0.001875  Loss: -0.0185  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3774  data: 0.1886  max mem: 2384
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.2074  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (97.7273)  time: 0.2051  data: 0.0174  max mem: 2384
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.3564  Acc@1: 93.7500 (86.9048)  Acc@5: 100.0000 (98.2143)  time: 0.1877  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0290  Acc@1: 81.2500 (85.4839)  Acc@5: 100.0000 (98.5887)  time: 0.1877  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0469  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.7805)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.0221  Acc@1: 87.5000 (85.5392)  Acc@5: 100.0000 (98.7745)  time: 0.1876  data: 0.0003  max mem: 2384
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1816  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (98.9754)  time: 0.1879  data: 0.0003  max mem: 2384
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.0166  Acc@1: 87.5000 (86.4437)  Acc@5: 100.0000 (98.9437)  time: 0.1878  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1369  Acc@1: 87.5000 (86.4198)  Acc@5: 100.0000 (98.9969)  time: 0.1878  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.2365  Acc@1: 81.2500 (86.1951)  Acc@5: 100.0000 (98.8324)  time: 0.1877  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0554  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.7624)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.4971  Acc@1: 87.5000 (86.7680)  Acc@5: 100.0000 (98.8176)  time: 0.1875  data: 0.0003  max mem: 2384
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0417  Acc@1: 87.5000 (86.5702)  Acc@5: 100.0000 (98.7087)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1922  Acc@1: 87.5000 (87.0706)  Acc@5: 100.0000 (98.7118)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.2063  Acc@1: 87.5000 (86.7021)  Acc@5: 100.0000 (98.7145)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1064  Acc@1: 87.5000 (86.7964)  Acc@5: 100.0000 (98.6755)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0595  Acc@1: 87.5000 (86.7236)  Acc@5: 100.0000 (98.6025)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0300  Acc@1: 87.5000 (86.8787)  Acc@5: 100.0000 (98.6111)  time: 0.1868  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.3296  Acc@1: 87.5000 (86.8094)  Acc@5: 100.0000 (98.6533)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0704  Acc@1: 87.5000 (86.8128)  Acc@5: 100.0000 (98.6584)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3246  Acc@1: 87.5000 (86.9403)  Acc@5: 100.0000 (98.6629)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0559  Acc@1: 93.7500 (87.1445)  Acc@5: 100.0000 (98.6078)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1314  Acc@1: 87.5000 (86.9061)  Acc@5: 100.0000 (98.5860)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2762  Acc@1: 81.2500 (86.7424)  Acc@5: 100.0000 (98.5931)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0494  Acc@1: 87.5000 (86.7998)  Acc@5: 100.0000 (98.5996)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2378  Acc@1: 87.5000 (86.8775)  Acc@5: 100.0000 (98.6554)  time: 0.1875  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0726  Acc@1: 87.5000 (86.8774)  Acc@5: 100.0000 (98.6830)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0539  Acc@1: 87.5000 (86.9234)  Acc@5: 100.0000 (98.7085)  time: 0.1876  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2798  Acc@1: 87.5000 (86.8550)  Acc@5: 100.0000 (98.7100)  time: 0.1877  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0826  Acc@1: 87.5000 (87.0275)  Acc@5: 100.0000 (98.7113)  time: 0.1877  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.4473  Acc@1: 87.5000 (86.9394)  Acc@5: 100.0000 (98.6711)  time: 0.1873  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1285  Acc@1: 81.2500 (86.9373)  Acc@5: 100.0000 (98.6736)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0816  Acc@1: 81.2500 (86.9600)  Acc@5: 100.0000 (98.6600)  time: 0.1826  data: 0.0002  max mem: 2384
Train: Epoch[4/5] Total time: 0:00:58 (0.1879 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0816  Acc@1: 81.2500 (86.9600)  Acc@5: 100.0000 (98.6600)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:56  Loss: 0.0318 (0.0318)  ASR: 100.0000 (100.0000)  time: 0.3731  data: 0.1766  max mem: 2384
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Loss: 0.0294 (0.0302)  ASR: 100.0000 (99.3007)  time: 0.2084  data: 0.0162  max mem: 2384
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Loss: 0.0293 (0.0300)  ASR: 100.0000 (99.6337)  time: 0.1915  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Loss: 0.0299 (0.0304)  ASR: 100.0000 (99.7519)  time: 0.1913  data: 0.0001  max mem: 2384
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 0.0299 (0.0303)  ASR: 100.0000 (99.8124)  time: 0.1911  data: 0.0001  max mem: 2384
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 0.0285 (0.0301)  ASR: 100.0000 (99.8492)  time: 0.1912  data: 0.0001  max mem: 2384
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 0.0294 (0.0302)  ASR: 100.0000 (99.7478)  time: 0.1916  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 0.0303 (0.0303)  ASR: 100.0000 (99.7833)  time: 0.1917  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 0.0287 (0.0299)  ASR: 100.0000 (99.8101)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 0.0274 (0.0297)  ASR: 100.0000 (99.8309)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 0.0301 (0.0298)  ASR: 100.0000 (99.8477)  time: 0.1924  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 0.0283 (0.0296)  ASR: 100.0000 (99.8614)  time: 0.1929  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 0.0279 (0.0296)  ASR: 100.0000 (99.8729)  time: 0.1928  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 0.0302 (0.0297)  ASR: 100.0000 (99.8238)  time: 0.1921  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 0.0302 (0.0296)  ASR: 100.0000 (99.7857)  time: 0.1927  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 0.0273 (0.0294)  ASR: 100.0000 (99.7999)  time: 0.1927  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 0.0277 (0.0294)  ASR: 100.0000 (99.8123)  time: 0.1929  data: 0.0003  max mem: 2384
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 0.0290 (0.0294)  ASR: 100.0000 (99.8233)  time: 0.1928  data: 0.0003  max mem: 2384
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 0.0286 (0.0293)  ASR: 100.0000 (99.8330)  time: 0.1917  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 0.0272 (0.0292)  ASR: 100.0000 (99.8015)  time: 0.1914  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 0.0273 (0.0292)  ASR: 100.0000 (99.8114)  time: 0.1909  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 0.0278 (0.0291)  ASR: 100.0000 (99.8203)  time: 0.1908  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 0.0268 (0.0291)  ASR: 100.0000 (99.8285)  time: 0.1912  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Loss: 0.0280 (0.0290)  ASR: 100.0000 (99.8359)  time: 0.1911  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 0.0271 (0.0290)  ASR: 100.0000 (99.8427)  time: 0.1910  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 0.0270 (0.0289)  ASR: 100.0000 (99.8490)  time: 0.1912  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 0.0270 (0.0289)  ASR: 100.0000 (99.8547)  time: 0.1915  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 0.0275 (0.0288)  ASR: 100.0000 (99.8601)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 0.0269 (0.0287)  ASR: 100.0000 (99.8651)  time: 0.1917  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 0.0282 (0.0288)  ASR: 100.0000 (99.8697)  time: 0.1910  data: 0.0001  max mem: 2384
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 0.0285 (0.0288)  ASR: 100.0000 (99.8740)  time: 0.1912  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 0.0272 (0.0287)  ASR: 100.0000 (99.8781)  time: 0.1915  data: 0.0002  max mem: 2384
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 0.0272 (0.0287)  ASR: 100.0000 (99.8787)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[4/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Loss: 0.0272 (0.0287)  ASR: 100.0000 (99.8787)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:41  Lr: 0.001875  Loss: -0.0620  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3232  data: 0.1332  max mem: 2384
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.1911  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (99.4318)  time: 0.1991  data: 0.0123  max mem: 2384
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.2524  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (99.1071)  time: 0.1865  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0056  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (99.3952)  time: 0.1865  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1226  Acc@1: 93.7500 (91.7683)  Acc@5: 100.0000 (99.2378)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.0970  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (99.2647)  time: 0.1872  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2947  Acc@1: 87.5000 (90.1639)  Acc@5: 100.0000 (99.2828)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3986  Acc@1: 81.2500 (89.3486)  Acc@5: 100.0000 (99.0317)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3304  Acc@1: 87.5000 (89.5062)  Acc@5: 100.0000 (98.9969)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0867  Acc@1: 87.5000 (89.6291)  Acc@5: 100.0000 (98.9011)  time: 0.1868  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1705  Acc@1: 87.5000 (89.5421)  Acc@5: 100.0000 (98.8861)  time: 0.1866  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0285  Acc@1: 87.5000 (89.0766)  Acc@5: 100.0000 (98.9302)  time: 0.1865  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1097  Acc@1: 87.5000 (89.0496)  Acc@5: 100.0000 (98.9153)  time: 0.1864  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.6108  Acc@1: 87.5000 (88.9313)  Acc@5: 100.0000 (98.7118)  time: 0.1863  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3254  Acc@1: 87.5000 (88.7411)  Acc@5: 100.0000 (98.8032)  time: 0.1866  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1004  Acc@1: 87.5000 (88.5348)  Acc@5: 100.0000 (98.7169)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1470  Acc@1: 87.5000 (88.3152)  Acc@5: 100.0000 (98.6801)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0983  Acc@1: 87.5000 (88.3772)  Acc@5: 100.0000 (98.6477)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1595  Acc@1: 81.2500 (88.1215)  Acc@5: 100.0000 (98.6878)  time: 0.1871  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0150  Acc@1: 87.5000 (88.3181)  Acc@5: 100.0000 (98.6911)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0985  Acc@1: 87.5000 (88.2774)  Acc@5: 100.0000 (98.7251)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2130  Acc@1: 87.5000 (88.2109)  Acc@5: 100.0000 (98.7559)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0430  Acc@1: 87.5000 (88.1222)  Acc@5: 100.0000 (98.7557)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2786  Acc@1: 87.5000 (88.2576)  Acc@5: 100.0000 (98.7554)  time: 0.1867  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0651  Acc@1: 93.7500 (88.3039)  Acc@5: 100.0000 (98.7293)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2756  Acc@1: 87.5000 (88.1972)  Acc@5: 100.0000 (98.6803)  time: 0.1871  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4200  Acc@1: 87.5000 (88.2663)  Acc@5: 100.0000 (98.6830)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4325  Acc@1: 87.5000 (88.2380)  Acc@5: 100.0000 (98.6162)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0298  Acc@1: 87.5000 (88.2117)  Acc@5: 100.0000 (98.6655)  time: 0.1868  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0269  Acc@1: 87.5000 (88.1229)  Acc@5: 100.0000 (98.6684)  time: 0.1867  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3858  Acc@1: 81.2500 (87.9568)  Acc@5: 100.0000 (98.6088)  time: 0.1868  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0165  Acc@1: 87.5000 (87.9622)  Acc@5: 100.0000 (98.6535)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2706  Acc@1: 87.5000 (87.9800)  Acc@5: 100.0000 (98.6600)  time: 0.1826  data: 0.0001  max mem: 2384
Train: Epoch[5/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2706  Acc@1: 87.5000 (87.9800)  Acc@5: 100.0000 (98.6600)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:01  Loss: 0.0281 (0.0281)  ASR: 100.0000 (100.0000)  time: 0.3866  data: 0.1887  max mem: 2384
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Loss: 0.0291 (0.0282)  ASR: 100.0000 (100.0000)  time: 0.2099  data: 0.0174  max mem: 2384
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Loss: 0.0257 (0.0270)  ASR: 100.0000 (100.0000)  time: 0.1925  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Loss: 0.0248 (0.0267)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 0.0247 (0.0268)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 0.0260 (0.0269)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 0.0261 (0.0268)  ASR: 100.0000 (100.0000)  time: 0.1915  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 0.0255 (0.0266)  ASR: 100.0000 (100.0000)  time: 0.1920  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 0.0270 (0.0268)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 0.0275 (0.0268)  ASR: 100.0000 (100.0000)  time: 0.1916  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 0.0267 (0.0267)  ASR: 100.0000 (100.0000)  time: 0.1917  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 0.0262 (0.0267)  ASR: 100.0000 (100.0000)  time: 0.1911  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 0.0264 (0.0268)  ASR: 100.0000 (100.0000)  time: 0.1918  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 0.0270 (0.0268)  ASR: 100.0000 (100.0000)  time: 0.1921  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 0.0259 (0.0268)  ASR: 100.0000 (99.9355)  time: 0.1915  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 0.0246 (0.0266)  ASR: 100.0000 (99.9398)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 0.0268 (0.0267)  ASR: 100.0000 (99.9435)  time: 0.1928  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 0.0277 (0.0267)  ASR: 100.0000 (99.9468)  time: 0.1931  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 0.0252 (0.0267)  ASR: 100.0000 (99.9498)  time: 0.1934  data: 0.0003  max mem: 2384
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 0.0246 (0.0266)  ASR: 100.0000 (99.9524)  time: 0.1928  data: 0.0003  max mem: 2384
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 0.0252 (0.0268)  ASR: 100.0000 (99.9548)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 0.0263 (0.0267)  ASR: 100.0000 (99.9569)  time: 0.1922  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 0.0258 (0.0267)  ASR: 100.0000 (99.9589)  time: 0.1921  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [230/313]  eta: 0:00:16  Loss: 0.0253 (0.0266)  ASR: 100.0000 (99.9606)  time: 0.1919  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 0.0244 (0.0266)  ASR: 100.0000 (99.9623)  time: 0.1920  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 0.0248 (0.0265)  ASR: 100.0000 (99.9372)  time: 0.1928  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 0.0258 (0.0265)  ASR: 100.0000 (99.9396)  time: 0.1934  data: 0.0003  max mem: 2384
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 0.0256 (0.0265)  ASR: 100.0000 (99.9419)  time: 0.1926  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 0.0256 (0.0265)  ASR: 100.0000 (99.9439)  time: 0.1920  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 0.0252 (0.0264)  ASR: 100.0000 (99.9459)  time: 0.1925  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 0.0250 (0.0264)  ASR: 100.0000 (99.9477)  time: 0.1926  data: 0.0003  max mem: 2384
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 0.0257 (0.0264)  ASR: 100.0000 (99.9493)  time: 0.1921  data: 0.0002  max mem: 2384
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 0.0255 (0.0264)  ASR: 100.0000 (99.9496)  time: 0.1874  data: 0.0002  max mem: 2384
Train: Epoch[5/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 0.0255 (0.0264)  ASR: 100.0000 (99.9496)
Test: [Task 1]  [ 0/63]  eta: 0:00:15  Loss: 0.3659 (0.3659)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2522  data: 0.1353  max mem: 2384
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.3659 (0.4015)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  time: 0.1287  data: 0.0125  max mem: 2384
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.3436 (0.4541)  Acc@1: 93.7500 (95.5357)  Acc@5: 100.0000 (100.0000)  time: 0.1166  data: 0.0002  max mem: 2384
Test: [Task 1]  [30/63]  eta: 0:00:03  Loss: 0.3017 (0.4054)  Acc@1: 100.0000 (96.5726)  Acc@5: 100.0000 (100.0000)  time: 0.1167  data: 0.0003  max mem: 2384
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.2818 (0.3987)  Acc@1: 100.0000 (96.6463)  Acc@5: 100.0000 (100.0000)  time: 0.1166  data: 0.0003  max mem: 2384
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.3524 (0.3888)  Acc@1: 100.0000 (96.9363)  Acc@5: 100.0000 (99.8775)  time: 0.1166  data: 0.0003  max mem: 2384
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3747 (0.3813)  Acc@1: 100.0000 (97.1311)  Acc@5: 100.0000 (99.8975)  time: 0.1165  data: 0.0002  max mem: 2384
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3524 (0.3799)  Acc@1: 100.0000 (97.2000)  Acc@5: 100.0000 (99.9000)  time: 0.1137  data: 0.0002  max mem: 2384
Test: [Task 1] Total time: 0:00:07 (0.1185 s / it)
* Acc@1 97.200 Acc@5 99.900 loss 0.380
Test: [Task 1]  [ 0/63]  eta: 0:00:17  ASR: 100.0000 (100.0000)  ACC: 100.0000 (100.0000)  Loss: 1.1663 (1.1663)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.2841  data: 0.1591  max mem: 2384
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 100.0000 (98.1132)  Loss: 1.4255 (1.5096)  Acc@1: 87.5000 (88.6364)  Acc@5: 87.5000 (90.3409)  time: 0.1330  data: 0.0147  max mem: 2384
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 100.0000 (95.7237)  Loss: 1.4255 (1.3943)  Acc@1: 87.5000 (88.0952)  Acc@5: 87.5000 (91.9643)  time: 0.1179  data: 0.0003  max mem: 2384
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 100.0000 (96.6292)  Loss: 1.1848 (1.3980)  Acc@1: 87.5000 (88.5081)  Acc@5: 93.7500 (91.7339)  time: 0.1178  data: 0.0002  max mem: 2384
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 100.0000 (96.5636)  Loss: 1.3897 (1.4532)  Acc@1: 87.5000 (87.8049)  Acc@5: 87.5000 (91.0061)  time: 0.1177  data: 0.0002  max mem: 2384
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 100.0000 (96.8536)  Loss: 1.2544 (1.3831)  Acc@1: 87.5000 (88.4804)  Acc@5: 87.5000 (91.2990)  time: 0.1177  data: 0.0002  max mem: 2384
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 100.0000 (97.0218)  Loss: 1.1856 (1.4054)  Acc@1: 87.5000 (88.4221)  Acc@5: 93.7500 (91.0861)  time: 0.1176  data: 0.0002  max mem: 2384
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 100.0000 (97.0982)  Loss: 1.1856 (1.3946)  Acc@1: 87.5000 (88.6000)  Acc@5: 93.7500 (91.2000)  time: 0.1148  data: 0.0002  max mem: 2384
Test: [Task 1] Total time: 0:00:07 (0.1202 s / it)
* Acc@1 88.600 Acc@5 91.200 loss 1.395
* Acc@1 nan ASR 97.098
[Average accuracy till task1]	Acc@1: 88.6000	Acc@5: 91.2000	Loss: 1.3946
Train: Epoch[1/5]  [  0/313]  eta: 0:02:09  Lr: 0.001875  Loss: 2.0322  Acc@1: 18.7500 (18.7500)  Acc@5: 62.5000 (62.5000)  time: 0.4126  data: 0.2229  max mem: 2384
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Lr: 0.001875  Loss: 1.8699  Acc@1: 25.0000 (27.8409)  Acc@5: 75.0000 (71.5909)  time: 0.2070  data: 0.0204  max mem: 2384
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.5932  Acc@1: 43.7500 (46.1310)  Acc@5: 87.5000 (82.1429)  time: 0.1868  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.4496  Acc@1: 68.7500 (53.4274)  Acc@5: 93.7500 (85.8871)  time: 0.1872  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 1.3824  Acc@1: 75.0000 (59.7561)  Acc@5: 93.7500 (88.4146)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.8748  Acc@1: 81.2500 (63.9706)  Acc@5: 93.7500 (90.0735)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.1832  Acc@1: 81.2500 (66.4959)  Acc@5: 93.7500 (90.5738)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.9471  Acc@1: 81.2500 (68.4859)  Acc@5: 93.7500 (91.6373)  time: 0.1868  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.5578  Acc@1: 81.2500 (69.6759)  Acc@5: 100.0000 (92.2068)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.5873  Acc@1: 81.2500 (70.6044)  Acc@5: 93.7500 (92.5137)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.7790  Acc@1: 81.2500 (72.0916)  Acc@5: 93.7500 (92.8837)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.6548  Acc@1: 81.2500 (72.9167)  Acc@5: 100.0000 (93.1869)  time: 0.1868  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4690  Acc@1: 81.2500 (73.1921)  Acc@5: 100.0000 (93.4401)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.5567  Acc@1: 81.2500 (74.2366)  Acc@5: 100.0000 (93.7977)  time: 0.1869  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.7597  Acc@1: 87.5000 (74.8670)  Acc@5: 100.0000 (94.0160)  time: 0.1870  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3389  Acc@1: 87.5000 (75.3725)  Acc@5: 100.0000 (94.2467)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1136  Acc@1: 81.2500 (75.8540)  Acc@5: 100.0000 (94.4099)  time: 0.1868  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.5898  Acc@1: 81.2500 (76.0965)  Acc@5: 100.0000 (94.6272)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.3858  Acc@1: 81.2500 (76.6575)  Acc@5: 100.0000 (94.6823)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2207  Acc@1: 87.5000 (76.9306)  Acc@5: 100.0000 (94.7644)  time: 0.1871  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2286  Acc@1: 87.5000 (77.4254)  Acc@5: 100.0000 (94.9627)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.8563  Acc@1: 87.5000 (77.7251)  Acc@5: 100.0000 (95.0829)  time: 0.1867  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4040  Acc@1: 87.5000 (77.8846)  Acc@5: 100.0000 (95.2206)  time: 0.1868  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3570  Acc@1: 81.2500 (77.8950)  Acc@5: 100.0000 (95.3193)  time: 0.1867  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3355  Acc@1: 81.2500 (77.9564)  Acc@5: 93.7500 (95.2541)  time: 0.1867  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3908  Acc@1: 81.2500 (78.0627)  Acc@5: 100.0000 (95.3685)  time: 0.1869  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2037  Acc@1: 81.2500 (78.2328)  Acc@5: 100.0000 (95.4023)  time: 0.1868  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4854  Acc@1: 81.2500 (78.3672)  Acc@5: 100.0000 (95.5028)  time: 0.1868  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0488  Acc@1: 87.5000 (78.6699)  Acc@5: 100.0000 (95.5738)  time: 0.1870  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0433  Acc@1: 87.5000 (78.7801)  Acc@5: 100.0000 (95.6615)  time: 0.1869  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.5266  Acc@1: 81.2500 (78.7375)  Acc@5: 100.0000 (95.7018)  time: 0.1866  data: 0.0002  max mem: 2384
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3992  Acc@1: 81.2500 (78.8183)  Acc@5: 100.0000 (95.7395)  time: 0.1867  data: 0.0001  max mem: 2384
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6105  Acc@1: 81.2500 (78.8600)  Acc@5: 100.0000 (95.7600)  time: 0.1823  data: 0.0001  max mem: 2384
Train: Epoch[1/5] Total time: 0:00:58 (0.1875 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6105  Acc@1: 81.2500 (78.8600)  Acc@5: 100.0000 (95.7600)
Train: Epoch[1/5]  [  0/313]  eta: 0:01:50  Loss: 1.0700 (1.0700)  ASR: 0.0000 (0.0000)  time: 0.3520  data: 0.1569  max mem: 2384
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0687 (1.0687)  ASR: 0.0000 (0.0000)  time: 0.2061  data: 0.0144  max mem: 2385
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0654 (1.0665)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0633 (1.0652)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0621 (1.0644)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0602 (1.0634)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0599 (1.0630)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0595 (1.0623)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0571 (1.0617)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0570 (1.0612)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0558 (1.0606)  ASR: 0.0000 (0.0000)  time: 0.1903  data: 0.0001  max mem: 2385
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0558 (1.0603)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0558 (1.0599)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0545 (1.0595)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0545 (1.0592)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0536 (1.0588)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0533 (1.0585)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0540 (1.0582)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0544 (1.0580)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0544 (1.0578)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0537 (1.0576)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0535 (1.0574)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0534 (1.0572)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Loss: 1.0537 (1.0570)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0528 (1.0568)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0518 (1.0566)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0515 (1.0564)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0514 (1.0562)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0510 (1.0561)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0501 (1.0558)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0496 (1.0557)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0524 (1.0556)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0524 (1.0555)  ASR: 0.0000 (0.0000)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[1/5] Total time: 0:01:00 (0.1921 s / it)
Averaged stats: Loss: 1.0524 (1.0555)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:50  Lr: 0.001875  Loss: -0.0505  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3526  data: 0.1632  max mem: 2385
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.7428  Acc@1: 81.2500 (82.9545)  Acc@5: 93.7500 (96.5909)  time: 0.2023  data: 0.0150  max mem: 2385
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.2713  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (97.6190)  time: 0.1870  data: 0.0001  max mem: 2385
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0148  Acc@1: 87.5000 (85.4839)  Acc@5: 100.0000 (97.5806)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3921  Acc@1: 87.5000 (85.2134)  Acc@5: 100.0000 (97.8659)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.3993  Acc@1: 81.2500 (84.5588)  Acc@5: 100.0000 (97.6716)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0944  Acc@1: 81.2500 (84.3238)  Acc@5: 100.0000 (97.9508)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.3796  Acc@1: 81.2500 (83.8028)  Acc@5: 100.0000 (97.7113)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2352  Acc@1: 81.2500 (83.0247)  Acc@5: 100.0000 (97.2994)  time: 0.1868  data: 0.0001  max mem: 2385
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1032  Acc@1: 81.2500 (83.2418)  Acc@5: 100.0000 (97.3214)  time: 0.1866  data: 0.0001  max mem: 2385
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3436  Acc@1: 81.2500 (83.5396)  Acc@5: 100.0000 (97.2772)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1679  Acc@1: 87.5000 (83.7275)  Acc@5: 100.0000 (97.2973)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0632  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (97.4174)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3320  Acc@1: 87.5000 (84.1603)  Acc@5: 100.0000 (97.3760)  time: 0.1865  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.8717  Acc@1: 87.5000 (83.7323)  Acc@5: 100.0000 (97.3848)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.4701  Acc@1: 87.5000 (84.0232)  Acc@5: 100.0000 (97.3096)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2129  Acc@1: 81.2500 (84.0062)  Acc@5: 100.0000 (97.3214)  time: 0.1865  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0324  Acc@1: 81.2500 (83.9547)  Acc@5: 100.0000 (97.3684)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3411  Acc@1: 81.2500 (83.6326)  Acc@5: 100.0000 (97.3757)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3166  Acc@1: 75.0000 (83.5406)  Acc@5: 100.0000 (97.3822)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0736  Acc@1: 87.5000 (83.6132)  Acc@5: 100.0000 (97.4502)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.4457  Acc@1: 87.5000 (83.8566)  Acc@5: 100.0000 (97.5415)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2336  Acc@1: 87.5000 (83.9084)  Acc@5: 100.0000 (97.5396)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.4048  Acc@1: 81.2500 (83.8474)  Acc@5: 100.0000 (97.5379)  time: 0.1870  data: 0.0001  max mem: 2385
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.2840  Acc@1: 81.2500 (83.8693)  Acc@5: 100.0000 (97.5882)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5530  Acc@1: 87.5000 (83.8396)  Acc@5: 100.0000 (97.6096)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2264  Acc@1: 87.5000 (84.0517)  Acc@5: 100.0000 (97.6054)  time: 0.1865  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.1377  Acc@1: 87.5000 (84.1098)  Acc@5: 100.0000 (97.6015)  time: 0.1865  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.6389  Acc@1: 87.5000 (84.1192)  Acc@5: 100.0000 (97.5756)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.5143  Acc@1: 81.2500 (84.0421)  Acc@5: 100.0000 (97.5730)  time: 0.1866  data: 0.0001  max mem: 2385
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0372  Acc@1: 81.2500 (84.1362)  Acc@5: 100.0000 (97.6121)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3577  Acc@1: 87.5000 (84.1238)  Acc@5: 100.0000 (97.6487)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0048  Acc@1: 87.5000 (84.1800)  Acc@5: 100.0000 (97.6600)  time: 0.1825  data: 0.0002  max mem: 2385
Train: Epoch[2/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0048  Acc@1: 87.5000 (84.1800)  Acc@5: 100.0000 (97.6600)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:59  Loss: 1.0519 (1.0519)  ASR: 0.0000 (0.0000)  time: 0.3820  data: 0.1840  max mem: 2385
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0478 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.2097  data: 0.0169  max mem: 2385
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0486 (1.0504)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0503 (1.0500)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0498 (1.0502)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0499 (1.0500)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0499 (1.0501)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0499 (1.0501)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0495 (1.0500)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0485 (1.0498)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0484 (1.0497)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0499 (1.0497)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0499 (1.0496)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0488 (1.0496)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0469 (1.0494)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0461 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0483 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0478 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0468 (1.0492)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0472 (1.0492)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0472 (1.0491)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0474 (1.0491)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0470 (1.0489)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2385
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Loss: 1.0459 (1.0488)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2385
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0461 (1.0488)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0475 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0493 (1.0488)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0490 (1.0488)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0477 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0477 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0463 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0463 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2385
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0463 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[2/5] Total time: 0:01:00 (0.1924 s / it)
Averaged stats: Loss: 1.0463 (1.0486)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.5264  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.3394  data: 0.1457  max mem: 2385
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.2543  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.2006  data: 0.0134  max mem: 2385
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.1722  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5119)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0665  Acc@1: 87.5000 (85.0806)  Acc@5: 100.0000 (98.1855)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0508  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.3232)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.0550  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (98.4069)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0839  Acc@1: 87.5000 (85.8607)  Acc@5: 100.0000 (98.4631)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3274  Acc@1: 81.2500 (85.2993)  Acc@5: 100.0000 (98.4155)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3156  Acc@1: 81.2500 (85.0309)  Acc@5: 100.0000 (98.4568)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.2912  Acc@1: 87.5000 (84.8901)  Acc@5: 100.0000 (98.4203)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.7226  Acc@1: 87.5000 (84.9010)  Acc@5: 100.0000 (98.3911)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1208  Acc@1: 93.7500 (85.5293)  Acc@5: 100.0000 (98.4797)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.3716  Acc@1: 93.7500 (85.6921)  Acc@5: 100.0000 (98.3988)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2132  Acc@1: 93.7500 (86.1164)  Acc@5: 100.0000 (98.3302)  time: 0.1872  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1850  Acc@1: 93.7500 (85.9929)  Acc@5: 100.0000 (98.1826)  time: 0.1872  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2084  Acc@1: 87.5000 (85.7616)  Acc@5: 93.7500 (98.0960)  time: 0.1872  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2496  Acc@1: 81.2500 (85.7919)  Acc@5: 100.0000 (98.0202)  time: 0.1875  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.4285  Acc@1: 81.2500 (85.6360)  Acc@5: 100.0000 (98.1360)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1772  Acc@1: 87.5000 (85.7735)  Acc@5: 100.0000 (98.0663)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.8628  Acc@1: 87.5000 (85.5694)  Acc@5: 100.0000 (98.1348)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0097  Acc@1: 87.5000 (85.6965)  Acc@5: 100.0000 (98.1654)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2565  Acc@1: 87.5000 (85.6635)  Acc@5: 100.0000 (98.2227)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0221  Acc@1: 87.5000 (85.6900)  Acc@5: 100.0000 (98.2183)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3036  Acc@1: 87.5000 (85.9307)  Acc@5: 100.0000 (98.2413)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.5194  Acc@1: 87.5000 (85.9959)  Acc@5: 100.0000 (98.2365)  time: 0.1871  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1433  Acc@1: 81.2500 (85.9064)  Acc@5: 100.0000 (98.1823)  time: 0.1870  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2132  Acc@1: 87.5000 (85.9435)  Acc@5: 100.0000 (98.1801)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.6946  Acc@1: 87.5000 (85.9087)  Acc@5: 100.0000 (98.2011)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0711  Acc@1: 87.5000 (86.0098)  Acc@5: 100.0000 (98.1539)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3665  Acc@1: 87.5000 (86.0180)  Acc@5: 100.0000 (98.1529)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3090  Acc@1: 87.5000 (86.0257)  Acc@5: 100.0000 (98.1312)  time: 0.1873  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1014  Acc@1: 87.5000 (86.1334)  Acc@5: 100.0000 (98.1712)  time: 0.1871  data: 0.0001  max mem: 2385
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1363  Acc@1: 87.5000 (86.1800)  Acc@5: 100.0000 (98.1800)  time: 0.1826  data: 0.0001  max mem: 2385
Train: Epoch[3/5] Total time: 0:00:58 (0.1875 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.1363  Acc@1: 87.5000 (86.1800)  Acc@5: 100.0000 (98.1800)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:53  Loss: 1.0496 (1.0496)  ASR: 0.0000 (0.0000)  time: 0.3638  data: 0.1651  max mem: 2385
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0496 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.2069  data: 0.0151  max mem: 2385
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0484 (1.0480)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0461 (1.0474)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0442 (1.0469)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0442 (1.0468)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0443 (1.0464)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0436 (1.0461)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2385
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0447 (1.0461)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0003  max mem: 2385
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0465 (1.0460)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0451 (1.0460)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0450 (1.0462)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2385
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0471 (1.0461)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0449 (1.0460)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0440 (1.0460)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0440 (1.0459)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0434 (1.0458)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0457 (1.0459)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0457 (1.0457)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0443 (1.0457)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0443 (1.0457)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0441 (1.0457)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0444 (1.0456)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Loss: 1.0444 (1.0456)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0456 (1.0456)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0455 (1.0456)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0443 (1.0455)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0444 (1.0455)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0446 (1.0455)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0442 (1.0454)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0426 (1.0453)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0446 (1.0453)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0455 (1.0453)  ASR: 0.0000 (0.0000)  time: 0.1876  data: 0.0002  max mem: 2385
Train: Epoch[3/5] Total time: 0:01:00 (0.1925 s / it)
Averaged stats: Loss: 1.0455 (1.0453)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:54  Lr: 0.001875  Loss: -0.0451  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3673  data: 0.1775  max mem: 2385
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0250  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (97.7273)  time: 0.2031  data: 0.0163  max mem: 2385
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.0222  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (97.3214)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2263  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (97.1774)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.0264  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (97.8659)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.0869  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (98.0392)  time: 0.1875  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7038  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (97.6434)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: -0.0214  Acc@1: 87.5000 (87.0599)  Acc@5: 93.7500 (97.6232)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3225  Acc@1: 87.5000 (86.8827)  Acc@5: 100.0000 (97.5309)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.2404  Acc@1: 87.5000 (86.3324)  Acc@5: 100.0000 (97.3901)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3852  Acc@1: 87.5000 (86.5718)  Acc@5: 100.0000 (97.4629)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5502  Acc@1: 87.5000 (86.2050)  Acc@5: 100.0000 (97.4662)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4950  Acc@1: 81.2500 (85.6921)  Acc@5: 93.7500 (97.3140)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2113  Acc@1: 81.2500 (85.8302)  Acc@5: 93.7500 (97.2328)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0023  Acc@1: 87.5000 (85.5496)  Acc@5: 100.0000 (97.3404)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3761  Acc@1: 87.5000 (85.7202)  Acc@5: 100.0000 (97.4338)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1053  Acc@1: 87.5000 (85.9472)  Acc@5: 100.0000 (97.4379)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0462  Acc@1: 87.5000 (86.2208)  Acc@5: 100.0000 (97.5146)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.3592  Acc@1: 87.5000 (86.0497)  Acc@5: 100.0000 (97.4448)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0902  Acc@1: 81.2500 (85.9293)  Acc@5: 100.0000 (97.5131)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0490  Acc@1: 81.2500 (85.7587)  Acc@5: 100.0000 (97.5746)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.1548  Acc@1: 87.5000 (85.6635)  Acc@5: 100.0000 (97.6600)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1394  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (97.6810)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1844  Acc@1: 87.5000 (85.6061)  Acc@5: 100.0000 (97.7002)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1253  Acc@1: 87.5000 (85.6328)  Acc@5: 100.0000 (97.7438)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0177  Acc@1: 87.5000 (85.6325)  Acc@5: 100.0000 (97.7839)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3245  Acc@1: 87.5000 (85.5843)  Acc@5: 100.0000 (97.8209)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4798  Acc@1: 87.5000 (85.6089)  Acc@5: 100.0000 (97.8090)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1784  Acc@1: 87.5000 (85.6317)  Acc@5: 100.0000 (97.8648)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1682  Acc@1: 87.5000 (85.6314)  Acc@5: 100.0000 (97.8737)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.2298  Acc@1: 87.5000 (85.7350)  Acc@5: 100.0000 (97.9444)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1227  Acc@1: 87.5000 (85.7516)  Acc@5: 100.0000 (97.9502)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5012  Acc@1: 87.5000 (85.7400)  Acc@5: 100.0000 (97.9600)  time: 0.1825  data: 0.0002  max mem: 2385
Train: Epoch[4/5] Total time: 0:00:58 (0.1876 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.5012  Acc@1: 87.5000 (85.7400)  Acc@5: 100.0000 (97.9600)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:45  Loss: 1.0426 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.3355  data: 0.1377  max mem: 2385
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0480 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.2047  data: 0.0127  max mem: 2385
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0473 (1.0471)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0437 (1.0460)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0434 (1.0457)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0422 (1.0453)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0423 (1.0451)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0427 (1.0450)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0446 (1.0451)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0451 (1.0451)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0432 (1.0448)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0421 (1.0447)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0412 (1.0443)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0414 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0438 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0438 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0445 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0431 (1.0443)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0427 (1.0443)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0437 (1.0443)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0434 (1.0443)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0441 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0445 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Loss: 1.0426 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0435 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0445 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0423 (1.0443)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0412 (1.0442)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0412 (1.0441)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0444 (1.0442)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0444 (1.0442)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0452 (1.0442)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2385
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0445 (1.0442)  ASR: 0.0000 (0.0000)  time: 0.1863  data: 0.0002  max mem: 2385
Train: Epoch[4/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Loss: 1.0445 (1.0442)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:52  Lr: 0.001875  Loss: -0.0962  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3584  data: 0.1685  max mem: 2385
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.5551  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.2023  data: 0.0154  max mem: 2385
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.0298  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.1071)  time: 0.1866  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.5851  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (98.9919)  time: 0.1865  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1264  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (98.7805)  time: 0.1865  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2376  Acc@1: 81.2500 (85.9069)  Acc@5: 100.0000 (98.1618)  time: 0.1864  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1016  Acc@1: 81.2500 (85.8607)  Acc@5: 100.0000 (97.9508)  time: 0.1864  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1651  Acc@1: 87.5000 (85.9155)  Acc@5: 100.0000 (98.0634)  time: 0.1864  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.1184  Acc@1: 93.7500 (86.8827)  Acc@5: 100.0000 (98.3025)  time: 0.1866  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.3402  Acc@1: 93.7500 (86.7445)  Acc@5: 100.0000 (98.3516)  time: 0.1871  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1492  Acc@1: 87.5000 (86.6955)  Acc@5: 100.0000 (98.3911)  time: 0.1871  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.4548  Acc@1: 87.5000 (86.4302)  Acc@5: 100.0000 (98.3671)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2031  Acc@1: 87.5000 (86.6219)  Acc@5: 100.0000 (98.4504)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0330  Acc@1: 87.5000 (86.8321)  Acc@5: 100.0000 (98.5687)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0883  Acc@1: 93.7500 (87.0124)  Acc@5: 100.0000 (98.6259)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.1060  Acc@1: 93.7500 (87.3344)  Acc@5: 100.0000 (98.6341)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2737  Acc@1: 93.7500 (87.3447)  Acc@5: 100.0000 (98.6025)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.6824  Acc@1: 87.5000 (87.4269)  Acc@5: 100.0000 (98.5380)  time: 0.1871  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1393  Acc@1: 93.7500 (87.5691)  Acc@5: 100.0000 (98.5843)  time: 0.1872  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3192  Acc@1: 87.5000 (87.4018)  Acc@5: 100.0000 (98.5602)  time: 0.1871  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0694  Acc@1: 87.5000 (87.4378)  Acc@5: 100.0000 (98.5386)  time: 0.1871  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2448  Acc@1: 87.5000 (87.2927)  Acc@5: 100.0000 (98.5782)  time: 0.1870  data: 0.0001  max mem: 2385
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1729  Acc@1: 87.5000 (87.3020)  Acc@5: 100.0000 (98.5577)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1042  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.5660)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0204  Acc@1: 87.5000 (87.2666)  Acc@5: 100.0000 (98.5477)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0241  Acc@1: 87.5000 (87.2759)  Acc@5: 100.0000 (98.5807)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.0651  Acc@1: 87.5000 (87.3324)  Acc@5: 100.0000 (98.6111)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.6821  Acc@1: 87.5000 (87.1771)  Acc@5: 100.0000 (98.5240)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0150  Acc@1: 87.5000 (87.2553)  Acc@5: 100.0000 (98.5765)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1533  Acc@1: 87.5000 (87.3282)  Acc@5: 100.0000 (98.5610)  time: 0.1877  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.6340  Acc@1: 93.7500 (87.3547)  Acc@5: 100.0000 (98.5257)  time: 0.1879  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1545  Acc@1: 87.5000 (87.2990)  Acc@5: 100.0000 (98.5129)  time: 0.1878  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6268  Acc@1: 87.5000 (87.3000)  Acc@5: 100.0000 (98.5200)  time: 0.1834  data: 0.0002  max mem: 2385
Train: Epoch[5/5] Total time: 0:00:58 (0.1875 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6268  Acc@1: 87.5000 (87.3000)  Acc@5: 100.0000 (98.5200)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:05  Loss: 1.0378 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.4009  data: 0.2017  max mem: 2385
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0420 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.2114  data: 0.0185  max mem: 2385
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0438 (1.0440)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0438 (1.0439)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0405 (1.0437)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0415 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0415 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0403 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0419 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2385
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0445 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0425 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0413 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0406 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0413 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0428 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0003  max mem: 2385
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0428 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0003  max mem: 2385
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0437 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2385
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0443 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2385
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0415 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2385
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0407 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0400 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0419 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0408 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [230/313]  eta: 0:00:16  Loss: 1.0394 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0409 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0458 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0420 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0415 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0425 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0427 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0436 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0420 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2385
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0420 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[5/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0420 (1.0429)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:17  Loss: 0.4050 (0.4050)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2851  data: 0.1677  max mem: 2385
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.4050 (0.4457)  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (100.0000)  time: 0.1317  data: 0.0155  max mem: 2385
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.3884 (0.4923)  Acc@1: 93.7500 (92.5595)  Acc@5: 100.0000 (100.0000)  time: 0.1166  data: 0.0003  max mem: 2385
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.3889 (0.4624)  Acc@1: 93.7500 (92.9435)  Acc@5: 100.0000 (100.0000)  time: 0.1168  data: 0.0003  max mem: 2385
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.4031 (0.4499)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.1166  data: 0.0002  max mem: 2385
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.3695 (0.4303)  Acc@1: 93.7500 (94.4853)  Acc@5: 100.0000 (99.8775)  time: 0.1167  data: 0.0002  max mem: 2385
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3531 (0.4179)  Acc@1: 93.7500 (94.4672)  Acc@5: 100.0000 (99.8975)  time: 0.1166  data: 0.0002  max mem: 2385
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3507 (0.4150)  Acc@1: 100.0000 (94.6000)  Acc@5: 100.0000 (99.9000)  time: 0.1138  data: 0.0002  max mem: 2385
Test: [Task 1] Total time: 0:00:07 (0.1192 s / it)
* Acc@1 94.600 Acc@5 99.900 loss 0.415
Test: [Task 1]  [ 0/63]  eta: 0:00:21  ASR: nan (nan)  ACC: 100.0000 (100.0000)  Loss: 0.4050 (0.4050)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3349  data: 0.2130  max mem: 2385
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 92.8571 (92.5466)  Loss: 0.8750 (0.8178)  Acc@1: 87.5000 (86.3636)  Acc@5: 93.7500 (93.7500)  time: 0.1375  data: 0.0196  max mem: 2385
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 92.8571 (92.0000)  Loss: 0.9652 (0.9382)  Acc@1: 87.5000 (84.5238)  Acc@5: 93.7500 (93.1548)  time: 0.1178  data: 0.0002  max mem: 2385
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.8571 (92.5843)  Loss: 0.9930 (0.8980)  Acc@1: 81.2500 (84.8790)  Acc@5: 93.7500 (92.7419)  time: 0.1177  data: 0.0003  max mem: 2385
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 93.3333 (93.5484)  Loss: 0.7699 (0.8825)  Acc@1: 87.5000 (85.5183)  Acc@5: 93.7500 (92.6829)  time: 0.1177  data: 0.0003  max mem: 2385
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 100.0000 (94.2623)  Loss: 0.7824 (0.8737)  Acc@1: 87.5000 (86.0294)  Acc@5: 93.7500 (92.2794)  time: 0.1178  data: 0.0002  max mem: 2385
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.7500 (94.1648)  Loss: 0.8051 (0.8634)  Acc@1: 87.5000 (86.1680)  Acc@5: 93.7500 (92.4180)  time: 0.1177  data: 0.0002  max mem: 2385
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 100.0000 (94.3080)  Loss: 0.7824 (0.8565)  Acc@1: 87.5000 (86.3000)  Acc@5: 93.7500 (92.4000)  time: 0.1149  data: 0.0002  max mem: 2385
Test: [Task 1] Total time: 0:00:07 (0.1210 s / it)
* Acc@1 86.300 Acc@5 92.400 loss 0.857
* Acc@1 nan ASR 94.308
Test: [Task 2]  [ 0/63]  eta: 0:00:18  Loss: 0.5567 (0.5567)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2905  data: 0.1734  max mem: 2385
Test: [Task 2]  [10/63]  eta: 0:00:07  Loss: 0.4394 (0.5256)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  time: 0.1322  data: 0.0160  max mem: 2385
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.5172 (0.6159)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.4048)  time: 0.1165  data: 0.0003  max mem: 2385
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.6207 (0.6113)  Acc@1: 93.7500 (93.5484)  Acc@5: 100.0000 (98.7903)  time: 0.1164  data: 0.0002  max mem: 2385
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.5464 (0.5916)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.7805)  time: 0.1164  data: 0.0002  max mem: 2385
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.5140 (0.5891)  Acc@1: 93.7500 (93.3824)  Acc@5: 100.0000 (98.7745)  time: 0.1165  data: 0.0003  max mem: 2385
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.4787 (0.5673)  Acc@1: 93.7500 (94.0574)  Acc@5: 100.0000 (98.9754)  time: 0.1164  data: 0.0002  max mem: 2385
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4459 (0.5578)  Acc@1: 100.0000 (94.2000)  Acc@5: 100.0000 (99.0000)  time: 0.1136  data: 0.0001  max mem: 2385
Test: [Task 2] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 94.200 Acc@5 99.000 loss 0.558
Test: [Task 2]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 1.2602 (1.2602)  Acc@1: 87.5000 (87.5000)  Acc@5: 87.5000 (87.5000)  time: 0.2645  data: 0.1414  max mem: 2385
Test: [Task 2]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 100.0000 (96.9325)  Loss: 0.9983 (0.8821)  Acc@1: 87.5000 (89.7727)  Acc@5: 93.7500 (92.6136)  time: 0.1317  data: 0.0132  max mem: 2385
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 93.3333 (94.1368)  Loss: 0.9983 (1.0346)  Acc@1: 87.5000 (86.0119)  Acc@5: 93.7500 (91.0714)  time: 0.1182  data: 0.0003  max mem: 2385
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.8571 (93.4978)  Loss: 1.0987 (1.1074)  Acc@1: 81.2500 (84.0726)  Acc@5: 87.5000 (89.1129)  time: 0.1178  data: 0.0003  max mem: 2385
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (93.7500)  Loss: 1.0145 (1.0606)  Acc@1: 81.2500 (84.9085)  Acc@5: 87.5000 (89.9390)  time: 0.1177  data: 0.0002  max mem: 2385
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.8571 (93.4783)  Loss: 0.9261 (1.0575)  Acc@1: 81.2500 (84.6814)  Acc@5: 93.7500 (89.8284)  time: 0.1178  data: 0.0002  max mem: 2385
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.7500 (94.1309)  Loss: 0.8415 (1.0133)  Acc@1: 81.2500 (85.7582)  Acc@5: 93.7500 (90.4713)  time: 0.1177  data: 0.0002  max mem: 2385
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 100.0000 (94.2731)  Loss: 0.8415 (1.0002)  Acc@1: 87.5000 (85.9000)  Acc@5: 93.7500 (90.5000)  time: 0.1150  data: 0.0002  max mem: 2385
Test: [Task 2] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 85.900 Acc@5 90.500 loss 1.000
* Acc@1 nan ASR 94.273
[Average accuracy till task2]	Acc@1: 86.1000	Acc@5: 91.4500	Loss: 0.9284	Forgetting: 2.3000	Backward: -2.3000
Train: Epoch[1/5]  [  0/313]  eta: 0:01:56  Lr: 0.001875  Loss: 2.1469  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  time: 0.3730  data: 0.1840  max mem: 2385
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.8106  Acc@1: 43.7500 (39.7727)  Acc@5: 87.5000 (78.4091)  time: 0.2035  data: 0.0169  max mem: 2385
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.4001  Acc@1: 62.5000 (55.3571)  Acc@5: 93.7500 (86.3095)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.0352  Acc@1: 75.0000 (64.1129)  Acc@5: 93.7500 (89.3145)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 1.0941  Acc@1: 87.5000 (68.5976)  Acc@5: 100.0000 (91.7683)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.1388  Acc@1: 81.2500 (70.8333)  Acc@5: 100.0000 (92.8922)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.8749  Acc@1: 81.2500 (73.2582)  Acc@5: 93.7500 (93.4426)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.8355  Acc@1: 81.2500 (74.1197)  Acc@5: 100.0000 (94.0141)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.9559  Acc@1: 81.2500 (74.8457)  Acc@5: 100.0000 (94.4444)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.6689  Acc@1: 81.2500 (76.0302)  Acc@5: 100.0000 (94.9176)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.7059  Acc@1: 81.2500 (76.5470)  Acc@5: 100.0000 (95.1733)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3787  Acc@1: 81.2500 (77.4212)  Acc@5: 100.0000 (95.3829)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1475  Acc@1: 87.5000 (77.7376)  Acc@5: 100.0000 (95.5579)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3849  Acc@1: 81.2500 (78.3397)  Acc@5: 100.0000 (95.6584)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.4642  Acc@1: 81.2500 (78.8121)  Acc@5: 100.0000 (95.8333)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0092  Acc@1: 81.2500 (78.9321)  Acc@5: 100.0000 (95.9851)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.6972  Acc@1: 81.2500 (79.0373)  Acc@5: 100.0000 (95.9239)  time: 0.1870  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2200  Acc@1: 81.2500 (79.6784)  Acc@5: 100.0000 (96.0892)  time: 0.1868  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1589  Acc@1: 93.7500 (80.0760)  Acc@5: 100.0000 (96.1671)  time: 0.1866  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.5827  Acc@1: 87.5000 (80.3010)  Acc@5: 93.7500 (96.1715)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3775  Acc@1: 87.5000 (80.5037)  Acc@5: 93.7500 (96.2065)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3593  Acc@1: 87.5000 (80.7761)  Acc@5: 100.0000 (96.3270)  time: 0.1874  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1957  Acc@1: 87.5000 (80.8824)  Acc@5: 100.0000 (96.4367)  time: 0.1872  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.7417  Acc@1: 87.5000 (80.9794)  Acc@5: 100.0000 (96.4556)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.4557  Acc@1: 87.5000 (81.1722)  Acc@5: 100.0000 (96.4730)  time: 0.1873  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5853  Acc@1: 87.5000 (81.4243)  Acc@5: 100.0000 (96.5139)  time: 0.1868  data: 0.0001  max mem: 2385
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2003  Acc@1: 87.5000 (81.6810)  Acc@5: 100.0000 (96.6236)  time: 0.1866  data: 0.0001  max mem: 2385
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3572  Acc@1: 87.5000 (81.6882)  Acc@5: 100.0000 (96.6790)  time: 0.1867  data: 0.0001  max mem: 2385
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1730  Acc@1: 81.2500 (81.8283)  Acc@5: 100.0000 (96.7527)  time: 0.1871  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2182  Acc@1: 87.5000 (82.0447)  Acc@5: 100.0000 (96.8213)  time: 0.1872  data: 0.0001  max mem: 2385
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0532  Acc@1: 87.5000 (82.2882)  Acc@5: 100.0000 (96.8854)  time: 0.1869  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4855  Acc@1: 87.5000 (82.2548)  Acc@5: 100.0000 (96.9051)  time: 0.1867  data: 0.0002  max mem: 2385
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4072  Acc@1: 87.5000 (82.2800)  Acc@5: 100.0000 (96.9000)  time: 0.1822  data: 0.0002  max mem: 2385
Train: Epoch[1/5] Total time: 0:00:58 (0.1874 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.4072  Acc@1: 87.5000 (82.2800)  Acc@5: 100.0000 (96.9000)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:06  Loss: 1.0647 (1.0647)  ASR: 0.0000 (0.0000)  time: 0.4031  data: 0.2032  max mem: 2385
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0606 (1.0603)  ASR: 0.0000 (0.0000)  time: 0.2105  data: 0.0187  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0587 (1.0586)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0557 (1.0577)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0542 (1.0565)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0518 (1.0558)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0516 (1.0551)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0504 (1.0544)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0506 (1.0540)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0507 (1.0536)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0506 (1.0533)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0503 (1.0531)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0479 (1.0526)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0479 (1.0523)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0478 (1.0519)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0474 (1.0517)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0471 (1.0514)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0481 (1.0512)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0488 (1.0511)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0480 (1.0510)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0474 (1.0508)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0461 (1.0506)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0470 (1.0504)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Loss: 1.0473 (1.0503)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0465 (1.0502)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0461 (1.0500)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0458 (1.0499)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0461 (1.0498)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0463 (1.0496)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0463 (1.0495)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0462 (1.0494)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0462 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0462 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1923 s / it)
Averaged stats: Loss: 1.0462 (1.0493)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:52  Lr: 0.001875  Loss: 0.1790  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3587  data: 0.1703  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.1036  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.2032  data: 0.0157  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.1221  Acc@1: 87.5000 (84.8214)  Acc@5: 100.0000 (97.9167)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.3302  Acc@1: 87.5000 (84.0726)  Acc@5: 100.0000 (97.9839)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1478  Acc@1: 87.5000 (84.7561)  Acc@5: 100.0000 (98.1707)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.5591  Acc@1: 87.5000 (84.5588)  Acc@5: 100.0000 (98.0392)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0174  Acc@1: 87.5000 (84.9385)  Acc@5: 100.0000 (98.2582)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.2000  Acc@1: 87.5000 (84.7711)  Acc@5: 100.0000 (98.2394)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4631  Acc@1: 87.5000 (84.4907)  Acc@5: 100.0000 (98.3796)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.4714  Acc@1: 87.5000 (84.6841)  Acc@5: 100.0000 (98.2830)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2147  Acc@1: 87.5000 (85.0866)  Acc@5: 100.0000 (98.3911)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3318  Acc@1: 87.5000 (85.3041)  Acc@5: 100.0000 (98.4234)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.0168  Acc@1: 87.5000 (85.3306)  Acc@5: 100.0000 (98.3988)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4822  Acc@1: 87.5000 (85.4962)  Acc@5: 100.0000 (98.4256)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.4113  Acc@1: 81.2500 (85.5053)  Acc@5: 100.0000 (98.4486)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3911  Acc@1: 87.5000 (85.6788)  Acc@5: 100.0000 (98.5099)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2367  Acc@1: 87.5000 (85.5978)  Acc@5: 100.0000 (98.4084)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.8316  Acc@1: 81.2500 (85.4532)  Acc@5: 100.0000 (98.3187)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0422  Acc@1: 87.5000 (85.6699)  Acc@5: 100.0000 (98.4116)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2812  Acc@1: 87.5000 (85.8639)  Acc@5: 100.0000 (98.3966)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5998  Acc@1: 81.2500 (85.4478)  Acc@5: 100.0000 (98.3209)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3224  Acc@1: 81.2500 (85.4858)  Acc@5: 100.0000 (98.3709)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0047  Acc@1: 87.5000 (85.6052)  Acc@5: 100.0000 (98.4163)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2100  Acc@1: 87.5000 (85.6331)  Acc@5: 100.0000 (98.4307)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.4208  Acc@1: 87.5000 (85.6328)  Acc@5: 100.0000 (98.3921)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2474  Acc@1: 81.2500 (85.5827)  Acc@5: 100.0000 (98.4313)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.9543  Acc@1: 87.5000 (85.7280)  Acc@5: 100.0000 (98.4674)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3592  Acc@1: 87.5000 (85.7011)  Acc@5: 100.0000 (98.4548)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2377  Acc@1: 87.5000 (85.8763)  Acc@5: 100.0000 (98.4875)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3702  Acc@1: 87.5000 (85.9107)  Acc@5: 100.0000 (98.4751)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0176  Acc@1: 87.5000 (85.9635)  Acc@5: 100.0000 (98.4219)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0247  Acc@1: 87.5000 (85.9526)  Acc@5: 100.0000 (98.4325)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.0903  Acc@1: 87.5000 (85.9000)  Acc@5: 100.0000 (98.4400)  time: 0.1826  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1876 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.0903  Acc@1: 87.5000 (85.9000)  Acc@5: 100.0000 (98.4400)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:55  Loss: 1.0396 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.3689  data: 0.1669  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0453 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.2064  data: 0.0153  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0453 (1.0452)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0440 (1.0451)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0449 (1.0453)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0428 (1.0446)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Loss: 1.0415 (1.0447)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Loss: 1.0442 (1.0447)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Loss: 1.0442 (1.0446)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Loss: 1.0435 (1.0444)  ASR: 0.0000 (0.0000)  time: 0.1902  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Loss: 1.0430 (1.0442)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0423 (1.0440)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0413 (1.0441)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0433 (1.0441)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0436 (1.0441)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0434 (1.0441)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0434 (1.0441)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0430 (1.0441)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0412 (1.0440)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0409 (1.0439)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0417 (1.0438)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0423 (1.0438)  ASR: 0.0000 (0.0000)  time: 0.1902  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0425 (1.0437)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Loss: 1.0428 (1.0436)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Loss: 1.0417 (1.0436)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0407 (1.0435)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0394 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0416 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0422 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0425 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0430 (1.0433)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0406 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0406 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Loss: 1.0406 (1.0432)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:54  Lr: 0.001875  Loss: -0.0981  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3649  data: 0.1767  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1113  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (99.4318)  time: 0.2033  data: 0.0162  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.1060  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (99.7024)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1798  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (99.1935)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0037  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (99.0854)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.2803  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (98.8971)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3993  Acc@1: 93.7500 (86.9877)  Acc@5: 100.0000 (98.9754)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.0015  Acc@1: 93.7500 (87.7641)  Acc@5: 100.0000 (99.0317)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2301  Acc@1: 93.7500 (87.7315)  Acc@5: 100.0000 (98.7654)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0147  Acc@1: 87.5000 (87.9808)  Acc@5: 100.0000 (98.8324)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1732  Acc@1: 93.7500 (88.1807)  Acc@5: 100.0000 (98.7624)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2793  Acc@1: 87.5000 (87.7815)  Acc@5: 100.0000 (98.6486)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2268  Acc@1: 81.2500 (87.6033)  Acc@5: 100.0000 (98.7603)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.0174  Acc@1: 87.5000 (87.5477)  Acc@5: 100.0000 (98.7118)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3551  Acc@1: 93.7500 (87.7216)  Acc@5: 100.0000 (98.5816)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3850  Acc@1: 87.5000 (87.3344)  Acc@5: 100.0000 (98.5513)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1247  Acc@1: 87.5000 (87.3059)  Acc@5: 100.0000 (98.5637)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0538  Acc@1: 87.5000 (87.1711)  Acc@5: 100.0000 (98.5380)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3045  Acc@1: 87.5000 (86.9475)  Acc@5: 100.0000 (98.4116)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2854  Acc@1: 87.5000 (86.9764)  Acc@5: 100.0000 (98.4293)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0917  Acc@1: 87.5000 (87.1269)  Acc@5: 100.0000 (98.4142)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.1828  Acc@1: 87.5000 (87.1742)  Acc@5: 100.0000 (98.4005)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1554  Acc@1: 87.5000 (87.1606)  Acc@5: 100.0000 (98.4446)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1653  Acc@1: 87.5000 (87.1483)  Acc@5: 100.0000 (98.5119)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1639  Acc@1: 87.5000 (87.2407)  Acc@5: 100.0000 (98.4959)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2806  Acc@1: 87.5000 (87.1514)  Acc@5: 100.0000 (98.5309)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.0006  Acc@1: 87.5000 (87.3803)  Acc@5: 100.0000 (98.5393)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0239  Acc@1: 93.7500 (87.3847)  Acc@5: 100.0000 (98.5009)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.5602  Acc@1: 87.5000 (87.5222)  Acc@5: 100.0000 (98.4431)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1620  Acc@1: 81.2500 (87.2637)  Acc@5: 100.0000 (98.4751)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0219  Acc@1: 81.2500 (87.3547)  Acc@5: 100.0000 (98.5050)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0120  Acc@1: 87.5000 (87.3794)  Acc@5: 100.0000 (98.5330)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1750  Acc@1: 87.5000 (87.4000)  Acc@5: 100.0000 (98.5400)  time: 0.1821  data: 0.0001  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.1750  Acc@1: 87.5000 (87.4000)  Acc@5: 100.0000 (98.5400)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:03  Loss: 1.0419 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.3930  data: 0.1880  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0413 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.2093  data: 0.0173  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0421 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0421 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0404 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0408 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0421 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0429 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0427 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0402 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0402 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0393 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0389 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0394 (1.0417)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0413 (1.0417)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0426 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0406 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0384 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0384 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0382 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0394 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0412 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0412 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:16  Loss: 1.0422 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0422 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0404 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0404 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0399 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0408 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0411 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0391 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0375 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0381 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1925 s / it)
Averaged stats: Loss: 1.0381 (1.0410)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:49  Lr: 0.001875  Loss: 0.1548  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.3486  data: 0.1598  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2642  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.1591)  time: 0.2014  data: 0.0147  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.1067  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.2143)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2316  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (98.5887)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3496  Acc@1: 81.2500 (85.8232)  Acc@5: 100.0000 (98.3232)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.1925  Acc@1: 81.2500 (85.5392)  Acc@5: 100.0000 (98.5294)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.4149  Acc@1: 87.5000 (85.3484)  Acc@5: 100.0000 (98.6680)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.2619  Acc@1: 87.5000 (85.7394)  Acc@5: 100.0000 (98.6796)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.0096  Acc@1: 87.5000 (86.1883)  Acc@5: 100.0000 (98.6883)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0162  Acc@1: 93.7500 (86.1264)  Acc@5: 100.0000 (98.6951)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0726  Acc@1: 93.7500 (86.5099)  Acc@5: 100.0000 (98.5767)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0525  Acc@1: 93.7500 (86.9932)  Acc@5: 100.0000 (98.6486)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0372  Acc@1: 87.5000 (86.8285)  Acc@5: 100.0000 (98.5537)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1854  Acc@1: 87.5000 (86.7844)  Acc@5: 100.0000 (98.4733)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3685  Acc@1: 87.5000 (87.0124)  Acc@5: 100.0000 (98.5816)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0031  Acc@1: 87.5000 (87.1275)  Acc@5: 100.0000 (98.5513)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1372  Acc@1: 87.5000 (87.1506)  Acc@5: 100.0000 (98.6025)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0295  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.5746)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2445  Acc@1: 87.5000 (87.0511)  Acc@5: 100.0000 (98.6533)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0134  Acc@1: 87.5000 (87.0419)  Acc@5: 100.0000 (98.5929)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0333  Acc@1: 87.5000 (87.1269)  Acc@5: 100.0000 (98.5386)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0341  Acc@1: 87.5000 (87.1149)  Acc@5: 100.0000 (98.5486)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2645  Acc@1: 87.5000 (87.1606)  Acc@5: 100.0000 (98.5294)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1593  Acc@1: 81.2500 (86.9048)  Acc@5: 100.0000 (98.5119)  time: 0.1873  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1106  Acc@1: 81.2500 (86.7739)  Acc@5: 100.0000 (98.4959)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.7909  Acc@1: 87.5000 (86.7032)  Acc@5: 100.0000 (98.4562)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0422  Acc@1: 87.5000 (86.7816)  Acc@5: 100.0000 (98.4435)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0369  Acc@1: 87.5000 (86.8542)  Acc@5: 100.0000 (98.4548)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0849  Acc@1: 87.5000 (87.0329)  Acc@5: 100.0000 (98.4653)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4965  Acc@1: 87.5000 (86.8771)  Acc@5: 100.0000 (98.4536)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.1902  Acc@1: 81.2500 (86.9809)  Acc@5: 100.0000 (98.4012)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0571  Acc@1: 87.5000 (86.9775)  Acc@5: 100.0000 (98.4325)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1155  Acc@1: 87.5000 (87.0200)  Acc@5: 100.0000 (98.4400)  time: 0.1823  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:00:58 (0.1875 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1155  Acc@1: 87.5000 (87.0200)  Acc@5: 100.0000 (98.4400)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:13  Loss: 1.0413 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.4278  data: 0.2273  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0399 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.2134  data: 0.0209  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0396 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0406 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:54  Loss: 1.0436 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0421 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0404 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0373 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0383 (1.0403)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0408 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0412 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0399 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0390 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0389 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0386 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0389 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0404 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0394 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0373 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0373 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0407 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0408 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0403 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:16  Loss: 1.0403 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0406 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0437 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0396 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0389 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0358 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0374 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0379 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0375 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0370 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1877  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0370 (1.0396)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:51  Lr: 0.001875  Loss: 0.1608  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3551  data: 0.1633  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0042  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8636)  time: 0.2023  data: 0.0151  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.3993  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (98.8095)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1848  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.3871)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3832  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (98.4756)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.0878  Acc@1: 87.5000 (88.1127)  Acc@5: 100.0000 (98.5294)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1017  Acc@1: 93.7500 (88.4221)  Acc@5: 100.0000 (98.5656)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.0912  Acc@1: 87.5000 (88.1162)  Acc@5: 100.0000 (98.5035)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3341  Acc@1: 87.5000 (88.1944)  Acc@5: 100.0000 (98.4568)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.6236  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.3516)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.0539  Acc@1: 87.5000 (88.4901)  Acc@5: 100.0000 (98.3292)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5361  Acc@1: 87.5000 (88.3446)  Acc@5: 100.0000 (98.4797)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0366  Acc@1: 87.5000 (88.2748)  Acc@5: 100.0000 (98.5021)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0326  Acc@1: 87.5000 (88.5496)  Acc@5: 100.0000 (98.6164)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1693  Acc@1: 87.5000 (88.2535)  Acc@5: 100.0000 (98.6259)  time: 0.1873  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0492  Acc@1: 87.5000 (88.3278)  Acc@5: 100.0000 (98.6755)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0337  Acc@1: 87.5000 (88.1988)  Acc@5: 100.0000 (98.6801)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0473  Acc@1: 87.5000 (88.2310)  Acc@5: 100.0000 (98.6111)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0438  Acc@1: 87.5000 (88.2942)  Acc@5: 100.0000 (98.6533)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.1699  Acc@1: 87.5000 (88.3181)  Acc@5: 100.0000 (98.6257)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0529  Acc@1: 87.5000 (88.4017)  Acc@5: 100.0000 (98.6318)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0248  Acc@1: 93.7500 (88.4479)  Acc@5: 100.0000 (98.6374)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1456  Acc@1: 93.7500 (88.6029)  Acc@5: 100.0000 (98.6708)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0766  Acc@1: 93.7500 (88.5823)  Acc@5: 100.0000 (98.7013)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0755  Acc@1: 87.5000 (88.7189)  Acc@5: 100.0000 (98.7552)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2614  Acc@1: 87.5000 (88.7201)  Acc@5: 100.0000 (98.7301)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1671  Acc@1: 87.5000 (88.5536)  Acc@5: 100.0000 (98.7069)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0103  Acc@1: 81.2500 (88.5148)  Acc@5: 100.0000 (98.7085)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2432  Acc@1: 87.5000 (88.5676)  Acc@5: 100.0000 (98.6877)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3248  Acc@1: 87.5000 (88.6383)  Acc@5: 100.0000 (98.7113)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1210  Acc@1: 87.5000 (88.5174)  Acc@5: 100.0000 (98.7334)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3244  Acc@1: 87.5000 (88.4646)  Acc@5: 100.0000 (98.7138)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0450  Acc@1: 87.5000 (88.4600)  Acc@5: 100.0000 (98.7200)  time: 0.1825  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1875 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0450  Acc@1: 87.5000 (88.4600)  Acc@5: 100.0000 (98.7200)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:53  Loss: 1.0383 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.3624  data: 0.1670  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0409 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.2070  data: 0.0154  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0399 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0399 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0411 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0386 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0386 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0379 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0368 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0368 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0381 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0381 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0369 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0369 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0378 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0390 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0390 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0386 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0378 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0375 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0380 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0379 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0378 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Loss: 1.0378 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0354 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0347 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0365 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0377 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0368 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0378 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0402 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0381 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0374 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Loss: 1.0374 (1.0386)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:19  Loss: 0.4118 (0.4118)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3053  data: 0.1880  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  Loss: 0.4261 (0.5024)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (100.0000)  time: 0.1337  data: 0.0173  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.4525 (0.5474)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.7024)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.4525 (0.5237)  Acc@1: 93.7500 (88.9113)  Acc@5: 100.0000 (99.5968)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.4197 (0.5099)  Acc@1: 93.7500 (89.9390)  Acc@5: 100.0000 (99.6951)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.4197 (0.4900)  Acc@1: 93.7500 (90.8088)  Acc@5: 100.0000 (99.7549)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.3832 (0.4755)  Acc@1: 93.7500 (91.0861)  Acc@5: 100.0000 (99.6926)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3690 (0.4718)  Acc@1: 93.7500 (91.2000)  Acc@5: 100.0000 (99.7000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 91.200 Acc@5 99.700 loss 0.472
Test: [Task 1]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 93.3333 (93.3333)  Loss: 0.7129 (0.7129)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2848  data: 0.1634  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 87.5000 (87.6543)  Loss: 0.7686 (0.8930)  Acc@1: 81.2500 (80.6818)  Acc@5: 93.7500 (94.3182)  time: 0.1334  data: 0.0152  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 87.5000 (88.0795)  Loss: 0.9102 (1.0126)  Acc@1: 75.0000 (79.7619)  Acc@5: 93.7500 (93.1548)  time: 0.1183  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.3077 (88.9640)  Loss: 1.1113 (1.0196)  Acc@1: 81.2500 (80.0403)  Acc@5: 93.7500 (92.3387)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (89.8973)  Loss: 1.0716 (1.0323)  Acc@1: 81.2500 (80.4878)  Acc@5: 93.7500 (91.7683)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 93.3333 (90.7459)  Loss: 0.8633 (1.0247)  Acc@1: 81.2500 (81.0049)  Acc@5: 93.7500 (91.7892)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (90.9507)  Loss: 0.8633 (0.9794)  Acc@1: 87.5000 (81.7623)  Acc@5: 93.7500 (92.1107)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (91.0714)  Loss: 0.7747 (0.9629)  Acc@1: 87.5000 (82.0000)  Acc@5: 93.7500 (92.3000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1204 s / it)
* Acc@1 82.000 Acc@5 92.300 loss 0.963
* Acc@1 nan ASR 91.071
Test: [Task 2]  [ 0/63]  eta: 0:00:20  Loss: 0.6378 (0.6378)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3324  data: 0.2138  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:07  Loss: 0.5240 (0.5983)  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (98.2955)  time: 0.1360  data: 0.0196  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.5703 (0.6789)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (98.2143)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.6823 (0.6551)  Acc@1: 87.5000 (91.1290)  Acc@5: 100.0000 (97.9839)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.5979 (0.6437)  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (98.1707)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.5904 (0.6372)  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (98.1618)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5420 (0.6192)  Acc@1: 93.7500 (91.8033)  Acc@5: 100.0000 (98.4631)  time: 0.1163  data: 0.0001  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.4706 (0.6103)  Acc@1: 93.7500 (91.9000)  Acc@5: 100.0000 (98.5000)  time: 0.1135  data: 0.0001  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1197 s / it)
* Acc@1 91.900 Acc@5 98.500 loss 0.610
Test: [Task 2]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 84.6154 (84.6154)  Loss: 1.3012 (1.3012)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2656  data: 0.1460  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 93.7500 (93.9394)  Loss: 0.8118 (0.8436)  Acc@1: 93.7500 (89.7727)  Acc@5: 93.7500 (94.8864)  time: 0.1310  data: 0.0135  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 93.3333 (91.1475)  Loss: 0.8666 (1.0039)  Acc@1: 87.5000 (86.0119)  Acc@5: 93.7500 (93.1548)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 87.5000 (91.3140)  Loss: 1.0099 (1.0286)  Acc@1: 81.2500 (85.0806)  Acc@5: 87.5000 (91.7339)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.3077 (91.4966)  Loss: 1.0338 (1.0797)  Acc@1: 81.2500 (83.9939)  Acc@5: 87.5000 (90.7012)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (91.0959)  Loss: 1.2291 (1.0900)  Acc@1: 81.2500 (83.2108)  Acc@5: 87.5000 (90.4412)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (91.6380)  Loss: 0.9092 (1.0763)  Acc@1: 81.2500 (83.4016)  Acc@5: 93.7500 (90.6762)  time: 0.1174  data: 0.0001  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (91.7318)  Loss: 0.9032 (1.0740)  Acc@1: 81.2500 (83.5000)  Acc@5: 93.7500 (90.7000)  time: 0.1146  data: 0.0001  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1197 s / it)
* Acc@1 83.500 Acc@5 90.700 loss 1.074
* Acc@1 nan ASR 91.732
Test: [Task 3]  [ 0/63]  eta: 0:00:20  Loss: 0.1765 (0.1765)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3239  data: 0.2057  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  Loss: 0.4212 (0.4453)  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (99.4318)  time: 0.1351  data: 0.0189  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.4820 (0.4585)  Acc@1: 87.5000 (91.0714)  Acc@5: 100.0000 (99.1071)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  Loss: 0.4171 (0.4577)  Acc@1: 87.5000 (90.7258)  Acc@5: 100.0000 (99.3952)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.4310 (0.4556)  Acc@1: 93.7500 (91.0061)  Acc@5: 100.0000 (99.3902)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.4365 (0.4538)  Acc@1: 93.7500 (91.7892)  Acc@5: 100.0000 (99.2647)  time: 0.1163  data: 0.0001  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.4718 (0.4629)  Acc@1: 93.7500 (91.4959)  Acc@5: 100.0000 (99.3852)  time: 0.1162  data: 0.0001  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.4787 (0.4645)  Acc@1: 87.5000 (91.4000)  Acc@5: 100.0000 (99.4000)  time: 0.1135  data: 0.0001  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 91.400 Acc@5 99.400 loss 0.465
Test: [Task 3]  [ 0/63]  eta: 0:00:17  ASR: nan (nan)  ACC: 100.0000 (100.0000)  Loss: 0.1765 (0.1765)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2786  data: 0.1577  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 93.3333 (91.5663)  Loss: 0.7869 (0.7416)  Acc@1: 87.5000 (86.3636)  Acc@5: 93.7500 (93.7500)  time: 0.1323  data: 0.0145  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 88.8889 (90.8784)  Loss: 0.8911 (1.0625)  Acc@1: 81.2500 (80.3571)  Acc@5: 87.5000 (88.0952)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 88.8889 (90.4328)  Loss: 1.1735 (1.0477)  Acc@1: 75.0000 (80.2419)  Acc@5: 87.5000 (88.5081)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.3077 (90.7850)  Loss: 0.8345 (1.0019)  Acc@1: 87.5000 (81.4024)  Acc@5: 93.7500 (89.3293)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 93.3333 (91.4718)  Loss: 0.8817 (1.0232)  Acc@1: 87.5000 (81.7402)  Acc@5: 87.5000 (88.8480)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (91.0959)  Loss: 0.8817 (0.9982)  Acc@1: 87.5000 (81.9672)  Acc@5: 93.7500 (89.5492)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 87.5000 (90.9900)  Loss: 0.8817 (0.9882)  Acc@1: 81.2500 (82.0000)  Acc@5: 93.7500 (89.7000)  time: 0.1146  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1199 s / it)
* Acc@1 82.000 Acc@5 89.700 loss 0.988
* Acc@1 nan ASR 90.990
[Average accuracy till task3]	Acc@1: 82.5000	Acc@5: 90.9000	Loss: 1.0084	Forgetting: 4.5000	Backward: -4.5000
Train: Epoch[1/5]  [  0/313]  eta: 0:01:54  Lr: 0.001875  Loss: 2.0353  Acc@1: 25.0000 (25.0000)  Acc@5: 68.7500 (68.7500)  time: 0.3668  data: 0.1775  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.8213  Acc@1: 56.2500 (53.4091)  Acc@5: 81.2500 (83.5227)  time: 0.2032  data: 0.0163  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.4384  Acc@1: 75.0000 (65.4762)  Acc@5: 87.5000 (88.3929)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.0949  Acc@1: 81.2500 (71.3710)  Acc@5: 93.7500 (90.1210)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.7113  Acc@1: 87.5000 (75.0000)  Acc@5: 100.0000 (92.2256)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.5606  Acc@1: 87.5000 (76.9608)  Acc@5: 100.0000 (93.0147)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.6399  Acc@1: 87.5000 (78.2787)  Acc@5: 93.7500 (93.6475)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.4208  Acc@1: 87.5000 (78.6092)  Acc@5: 100.0000 (94.0141)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.5468  Acc@1: 81.2500 (79.2438)  Acc@5: 100.0000 (94.5216)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.7083  Acc@1: 87.5000 (80.2198)  Acc@5: 100.0000 (94.9176)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.0959  Acc@1: 87.5000 (81.0025)  Acc@5: 100.0000 (95.2970)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5604  Acc@1: 87.5000 (81.6441)  Acc@5: 100.0000 (95.4392)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0215  Acc@1: 87.5000 (82.3347)  Acc@5: 100.0000 (95.6612)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4507  Acc@1: 87.5000 (82.5859)  Acc@5: 100.0000 (95.8015)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0131  Acc@1: 87.5000 (83.2004)  Acc@5: 100.0000 (95.9220)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0176  Acc@1: 93.7500 (83.7334)  Acc@5: 100.0000 (96.0679)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0177  Acc@1: 87.5000 (83.8509)  Acc@5: 100.0000 (96.0792)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.5978  Acc@1: 87.5000 (83.8816)  Acc@5: 100.0000 (96.2354)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2598  Acc@1: 87.5000 (83.9088)  Acc@5: 100.0000 (96.2362)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3740  Acc@1: 87.5000 (84.1950)  Acc@5: 100.0000 (96.2696)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1501  Acc@1: 87.5000 (84.3595)  Acc@5: 100.0000 (96.3308)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2736  Acc@1: 87.5000 (84.4787)  Acc@5: 100.0000 (96.3270)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0631  Acc@1: 87.5000 (84.6719)  Acc@5: 100.0000 (96.4084)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3592  Acc@1: 87.5000 (84.8485)  Acc@5: 100.0000 (96.4286)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3109  Acc@1: 87.5000 (84.9585)  Acc@5: 100.0000 (96.4471)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.8067  Acc@1: 87.5000 (84.9851)  Acc@5: 100.0000 (96.5139)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2932  Acc@1: 87.5000 (85.0335)  Acc@5: 100.0000 (96.5278)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2543  Acc@1: 87.5000 (85.1476)  Acc@5: 100.0000 (96.6098)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.6757  Acc@1: 87.5000 (85.1868)  Acc@5: 100.0000 (96.6415)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.6701  Acc@1: 87.5000 (85.0945)  Acc@5: 100.0000 (96.6924)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1357  Acc@1: 87.5000 (85.1329)  Acc@5: 100.0000 (96.6777)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0563  Acc@1: 87.5000 (85.1688)  Acc@5: 100.0000 (96.7645)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2760  Acc@1: 87.5000 (85.2000)  Acc@5: 100.0000 (96.7800)  time: 0.1823  data: 0.0001  max mem: 2386
Train: Epoch[1/5] Total time: 0:00:58 (0.1871 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2760  Acc@1: 87.5000 (85.2000)  Acc@5: 100.0000 (96.7800)
Train: Epoch[1/5]  [  0/313]  eta: 0:01:56  Loss: 1.0646 (1.0646)  ASR: 0.0000 (0.0000)  time: 0.3729  data: 0.1751  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0601 (1.0604)  ASR: 0.0000 (0.0000)  time: 0.2075  data: 0.0161  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0564 (1.0572)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0536 (1.0559)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0523 (1.0547)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0498 (1.0538)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0482 (1.0528)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0480 (1.0524)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0489 (1.0520)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0482 (1.0515)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0466 (1.0511)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0474 (1.0509)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0490 (1.0507)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0486 (1.0505)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0485 (1.0503)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0466 (1.0500)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0466 (1.0498)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0466 (1.0496)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0456 (1.0494)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0451 (1.0492)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0442 (1.0490)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0448 (1.0489)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0457 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Loss: 1.0436 (1.0485)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0455 (1.0484)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0455 (1.0483)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0451 (1.0482)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0451 (1.0481)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0433 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0435 (1.0478)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0440 (1.0477)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0437 (1.0476)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0433 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Loss: 1.0433 (1.0475)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:45  Lr: 0.001875  Loss: 0.3214  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.3370  data: 0.1472  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.4266  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.2004  data: 0.0135  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.3472  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (98.2143)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2729  Acc@1: 87.5000 (90.1210)  Acc@5: 100.0000 (98.5887)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3334  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (98.6280)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.1828  Acc@1: 87.5000 (88.8480)  Acc@5: 100.0000 (98.7745)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2355  Acc@1: 87.5000 (88.7295)  Acc@5: 100.0000 (98.8730)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.4406  Acc@1: 87.5000 (88.0282)  Acc@5: 100.0000 (98.6796)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.5081  Acc@1: 87.5000 (87.7315)  Acc@5: 100.0000 (98.5340)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.1829  Acc@1: 87.5000 (87.7747)  Acc@5: 100.0000 (98.5577)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.4394  Acc@1: 87.5000 (87.5619)  Acc@5: 100.0000 (98.5149)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5507  Acc@1: 87.5000 (87.1622)  Acc@5: 100.0000 (98.4797)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1052  Acc@1: 87.5000 (87.5517)  Acc@5: 100.0000 (98.5021)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1555  Acc@1: 87.5000 (87.2137)  Acc@5: 100.0000 (98.4256)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1162  Acc@1: 87.5000 (87.5443)  Acc@5: 100.0000 (98.5372)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0032  Acc@1: 93.7500 (87.7897)  Acc@5: 100.0000 (98.5513)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0357  Acc@1: 87.5000 (87.6165)  Acc@5: 100.0000 (98.5637)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2015  Acc@1: 87.5000 (87.8289)  Acc@5: 100.0000 (98.5746)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3079  Acc@1: 93.7500 (87.8453)  Acc@5: 100.0000 (98.5843)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0041  Acc@1: 87.5000 (87.8927)  Acc@5: 100.0000 (98.6257)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3786  Acc@1: 87.5000 (87.8731)  Acc@5: 100.0000 (98.6629)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2406  Acc@1: 87.5000 (87.7666)  Acc@5: 100.0000 (98.6967)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0866  Acc@1: 87.5000 (87.8111)  Acc@5: 100.0000 (98.6708)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3918  Acc@1: 87.5000 (87.8788)  Acc@5: 100.0000 (98.6201)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1956  Acc@1: 87.5000 (87.7334)  Acc@5: 100.0000 (98.5996)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3185  Acc@1: 87.5000 (87.8486)  Acc@5: 100.0000 (98.6056)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0257  Acc@1: 93.7500 (88.0029)  Acc@5: 100.0000 (98.6590)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3427  Acc@1: 87.5000 (87.9613)  Acc@5: 100.0000 (98.5932)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1348  Acc@1: 87.5000 (87.8559)  Acc@5: 100.0000 (98.5765)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0206  Acc@1: 87.5000 (87.8866)  Acc@5: 100.0000 (98.4966)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.1776  Acc@1: 93.7500 (87.9983)  Acc@5: 100.0000 (98.5050)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0140  Acc@1: 93.7500 (88.0225)  Acc@5: 100.0000 (98.4727)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.8383  Acc@1: 93.7500 (88.0000)  Acc@5: 100.0000 (98.4600)  time: 0.1821  data: 0.0001  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1871 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.8383  Acc@1: 93.7500 (88.0000)  Acc@5: 100.0000 (98.4600)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:21  Loss: 1.0499 (1.0499)  ASR: 0.0000 (0.0000)  time: 0.4525  data: 0.2567  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:05  Loss: 1.0393 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.2159  data: 0.0235  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0411 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0425 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:54  Loss: 1.0409 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0409 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0411 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0416 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0420 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0422 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0429 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0411 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0411 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0410 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0409 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0422 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0432 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0432 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0399 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0402 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0405 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0402 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1935  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0415 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:16  Loss: 1.0425 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0416 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0398 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0398 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0394 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0397 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0396 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1936  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0395 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0396 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0403 (1.0417)  ASR: 0.0000 (0.0000)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:01:00 (0.1931 s / it)
Averaged stats: Loss: 1.0403 (1.0417)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:58  Lr: 0.001875  Loss: -0.0886  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3784  data: 0.1896  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.2472  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (100.0000)  time: 0.2045  data: 0.0174  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.1571  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.8095)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0487  Acc@1: 87.5000 (89.9194)  Acc@5: 100.0000 (99.1935)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1103  Acc@1: 87.5000 (89.4817)  Acc@5: 100.0000 (99.2378)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.4783  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (98.8971)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0470  Acc@1: 93.7500 (89.7541)  Acc@5: 100.0000 (98.8730)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.3601  Acc@1: 87.5000 (89.2606)  Acc@5: 100.0000 (98.8556)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1695  Acc@1: 87.5000 (88.9660)  Acc@5: 100.0000 (98.9198)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.7976  Acc@1: 87.5000 (88.5302)  Acc@5: 100.0000 (98.6951)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2720  Acc@1: 87.5000 (88.5520)  Acc@5: 100.0000 (98.7005)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1145  Acc@1: 87.5000 (88.6261)  Acc@5: 100.0000 (98.7050)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0689  Acc@1: 87.5000 (88.5331)  Acc@5: 100.0000 (98.6054)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4661  Acc@1: 87.5000 (88.5019)  Acc@5: 100.0000 (98.6164)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0771  Acc@1: 87.5000 (88.4309)  Acc@5: 100.0000 (98.5816)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.1309  Acc@1: 87.5000 (88.2450)  Acc@5: 100.0000 (98.6341)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1403  Acc@1: 87.5000 (88.1988)  Acc@5: 100.0000 (98.6801)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2663  Acc@1: 87.5000 (88.2675)  Acc@5: 100.0000 (98.6477)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1091  Acc@1: 93.7500 (88.5359)  Acc@5: 100.0000 (98.6878)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0510  Acc@1: 93.7500 (88.7762)  Acc@5: 100.0000 (98.7238)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.8663  Acc@1: 93.7500 (88.4017)  Acc@5: 100.0000 (98.6007)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2306  Acc@1: 81.2500 (88.3886)  Acc@5: 100.0000 (98.5486)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1622  Acc@1: 87.5000 (88.4333)  Acc@5: 100.0000 (98.5011)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.9478  Acc@1: 93.7500 (88.5281)  Acc@5: 100.0000 (98.4578)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0979  Acc@1: 93.7500 (88.6151)  Acc@5: 100.0000 (98.4699)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1100  Acc@1: 87.5000 (88.7201)  Acc@5: 100.0000 (98.4811)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.5428  Acc@1: 87.5000 (88.6255)  Acc@5: 100.0000 (98.4435)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3245  Acc@1: 87.5000 (88.2611)  Acc@5: 93.7500 (98.3395)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1672  Acc@1: 87.5000 (88.2340)  Acc@5: 100.0000 (98.3541)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1589  Acc@1: 87.5000 (88.3162)  Acc@5: 100.0000 (98.3462)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0838  Acc@1: 87.5000 (88.3098)  Acc@5: 100.0000 (98.2973)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0268  Acc@1: 87.5000 (88.3240)  Acc@5: 100.0000 (98.3119)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0934  Acc@1: 87.5000 (88.3200)  Acc@5: 100.0000 (98.3000)  time: 0.1823  data: 0.0001  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0934  Acc@1: 87.5000 (88.3200)  Acc@5: 100.0000 (98.3000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:46  Loss: 1.0392 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.3390  data: 0.1420  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0392 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.2047  data: 0.0131  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0393 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0386 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0403 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1903  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Loss: 1.0410 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Loss: 1.0390 (1.0407)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Loss: 1.0391 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Loss: 1.0381 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Loss: 1.0380 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0389 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0389 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0404 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0408 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0384 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0386 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0402 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0401 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0411 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0413 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0375 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0366 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0395 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Loss: 1.0407 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0387 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0384 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0379 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0381 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0385 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0392 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0411 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0407 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0407 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Loss: 1.0407 (1.0399)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:09  Lr: 0.001875  Loss: -0.0395  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.4122  data: 0.2231  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.2646  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (100.0000)  time: 0.2076  data: 0.0204  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.3937  Acc@1: 93.7500 (93.1548)  Acc@5: 100.0000 (99.4048)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6893  Acc@1: 87.5000 (91.1290)  Acc@5: 100.0000 (98.9919)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0449  Acc@1: 87.5000 (90.5488)  Acc@5: 100.0000 (98.9329)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.0686  Acc@1: 93.7500 (90.1961)  Acc@5: 100.0000 (99.0196)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1253  Acc@1: 87.5000 (89.8566)  Acc@5: 100.0000 (98.7705)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.0937  Acc@1: 87.5000 (90.2289)  Acc@5: 100.0000 (98.7676)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.1044  Acc@1: 87.5000 (89.9691)  Acc@5: 100.0000 (98.6111)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0085  Acc@1: 87.5000 (90.2473)  Acc@5: 100.0000 (98.7637)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3015  Acc@1: 87.5000 (89.9134)  Acc@5: 100.0000 (98.6386)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5591  Acc@1: 87.5000 (89.9212)  Acc@5: 100.0000 (98.6486)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1866  Acc@1: 87.5000 (89.9277)  Acc@5: 100.0000 (98.6570)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0748  Acc@1: 87.5000 (89.8855)  Acc@5: 100.0000 (98.7595)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0679  Acc@1: 87.5000 (89.7606)  Acc@5: 100.0000 (98.7145)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0459  Acc@1: 93.7500 (90.0248)  Acc@5: 100.0000 (98.7997)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1048  Acc@1: 93.7500 (89.7904)  Acc@5: 100.0000 (98.7966)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.3630  Acc@1: 87.5000 (89.7295)  Acc@5: 100.0000 (98.7939)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: -0.0763  Acc@1: 87.5000 (89.6754)  Acc@5: 100.0000 (98.7224)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.1209  Acc@1: 87.5000 (89.6924)  Acc@5: 100.0000 (98.6911)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1346  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.7562)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3712  Acc@1: 87.5000 (89.4550)  Acc@5: 100.0000 (98.6671)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0406  Acc@1: 87.5000 (89.4796)  Acc@5: 100.0000 (98.5860)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3463  Acc@1: 87.5000 (89.4210)  Acc@5: 100.0000 (98.5931)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0394  Acc@1: 87.5000 (89.3672)  Acc@5: 100.0000 (98.5737)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1588  Acc@1: 87.5000 (89.2928)  Acc@5: 100.0000 (98.4811)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1354  Acc@1: 87.5000 (89.3199)  Acc@5: 100.0000 (98.4674)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2281  Acc@1: 87.5000 (89.3681)  Acc@5: 100.0000 (98.4317)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1627  Acc@1: 87.5000 (89.3461)  Acc@5: 100.0000 (98.4875)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4028  Acc@1: 87.5000 (89.3041)  Acc@5: 100.0000 (98.5180)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1600  Acc@1: 87.5000 (89.3272)  Acc@5: 100.0000 (98.5465)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0827  Acc@1: 87.5000 (89.3087)  Acc@5: 100.0000 (98.5531)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0417  Acc@1: 87.5000 (89.3600)  Acc@5: 100.0000 (98.5600)  time: 0.1824  data: 0.0001  max mem: 2386
Train: Epoch[4/5] Total time: 0:00:58 (0.1874 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0417  Acc@1: 87.5000 (89.3600)  Acc@5: 100.0000 (98.5600)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:57  Loss: 1.0350 (1.0350)  ASR: 0.0000 (0.0000)  time: 0.3763  data: 0.1798  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0359 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.2088  data: 0.0165  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0354 (1.0363)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0357 (1.0374)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0379 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0381 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0369 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0366 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0368 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0368 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0375 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0376 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0383 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0368 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0374 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0383 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0383 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0380 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0368 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0372 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0380 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0380 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0376 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Loss: 1.0364 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0364 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0359 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0359 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0376 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0376 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0375 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0394 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0395 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0392 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1925 s / it)
Averaged stats: Loss: 1.0392 (1.0382)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:45  Lr: 0.001875  Loss: -0.0883  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3377  data: 0.1491  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.2864  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (97.7273)  time: 0.2005  data: 0.0137  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: -0.0749  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.5119)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1263  Acc@1: 93.7500 (89.1129)  Acc@5: 100.0000 (98.3871)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1406  Acc@1: 93.7500 (90.3963)  Acc@5: 100.0000 (98.6280)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: -0.0084  Acc@1: 93.7500 (89.9510)  Acc@5: 100.0000 (98.4069)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0621  Acc@1: 87.5000 (90.1639)  Acc@5: 100.0000 (98.6680)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2489  Acc@1: 87.5000 (89.8768)  Acc@5: 100.0000 (98.6796)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.0372  Acc@1: 87.5000 (89.7377)  Acc@5: 100.0000 (98.6883)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1734  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.6951)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3593  Acc@1: 87.5000 (89.4183)  Acc@5: 100.0000 (98.7624)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1355  Acc@1: 87.5000 (89.4144)  Acc@5: 100.0000 (98.7050)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.0525  Acc@1: 87.5000 (89.5145)  Acc@5: 100.0000 (98.7603)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1314  Acc@1: 87.5000 (89.3607)  Acc@5: 100.0000 (98.7118)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3738  Acc@1: 87.5000 (89.2287)  Acc@5: 100.0000 (98.6259)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0843  Acc@1: 87.5000 (89.4454)  Acc@5: 100.0000 (98.5099)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0306  Acc@1: 93.7500 (89.7516)  Acc@5: 100.0000 (98.6025)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0057  Acc@1: 93.7500 (89.9488)  Acc@5: 100.0000 (98.6111)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0447  Acc@1: 93.7500 (90.0898)  Acc@5: 100.0000 (98.6188)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0147  Acc@1: 93.7500 (90.1505)  Acc@5: 100.0000 (98.6911)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0181  Acc@1: 87.5000 (90.0808)  Acc@5: 100.0000 (98.5697)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0382  Acc@1: 87.5000 (89.9585)  Acc@5: 100.0000 (98.6078)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3615  Acc@1: 87.5000 (90.0452)  Acc@5: 100.0000 (98.6708)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3064  Acc@1: 93.7500 (89.9351)  Acc@5: 100.0000 (98.7013)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3007  Acc@1: 87.5000 (89.7562)  Acc@5: 100.0000 (98.7033)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0131  Acc@1: 93.7500 (89.9153)  Acc@5: 100.0000 (98.7052)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0757  Acc@1: 93.7500 (89.9425)  Acc@5: 100.0000 (98.7308)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.1171  Acc@1: 87.5000 (89.8985)  Acc@5: 100.0000 (98.6854)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0577  Acc@1: 87.5000 (89.9244)  Acc@5: 100.0000 (98.7100)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0940  Acc@1: 87.5000 (89.9270)  Acc@5: 100.0000 (98.7328)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0885  Acc@1: 93.7500 (89.9709)  Acc@5: 100.0000 (98.7749)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1089  Acc@1: 87.5000 (89.9317)  Acc@5: 100.0000 (98.7741)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0161  Acc@1: 87.5000 (89.9200)  Acc@5: 100.0000 (98.7600)  time: 0.1823  data: 0.0001  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0161  Acc@1: 87.5000 (89.9200)  Acc@5: 100.0000 (98.7600)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:01  Loss: 1.0353 (1.0353)  ASR: 0.0000 (0.0000)  time: 0.3868  data: 0.1863  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0356 (1.0359)  ASR: 0.0000 (0.0000)  time: 0.2094  data: 0.0171  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0372 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0376 (1.0373)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0382 (1.0376)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0385 (1.0375)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0350 (1.0373)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0371 (1.0376)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0374 (1.0375)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0357 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0357 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0359 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0359 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0359 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0357 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0358 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0419 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0397 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0372 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0368 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0366 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0363 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0363 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Loss: 1.0334 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0340 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0365 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0375 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0357 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0359 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0369 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0362 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0368 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0368 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1925 s / it)
Averaged stats: Loss: 1.0368 (1.0370)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:17  Loss: 0.4670 (0.4670)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2818  data: 0.1644  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.4862 (0.4889)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (99.4318)  time: 0.1315  data: 0.0152  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.4862 (0.5355)  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (99.4048)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.4741 (0.5205)  Acc@1: 93.7500 (89.1129)  Acc@5: 100.0000 (99.5968)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.4741 (0.5056)  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (99.6951)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.4223 (0.4868)  Acc@1: 93.7500 (90.5637)  Acc@5: 100.0000 (99.7549)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4093 (0.4743)  Acc@1: 93.7500 (90.9836)  Acc@5: 100.0000 (99.6926)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.3751 (0.4719)  Acc@1: 93.7500 (91.1000)  Acc@5: 100.0000 (99.7000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 91.100 Acc@5 99.700 loss 0.472
Test: [Task 1]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 78.5714 (78.5714)  Loss: 1.2219 (1.2219)  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.2878  data: 0.1641  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 90.0000 (88.1988)  Loss: 0.8261 (0.9533)  Acc@1: 87.5000 (80.6818)  Acc@5: 93.7500 (92.0455)  time: 0.1334  data: 0.0152  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 87.5000 (88.0795)  Loss: 0.8490 (1.0044)  Acc@1: 81.2500 (79.4643)  Acc@5: 93.7500 (91.6667)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.8571 (88.9625)  Loss: 0.8490 (0.9155)  Acc@1: 81.2500 (81.8548)  Acc@5: 93.7500 (93.3468)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 93.3333 (90.0673)  Loss: 0.6114 (0.9217)  Acc@1: 87.5000 (82.3171)  Acc@5: 93.7500 (93.1402)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 93.7500 (90.9091)  Loss: 0.7338 (0.9063)  Acc@1: 87.5000 (82.9657)  Acc@5: 93.7500 (93.1373)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (91.3143)  Loss: 0.8760 (0.9207)  Acc@1: 87.5000 (82.8893)  Acc@5: 93.7500 (92.9303)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (91.4158)  Loss: 0.7698 (0.9095)  Acc@1: 87.5000 (83.0000)  Acc@5: 93.7500 (93.1000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1202 s / it)
* Acc@1 83.000 Acc@5 93.100 loss 0.909
* Acc@1 nan ASR 91.416
Test: [Task 2]  [ 0/63]  eta: 0:00:18  Loss: 0.8030 (0.8030)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3015  data: 0.1829  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:07  Loss: 0.5885 (0.6743)  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  time: 0.1334  data: 0.0168  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.6772 (0.7449)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2143)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.6822 (0.7216)  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (97.7823)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.6651 (0.7050)  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (98.0183)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.6651 (0.6997)  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (97.9167)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.5459 (0.6727)  Acc@1: 87.5000 (88.4221)  Acc@5: 100.0000 (98.2582)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5047 (0.6637)  Acc@1: 87.5000 (88.5000)  Acc@5: 100.0000 (98.3000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1193 s / it)
* Acc@1 88.500 Acc@5 98.300 loss 0.664
Test: [Task 2]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 93.3333 (93.3333)  Loss: 0.8999 (0.8999)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2628  data: 0.1407  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 92.8571 (91.6129)  Loss: 1.0018 (1.1232)  Acc@1: 81.2500 (80.6818)  Acc@5: 93.7500 (88.0682)  time: 0.1310  data: 0.0130  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 90.0000 (87.5839)  Loss: 1.1278 (1.1732)  Acc@1: 75.0000 (77.6786)  Acc@5: 87.5000 (88.9881)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (88.1007)  Loss: 1.1614 (1.1924)  Acc@1: 75.0000 (77.6210)  Acc@5: 87.5000 (88.1048)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (87.7133)  Loss: 1.0962 (1.1386)  Acc@1: 81.2500 (78.3537)  Acc@5: 93.7500 (89.1768)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (87.4830)  Loss: 0.8126 (1.1006)  Acc@1: 81.2500 (78.7990)  Acc@5: 93.7500 (89.5833)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (88.5584)  Loss: 0.8842 (1.0996)  Acc@1: 81.2500 (79.3033)  Acc@5: 87.5000 (89.4467)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (88.6288)  Loss: 0.8126 (1.0812)  Acc@1: 81.2500 (79.5000)  Acc@5: 93.7500 (89.6000)  time: 0.1149  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1200 s / it)
* Acc@1 79.500 Acc@5 89.600 loss 1.081
* Acc@1 nan ASR 88.629
Test: [Task 3]  [ 0/63]  eta: 0:00:18  Loss: 0.1650 (0.1650)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2972  data: 0.1797  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  Loss: 0.5091 (0.4836)  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.8636)  time: 0.1329  data: 0.0166  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.5441 (0.4996)  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.5119)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  Loss: 0.4909 (0.5012)  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (98.9919)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.4471 (0.4908)  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (99.0854)  time: 0.1167  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.4635 (0.4902)  Acc@1: 93.7500 (90.4412)  Acc@5: 100.0000 (99.0196)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5095 (0.4980)  Acc@1: 87.5000 (90.2664)  Acc@5: 100.0000 (99.0779)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5095 (0.4989)  Acc@1: 87.5000 (90.0000)  Acc@5: 100.0000 (99.1000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1193 s / it)
* Acc@1 90.000 Acc@5 99.100 loss 0.499
Test: [Task 3]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 0.5610 (0.5610)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.2867  data: 0.1637  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 92.8571 (89.1566)  Loss: 0.6100 (0.7638)  Acc@1: 87.5000 (84.0909)  Acc@5: 93.7500 (93.7500)  time: 0.1341  data: 0.0152  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 87.5000 (89.2157)  Loss: 0.6977 (0.9368)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (90.7738)  time: 0.1184  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 86.6667 (89.3096)  Loss: 0.9454 (0.9510)  Acc@1: 75.0000 (80.8468)  Acc@5: 93.7500 (91.7339)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (89.9160)  Loss: 0.7764 (0.9286)  Acc@1: 87.5000 (81.5549)  Acc@5: 93.7500 (91.7683)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 93.3333 (90.6377)  Loss: 0.7764 (0.9365)  Acc@1: 87.5000 (81.8627)  Acc@5: 93.7500 (91.4216)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (90.6712)  Loss: 0.9147 (0.9501)  Acc@1: 81.2500 (81.6598)  Acc@5: 87.5000 (91.0861)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (90.3548)  Loss: 0.9147 (0.9424)  Acc@1: 81.2500 (81.5000)  Acc@5: 87.5000 (91.2000)  time: 0.1149  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1205 s / it)
* Acc@1 81.500 Acc@5 91.200 loss 0.942
* Acc@1 nan ASR 90.355
Test: [Task 4]  [ 0/63]  eta: 0:00:17  Loss: 0.8790 (0.8790)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.2848  data: 0.1674  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:06  Loss: 0.5505 (0.5661)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.1317  data: 0.0154  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  Loss: 0.5074 (0.5644)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.2143)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  Loss: 0.4911 (0.5406)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.3871)  time: 0.1168  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  Loss: 0.2933 (0.4937)  Acc@1: 93.7500 (89.1768)  Acc@5: 100.0000 (98.6280)  time: 0.1167  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  Loss: 0.3698 (0.5071)  Acc@1: 93.7500 (89.7059)  Acc@5: 100.0000 (98.6520)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.4803 (0.5180)  Acc@1: 87.5000 (89.1393)  Acc@5: 100.0000 (98.1557)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.4387 (0.5115)  Acc@1: 87.5000 (89.4000)  Acc@5: 100.0000 (98.2000)  time: 0.1138  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 89.400 Acc@5 98.200 loss 0.511
Test: [Task 4]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  ACC: 73.3333 (73.3333)  Loss: 1.2026 (1.2026)  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.3109  data: 0.1902  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 92.8571 (89.1720)  Loss: 1.0886 (1.1111)  Acc@1: 75.0000 (79.5455)  Acc@5: 87.5000 (88.0682)  time: 0.1355  data: 0.0175  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 86.6667 (87.2131)  Loss: 0.9256 (1.0374)  Acc@1: 81.2500 (79.1667)  Acc@5: 87.5000 (89.2857)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 86.6667 (87.9464)  Loss: 0.9127 (1.0372)  Acc@1: 81.2500 (79.4355)  Acc@5: 87.5000 (89.3145)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (89.3581)  Loss: 0.9561 (1.0045)  Acc@1: 81.2500 (80.6402)  Acc@5: 87.5000 (89.3293)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.8571 (89.9045)  Loss: 1.0097 (1.0452)  Acc@1: 81.2500 (80.7598)  Acc@5: 87.5000 (88.8480)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (89.0930)  Loss: 1.1714 (1.0840)  Acc@1: 75.0000 (79.5082)  Acc@5: 81.2500 (87.7049)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 87.5000 (89.3617)  Loss: 1.1714 (1.0753)  Acc@1: 81.2500 (79.8000)  Acc@5: 81.2500 (87.8000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1207 s / it)
* Acc@1 79.800 Acc@5 87.800 loss 1.075
* Acc@1 nan ASR 89.362
[Average accuracy till task4]	Acc@1: 80.9500	Acc@5: 90.4250	Loss: 1.0021	Forgetting: 4.1667	Backward: -4.1667
Train: Epoch[1/5]  [  0/313]  eta: 0:01:56  Lr: 0.001875  Loss: 2.0895  Acc@1: 6.2500 (6.2500)  Acc@5: 62.5000 (62.5000)  time: 0.3708  data: 0.1825  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.7819  Acc@1: 50.0000 (46.5909)  Acc@5: 81.2500 (80.1136)  time: 0.2033  data: 0.0167  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.5013  Acc@1: 62.5000 (57.1429)  Acc@5: 93.7500 (85.1190)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.5076  Acc@1: 75.0000 (65.3226)  Acc@5: 93.7500 (89.3145)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 1.1769  Acc@1: 87.5000 (70.2744)  Acc@5: 100.0000 (91.3110)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.1466  Acc@1: 87.5000 (72.6716)  Acc@5: 100.0000 (92.7696)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7959  Acc@1: 81.2500 (74.3852)  Acc@5: 100.0000 (93.4426)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.7093  Acc@1: 81.2500 (75.7923)  Acc@5: 100.0000 (94.1901)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.6981  Acc@1: 87.5000 (76.8519)  Acc@5: 100.0000 (94.6759)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.5123  Acc@1: 87.5000 (77.4725)  Acc@5: 100.0000 (94.9863)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3351  Acc@1: 87.5000 (78.2797)  Acc@5: 100.0000 (95.2351)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3161  Acc@1: 87.5000 (78.9414)  Acc@5: 100.0000 (95.4955)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1216  Acc@1: 87.5000 (79.5455)  Acc@5: 100.0000 (95.7128)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1160  Acc@1: 87.5000 (80.3435)  Acc@5: 100.0000 (95.8015)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.6734  Acc@1: 87.5000 (80.8067)  Acc@5: 100.0000 (96.0106)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2615  Acc@1: 87.5000 (81.3328)  Acc@5: 100.0000 (96.1921)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1329  Acc@1: 93.7500 (81.8323)  Acc@5: 100.0000 (96.3121)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2363  Acc@1: 87.5000 (82.0541)  Acc@5: 100.0000 (96.4912)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2958  Acc@1: 87.5000 (82.3550)  Acc@5: 100.0000 (96.5815)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0630  Acc@1: 87.5000 (82.6898)  Acc@5: 100.0000 (96.6623)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1670  Acc@1: 87.5000 (82.8980)  Acc@5: 100.0000 (96.7040)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2781  Acc@1: 87.5000 (83.1161)  Acc@5: 100.0000 (96.7713)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0432  Acc@1: 87.5000 (83.3428)  Acc@5: 100.0000 (96.8326)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0558  Acc@1: 87.5000 (83.3874)  Acc@5: 100.0000 (96.8885)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.2290  Acc@1: 87.5000 (83.6878)  Acc@5: 100.0000 (96.9658)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1318  Acc@1: 87.5000 (83.6404)  Acc@5: 100.0000 (97.0369)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2170  Acc@1: 81.2500 (83.5967)  Acc@5: 100.0000 (97.0307)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1903  Acc@1: 87.5000 (83.8100)  Acc@5: 100.0000 (97.0941)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1011  Acc@1: 87.5000 (83.9413)  Acc@5: 100.0000 (97.1530)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2036  Acc@1: 87.5000 (83.9347)  Acc@5: 100.0000 (97.1864)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0583  Acc@1: 81.2500 (83.9493)  Acc@5: 100.0000 (97.2176)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3730  Acc@1: 87.5000 (84.0434)  Acc@5: 100.0000 (97.2669)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3473  Acc@1: 87.5000 (84.0600)  Acc@5: 100.0000 (97.2600)  time: 0.1823  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.3473  Acc@1: 87.5000 (84.0600)  Acc@5: 100.0000 (97.2600)
Train: Epoch[1/5]  [  0/313]  eta: 0:01:44  Loss: 1.0643 (1.0643)  ASR: 0.0000 (0.0000)  time: 0.3342  data: 0.1334  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Loss: 1.0603 (1.0601)  ASR: 0.0000 (0.0000)  time: 0.2046  data: 0.0123  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0566 (1.0579)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0526 (1.0559)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0503 (1.0546)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0505 (1.0539)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Loss: 1.0505 (1.0534)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Loss: 1.0497 (1.0528)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Loss: 1.0488 (1.0522)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Loss: 1.0477 (1.0517)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0470 (1.0514)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0472 (1.0510)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0463 (1.0505)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0469 (1.0503)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0474 (1.0501)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0474 (1.0499)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0463 (1.0497)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0460 (1.0495)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0450 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0457 (1.0491)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0449 (1.0488)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0445 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0449 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Loss: 1.0466 (1.0485)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0473 (1.0484)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0448 (1.0483)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0433 (1.0481)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0437 (1.0480)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0445 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0445 (1.0477)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0437 (1.0476)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0438 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0446 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Loss: 1.0446 (1.0475)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:42  Lr: 0.001875  Loss: 0.1591  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3272  data: 0.1372  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.4235  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (97.7273)  time: 0.1996  data: 0.0126  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.2263  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (98.5119)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1947  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (98.9919)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.3338  Acc@1: 87.5000 (87.8049)  Acc@5: 100.0000 (98.7805)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: -0.0082  Acc@1: 93.7500 (87.8676)  Acc@5: 100.0000 (98.8971)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.3730  Acc@1: 87.5000 (87.8074)  Acc@5: 100.0000 (98.7705)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.5629  Acc@1: 87.5000 (87.1479)  Acc@5: 100.0000 (98.7676)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.2050  Acc@1: 87.5000 (86.5741)  Acc@5: 100.0000 (98.6111)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0604  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.6264)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3719  Acc@1: 87.5000 (86.9431)  Acc@5: 100.0000 (98.7624)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1226  Acc@1: 87.5000 (87.2185)  Acc@5: 100.0000 (98.8176)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2128  Acc@1: 93.7500 (87.6550)  Acc@5: 100.0000 (98.8120)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4000  Acc@1: 87.5000 (87.4046)  Acc@5: 100.0000 (98.7118)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.1564  Acc@1: 87.5000 (87.4113)  Acc@5: 100.0000 (98.7145)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.1469  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7169)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3028  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7578)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1114  Acc@1: 87.5000 (87.4269)  Acc@5: 100.0000 (98.7208)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3058  Acc@1: 87.5000 (87.3964)  Acc@5: 100.0000 (98.6533)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.4667  Acc@1: 87.5000 (87.4346)  Acc@5: 100.0000 (98.6911)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1436  Acc@1: 87.5000 (87.5622)  Acc@5: 100.0000 (98.7251)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3954  Acc@1: 87.5000 (87.5889)  Acc@5: 100.0000 (98.6671)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2253  Acc@1: 87.5000 (87.6697)  Acc@5: 100.0000 (98.7274)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1813  Acc@1: 87.5000 (87.5541)  Acc@5: 100.0000 (98.7284)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3134  Acc@1: 81.2500 (87.4741)  Acc@5: 100.0000 (98.7033)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0839  Acc@1: 87.5000 (87.4751)  Acc@5: 100.0000 (98.7550)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2199  Acc@1: 87.5000 (87.4282)  Acc@5: 100.0000 (98.7787)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0440  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8238)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0886  Acc@1: 93.7500 (87.5445)  Acc@5: 100.0000 (98.8212)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4522  Acc@1: 87.5000 (87.4785)  Acc@5: 100.0000 (98.7758)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0590  Acc@1: 87.5000 (87.4377)  Acc@5: 100.0000 (98.7126)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0537  Acc@1: 87.5000 (87.5201)  Acc@5: 100.0000 (98.7339)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5014  Acc@1: 87.5000 (87.5200)  Acc@5: 100.0000 (98.7200)  time: 0.1824  data: 0.0001  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.5014  Acc@1: 87.5000 (87.5200)  Acc@5: 100.0000 (98.7200)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:58  Loss: 1.0408 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.3778  data: 0.1822  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0432 (1.0436)  ASR: 0.0000 (0.0000)  time: 0.2083  data: 0.0168  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0432 (1.0433)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0425 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0414 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0423 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0426 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0421 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0421 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0417 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0417 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0413 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0424 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0419 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0409 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0411 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0409 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0409 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0419 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0423 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0412 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0403 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1935  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0397 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:16  Loss: 1.0414 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0411 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0400 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0390 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0407 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0407 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0407 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0405 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0394 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0394 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0394 (1.0418)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:57  Lr: 0.001875  Loss: 0.2319  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.3764  data: 0.1826  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.0670  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (99.4318)  time: 0.2048  data: 0.0168  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.0617  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (99.1071)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1525  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.7903)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.0386  Acc@1: 87.5000 (88.4146)  Acc@5: 100.0000 (98.9329)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.2676  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (99.0196)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0747  Acc@1: 87.5000 (88.5246)  Acc@5: 100.0000 (98.9754)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1073  Acc@1: 87.5000 (87.9401)  Acc@5: 100.0000 (98.9437)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0934  Acc@1: 87.5000 (88.0401)  Acc@5: 100.0000 (98.9198)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0881  Acc@1: 93.7500 (88.6676)  Acc@5: 100.0000 (98.9698)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2873  Acc@1: 93.7500 (88.4282)  Acc@5: 100.0000 (99.0718)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0821  Acc@1: 87.5000 (88.3446)  Acc@5: 100.0000 (98.9865)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2404  Acc@1: 87.5000 (88.3264)  Acc@5: 100.0000 (98.9669)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1274  Acc@1: 87.5000 (88.0725)  Acc@5: 100.0000 (98.9504)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.5502  Acc@1: 87.5000 (88.3422)  Acc@5: 100.0000 (98.9805)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3870  Acc@1: 93.7500 (88.4934)  Acc@5: 100.0000 (99.0480)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0061  Acc@1: 87.5000 (88.2764)  Acc@5: 100.0000 (98.9519)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1666  Acc@1: 87.5000 (88.3772)  Acc@5: 100.0000 (98.9401)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1103  Acc@1: 87.5000 (88.3287)  Acc@5: 100.0000 (98.8605)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0779  Acc@1: 87.5000 (88.3508)  Acc@5: 100.0000 (98.8874)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0156  Acc@1: 87.5000 (88.3085)  Acc@5: 100.0000 (98.9428)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3369  Acc@1: 87.5000 (88.2998)  Acc@5: 100.0000 (98.9040)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1385  Acc@1: 87.5000 (88.4615)  Acc@5: 100.0000 (98.8688)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0216  Acc@1: 87.5000 (88.5552)  Acc@5: 100.0000 (98.8907)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0822  Acc@1: 87.5000 (88.5114)  Acc@5: 100.0000 (98.8849)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0894  Acc@1: 87.5000 (88.6703)  Acc@5: 100.0000 (98.8795)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4242  Acc@1: 93.7500 (88.7452)  Acc@5: 100.0000 (98.8266)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3665  Acc@1: 87.5000 (88.7454)  Acc@5: 100.0000 (98.7777)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0071  Acc@1: 87.5000 (88.7011)  Acc@5: 100.0000 (98.8212)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0072  Acc@1: 87.5000 (88.8316)  Acc@5: 100.0000 (98.8402)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0882  Acc@1: 93.7500 (88.9743)  Acc@5: 100.0000 (98.8787)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0276  Acc@1: 93.7500 (89.0474)  Acc@5: 100.0000 (98.8947)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1137  Acc@1: 93.7500 (89.0200)  Acc@5: 100.0000 (98.9000)  time: 0.1824  data: 0.0001  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1137  Acc@1: 93.7500 (89.0200)  Acc@5: 100.0000 (98.9000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:56  Loss: 1.0378 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.3709  data: 0.1730  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0397 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.2081  data: 0.0159  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0397 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0403 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0403 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0393 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0392 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0398 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0400 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0388 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0397 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0403 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0388 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0388 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0400 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0400 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0405 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0381 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0379 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0393 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0405 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0387 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0373 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Loss: 1.0370 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0370 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0396 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0405 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0394 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0378 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0378 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0386 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0388 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1902  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0391 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1856  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Loss: 1.0391 (1.0395)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:55  Lr: 0.001875  Loss: 0.1582  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.3678  data: 0.1793  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0591  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (97.7273)  time: 0.2032  data: 0.0164  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.1810  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (98.8095)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0288  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (98.3871)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3550  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (98.0183)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.1246  Acc@1: 93.7500 (90.0735)  Acc@5: 100.0000 (98.4069)  time: 0.1861  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0693  Acc@1: 93.7500 (90.1639)  Acc@5: 100.0000 (98.3607)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0405  Acc@1: 93.7500 (90.4049)  Acc@5: 100.0000 (98.5035)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.0566  Acc@1: 87.5000 (90.2778)  Acc@5: 100.0000 (98.5340)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0478  Acc@1: 87.5000 (90.3159)  Acc@5: 100.0000 (98.4203)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0857  Acc@1: 93.7500 (90.2228)  Acc@5: 100.0000 (98.5149)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0245  Acc@1: 93.7500 (90.4279)  Acc@5: 100.0000 (98.6486)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1104  Acc@1: 93.7500 (90.0310)  Acc@5: 100.0000 (98.6570)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0886  Acc@1: 87.5000 (90.0763)  Acc@5: 100.0000 (98.6641)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.4448  Acc@1: 93.7500 (89.9823)  Acc@5: 100.0000 (98.5816)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2449  Acc@1: 87.5000 (89.6109)  Acc@5: 100.0000 (98.5927)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1613  Acc@1: 87.5000 (89.7127)  Acc@5: 100.0000 (98.6413)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1349  Acc@1: 87.5000 (89.6199)  Acc@5: 100.0000 (98.6477)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1312  Acc@1: 87.5000 (89.5718)  Acc@5: 100.0000 (98.6878)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0828  Acc@1: 93.7500 (89.7906)  Acc@5: 100.0000 (98.7238)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1132  Acc@1: 93.7500 (89.8632)  Acc@5: 100.0000 (98.7251)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0656  Acc@1: 93.7500 (90.0474)  Acc@5: 100.0000 (98.7559)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.5233  Acc@1: 87.5000 (89.9887)  Acc@5: 100.0000 (98.7557)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0458  Acc@1: 81.2500 (89.7186)  Acc@5: 100.0000 (98.7284)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3967  Acc@1: 87.5000 (89.6784)  Acc@5: 100.0000 (98.6255)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2993  Acc@1: 87.5000 (89.7410)  Acc@5: 100.0000 (98.6554)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1768  Acc@1: 87.5000 (89.7031)  Acc@5: 100.0000 (98.6590)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1035  Acc@1: 87.5000 (89.5987)  Acc@5: 100.0000 (98.7085)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0697  Acc@1: 87.5000 (89.5018)  Acc@5: 100.0000 (98.7322)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4236  Acc@1: 87.5000 (89.4545)  Acc@5: 100.0000 (98.7328)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.2866  Acc@1: 81.2500 (89.2650)  Acc@5: 100.0000 (98.6711)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2884  Acc@1: 87.5000 (89.2886)  Acc@5: 100.0000 (98.6937)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0821  Acc@1: 87.5000 (89.3400)  Acc@5: 100.0000 (98.7000)  time: 0.1822  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:00:58 (0.1870 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0821  Acc@1: 87.5000 (89.3400)  Acc@5: 100.0000 (98.7000)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:49  Loss: 1.0314 (1.0314)  ASR: 0.0000 (0.0000)  time: 0.3507  data: 0.1527  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0353 (1.0369)  ASR: 0.0000 (0.0000)  time: 0.2072  data: 0.0141  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0359 (1.0361)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0365 (1.0374)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0393 (1.0375)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0375 (1.0376)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0367 (1.0375)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0369 (1.0375)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0381 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0412 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0400 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0396 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0395 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0392 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0385 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0365 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0361 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0382 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0383 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0398 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0398 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0381 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0367 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Loss: 1.0378 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0379 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0392 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0380 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0365 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0366 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0383 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0381 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0386 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0386 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1924 s / it)
Averaged stats: Loss: 1.0386 (1.0384)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:45  Lr: 0.001875  Loss: 0.3608  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.3374  data: 0.1480  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.1670  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.8636)  time: 0.2003  data: 0.0136  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: -0.0724  Acc@1: 93.7500 (91.3690)  Acc@5: 100.0000 (99.1071)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2232  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (98.9919)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1323  Acc@1: 87.5000 (89.9390)  Acc@5: 100.0000 (99.0854)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: -0.0269  Acc@1: 93.7500 (90.0735)  Acc@5: 100.0000 (99.0196)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2138  Acc@1: 93.7500 (90.4713)  Acc@5: 100.0000 (99.1803)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1024  Acc@1: 93.7500 (90.3169)  Acc@5: 100.0000 (99.2958)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.1324  Acc@1: 87.5000 (90.2778)  Acc@5: 100.0000 (99.3056)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0972  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (99.1071)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.0621  Acc@1: 87.5000 (89.9134)  Acc@5: 100.0000 (99.1955)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3776  Acc@1: 87.5000 (89.6396)  Acc@5: 100.0000 (99.2680)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1322  Acc@1: 87.5000 (89.7211)  Acc@5: 100.0000 (99.3285)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3221  Acc@1: 87.5000 (89.2653)  Acc@5: 100.0000 (99.1889)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0973  Acc@1: 81.2500 (89.3174)  Acc@5: 100.0000 (99.2465)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2518  Acc@1: 87.5000 (89.1970)  Acc@5: 100.0000 (99.1722)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.4482  Acc@1: 87.5000 (89.2469)  Acc@5: 100.0000 (99.1460)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.2154  Acc@1: 93.7500 (89.5102)  Acc@5: 100.0000 (99.1228)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0936  Acc@1: 93.7500 (89.5373)  Acc@5: 100.0000 (99.1713)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0755  Acc@1: 87.5000 (89.5615)  Acc@5: 100.0000 (99.1819)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1778  Acc@1: 87.5000 (89.5211)  Acc@5: 100.0000 (99.1915)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2525  Acc@1: 87.5000 (89.5735)  Acc@5: 100.0000 (99.1114)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.3527  Acc@1: 87.5000 (89.5928)  Acc@5: 100.0000 (99.0950)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1668  Acc@1: 93.7500 (89.7186)  Acc@5: 100.0000 (99.1071)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1592  Acc@1: 87.5000 (89.6006)  Acc@5: 100.0000 (99.1442)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0225  Acc@1: 87.5000 (89.6663)  Acc@5: 100.0000 (99.1534)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.1784  Acc@1: 87.5000 (89.7031)  Acc@5: 100.0000 (99.1858)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.2111  Acc@1: 87.5000 (89.8063)  Acc@5: 100.0000 (99.1928)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2929  Acc@1: 87.5000 (89.6797)  Acc@5: 100.0000 (99.1770)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4186  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.2053)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.1341  Acc@1: 87.5000 (89.6595)  Acc@5: 100.0000 (99.1902)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0124  Acc@1: 93.7500 (89.7508)  Acc@5: 100.0000 (99.2162)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3225  Acc@1: 87.5000 (89.7400)  Acc@5: 100.0000 (99.2200)  time: 0.1825  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.3225  Acc@1: 87.5000 (89.7400)  Acc@5: 100.0000 (99.2200)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:54  Loss: 1.0376 (1.0376)  ASR: 0.0000 (0.0000)  time: 0.3668  data: 0.1671  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0418 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.2071  data: 0.0154  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0388 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0351 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0384 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0397 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0369 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0361 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0377 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0382 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0370 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0377 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0378 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0368 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0390 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0359 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0359 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0383 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0370 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0374 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0407 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0402 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0363 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Loss: 1.0366 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0398 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0379 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0362 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0399 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0363 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0363 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0381 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0352 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0363 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1923 s / it)
Averaged stats: Loss: 1.0363 (1.0382)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:17  Loss: 0.5643 (0.5643)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2852  data: 0.1645  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.5643 (0.5663)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (99.4318)  time: 0.1320  data: 0.0152  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.6315 (0.6154)  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (99.4048)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.5114 (0.5851)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (99.3952)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.4985 (0.5697)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.3902)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.4961 (0.5503)  Acc@1: 93.7500 (88.3578)  Acc@5: 100.0000 (99.3873)  time: 0.1167  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4333 (0.5339)  Acc@1: 93.7500 (88.6270)  Acc@5: 100.0000 (99.2828)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4322 (0.5324)  Acc@1: 93.7500 (88.7000)  Acc@5: 100.0000 (99.3000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1193 s / it)
* Acc@1 88.700 Acc@5 99.300 loss 0.532
Test: [Task 1]  [ 0/63]  eta: 0:00:15  ASR: 0.0000 (0.0000)  ACC: 84.6154 (84.6154)  Loss: 1.1653 (1.1653)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.2531  data: 0.1317  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 87.5000 (86.3354)  Loss: 0.9504 (0.9481)  Acc@1: 81.2500 (79.5455)  Acc@5: 93.7500 (92.6136)  time: 0.1309  data: 0.0129  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 87.5000 (86.7110)  Loss: 1.0036 (1.0417)  Acc@1: 81.2500 (78.2738)  Acc@5: 93.7500 (90.7738)  time: 0.1181  data: 0.0006  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 91.6667 (88.1960)  Loss: 1.0036 (0.9936)  Acc@1: 81.2500 (80.4435)  Acc@5: 93.7500 (91.5323)  time: 0.1175  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 87.5000 (88.3643)  Loss: 0.8407 (0.9934)  Acc@1: 81.2500 (80.4878)  Acc@5: 93.7500 (91.3110)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (89.0561)  Loss: 0.9170 (1.0124)  Acc@1: 81.2500 (80.3922)  Acc@5: 93.7500 (90.8088)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (89.2694)  Loss: 0.9170 (0.9874)  Acc@1: 81.2500 (80.7377)  Acc@5: 93.7500 (90.9836)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (89.3096)  Loss: 0.9128 (0.9846)  Acc@1: 81.2500 (80.8000)  Acc@5: 93.7500 (91.0000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1198 s / it)
* Acc@1 80.800 Acc@5 91.000 loss 0.985
* Acc@1 nan ASR 89.310
Test: [Task 2]  [ 0/63]  eta: 0:00:16  Loss: 0.9003 (0.9003)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2627  data: 0.1452  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  Loss: 0.6919 (0.7354)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (97.7273)  time: 0.1297  data: 0.0134  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.7346 (0.7965)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.3214)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:03  Loss: 0.7803 (0.7700)  Acc@1: 81.2500 (84.6774)  Acc@5: 100.0000 (96.9758)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.7178 (0.7558)  Acc@1: 87.5000 (85.2134)  Acc@5: 100.0000 (97.2561)  time: 0.1163  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.6975 (0.7553)  Acc@1: 87.5000 (84.8039)  Acc@5: 100.0000 (97.1814)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6342 (0.7321)  Acc@1: 81.2500 (85.1434)  Acc@5: 100.0000 (97.5410)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6236 (0.7246)  Acc@1: 87.5000 (85.3000)  Acc@5: 100.0000 (97.6000)  time: 0.1135  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1185 s / it)
* Acc@1 85.300 Acc@5 97.600 loss 0.725
Test: [Task 2]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 78.5714 (78.5714)  Loss: 1.3539 (1.3539)  Acc@1: 68.7500 (68.7500)  Acc@5: 81.2500 (81.2500)  time: 0.2829  data: 0.1617  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 85.7143 (87.0748)  Loss: 1.4348 (1.4439)  Acc@1: 75.0000 (73.2955)  Acc@5: 81.2500 (83.5227)  time: 0.1329  data: 0.0150  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (83.1615)  Loss: 1.3544 (1.3583)  Acc@1: 75.0000 (72.3214)  Acc@5: 87.5000 (86.0119)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 81.2500 (83.8269)  Loss: 1.0392 (1.2599)  Acc@1: 75.0000 (74.3952)  Acc@5: 93.7500 (87.2984)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 85.7143 (84.8797)  Loss: 1.0811 (1.2334)  Acc@1: 81.2500 (75.4573)  Acc@5: 87.5000 (87.8049)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (84.3621)  Loss: 1.0811 (1.2017)  Acc@1: 75.0000 (75.4902)  Acc@5: 87.5000 (88.3578)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (84.7206)  Loss: 1.0121 (1.1574)  Acc@1: 81.2500 (76.2295)  Acc@5: 93.7500 (89.1393)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (84.8384)  Loss: 1.0420 (1.1648)  Acc@1: 81.2500 (76.2000)  Acc@5: 93.7500 (89.0000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1203 s / it)
* Acc@1 76.200 Acc@5 89.000 loss 1.165
* Acc@1 nan ASR 84.838
Test: [Task 3]  [ 0/63]  eta: 0:00:17  Loss: 0.3596 (0.3596)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.2833  data: 0.1655  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:06  Loss: 0.5050 (0.5341)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.8636)  time: 0.1316  data: 0.0153  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.5643 (0.5639)  Acc@1: 81.2500 (86.0119)  Acc@5: 100.0000 (97.9167)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  Loss: 0.5801 (0.5749)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (98.3871)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.4840 (0.5545)  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (98.4756)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.5001 (0.5569)  Acc@1: 87.5000 (86.8873)  Acc@5: 100.0000 (98.4069)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5866 (0.5615)  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.4631)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6207 (0.5632)  Acc@1: 87.5000 (86.6000)  Acc@5: 100.0000 (98.5000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 86.600 Acc@5 98.500 loss 0.563
Test: [Task 3]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  ACC: 92.8571 (92.8571)  Loss: 0.7275 (0.7275)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.3030  data: 0.1827  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 85.7143 (85.2564)  Loss: 1.0791 (1.1146)  Acc@1: 75.0000 (76.1364)  Acc@5: 87.5000 (88.6364)  time: 0.1345  data: 0.0168  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 81.2500 (85.5219)  Loss: 0.9900 (1.1213)  Acc@1: 75.0000 (75.8929)  Acc@5: 87.5000 (87.7976)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (84.6154)  Loss: 0.9900 (1.0825)  Acc@1: 75.0000 (75.6048)  Acc@5: 93.7500 (89.3145)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 91.6667 (86.5052)  Loss: 1.0365 (1.0833)  Acc@1: 81.2500 (76.5244)  Acc@5: 93.7500 (88.8720)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 91.6667 (86.5358)  Loss: 1.0875 (1.1210)  Acc@1: 81.2500 (75.8578)  Acc@5: 87.5000 (87.7451)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (86.6040)  Loss: 1.1422 (1.1191)  Acc@1: 75.0000 (75.7172)  Acc@5: 81.2500 (87.8074)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (86.3061)  Loss: 1.1194 (1.1327)  Acc@1: 68.7500 (75.3000)  Acc@5: 81.2500 (87.6000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1205 s / it)
* Acc@1 75.300 Acc@5 87.600 loss 1.133
* Acc@1 nan ASR 86.306
Test: [Task 4]  [ 0/63]  eta: 0:00:18  Loss: 0.8064 (0.8064)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2959  data: 0.1777  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  Loss: 0.6626 (0.6212)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  time: 0.1326  data: 0.0164  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  Loss: 0.5643 (0.6239)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (98.5119)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  Loss: 0.5571 (0.6068)  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (98.3871)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  Loss: 0.3935 (0.5574)  Acc@1: 93.7500 (87.3476)  Acc@5: 100.0000 (98.6280)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  Loss: 0.4500 (0.5796)  Acc@1: 93.7500 (87.3775)  Acc@5: 100.0000 (98.2843)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5175 (0.5920)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (97.9508)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5175 (0.5905)  Acc@1: 87.5000 (87.3000)  Acc@5: 100.0000 (98.0000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 87.300 Acc@5 98.000 loss 0.590
Test: [Task 4]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 1.0298 (1.0298)  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.2870  data: 0.1667  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 86.6667 (87.7301)  Loss: 0.8272 (0.8524)  Acc@1: 81.2500 (83.5227)  Acc@5: 93.7500 (94.3182)  time: 0.1329  data: 0.0153  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (84.7403)  Loss: 0.8577 (0.9606)  Acc@1: 81.2500 (79.1667)  Acc@5: 93.7500 (92.2619)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 83.3333 (85.0112)  Loss: 0.9885 (1.0542)  Acc@1: 75.0000 (78.0242)  Acc@5: 87.5000 (90.5242)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (87.3096)  Loss: 0.9394 (1.0050)  Acc@1: 81.2500 (80.0305)  Acc@5: 93.7500 (90.8537)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.8571 (87.5000)  Loss: 0.9267 (1.0172)  Acc@1: 87.5000 (80.2696)  Acc@5: 93.7500 (90.6863)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (87.0602)  Loss: 0.9737 (1.0151)  Acc@1: 81.2500 (80.1230)  Acc@5: 93.7500 (90.9836)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (87.2506)  Loss: 0.9737 (1.0300)  Acc@1: 81.2500 (80.2000)  Acc@5: 93.7500 (90.9000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1202 s / it)
* Acc@1 80.200 Acc@5 90.900 loss 1.030
* Acc@1 nan ASR 87.251
Test: [Task 5]  [ 0/63]  eta: 0:00:21  Loss: 0.2557 (0.2557)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3478  data: 0.2303  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  Loss: 0.4607 (0.5563)  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.2955)  time: 0.1375  data: 0.0212  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  Loss: 0.4607 (0.5155)  Acc@1: 87.5000 (90.4762)  Acc@5: 100.0000 (98.8095)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  Loss: 0.3956 (0.5087)  Acc@1: 87.5000 (90.7258)  Acc@5: 100.0000 (98.7903)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  Loss: 0.3956 (0.4893)  Acc@1: 93.7500 (90.8537)  Acc@5: 100.0000 (98.9329)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  Loss: 0.4795 (0.4905)  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (99.0196)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.4795 (0.4979)  Acc@1: 87.5000 (90.8811)  Acc@5: 100.0000 (98.7705)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.4959 (0.5097)  Acc@1: 87.5000 (90.4000)  Acc@5: 100.0000 (98.8000)  time: 0.1135  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1199 s / it)
* Acc@1 90.400 Acc@5 98.800 loss 0.510
Test: [Task 5]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 0.5499 (0.5499)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.2664  data: 0.1444  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  ACC: 93.3333 (90.9091)  Loss: 0.9809 (1.1464)  Acc@1: 81.2500 (79.5455)  Acc@5: 87.5000 (86.3636)  time: 0.1314  data: 0.0134  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 92.8571 (91.4191)  Loss: 0.9128 (0.9851)  Acc@1: 81.2500 (82.4405)  Acc@5: 87.5000 (89.2857)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.8571 (91.1308)  Loss: 0.9128 (0.9574)  Acc@1: 81.2500 (82.8629)  Acc@5: 93.7500 (89.9194)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 93.3333 (91.1223)  Loss: 0.9973 (0.9378)  Acc@1: 81.2500 (82.9268)  Acc@5: 93.7500 (90.2439)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (91.3279)  Loss: 0.9973 (0.9791)  Acc@1: 81.2500 (82.5980)  Acc@5: 87.5000 (89.7059)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (91.1765)  Loss: 1.0387 (0.9733)  Acc@1: 81.2500 (82.5820)  Acc@5: 87.5000 (89.5492)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (90.6181)  Loss: 1.0387 (0.9805)  Acc@1: 81.2500 (82.1000)  Acc@5: 87.5000 (89.6000)  time: 0.1151  data: 0.0003  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 82.100 Acc@5 89.600 loss 0.980
* Acc@1 nan ASR 90.618
[Average accuracy till task5]	Acc@1: 78.9200	Acc@5: 89.6200	Loss: 1.0585	Forgetting: 6.0500	Backward: -5.9500
Train: Epoch[1/5]  [  0/313]  eta: 0:01:51  Lr: 0.001875  Loss: 2.1014  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  time: 0.3547  data: 0.1657  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.6138  Acc@1: 43.7500 (51.7045)  Acc@5: 93.7500 (84.6591)  time: 0.2024  data: 0.0153  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.1825  Acc@1: 75.0000 (67.2619)  Acc@5: 100.0000 (90.4762)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.0971  Acc@1: 81.2500 (70.7661)  Acc@5: 100.0000 (92.7419)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.5233  Acc@1: 81.2500 (73.6280)  Acc@5: 100.0000 (93.4451)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.7594  Acc@1: 81.2500 (75.7353)  Acc@5: 100.0000 (93.9951)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.5058  Acc@1: 87.5000 (77.3566)  Acc@5: 100.0000 (94.9795)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3859  Acc@1: 87.5000 (78.3451)  Acc@5: 100.0000 (95.5106)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3002  Acc@1: 87.5000 (79.7068)  Acc@5: 100.0000 (95.9877)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.2495  Acc@1: 87.5000 (80.8379)  Acc@5: 100.0000 (96.4286)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1804  Acc@1: 87.5000 (81.4356)  Acc@5: 100.0000 (96.5347)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2593  Acc@1: 87.5000 (81.8694)  Acc@5: 100.0000 (96.5653)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4575  Acc@1: 87.5000 (82.0764)  Acc@5: 100.0000 (96.6426)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2321  Acc@1: 87.5000 (82.5382)  Acc@5: 100.0000 (96.7557)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.4583  Acc@1: 87.5000 (82.7128)  Acc@5: 100.0000 (96.9415)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1544  Acc@1: 87.5000 (82.7401)  Acc@5: 100.0000 (97.1026)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1009  Acc@1: 87.5000 (82.9193)  Acc@5: 100.0000 (97.2826)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.4023  Acc@1: 81.2500 (82.8582)  Acc@5: 100.0000 (97.4415)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0694  Acc@1: 87.5000 (83.1837)  Acc@5: 100.0000 (97.5483)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2372  Acc@1: 87.5000 (83.4424)  Acc@5: 100.0000 (97.6440)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1652  Acc@1: 87.5000 (83.7065)  Acc@5: 100.0000 (97.7612)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3852  Acc@1: 87.5000 (83.9751)  Acc@5: 100.0000 (97.8377)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0286  Acc@1: 87.5000 (84.1063)  Acc@5: 100.0000 (97.8507)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3345  Acc@1: 87.5000 (84.4156)  Acc@5: 100.0000 (97.8626)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.4758  Acc@1: 93.7500 (84.5436)  Acc@5: 100.0000 (97.9512)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2058  Acc@1: 87.5000 (84.6614)  Acc@5: 100.0000 (97.9582)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.1489  Acc@1: 93.7500 (84.7462)  Acc@5: 100.0000 (97.8927)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.3165  Acc@1: 87.5000 (84.7325)  Acc@5: 100.0000 (97.9474)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.1204  Acc@1: 87.5000 (84.8754)  Acc@5: 100.0000 (98.0205)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0544  Acc@1: 87.5000 (84.8582)  Acc@5: 100.0000 (98.0241)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0689  Acc@1: 81.2500 (84.8214)  Acc@5: 100.0000 (98.0689)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2175  Acc@1: 87.5000 (84.9879)  Acc@5: 100.0000 (98.1310)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0432  Acc@1: 87.5000 (85.0000)  Acc@5: 100.0000 (98.1400)  time: 0.1826  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:00:58 (0.1874 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0432  Acc@1: 87.5000 (85.0000)  Acc@5: 100.0000 (98.1400)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:06  Loss: 1.0622 (1.0622)  ASR: 0.0000 (0.0000)  time: 0.4056  data: 0.2089  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0626 (1.0627)  ASR: 0.0000 (0.0000)  time: 0.2105  data: 0.0191  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0586 (1.0597)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0550 (1.0581)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0532 (1.0566)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0514 (1.0556)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0502 (1.0545)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0485 (1.0540)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0491 (1.0534)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0487 (1.0529)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0005  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0490 (1.0526)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0004  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0490 (1.0522)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0471 (1.0518)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0463 (1.0515)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0474 (1.0512)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0474 (1.0509)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0469 (1.0507)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0466 (1.0505)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0465 (1.0503)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0469 (1.0502)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0469 (1.0500)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0442 (1.0497)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0449 (1.0495)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:16  Loss: 1.0465 (1.0494)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0473 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0456 (1.0491)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0447 (1.0490)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0447 (1.0489)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0455 (1.0488)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0472 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0449 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0446 (1.0485)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0452 (1.0485)  ASR: 0.0000 (0.0000)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1928 s / it)
Averaged stats: Loss: 1.0452 (1.0485)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:49  Lr: 0.001875  Loss: -0.1691  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3498  data: 0.1579  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1799  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  time: 0.2022  data: 0.0146  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.2376  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (98.8095)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0808  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.5887)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.2568  Acc@1: 87.5000 (88.1098)  Acc@5: 100.0000 (98.4756)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.3354  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (98.7745)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0781  Acc@1: 87.5000 (88.1148)  Acc@5: 100.0000 (98.7705)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1224  Acc@1: 87.5000 (87.9401)  Acc@5: 100.0000 (98.6796)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0583  Acc@1: 87.5000 (88.4259)  Acc@5: 100.0000 (98.8426)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.3692  Acc@1: 87.5000 (88.2555)  Acc@5: 100.0000 (98.8324)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0898  Acc@1: 87.5000 (88.6757)  Acc@5: 100.0000 (98.9480)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1030  Acc@1: 93.7500 (88.7950)  Acc@5: 100.0000 (98.9865)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1590  Acc@1: 87.5000 (88.9463)  Acc@5: 100.0000 (99.0186)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2785  Acc@1: 87.5000 (88.9313)  Acc@5: 100.0000 (98.9981)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.2983  Acc@1: 87.5000 (88.8741)  Acc@5: 100.0000 (99.0691)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.1423  Acc@1: 87.5000 (89.0315)  Acc@5: 100.0000 (99.0894)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1816  Acc@1: 87.5000 (88.9752)  Acc@5: 100.0000 (99.0683)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1075  Acc@1: 87.5000 (88.3406)  Acc@5: 100.0000 (99.0132)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2321  Acc@1: 87.5000 (88.5359)  Acc@5: 100.0000 (99.0331)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0834  Acc@1: 87.5000 (88.3835)  Acc@5: 100.0000 (99.0183)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1023  Acc@1: 87.5000 (88.4017)  Acc@5: 100.0000 (99.0672)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3236  Acc@1: 87.5000 (88.1220)  Acc@5: 100.0000 (98.9929)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4035  Acc@1: 87.5000 (88.1787)  Acc@5: 100.0000 (99.0102)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0500  Acc@1: 93.7500 (88.2035)  Acc@5: 100.0000 (98.9989)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0114  Acc@1: 87.5000 (88.2261)  Acc@5: 100.0000 (99.0145)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0711  Acc@1: 93.7500 (88.3217)  Acc@5: 100.0000 (98.9791)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3072  Acc@1: 93.7500 (88.3621)  Acc@5: 100.0000 (99.0182)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2439  Acc@1: 87.5000 (88.3764)  Acc@5: 100.0000 (99.0314)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0770  Acc@1: 87.5000 (88.3897)  Acc@5: 100.0000 (99.0658)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4562  Acc@1: 87.5000 (88.3162)  Acc@5: 100.0000 (99.0335)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0653  Acc@1: 87.5000 (88.2683)  Acc@5: 100.0000 (98.9826)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0310  Acc@1: 87.5000 (88.3842)  Acc@5: 100.0000 (98.9751)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1636  Acc@1: 87.5000 (88.3800)  Acc@5: 100.0000 (98.9600)  time: 0.1823  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1876 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1636  Acc@1: 87.5000 (88.3800)  Acc@5: 100.0000 (98.9600)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:53  Loss: 1.0374 (1.0374)  ASR: 0.0000 (0.0000)  time: 0.3617  data: 0.1630  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0409 (1.0433)  ASR: 0.0000 (0.0000)  time: 0.2074  data: 0.0150  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0435 (1.0438)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0435 (1.0435)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0415 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0419 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0434 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0420 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0420 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0417 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0425 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0433 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0418 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0418 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0443 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0442 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0436 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0434 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0427 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0423 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0433 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0441 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0402 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Loss: 1.0407 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0409 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0412 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0409 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0398 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0400 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0412 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0424 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0424 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0432 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Loss: 1.0432 (1.0426)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:50  Lr: 0.001875  Loss: 0.0556  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3537  data: 0.1649  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1435  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.2017  data: 0.0151  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: -0.0651  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (98.2143)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1623  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.1855)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1631  Acc@1: 93.7500 (89.1768)  Acc@5: 100.0000 (98.4756)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.1647  Acc@1: 93.7500 (89.4608)  Acc@5: 100.0000 (98.7745)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1667  Acc@1: 87.5000 (88.8320)  Acc@5: 100.0000 (98.7705)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: -0.1123  Acc@1: 93.7500 (89.1725)  Acc@5: 100.0000 (98.7676)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.0347  Acc@1: 93.7500 (89.6605)  Acc@5: 100.0000 (98.9198)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0556  Acc@1: 87.5000 (89.4231)  Acc@5: 100.0000 (98.9698)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0121  Acc@1: 87.5000 (88.9233)  Acc@5: 100.0000 (98.9480)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1559  Acc@1: 81.2500 (88.3446)  Acc@5: 100.0000 (98.9865)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.0137  Acc@1: 81.2500 (87.8616)  Acc@5: 100.0000 (98.8636)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1955  Acc@1: 81.2500 (87.7385)  Acc@5: 100.0000 (98.8550)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.5281  Acc@1: 87.5000 (87.6330)  Acc@5: 100.0000 (98.8475)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1287  Acc@1: 93.7500 (87.9139)  Acc@5: 100.0000 (98.9238)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2544  Acc@1: 87.5000 (87.7329)  Acc@5: 100.0000 (98.9130)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0134  Acc@1: 87.5000 (88.0848)  Acc@5: 100.0000 (98.9766)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.3524  Acc@1: 93.7500 (88.1215)  Acc@5: 100.0000 (99.0331)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3059  Acc@1: 87.5000 (88.2199)  Acc@5: 100.0000 (99.0838)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2586  Acc@1: 93.7500 (88.3706)  Acc@5: 100.0000 (99.0983)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0606  Acc@1: 93.7500 (88.3886)  Acc@5: 100.0000 (99.1114)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1162  Acc@1: 87.5000 (88.3767)  Acc@5: 100.0000 (99.1233)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1313  Acc@1: 87.5000 (88.5281)  Acc@5: 100.0000 (99.1613)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.4077  Acc@1: 87.5000 (88.6411)  Acc@5: 100.0000 (99.1701)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0931  Acc@1: 87.5000 (88.5458)  Acc@5: 100.0000 (99.1783)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3278  Acc@1: 87.5000 (88.5297)  Acc@5: 100.0000 (99.1140)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0684  Acc@1: 87.5000 (88.5378)  Acc@5: 100.0000 (99.1006)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.2861  Acc@1: 87.5000 (88.5454)  Acc@5: 100.0000 (99.1103)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3125  Acc@1: 87.5000 (88.4450)  Acc@5: 100.0000 (99.0979)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1410  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (99.1279)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0558  Acc@1: 87.5000 (88.3039)  Acc@5: 100.0000 (99.1559)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.8048  Acc@1: 87.5000 (88.2400)  Acc@5: 100.0000 (99.1600)  time: 0.1823  data: 0.0001  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.8048  Acc@1: 87.5000 (88.2400)  Acc@5: 100.0000 (99.1600)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:55  Loss: 1.0465 (1.0465)  ASR: 0.0000 (0.0000)  time: 0.3705  data: 0.1703  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0436 (1.0439)  ASR: 0.0000 (0.0000)  time: 0.2075  data: 0.0157  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0432 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0401 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0401 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0384 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0375 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0404 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1903  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0404 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1903  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0404 (1.0415)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0416 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0398 (1.0415)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0388 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0396 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0414 (1.0415)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0414 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0406 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0405 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0372 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0385 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0406 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0386 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0384 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Loss: 1.0391 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0394 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0405 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0398 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0397 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0402 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0431 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0004  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0401 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0004  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0400 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0401 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Loss: 1.0401 (1.0409)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:46  Lr: 0.001875  Loss: 0.0185  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3393  data: 0.1508  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.2698  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (99.4318)  time: 0.2007  data: 0.0139  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.3624  Acc@1: 87.5000 (91.0714)  Acc@5: 100.0000 (99.1071)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4437  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (98.9919)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1152  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (98.7805)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.1459  Acc@1: 87.5000 (89.0931)  Acc@5: 100.0000 (98.8971)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.3431  Acc@1: 87.5000 (89.1393)  Acc@5: 100.0000 (98.8730)  time: 0.1861  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: -0.0464  Acc@1: 93.7500 (89.4366)  Acc@5: 100.0000 (99.0317)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.0813  Acc@1: 93.7500 (89.8148)  Acc@5: 100.0000 (99.0741)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:41  Lr: 0.001875  Loss: -0.0273  Acc@1: 93.7500 (90.1099)  Acc@5: 100.0000 (99.1758)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.0843  Acc@1: 93.7500 (90.0371)  Acc@5: 100.0000 (99.1955)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1186  Acc@1: 93.7500 (90.3716)  Acc@5: 100.0000 (99.2680)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1747  Acc@1: 93.7500 (90.1343)  Acc@5: 100.0000 (99.3285)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1422  Acc@1: 87.5000 (90.0286)  Acc@5: 100.0000 (99.3321)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1966  Acc@1: 87.5000 (89.8050)  Acc@5: 100.0000 (99.2908)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1690  Acc@1: 87.5000 (89.9834)  Acc@5: 100.0000 (99.3377)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3946  Acc@1: 87.5000 (89.9457)  Acc@5: 100.0000 (99.3012)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0272  Acc@1: 87.5000 (89.6564)  Acc@5: 100.0000 (99.3056)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1644  Acc@1: 81.2500 (89.6064)  Acc@5: 100.0000 (99.3439)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1076  Acc@1: 87.5000 (89.5288)  Acc@5: 100.0000 (99.3128)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1771  Acc@1: 87.5000 (89.5211)  Acc@5: 100.0000 (99.3470)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.5349  Acc@1: 93.7500 (89.6031)  Acc@5: 100.0000 (99.3483)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0037  Acc@1: 93.7500 (89.6493)  Acc@5: 100.0000 (99.3778)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1681  Acc@1: 87.5000 (89.5563)  Acc@5: 100.0000 (99.4048)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0251  Acc@1: 87.5000 (89.4969)  Acc@5: 100.0000 (99.4035)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1013  Acc@1: 87.5000 (89.3675)  Acc@5: 100.0000 (99.4273)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0671  Acc@1: 87.5000 (89.3678)  Acc@5: 100.0000 (99.4492)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0303  Acc@1: 87.5000 (89.2066)  Acc@5: 100.0000 (99.4234)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0665  Acc@1: 87.5000 (89.3461)  Acc@5: 100.0000 (99.4217)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0196  Acc@1: 93.7500 (89.3041)  Acc@5: 100.0000 (99.4201)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.1568  Acc@1: 87.5000 (89.3688)  Acc@5: 100.0000 (99.4186)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0449  Acc@1: 87.5000 (89.4293)  Acc@5: 100.0000 (99.3971)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0066  Acc@1: 87.5000 (89.4400)  Acc@5: 100.0000 (99.4000)  time: 0.1828  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0066  Acc@1: 87.5000 (89.4400)  Acc@5: 100.0000 (99.4000)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:01  Loss: 1.0332 (1.0332)  ASR: 0.0000 (0.0000)  time: 0.3868  data: 0.1872  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0393 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.2096  data: 0.0172  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0393 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0394 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0397 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0368 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0407 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0401 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0376 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0392 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0392 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0385 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0393 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0393 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0387 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0403 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0380 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0377 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0375 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0377 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0381 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0380 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0368 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Loss: 1.0368 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0004  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0379 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0004  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0390 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0383 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0376 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0397 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0394 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0374 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0370 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0370 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1884  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1925 s / it)
Averaged stats: Loss: 1.0370 (1.0391)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:57  Lr: 0.001875  Loss: 0.3759  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.3759  data: 0.1871  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0738  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (99.4318)  time: 0.2039  data: 0.0171  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.3842  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (99.7024)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.1211  Acc@1: 93.7500 (89.9194)  Acc@5: 100.0000 (99.5968)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3132  Acc@1: 87.5000 (90.0915)  Acc@5: 100.0000 (99.5427)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.0262  Acc@1: 87.5000 (89.8284)  Acc@5: 100.0000 (99.2647)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.0923  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (99.2828)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.0343  Acc@1: 87.5000 (89.5246)  Acc@5: 100.0000 (99.2958)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.0134  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (99.3056)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0206  Acc@1: 93.7500 (89.9038)  Acc@5: 100.0000 (99.3819)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0736  Acc@1: 93.7500 (90.0990)  Acc@5: 100.0000 (99.3812)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.4512  Acc@1: 87.5000 (89.7523)  Acc@5: 100.0000 (99.3243)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1965  Acc@1: 87.5000 (89.4112)  Acc@5: 100.0000 (99.2252)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3669  Acc@1: 87.5000 (89.3130)  Acc@5: 100.0000 (99.2844)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.1305  Acc@1: 87.5000 (89.2287)  Acc@5: 100.0000 (99.2465)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0493  Acc@1: 93.7500 (89.1970)  Acc@5: 100.0000 (99.0894)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0747  Acc@1: 87.5000 (89.0916)  Acc@5: 100.0000 (99.1071)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0219  Acc@1: 87.5000 (89.2178)  Acc@5: 100.0000 (99.1228)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2916  Acc@1: 87.5000 (89.1229)  Acc@5: 100.0000 (99.0331)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0660  Acc@1: 93.7500 (89.2997)  Acc@5: 100.0000 (99.0838)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2216  Acc@1: 87.5000 (89.3035)  Acc@5: 100.0000 (99.0983)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2684  Acc@1: 87.5000 (89.4846)  Acc@5: 100.0000 (99.1410)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0994  Acc@1: 93.7500 (89.4796)  Acc@5: 100.0000 (99.1516)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0394  Acc@1: 93.7500 (89.5563)  Acc@5: 100.0000 (99.1613)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1284  Acc@1: 87.5000 (89.4450)  Acc@5: 100.0000 (99.1701)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1662  Acc@1: 87.5000 (89.5169)  Acc@5: 100.0000 (99.1534)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0100  Acc@1: 93.7500 (89.5354)  Acc@5: 100.0000 (99.1619)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1484  Acc@1: 87.5000 (89.5065)  Acc@5: 100.0000 (99.1928)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.1261  Acc@1: 87.5000 (89.3238)  Acc@5: 100.0000 (99.1993)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2191  Acc@1: 87.5000 (89.3686)  Acc@5: 100.0000 (99.2053)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0139  Acc@1: 87.5000 (89.3688)  Acc@5: 100.0000 (99.2317)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0063  Acc@1: 93.7500 (89.4293)  Acc@5: 100.0000 (99.2363)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7474  Acc@1: 93.7500 (89.4200)  Acc@5: 100.0000 (99.2400)  time: 0.1826  data: 0.0001  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1874 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7474  Acc@1: 93.7500 (89.4200)  Acc@5: 100.0000 (99.2400)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:11  Loss: 1.0393 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.4198  data: 0.2204  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0388 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.2135  data: 0.0203  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0394 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0392 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0366 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0379 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0400 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0389 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0392 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0386 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0374 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0380 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0382 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0363 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0385 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0380 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0373 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0377 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0391 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0389 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0400 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0401 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0370 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:16  Loss: 1.0363 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0363 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0389 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0383 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0376 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0384 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0394 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0374 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0378 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0386 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1927 s / it)
Averaged stats: Loss: 1.0386 (1.0389)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:16  Loss: 0.6289 (0.6289)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2664  data: 0.1479  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.6165 (0.5851)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (98.8636)  time: 0.1301  data: 0.0137  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.6165 (0.6319)  Acc@1: 81.2500 (84.2262)  Acc@5: 100.0000 (98.8095)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.5614 (0.5982)  Acc@1: 81.2500 (85.8871)  Acc@5: 100.0000 (98.9919)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.4784 (0.5766)  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (99.2378)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.4742 (0.5576)  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (99.3873)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4558 (0.5399)  Acc@1: 93.7500 (88.1148)  Acc@5: 100.0000 (99.3852)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4293 (0.5361)  Acc@1: 93.7500 (88.2000)  Acc@5: 100.0000 (99.4000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1188 s / it)
* Acc@1 88.200 Acc@5 99.400 loss 0.536
Test: [Task 1]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 83.3333 (83.3333)  Loss: 1.1800 (1.1800)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  time: 0.2991  data: 0.1786  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 86.6667 (84.6154)  Loss: 1.1221 (1.0477)  Acc@1: 75.0000 (75.5682)  Acc@5: 93.7500 (89.2045)  time: 0.1341  data: 0.0164  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (84.8993)  Loss: 1.1221 (1.0804)  Acc@1: 75.0000 (75.5952)  Acc@5: 87.5000 (88.6905)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (86.2921)  Loss: 1.0330 (1.0250)  Acc@1: 75.0000 (77.6210)  Acc@5: 87.5000 (89.7177)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 87.5000 (86.8908)  Loss: 0.6358 (0.9598)  Acc@1: 87.5000 (79.1159)  Acc@5: 93.7500 (91.1585)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (87.6526)  Loss: 0.7239 (0.9587)  Acc@1: 87.5000 (79.4118)  Acc@5: 93.7500 (90.9314)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (88.3352)  Loss: 0.8028 (0.9361)  Acc@1: 87.5000 (80.2254)  Acc@5: 93.7500 (91.2910)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (88.4701)  Loss: 0.8028 (0.9501)  Acc@1: 87.5000 (80.1000)  Acc@5: 93.7500 (91.0000)  time: 0.1146  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1203 s / it)
* Acc@1 80.100 Acc@5 91.000 loss 0.950
* Acc@1 nan ASR 88.470
Test: [Task 2]  [ 0/63]  eta: 0:00:17  Loss: 0.8760 (0.8760)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2798  data: 0.1611  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  Loss: 0.6611 (0.7237)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (97.7273)  time: 0.1311  data: 0.0149  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.6937 (0.7852)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.0238)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.8024 (0.7806)  Acc@1: 75.0000 (82.2581)  Acc@5: 100.0000 (96.7742)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.6906 (0.7615)  Acc@1: 81.2500 (83.3841)  Acc@5: 100.0000 (96.7988)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.7126 (0.7607)  Acc@1: 81.2500 (83.5784)  Acc@5: 100.0000 (96.8137)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6419 (0.7352)  Acc@1: 87.5000 (84.2213)  Acc@5: 100.0000 (97.0287)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.5601 (0.7277)  Acc@1: 87.5000 (84.3000)  Acc@5: 100.0000 (97.1000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1188 s / it)
* Acc@1 84.300 Acc@5 97.100 loss 0.728
Test: [Task 2]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 0.8430 (0.8430)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2740  data: 0.1523  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 86.6667 (85.7143)  Loss: 0.8696 (1.1025)  Acc@1: 81.2500 (78.4091)  Acc@5: 87.5000 (89.7727)  time: 0.1320  data: 0.0141  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 83.3333 (82.4675)  Loss: 1.0263 (1.1669)  Acc@1: 68.7500 (75.5952)  Acc@5: 87.5000 (88.9881)  time: 0.1182  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 76.9231 (81.8584)  Loss: 1.2133 (1.1747)  Acc@1: 68.7500 (74.5968)  Acc@5: 87.5000 (88.3065)  time: 0.1182  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 84.6154 (83.3052)  Loss: 1.1229 (1.1757)  Acc@1: 75.0000 (75.4573)  Acc@5: 87.5000 (87.9573)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 84.6154 (83.4912)  Loss: 1.0148 (1.1522)  Acc@1: 75.0000 (75.7353)  Acc@5: 93.7500 (88.2353)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (84.1686)  Loss: 0.9810 (1.1538)  Acc@1: 81.2500 (75.8197)  Acc@5: 87.5000 (87.7049)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (84.2047)  Loss: 1.1430 (1.1451)  Acc@1: 81.2500 (75.8000)  Acc@5: 87.5000 (87.7000)  time: 0.1149  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1203 s / it)
* Acc@1 75.800 Acc@5 87.700 loss 1.145
* Acc@1 nan ASR 84.205
Test: [Task 3]  [ 0/63]  eta: 0:00:17  Loss: 0.2333 (0.2333)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.2832  data: 0.1664  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:06  Loss: 0.5371 (0.5817)  Acc@1: 87.5000 (85.7955)  Acc@5: 93.7500 (96.5909)  time: 0.1315  data: 0.0153  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.5991 (0.5887)  Acc@1: 87.5000 (85.7143)  Acc@5: 93.7500 (97.0238)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  Loss: 0.6050 (0.6098)  Acc@1: 81.2500 (84.8790)  Acc@5: 100.0000 (97.1774)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.5670 (0.5895)  Acc@1: 87.5000 (85.9756)  Acc@5: 100.0000 (97.7134)  time: 0.1162  data: 0.0002  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.5227 (0.5969)  Acc@1: 87.5000 (86.3971)  Acc@5: 100.0000 (97.6716)  time: 0.1162  data: 0.0001  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.5853 (0.6055)  Acc@1: 87.5000 (86.5779)  Acc@5: 100.0000 (97.8484)  time: 0.1162  data: 0.0001  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.5924 (0.6091)  Acc@1: 87.5000 (86.3000)  Acc@5: 100.0000 (97.8000)  time: 0.1134  data: 0.0001  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1188 s / it)
* Acc@1 86.300 Acc@5 97.800 loss 0.609
Test: [Task 3]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  ACC: 92.8571 (92.8571)  Loss: 0.8007 (0.8007)  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.3333  data: 0.2132  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 83.3333 (83.8710)  Loss: 0.9954 (1.0938)  Acc@1: 75.0000 (74.4318)  Acc@5: 87.5000 (87.5000)  time: 0.1372  data: 0.0196  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (85.0498)  Loss: 0.9954 (1.0513)  Acc@1: 75.0000 (76.4881)  Acc@5: 87.5000 (88.6905)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (84.3400)  Loss: 1.0291 (1.0501)  Acc@1: 75.0000 (76.2097)  Acc@5: 93.7500 (89.3145)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 87.5000 (85.5705)  Loss: 1.0065 (1.0016)  Acc@1: 81.2500 (77.8963)  Acc@5: 93.7500 (90.2439)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 87.5000 (86.4065)  Loss: 0.7156 (0.9915)  Acc@1: 81.2500 (78.7990)  Acc@5: 93.7500 (90.3186)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (86.4198)  Loss: 1.0369 (0.9851)  Acc@1: 81.2500 (78.9959)  Acc@5: 93.7500 (90.7787)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (86.3089)  Loss: 1.0702 (0.9858)  Acc@1: 81.2500 (78.9000)  Acc@5: 87.5000 (90.8000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1208 s / it)
* Acc@1 78.900 Acc@5 90.800 loss 0.986
* Acc@1 nan ASR 86.309
Test: [Task 4]  [ 0/63]  eta: 0:00:17  Loss: 0.7955 (0.7955)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2782  data: 0.1611  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:06  Loss: 0.7146 (0.6684)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.7273)  time: 0.1312  data: 0.0149  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  Loss: 0.6348 (0.6676)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (97.3214)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  Loss: 0.5628 (0.6262)  Acc@1: 87.5000 (83.4677)  Acc@5: 100.0000 (97.5806)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  Loss: 0.4181 (0.5741)  Acc@1: 87.5000 (85.8232)  Acc@5: 100.0000 (98.0183)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  Loss: 0.4241 (0.5902)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (97.9167)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5730 (0.5974)  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (97.5410)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.5730 (0.5989)  Acc@1: 87.5000 (86.4000)  Acc@5: 100.0000 (97.6000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 86.400 Acc@5 97.600 loss 0.599
Test: [Task 4]  [ 0/63]  eta: 0:00:24  ASR: 0.0000 (0.0000)  ACC: 78.5714 (78.5714)  Loss: 1.1543 (1.1543)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.3892  data: 0.2657  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 81.2500 (83.7500)  Loss: 1.1543 (1.0918)  Acc@1: 75.0000 (76.7045)  Acc@5: 87.5000 (89.2045)  time: 0.1423  data: 0.0244  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (83.4984)  Loss: 1.0403 (1.0688)  Acc@1: 81.2500 (76.4881)  Acc@5: 87.5000 (89.2857)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (84.9890)  Loss: 0.9030 (0.9739)  Acc@1: 81.2500 (78.6290)  Acc@5: 93.7500 (90.9274)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.3077 (86.7672)  Loss: 0.6605 (0.9560)  Acc@1: 87.5000 (80.0305)  Acc@5: 93.7500 (91.0061)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (86.9799)  Loss: 0.8208 (0.9490)  Acc@1: 81.2500 (80.5147)  Acc@5: 93.7500 (91.4216)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (87.0932)  Loss: 0.9623 (0.9626)  Acc@1: 81.2500 (80.4303)  Acc@5: 87.5000 (90.8811)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (87.1711)  Loss: 1.0672 (0.9784)  Acc@1: 81.2500 (80.4000)  Acc@5: 87.5000 (90.8000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1218 s / it)
* Acc@1 80.400 Acc@5 90.800 loss 0.978
* Acc@1 nan ASR 87.171
Test: [Task 5]  [ 0/63]  eta: 0:00:18  Loss: 0.2582 (0.2582)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3001  data: 0.1781  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  Loss: 0.4726 (0.5569)  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (99.4318)  time: 0.1333  data: 0.0165  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  Loss: 0.4726 (0.5153)  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (99.4048)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  Loss: 0.4333 (0.5121)  Acc@1: 93.7500 (91.5323)  Acc@5: 100.0000 (98.9919)  time: 0.1166  data: 0.0002  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  Loss: 0.4254 (0.4967)  Acc@1: 93.7500 (91.7683)  Acc@5: 100.0000 (98.9329)  time: 0.1166  data: 0.0002  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  Loss: 0.4642 (0.5051)  Acc@1: 93.7500 (91.7892)  Acc@5: 100.0000 (98.7745)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5053 (0.5138)  Acc@1: 87.5000 (91.2910)  Acc@5: 100.0000 (98.6680)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5201 (0.5285)  Acc@1: 87.5000 (90.8000)  Acc@5: 100.0000 (98.7000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1192 s / it)
* Acc@1 90.800 Acc@5 98.700 loss 0.528
Test: [Task 5]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 1.3518 (1.3518)  Acc@1: 81.2500 (81.2500)  Acc@5: 81.2500 (81.2500)  time: 0.2950  data: 0.1748  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 87.5000 (91.0828)  Loss: 1.1318 (1.0321)  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (90.3409)  time: 0.1341  data: 0.0162  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 93.3333 (92.1824)  Loss: 0.8036 (0.9090)  Acc@1: 87.5000 (84.2262)  Acc@5: 93.7500 (91.6667)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 93.3333 (91.5743)  Loss: 0.7821 (0.9297)  Acc@1: 87.5000 (83.2661)  Acc@5: 87.5000 (90.5242)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (91.8919)  Loss: 0.9767 (0.9474)  Acc@1: 81.2500 (82.9268)  Acc@5: 87.5000 (89.6341)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 93.3333 (91.9289)  Loss: 1.0513 (0.9901)  Acc@1: 81.2500 (82.3529)  Acc@5: 87.5000 (88.8480)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (91.3242)  Loss: 1.1230 (0.9919)  Acc@1: 75.0000 (81.9672)  Acc@5: 87.5000 (88.9344)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (90.7572)  Loss: 1.1230 (1.0020)  Acc@1: 75.0000 (81.5000)  Acc@5: 87.5000 (89.0000)  time: 0.1150  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1205 s / it)
* Acc@1 81.500 Acc@5 89.000 loss 1.002
* Acc@1 nan ASR 90.757
Test: [Task 6]  [ 0/63]  eta: 0:00:17  Loss: 0.3231 (0.3231)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.2828  data: 0.1656  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:06  Loss: 0.5526 (0.4842)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  time: 0.1315  data: 0.0153  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  Loss: 0.5526 (0.5349)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.8095)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  Loss: 0.5426 (0.5312)  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (99.1935)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  Loss: 0.5570 (0.5628)  Acc@1: 81.2500 (84.2988)  Acc@5: 100.0000 (98.9329)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  Loss: 0.6101 (0.5562)  Acc@1: 81.2500 (84.9265)  Acc@5: 100.0000 (99.1422)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.6101 (0.5756)  Acc@1: 81.2500 (84.8361)  Acc@5: 100.0000 (98.8730)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.5379 (0.5715)  Acc@1: 81.2500 (85.0000)  Acc@5: 100.0000 (98.9000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 85.000 Acc@5 98.900 loss 0.571
Test: [Task 6]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 0.7173 (0.7173)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2881  data: 0.1684  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.0760)  Loss: 0.9978 (1.0588)  Acc@1: 81.2500 (77.2727)  Acc@5: 87.5000 (88.0682)  time: 0.1332  data: 0.0156  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (85.3333)  Loss: 0.9978 (1.0989)  Acc@1: 75.0000 (76.1905)  Acc@5: 87.5000 (88.0952)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 84.6154 (84.3537)  Loss: 1.0355 (1.1131)  Acc@1: 68.7500 (75.0000)  Acc@5: 87.5000 (88.1048)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 84.6154 (84.0206)  Loss: 1.1713 (1.1487)  Acc@1: 68.7500 (74.5427)  Acc@5: 87.5000 (87.6524)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: 0.0000 (nan)  ACC: 85.7143 (84.6897)  Loss: 1.2376 (1.1360)  Acc@1: 75.0000 (75.2451)  Acc@5: 87.5000 (87.9902)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: 0.0000 (nan)  ACC: 85.7143 (84.8555)  Loss: 1.1855 (1.1571)  Acc@1: 75.0000 (75.2049)  Acc@5: 87.5000 (87.6025)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (85.0394)  Loss: 1.1647 (1.1346)  Acc@1: 75.0000 (75.6000)  Acc@5: 87.5000 (87.9000)  time: 0.1150  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1206 s / it)
* Acc@1 75.600 Acc@5 87.900 loss 1.135
* Acc@1 nan ASR 85.039
[Average accuracy till task6]	Acc@1: 78.7167	Acc@5: 89.5333	Loss: 1.0327	Forgetting: 4.4600	Backward: -4.3400
Train: Epoch[1/5]  [  0/313]  eta: 0:01:48  Lr: 0.001875  Loss: 2.1246  Acc@1: 0.0000 (0.0000)  Acc@5: 12.5000 (12.5000)  time: 0.3473  data: 0.1586  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 1.6818  Acc@1: 56.2500 (50.5682)  Acc@5: 87.5000 (80.6818)  time: 0.2012  data: 0.0146  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 1.4692  Acc@1: 68.7500 (63.6905)  Acc@5: 93.7500 (87.7976)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.2023  Acc@1: 75.0000 (68.7500)  Acc@5: 100.0000 (90.5242)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.6227  Acc@1: 81.2500 (71.9512)  Acc@5: 100.0000 (91.9207)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.9821  Acc@1: 81.2500 (73.2843)  Acc@5: 100.0000 (93.2598)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7203  Acc@1: 81.2500 (75.5123)  Acc@5: 100.0000 (94.1598)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.4010  Acc@1: 87.5000 (76.5845)  Acc@5: 100.0000 (94.8063)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.2942  Acc@1: 87.5000 (77.3148)  Acc@5: 100.0000 (95.1389)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1775  Acc@1: 87.5000 (78.3654)  Acc@5: 100.0000 (95.6044)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2584  Acc@1: 87.5000 (79.0842)  Acc@5: 100.0000 (95.7921)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.6009  Acc@1: 87.5000 (79.7297)  Acc@5: 100.0000 (96.1149)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1612  Acc@1: 87.5000 (80.2169)  Acc@5: 100.0000 (96.0744)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.3464  Acc@1: 81.2500 (80.2481)  Acc@5: 100.0000 (96.2786)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.4677  Acc@1: 81.2500 (80.7624)  Acc@5: 100.0000 (96.4982)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3563  Acc@1: 87.5000 (81.2086)  Acc@5: 100.0000 (96.6887)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1896  Acc@1: 87.5000 (81.4829)  Acc@5: 100.0000 (96.7391)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2246  Acc@1: 87.5000 (81.6886)  Acc@5: 100.0000 (96.8567)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2368  Acc@1: 87.5000 (81.6989)  Acc@5: 100.0000 (96.9959)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0806  Acc@1: 87.5000 (81.9699)  Acc@5: 100.0000 (97.1204)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1465  Acc@1: 87.5000 (82.2450)  Acc@5: 100.0000 (97.2015)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2846  Acc@1: 81.2500 (82.1979)  Acc@5: 100.0000 (97.2749)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2806  Acc@1: 81.2500 (82.3529)  Acc@5: 100.0000 (97.2568)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.4344  Acc@1: 87.5000 (82.6299)  Acc@5: 100.0000 (97.2944)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.5817  Acc@1: 87.5000 (82.6763)  Acc@5: 100.0000 (97.3548)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0849  Acc@1: 87.5000 (82.7689)  Acc@5: 100.0000 (97.4104)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2265  Acc@1: 87.5000 (82.9023)  Acc@5: 100.0000 (97.3659)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1435  Acc@1: 87.5000 (83.0028)  Acc@5: 93.7500 (97.3478)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.3492  Acc@1: 87.5000 (82.9404)  Acc@5: 100.0000 (97.3754)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3007  Acc@1: 81.2500 (83.0541)  Acc@5: 100.0000 (97.4227)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0512  Acc@1: 87.5000 (83.1811)  Acc@5: 100.0000 (97.4460)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1327  Acc@1: 87.5000 (83.3802)  Acc@5: 100.0000 (97.4277)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0056  Acc@1: 87.5000 (83.4600)  Acc@5: 100.0000 (97.4400)  time: 0.1822  data: 0.0001  max mem: 2386
Train: Epoch[1/5] Total time: 0:00:58 (0.1871 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0056  Acc@1: 87.5000 (83.4600)  Acc@5: 100.0000 (97.4400)
Train: Epoch[1/5]  [  0/313]  eta: 0:01:51  Loss: 1.0683 (1.0683)  ASR: 0.0000 (0.0000)  time: 0.3569  data: 0.1603  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0633 (1.0632)  ASR: 0.0000 (0.0000)  time: 0.2061  data: 0.0148  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0581 (1.0598)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0554 (1.0582)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0534 (1.0567)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0515 (1.0554)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0494 (1.0545)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0491 (1.0539)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0490 (1.0532)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0490 (1.0527)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0480 (1.0523)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0473 (1.0518)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0454 (1.0513)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0456 (1.0509)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0453 (1.0505)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0453 (1.0502)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0453 (1.0499)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0447 (1.0496)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0452 (1.0494)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0453 (1.0492)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0459 (1.0490)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0440 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0440 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Loss: 1.0440 (1.0484)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0435 (1.0482)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0441 (1.0481)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0431 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0437 (1.0478)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0444 (1.0477)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0442 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0442 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0431 (1.0473)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0428 (1.0473)  ASR: 0.0000 (0.0000)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1923 s / it)
Averaged stats: Loss: 1.0428 (1.0473)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:51  Lr: 0.001875  Loss: 0.2498  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.3561  data: 0.1681  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1329  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.1591)  time: 0.2019  data: 0.0154  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.4062  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (97.9167)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1244  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (98.3871)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.4888  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.6280)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.4132  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (98.7745)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0692  Acc@1: 93.7500 (88.1148)  Acc@5: 100.0000 (98.8730)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2112  Acc@1: 93.7500 (88.7324)  Acc@5: 100.0000 (99.0317)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4871  Acc@1: 93.7500 (88.3488)  Acc@5: 100.0000 (98.9969)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1125  Acc@1: 87.5000 (88.1868)  Acc@5: 100.0000 (98.9698)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3611  Acc@1: 87.5000 (87.9950)  Acc@5: 100.0000 (98.9480)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0707  Acc@1: 87.5000 (88.0631)  Acc@5: 100.0000 (99.0428)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1124  Acc@1: 87.5000 (88.0165)  Acc@5: 100.0000 (99.0186)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1626  Acc@1: 87.5000 (87.9771)  Acc@5: 100.0000 (99.0458)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.7295  Acc@1: 87.5000 (87.9433)  Acc@5: 100.0000 (99.0691)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.4836  Acc@1: 87.5000 (88.0795)  Acc@5: 100.0000 (99.0066)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3405  Acc@1: 87.5000 (87.8882)  Acc@5: 100.0000 (98.9907)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1729  Acc@1: 87.5000 (87.8655)  Acc@5: 100.0000 (99.0497)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1513  Acc@1: 87.5000 (87.5691)  Acc@5: 100.0000 (98.9986)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0070  Acc@1: 87.5000 (87.7291)  Acc@5: 100.0000 (99.0510)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0714  Acc@1: 87.5000 (87.7799)  Acc@5: 100.0000 (99.0983)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.1058  Acc@1: 87.5000 (87.9147)  Acc@5: 100.0000 (99.1410)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0470  Acc@1: 87.5000 (87.9242)  Acc@5: 100.0000 (99.1516)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0455  Acc@1: 87.5000 (87.8247)  Acc@5: 100.0000 (99.1613)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0823  Acc@1: 87.5000 (87.7075)  Acc@5: 100.0000 (99.1701)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2235  Acc@1: 87.5000 (87.5996)  Acc@5: 100.0000 (99.1534)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1188  Acc@1: 81.2500 (87.3084)  Acc@5: 100.0000 (99.0900)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0333  Acc@1: 87.5000 (87.3155)  Acc@5: 100.0000 (99.0775)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1953  Acc@1: 87.5000 (87.3443)  Acc@5: 100.0000 (99.0658)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0493  Acc@1: 87.5000 (87.4785)  Acc@5: 100.0000 (99.0979)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0190  Acc@1: 87.5000 (87.4585)  Acc@5: 100.0000 (99.0656)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2625  Acc@1: 87.5000 (87.4799)  Acc@5: 100.0000 (99.0756)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1778  Acc@1: 87.5000 (87.5400)  Acc@5: 100.0000 (99.0800)  time: 0.1823  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1778  Acc@1: 87.5000 (87.5400)  Acc@5: 100.0000 (99.0800)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:43  Loss: 1.0449 (1.0449)  ASR: 0.0000 (0.0000)  time: 0.3318  data: 0.1338  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Loss: 1.0423 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.2035  data: 0.0123  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0411 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0404 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0415 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0415 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0411 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0402 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0411 (1.0420)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0424 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0405 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0408 (1.0417)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0404 (1.0415)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0385 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0400 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0406 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0406 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0405 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0405 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0407 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0406 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0392 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0392 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Loss: 1.0392 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0395 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0402 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0392 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0392 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0409 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0409 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0412 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0406 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0406 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:01:00 (0.1925 s / it)
Averaged stats: Loss: 1.0406 (1.0409)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:48  Lr: 0.001875  Loss: 0.1379  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3470  data: 0.1587  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.3434  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.2012  data: 0.0146  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.1083  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8095)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2660  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (98.9919)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.5055  Acc@1: 87.5000 (87.1951)  Acc@5: 100.0000 (99.2378)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.0492  Acc@1: 87.5000 (87.1324)  Acc@5: 100.0000 (99.3873)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2705  Acc@1: 87.5000 (87.6025)  Acc@5: 100.0000 (99.3852)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0239  Acc@1: 87.5000 (87.6761)  Acc@5: 100.0000 (99.2077)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.0695  Acc@1: 87.5000 (88.1173)  Acc@5: 100.0000 (99.1512)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.6082  Acc@1: 87.5000 (87.9121)  Acc@5: 100.0000 (98.9698)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1961  Acc@1: 87.5000 (88.1807)  Acc@5: 100.0000 (99.0099)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2624  Acc@1: 87.5000 (87.8941)  Acc@5: 100.0000 (98.9302)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4206  Acc@1: 81.2500 (87.4483)  Acc@5: 100.0000 (98.9153)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1531  Acc@1: 87.5000 (87.4046)  Acc@5: 100.0000 (98.8550)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3693  Acc@1: 87.5000 (87.6330)  Acc@5: 100.0000 (98.9362)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2502  Acc@1: 87.5000 (87.6656)  Acc@5: 100.0000 (99.0066)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0871  Acc@1: 87.5000 (87.8106)  Acc@5: 100.0000 (99.0295)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.1204  Acc@1: 87.5000 (87.9020)  Acc@5: 100.0000 (99.0497)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1252  Acc@1: 87.5000 (88.0180)  Acc@5: 100.0000 (98.9986)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1876  Acc@1: 87.5000 (88.1545)  Acc@5: 100.0000 (99.0183)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0615  Acc@1: 87.5000 (88.2152)  Acc@5: 100.0000 (99.0672)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2472  Acc@1: 87.5000 (88.0036)  Acc@5: 100.0000 (99.0225)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2320  Acc@1: 87.5000 (88.1787)  Acc@5: 100.0000 (99.0667)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0242  Acc@1: 93.7500 (88.3117)  Acc@5: 100.0000 (99.0801)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0728  Acc@1: 93.7500 (88.3817)  Acc@5: 100.0000 (99.0923)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1236  Acc@1: 93.7500 (88.5458)  Acc@5: 100.0000 (99.0787)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1288  Acc@1: 93.7500 (88.5776)  Acc@5: 100.0000 (99.0900)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0064  Acc@1: 93.7500 (88.6301)  Acc@5: 100.0000 (99.1006)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.5374  Acc@1: 87.5000 (88.5676)  Acc@5: 100.0000 (99.1326)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2497  Acc@1: 87.5000 (88.5524)  Acc@5: 100.0000 (99.1194)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0293  Acc@1: 87.5000 (88.4344)  Acc@5: 100.0000 (99.1279)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2982  Acc@1: 87.5000 (88.3039)  Acc@5: 100.0000 (99.1359)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0935  Acc@1: 87.5000 (88.2600)  Acc@5: 100.0000 (99.1400)  time: 0.1824  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0935  Acc@1: 87.5000 (88.2600)  Acc@5: 100.0000 (99.1400)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:54  Loss: 1.0350 (1.0350)  ASR: 0.0000 (0.0000)  time: 0.3672  data: 0.1677  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0409 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.2086  data: 0.0155  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0387 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1932  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0387 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0362 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0369 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0389 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0384 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0371 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0384 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0384 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0393 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0389 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0385 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0396 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0383 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0382 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0386 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0406 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0406 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0393 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0386 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0386 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Loss: 1.0378 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0364 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0389 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0391 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0378 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0378 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0371 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0371 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0371 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0352 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1921 s / it)
Averaged stats: Loss: 1.0352 (1.0390)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:58  Lr: 0.001875  Loss: 0.1701  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.3786  data: 0.1888  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0467  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.8636)  time: 0.2045  data: 0.0173  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.1849  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (99.1071)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1147  Acc@1: 93.7500 (89.7177)  Acc@5: 100.0000 (99.3952)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0133  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (99.2378)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.0665  Acc@1: 87.5000 (89.8284)  Acc@5: 100.0000 (99.3873)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.2348  Acc@1: 87.5000 (89.7541)  Acc@5: 100.0000 (99.2828)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1003  Acc@1: 87.5000 (89.8768)  Acc@5: 100.0000 (99.2958)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.3737  Acc@1: 87.5000 (89.6605)  Acc@5: 100.0000 (99.0741)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0569  Acc@1: 93.7500 (89.4918)  Acc@5: 100.0000 (99.1758)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.4598  Acc@1: 87.5000 (89.2327)  Acc@5: 100.0000 (99.0099)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0312  Acc@1: 87.5000 (89.0766)  Acc@5: 100.0000 (99.0428)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.2443  Acc@1: 87.5000 (88.9979)  Acc@5: 100.0000 (99.0186)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1231  Acc@1: 87.5000 (88.8359)  Acc@5: 100.0000 (98.9504)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1444  Acc@1: 87.5000 (88.7855)  Acc@5: 100.0000 (98.8032)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2036  Acc@1: 87.5000 (88.7003)  Acc@5: 100.0000 (98.8411)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0808  Acc@1: 87.5000 (88.8975)  Acc@5: 100.0000 (98.7966)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1615  Acc@1: 93.7500 (88.9985)  Acc@5: 100.0000 (98.8304)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0209  Acc@1: 93.7500 (89.1575)  Acc@5: 100.0000 (98.8605)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1208  Acc@1: 93.7500 (89.2016)  Acc@5: 100.0000 (98.8874)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0360  Acc@1: 87.5000 (89.1169)  Acc@5: 100.0000 (98.9428)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0939  Acc@1: 87.5000 (89.1291)  Acc@5: 100.0000 (98.9929)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1587  Acc@1: 87.5000 (88.9706)  Acc@5: 100.0000 (99.0102)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0142  Acc@1: 87.5000 (88.9340)  Acc@5: 100.0000 (99.0260)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0697  Acc@1: 93.7500 (89.1079)  Acc@5: 100.0000 (99.0145)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0176  Acc@1: 93.7500 (89.1932)  Acc@5: 100.0000 (99.0289)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4002  Acc@1: 87.5000 (89.1284)  Acc@5: 100.0000 (99.0421)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1100  Acc@1: 87.5000 (89.0683)  Acc@5: 100.0000 (99.0775)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0433  Acc@1: 87.5000 (89.0569)  Acc@5: 100.0000 (99.0658)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0268  Acc@1: 87.5000 (88.9175)  Acc@5: 100.0000 (99.0550)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0543  Acc@1: 87.5000 (88.9327)  Acc@5: 100.0000 (99.0864)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0756  Acc@1: 87.5000 (88.8465)  Acc@5: 100.0000 (99.0756)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0387  Acc@1: 87.5000 (88.8400)  Acc@5: 100.0000 (99.0800)  time: 0.1823  data: 0.0001  max mem: 2386
Train: Epoch[4/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0387  Acc@1: 87.5000 (88.8400)  Acc@5: 100.0000 (99.0800)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:10  Loss: 1.0428 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.4166  data: 0.2203  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0327 (1.0360)  ASR: 0.0000 (0.0000)  time: 0.2122  data: 0.0202  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0362 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0367 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0367 (1.0376)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0408 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0406 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0401 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0379 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0376 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0378 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0397 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0390 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0393 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0407 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0383 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0387 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0357 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0392 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0396 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0381 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0373 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0389 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:16  Loss: 1.0390 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0378 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0376 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0369 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0363 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0376 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0359 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0345 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0369 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0384 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1926 s / it)
Averaged stats: Loss: 1.0384 (1.0386)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:51  Lr: 0.001875  Loss: -0.0185  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3561  data: 0.1675  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1593  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.2955)  time: 0.2020  data: 0.0154  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.0285  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (98.5119)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1387  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (98.7903)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.2105  Acc@1: 87.5000 (89.4817)  Acc@5: 100.0000 (98.6280)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2034  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.7745)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.0975  Acc@1: 87.5000 (89.4467)  Acc@5: 100.0000 (98.7705)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: -0.1802  Acc@1: 87.5000 (89.7887)  Acc@5: 100.0000 (98.9437)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.5328  Acc@1: 87.5000 (89.4290)  Acc@5: 100.0000 (98.9198)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0764  Acc@1: 87.5000 (89.6291)  Acc@5: 100.0000 (98.9011)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1551  Acc@1: 93.7500 (89.7896)  Acc@5: 100.0000 (98.8861)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2571  Acc@1: 93.7500 (89.9212)  Acc@5: 100.0000 (98.9865)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1787  Acc@1: 87.5000 (89.9277)  Acc@5: 100.0000 (99.0702)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2671  Acc@1: 87.5000 (89.9332)  Acc@5: 100.0000 (99.0458)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.5427  Acc@1: 87.5000 (89.7606)  Acc@5: 100.0000 (98.9805)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2784  Acc@1: 87.5000 (89.6937)  Acc@5: 100.0000 (99.0066)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2260  Acc@1: 93.7500 (89.6739)  Acc@5: 100.0000 (99.0295)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.4257  Acc@1: 93.7500 (89.6199)  Acc@5: 100.0000 (99.0132)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1065  Acc@1: 93.7500 (89.6064)  Acc@5: 100.0000 (98.9986)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1683  Acc@1: 93.7500 (89.7906)  Acc@5: 100.0000 (99.0183)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3083  Acc@1: 93.7500 (89.6766)  Acc@5: 100.0000 (99.0361)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0472  Acc@1: 93.7500 (89.7512)  Acc@5: 100.0000 (99.0521)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0548  Acc@1: 93.7500 (89.8473)  Acc@5: 100.0000 (99.0667)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0225  Acc@1: 87.5000 (89.7186)  Acc@5: 100.0000 (98.9989)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.2362  Acc@1: 87.5000 (89.6266)  Acc@5: 100.0000 (99.0145)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0487  Acc@1: 87.5000 (89.5169)  Acc@5: 100.0000 (99.0538)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1260  Acc@1: 87.5000 (89.3918)  Acc@5: 100.0000 (99.0661)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.1086  Acc@1: 87.5000 (89.3450)  Acc@5: 100.0000 (99.0775)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0615  Acc@1: 87.5000 (89.3683)  Acc@5: 100.0000 (99.1103)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.5623  Acc@1: 87.5000 (89.2826)  Acc@5: 100.0000 (99.1409)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.2113  Acc@1: 87.5000 (89.2234)  Acc@5: 100.0000 (99.1071)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2578  Acc@1: 87.5000 (89.2886)  Acc@5: 100.0000 (99.0555)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1647  Acc@1: 93.7500 (89.3000)  Acc@5: 100.0000 (99.0600)  time: 0.1828  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1647  Acc@1: 93.7500 (89.3000)  Acc@5: 100.0000 (99.0600)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:02  Loss: 1.0307 (1.0307)  ASR: 0.0000 (0.0000)  time: 0.3922  data: 0.1934  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0350 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.2109  data: 0.0178  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0380 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0397 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0373 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0360 (1.0376)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0366 (1.0375)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0387 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0378 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0361 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0364 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0369 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0371 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0377 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0387 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0394 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0368 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0368 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0365 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0362 (1.0378)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0382 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0390 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0363 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:16  Loss: 1.0366 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0374 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0374 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0370 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0364 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0364 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0359 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0347 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0387 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0382 (1.0377)  ASR: 0.0000 (0.0000)  time: 0.1883  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1930 s / it)
Averaged stats: Loss: 1.0382 (1.0377)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:18  Loss: 0.5768 (0.5768)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2922  data: 0.1676  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  Loss: 0.5768 (0.5510)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (97.7273)  time: 0.1323  data: 0.0155  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.6097 (0.6150)  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (97.9167)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.5678 (0.5907)  Acc@1: 81.2500 (87.2984)  Acc@5: 100.0000 (98.1855)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.5366 (0.5772)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.6280)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.5495 (0.5640)  Acc@1: 93.7500 (88.1127)  Acc@5: 100.0000 (98.6520)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4151 (0.5453)  Acc@1: 87.5000 (88.3197)  Acc@5: 100.0000 (98.6680)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4151 (0.5434)  Acc@1: 87.5000 (88.3000)  Acc@5: 100.0000 (98.7000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1192 s / it)
* Acc@1 88.300 Acc@5 98.700 loss 0.543
Test: [Task 1]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 0.7334 (0.7334)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.3325  data: 0.2127  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 87.5000 (87.3418)  Loss: 0.8497 (0.9709)  Acc@1: 75.0000 (78.9773)  Acc@5: 93.7500 (90.3409)  time: 0.1375  data: 0.0197  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 84.6154 (85.2843)  Loss: 1.1494 (1.1002)  Acc@1: 75.0000 (76.1905)  Acc@5: 87.5000 (88.9881)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (86.2613)  Loss: 1.0922 (1.0608)  Acc@1: 81.2500 (77.4194)  Acc@5: 87.5000 (89.1129)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (86.6102)  Loss: 0.9069 (1.0363)  Acc@1: 81.2500 (78.0488)  Acc@5: 93.7500 (89.6341)  time: 0.1179  data: 0.0002  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 91.6667 (87.3297)  Loss: 0.9572 (1.0118)  Acc@1: 81.2500 (78.7990)  Acc@5: 93.7500 (89.8284)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (88.0137)  Loss: 0.9501 (0.9942)  Acc@1: 81.2500 (79.2008)  Acc@5: 87.5000 (89.6516)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (87.9733)  Loss: 0.9501 (0.9893)  Acc@1: 81.2500 (79.2000)  Acc@5: 87.5000 (89.7000)  time: 0.1150  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1211 s / it)
* Acc@1 79.200 Acc@5 89.700 loss 0.989
* Acc@1 nan ASR 87.973
Test: [Task 2]  [ 0/63]  eta: 0:00:17  Loss: 0.9473 (0.9473)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2827  data: 0.1608  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  Loss: 0.7413 (0.7477)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.2955)  time: 0.1315  data: 0.0148  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.7512 (0.8117)  Acc@1: 87.5000 (82.4405)  Acc@5: 100.0000 (97.3214)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.7664 (0.8118)  Acc@1: 81.2500 (82.8629)  Acc@5: 100.0000 (96.1694)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.7641 (0.7977)  Acc@1: 81.2500 (83.0793)  Acc@5: 93.7500 (96.3415)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.7446 (0.7965)  Acc@1: 81.2500 (82.7206)  Acc@5: 100.0000 (96.4461)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.6831 (0.7735)  Acc@1: 81.2500 (83.2992)  Acc@5: 100.0000 (97.0287)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6610 (0.7645)  Acc@1: 81.2500 (83.4000)  Acc@5: 100.0000 (97.1000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 83.400 Acc@5 97.100 loss 0.765
Test: [Task 2]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 80.0000 (80.0000)  Loss: 1.2221 (1.2221)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.2840  data: 0.1625  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 86.6667 (84.2767)  Loss: 1.2221 (1.1439)  Acc@1: 81.2500 (76.1364)  Acc@5: 87.5000 (88.6364)  time: 0.1329  data: 0.0151  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (81.4570)  Loss: 1.2775 (1.2470)  Acc@1: 75.0000 (73.2143)  Acc@5: 87.5000 (87.2024)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (82.7354)  Loss: 1.2775 (1.2348)  Acc@1: 75.0000 (74.3952)  Acc@5: 87.5000 (86.4919)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 85.7143 (82.8571)  Loss: 1.0906 (1.1898)  Acc@1: 75.0000 (75.1524)  Acc@5: 87.5000 (87.5000)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 81.2500 (82.5971)  Loss: 0.9292 (1.1539)  Acc@1: 75.0000 (75.6127)  Acc@5: 93.7500 (88.6029)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (83.0528)  Loss: 1.0438 (1.1490)  Acc@1: 75.0000 (75.8197)  Acc@5: 93.7500 (88.8320)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (83.2053)  Loss: 1.0438 (1.1545)  Acc@1: 75.0000 (75.8000)  Acc@5: 93.7500 (88.7000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1204 s / it)
* Acc@1 75.800 Acc@5 88.700 loss 1.154
* Acc@1 nan ASR 83.205
Test: [Task 3]  [ 0/63]  eta: 0:00:16  Loss: 0.3636 (0.3636)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.2591  data: 0.1413  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:06  Loss: 0.5658 (0.6159)  Acc@1: 87.5000 (84.0909)  Acc@5: 93.7500 (95.4545)  time: 0.1294  data: 0.0131  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.6896 (0.6393)  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (96.4286)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:03  Loss: 0.6373 (0.6479)  Acc@1: 81.2500 (83.2661)  Acc@5: 100.0000 (97.1774)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.5364 (0.6200)  Acc@1: 87.5000 (84.2988)  Acc@5: 100.0000 (97.4085)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.5905 (0.6226)  Acc@1: 87.5000 (84.9265)  Acc@5: 100.0000 (97.1814)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.6413 (0.6352)  Acc@1: 81.2500 (84.4262)  Acc@5: 100.0000 (97.3361)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.6534 (0.6397)  Acc@1: 81.2500 (84.1000)  Acc@5: 100.0000 (97.3000)  time: 0.1135  data: 0.0001  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1184 s / it)
* Acc@1 84.100 Acc@5 97.300 loss 0.640
Test: [Task 3]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 0.6565 (0.6565)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.3237  data: 0.2038  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 85.7143 (82.9114)  Loss: 1.0028 (1.0534)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (86.9318)  time: 0.1364  data: 0.0187  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 81.2500 (83.7838)  Loss: 1.1149 (1.1532)  Acc@1: 75.0000 (74.1071)  Acc@5: 87.5000 (86.3095)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 80.0000 (82.8829)  Loss: 1.1225 (1.0892)  Acc@1: 75.0000 (74.3952)  Acc@5: 87.5000 (88.1048)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 85.7143 (83.8983)  Loss: 0.9046 (1.0443)  Acc@1: 75.0000 (75.6098)  Acc@5: 93.7500 (89.0244)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (84.7203)  Loss: 0.8990 (1.0455)  Acc@1: 81.2500 (76.2255)  Acc@5: 93.7500 (88.6029)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (84.3360)  Loss: 0.9709 (1.0439)  Acc@1: 75.0000 (76.3320)  Acc@5: 93.7500 (89.0369)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (83.9424)  Loss: 0.9709 (1.0424)  Acc@1: 75.0000 (76.0000)  Acc@5: 93.7500 (89.0000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1208 s / it)
* Acc@1 76.000 Acc@5 89.000 loss 1.042
* Acc@1 nan ASR 83.942
Test: [Task 4]  [ 0/63]  eta: 0:00:16  Loss: 0.7951 (0.7951)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.2599  data: 0.1433  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:06  Loss: 0.7476 (0.7120)  Acc@1: 87.5000 (84.6591)  Acc@5: 93.7500 (96.5909)  time: 0.1294  data: 0.0132  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  Loss: 0.6706 (0.7148)  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (96.7262)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:03  Loss: 0.5764 (0.6854)  Acc@1: 81.2500 (82.8629)  Acc@5: 93.7500 (96.5726)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  Loss: 0.3983 (0.6231)  Acc@1: 93.7500 (84.9085)  Acc@5: 100.0000 (97.2561)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  Loss: 0.4433 (0.6428)  Acc@1: 93.7500 (85.0490)  Acc@5: 100.0000 (96.9363)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5670 (0.6455)  Acc@1: 87.5000 (84.9385)  Acc@5: 93.7500 (96.6189)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6950 (0.6476)  Acc@1: 87.5000 (84.9000)  Acc@5: 93.7500 (96.6000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1186 s / it)
* Acc@1 84.900 Acc@5 96.600 loss 0.648
Test: [Task 4]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 93.3333 (93.3333)  Loss: 0.9909 (0.9909)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2745  data: 0.1539  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 85.7143 (87.6712)  Loss: 1.2998 (1.3701)  Acc@1: 75.0000 (73.2955)  Acc@5: 87.5000 (82.3864)  time: 0.1324  data: 0.0142  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 84.6154 (83.6806)  Loss: 1.2967 (1.2934)  Acc@1: 75.0000 (72.6190)  Acc@5: 81.2500 (84.5238)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 84.6154 (84.1379)  Loss: 1.0504 (1.1921)  Acc@1: 75.0000 (74.3952)  Acc@5: 87.5000 (85.8871)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 93.3333 (85.8362)  Loss: 0.8509 (1.0690)  Acc@1: 81.2500 (77.2866)  Acc@5: 93.7500 (88.1098)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 93.3333 (85.9697)  Loss: 0.8911 (1.1102)  Acc@1: 87.5000 (77.2059)  Acc@5: 93.7500 (87.5000)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (85.7635)  Loss: 1.0663 (1.1055)  Acc@1: 81.2500 (77.0492)  Acc@5: 87.5000 (87.3975)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (85.6502)  Loss: 1.1445 (1.1148)  Acc@1: 75.0000 (76.9000)  Acc@5: 87.5000 (87.3000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 76.900 Acc@5 87.300 loss 1.115
* Acc@1 nan ASR 85.650
Test: [Task 5]  [ 0/63]  eta: 0:00:19  Loss: 0.2871 (0.2871)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3129  data: 0.1956  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  Loss: 0.5343 (0.6112)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (97.1591)  time: 0.1343  data: 0.0180  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  Loss: 0.5167 (0.5685)  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (97.9167)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  Loss: 0.4401 (0.5664)  Acc@1: 93.7500 (90.7258)  Acc@5: 100.0000 (98.1855)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  Loss: 0.4395 (0.5464)  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (98.1707)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  Loss: 0.5093 (0.5476)  Acc@1: 87.5000 (90.8088)  Acc@5: 100.0000 (98.2843)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5598 (0.5549)  Acc@1: 87.5000 (90.2664)  Acc@5: 100.0000 (98.3607)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5656 (0.5716)  Acc@1: 87.5000 (89.8000)  Acc@5: 100.0000 (98.2000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1196 s / it)
* Acc@1 89.800 Acc@5 98.200 loss 0.572
Test: [Task 5]  [ 0/63]  eta: 0:00:17  ASR: nan (nan)  ACC: 100.0000 (100.0000)  Loss: 0.2871 (0.2871)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2845  data: 0.1652  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 90.9091 (89.8089)  Loss: 0.7772 (1.1126)  Acc@1: 81.2500 (80.1136)  Acc@5: 93.7500 (88.0682)  time: 0.1329  data: 0.0152  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 93.3333 (90.8197)  Loss: 0.8160 (1.0016)  Acc@1: 87.5000 (82.4405)  Acc@5: 93.7500 (90.1786)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 93.3333 (90.8277)  Loss: 0.8946 (1.0389)  Acc@1: 81.2500 (81.8548)  Acc@5: 93.7500 (89.7177)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (91.1765)  Loss: 1.0573 (1.1023)  Acc@1: 81.2500 (80.6402)  Acc@5: 87.5000 (87.8049)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (90.7692)  Loss: 1.2890 (1.1292)  Acc@1: 75.0000 (79.7794)  Acc@5: 81.2500 (87.5000)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (90.1620)  Loss: 0.8524 (1.0953)  Acc@1: 75.0000 (80.0205)  Acc@5: 93.7500 (88.4221)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (89.6280)  Loss: 1.0214 (1.1005)  Acc@1: 75.0000 (79.7000)  Acc@5: 93.7500 (88.4000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 79.700 Acc@5 88.400 loss 1.101
* Acc@1 nan ASR 89.628
Test: [Task 6]  [ 0/63]  eta: 0:00:16  Loss: 0.4212 (0.4212)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.2554  data: 0.1377  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:06  Loss: 0.6388 (0.5985)  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (97.7273)  time: 0.1295  data: 0.0128  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  Loss: 0.6661 (0.6521)  Acc@1: 81.2500 (82.4405)  Acc@5: 100.0000 (97.9167)  time: 0.1168  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:03  Loss: 0.5924 (0.6426)  Acc@1: 87.5000 (82.8629)  Acc@5: 100.0000 (98.3871)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  Loss: 0.6224 (0.6776)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.8659)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  Loss: 0.6499 (0.6647)  Acc@1: 81.2500 (82.1078)  Acc@5: 100.0000 (98.1618)  time: 0.1167  data: 0.0002  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.6343 (0.6836)  Acc@1: 81.2500 (81.8648)  Acc@5: 100.0000 (98.0533)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6249 (0.6797)  Acc@1: 81.2500 (82.0000)  Acc@5: 100.0000 (98.1000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1186 s / it)
* Acc@1 82.000 Acc@5 98.100 loss 0.680
Test: [Task 6]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  ACC: 84.6154 (84.6154)  Loss: 1.5004 (1.5004)  Acc@1: 68.7500 (68.7500)  Acc@5: 81.2500 (81.2500)  time: 0.3044  data: 0.1838  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 84.6154 (84.1060)  Loss: 1.3389 (1.2984)  Acc@1: 68.7500 (72.1591)  Acc@5: 87.5000 (84.6591)  time: 0.1346  data: 0.0169  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 83.3333 (82.4324)  Loss: 1.2475 (1.2272)  Acc@1: 75.0000 (72.9167)  Acc@5: 87.5000 (86.9048)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 83.3333 (82.7664)  Loss: 0.9288 (1.1610)  Acc@1: 75.0000 (73.7903)  Acc@5: 87.5000 (88.1048)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 80.0000 (80.8950)  Loss: 1.0390 (1.1995)  Acc@1: 68.7500 (71.9512)  Acc@5: 87.5000 (87.6524)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 80.0000 (81.5681)  Loss: 1.0819 (1.1751)  Acc@1: 75.0000 (72.9167)  Acc@5: 87.5000 (88.2353)  time: 0.1175  data: 0.0003  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (81.3927)  Loss: 1.0376 (1.1485)  Acc@1: 75.0000 (73.4631)  Acc@5: 93.7500 (89.0369)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (81.5350)  Loss: 1.0376 (1.1300)  Acc@1: 75.0000 (73.8000)  Acc@5: 93.7500 (89.3000)  time: 0.1146  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1203 s / it)
* Acc@1 73.800 Acc@5 89.300 loss 1.130
* Acc@1 nan ASR 81.535
Test: [Task 7]  [ 0/63]  eta: 0:00:17  Loss: 0.5664 (0.5664)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.2771  data: 0.1600  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:06  Loss: 0.5476 (0.5497)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  time: 0.1309  data: 0.0148  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  Loss: 0.5476 (0.5869)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (97.6190)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  Loss: 0.5702 (0.5918)  Acc@1: 81.2500 (86.2903)  Acc@5: 100.0000 (97.5806)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  Loss: 0.5187 (0.5852)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (97.2561)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  Loss: 0.5068 (0.6048)  Acc@1: 87.5000 (86.5196)  Acc@5: 93.7500 (96.6912)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.5068 (0.5855)  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (96.9262)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.4945 (0.5822)  Acc@1: 87.5000 (87.3000)  Acc@5: 100.0000 (97.0000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1187 s / it)
* Acc@1 87.300 Acc@5 97.000 loss 0.582
Test: [Task 7]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 85.7143 (85.7143)  Loss: 1.3047 (1.3047)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.2854  data: 0.1653  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 85.7143 (84.6626)  Loss: 0.9250 (0.9478)  Acc@1: 75.0000 (78.4091)  Acc@5: 93.7500 (90.9091)  time: 0.1326  data: 0.0152  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (85.2564)  Loss: 0.9091 (0.9842)  Acc@1: 81.2500 (79.1667)  Acc@5: 93.7500 (90.7738)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 83.3333 (85.5580)  Loss: 1.0543 (1.0222)  Acc@1: 81.2500 (78.8306)  Acc@5: 93.7500 (89.9194)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (86.2876)  Loss: 1.1186 (1.0666)  Acc@1: 81.2500 (78.6585)  Acc@5: 87.5000 (88.7195)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 85.7143 (85.9060)  Loss: 1.1186 (1.0753)  Acc@1: 75.0000 (78.4314)  Acc@5: 87.5000 (88.3578)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 87.5000 (86.9075)  Loss: 0.9815 (1.0844)  Acc@1: 81.2500 (78.8934)  Acc@5: 87.5000 (88.1148)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 87.5000 (87.0044)  Loss: 0.9815 (1.0820)  Acc@1: 81.2500 (79.0000)  Acc@5: 87.5000 (88.2000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 79.000 Acc@5 88.200 loss 1.082
* Acc@1 nan ASR 87.004
[Average accuracy till task7]	Acc@1: 77.2000	Acc@5: 88.6571	Loss: 1.0876	Forgetting: 5.5333	Backward: -5.4333
Train: Epoch[1/5]  [  0/313]  eta: 0:01:59  Lr: 0.001875  Loss: 2.0789  Acc@1: 18.7500 (18.7500)  Acc@5: 50.0000 (50.0000)  time: 0.3818  data: 0.1937  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.5653  Acc@1: 62.5000 (53.4091)  Acc@5: 81.2500 (78.9773)  time: 0.2040  data: 0.0178  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.5117  Acc@1: 68.7500 (66.6667)  Acc@5: 87.5000 (86.3095)  time: 0.1861  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.2394  Acc@1: 81.2500 (69.3548)  Acc@5: 93.7500 (89.1129)  time: 0.1860  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.7552  Acc@1: 81.2500 (72.5610)  Acc@5: 100.0000 (91.1585)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.6696  Acc@1: 81.2500 (73.8971)  Acc@5: 100.0000 (92.1569)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.8655  Acc@1: 81.2500 (76.1270)  Acc@5: 100.0000 (93.2377)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.3194  Acc@1: 81.2500 (77.6408)  Acc@5: 100.0000 (93.9261)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.5012  Acc@1: 87.5000 (79.0895)  Acc@5: 100.0000 (94.5216)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.6115  Acc@1: 87.5000 (80.0137)  Acc@5: 100.0000 (94.9176)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.4788  Acc@1: 87.5000 (80.3837)  Acc@5: 100.0000 (95.1733)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1996  Acc@1: 87.5000 (81.1374)  Acc@5: 100.0000 (95.5518)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.5617  Acc@1: 87.5000 (81.3533)  Acc@5: 100.0000 (95.9194)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.6014  Acc@1: 81.2500 (81.5363)  Acc@5: 100.0000 (95.8969)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.4930  Acc@1: 81.2500 (81.6489)  Acc@5: 100.0000 (96.0550)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1496  Acc@1: 87.5000 (82.1606)  Acc@5: 100.0000 (96.2748)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3044  Acc@1: 87.5000 (82.3758)  Acc@5: 100.0000 (96.4286)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0555  Acc@1: 87.5000 (82.7120)  Acc@5: 100.0000 (96.5278)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2467  Acc@1: 87.5000 (82.9765)  Acc@5: 100.0000 (96.6160)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1677  Acc@1: 87.5000 (83.2134)  Acc@5: 100.0000 (96.7605)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2466  Acc@1: 87.5000 (83.5510)  Acc@5: 100.0000 (96.8595)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.5622  Acc@1: 87.5000 (83.6197)  Acc@5: 100.0000 (96.8898)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2622  Acc@1: 87.5000 (83.7952)  Acc@5: 100.0000 (96.9174)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.3973  Acc@1: 87.5000 (83.8474)  Acc@5: 100.0000 (96.9697)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.0479  Acc@1: 87.5000 (84.1027)  Acc@5: 100.0000 (96.9917)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0173  Acc@1: 87.5000 (84.0139)  Acc@5: 100.0000 (96.9871)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3606  Acc@1: 87.5000 (84.1236)  Acc@5: 100.0000 (97.0067)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2759  Acc@1: 87.5000 (84.2251)  Acc@5: 100.0000 (97.1172)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1099  Acc@1: 93.7500 (84.5196)  Acc@5: 100.0000 (97.2198)  time: 0.1872  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.6052  Acc@1: 87.5000 (84.3428)  Acc@5: 100.0000 (97.2723)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0794  Acc@1: 81.2500 (84.4269)  Acc@5: 100.0000 (97.3214)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2065  Acc@1: 81.2500 (84.4855)  Acc@5: 100.0000 (97.3272)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4079  Acc@1: 81.2500 (84.4200)  Acc@5: 100.0000 (97.3000)  time: 0.1823  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:00:58 (0.1873 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.4079  Acc@1: 81.2500 (84.4200)  Acc@5: 100.0000 (97.3000)
Train: Epoch[1/5]  [  0/313]  eta: 0:01:50  Loss: 1.0674 (1.0674)  ASR: 0.0000 (0.0000)  time: 0.3527  data: 0.1572  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0603 (1.0611)  ASR: 0.0000 (0.0000)  time: 0.2070  data: 0.0145  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0570 (1.0579)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0538 (1.0564)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0534 (1.0553)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0523 (1.0545)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0504 (1.0536)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0485 (1.0529)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0476 (1.0524)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0477 (1.0519)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0478 (1.0514)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0469 (1.0510)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0467 (1.0508)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0468 (1.0505)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0482 (1.0504)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0480 (1.0501)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0450 (1.0499)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0461 (1.0498)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0460 (1.0496)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0451 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0444 (1.0491)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0451 (1.0489)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0458 (1.0489)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Loss: 1.0462 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0451 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0451 (1.0484)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0446 (1.0483)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0446 (1.0482)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0452 (1.0481)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0452 (1.0480)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0455 (1.0480)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0463 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0463 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Loss: 1.0463 (1.0479)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:51  Lr: 0.001875  Loss: 0.5664  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3561  data: 0.1661  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1133  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (99.4318)  time: 0.2022  data: 0.0152  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.0474  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (99.1071)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0877  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.3952)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.3486  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (99.2378)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2411  Acc@1: 93.7500 (88.2353)  Acc@5: 100.0000 (98.8971)  time: 0.1861  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.4362  Acc@1: 93.7500 (88.5246)  Acc@5: 100.0000 (99.0779)  time: 0.1860  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1133  Acc@1: 93.7500 (88.9965)  Acc@5: 100.0000 (99.2077)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.1666  Acc@1: 87.5000 (88.8117)  Acc@5: 100.0000 (99.2284)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.4467  Acc@1: 87.5000 (88.6676)  Acc@5: 100.0000 (99.1071)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2614  Acc@1: 87.5000 (88.0569)  Acc@5: 100.0000 (99.1337)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.4001  Acc@1: 87.5000 (87.7815)  Acc@5: 100.0000 (99.0428)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.3374  Acc@1: 87.5000 (87.6550)  Acc@5: 100.0000 (99.0702)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0031  Acc@1: 93.7500 (87.9771)  Acc@5: 100.0000 (98.9504)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0120  Acc@1: 93.7500 (88.1206)  Acc@5: 100.0000 (98.9805)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.2927  Acc@1: 93.7500 (88.2036)  Acc@5: 100.0000 (99.0066)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1246  Acc@1: 87.5000 (87.7329)  Acc@5: 100.0000 (98.8742)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1039  Acc@1: 87.5000 (87.9020)  Acc@5: 100.0000 (98.9401)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1168  Acc@1: 87.5000 (88.0525)  Acc@5: 100.0000 (98.9296)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0261  Acc@1: 87.5000 (88.1217)  Acc@5: 100.0000 (98.9202)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0574  Acc@1: 87.5000 (87.9664)  Acc@5: 100.0000 (98.8806)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0244  Acc@1: 87.5000 (87.8258)  Acc@5: 100.0000 (98.8152)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.6575  Acc@1: 87.5000 (87.8111)  Acc@5: 100.0000 (98.7274)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1708  Acc@1: 87.5000 (87.8788)  Acc@5: 100.0000 (98.7013)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.1263  Acc@1: 87.5000 (87.9409)  Acc@5: 100.0000 (98.6515)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2105  Acc@1: 87.5000 (88.0478)  Acc@5: 100.0000 (98.6803)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.1125  Acc@1: 87.5000 (88.0508)  Acc@5: 100.0000 (98.6830)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2541  Acc@1: 87.5000 (87.9843)  Acc@5: 100.0000 (98.6854)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0761  Acc@1: 87.5000 (87.9893)  Acc@5: 100.0000 (98.6432)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0729  Acc@1: 87.5000 (88.0369)  Acc@5: 100.0000 (98.6684)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.6426  Acc@1: 87.5000 (87.8945)  Acc@5: 100.0000 (98.6503)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.5943  Acc@1: 81.2500 (87.8215)  Acc@5: 100.0000 (98.6736)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1656  Acc@1: 87.5000 (87.8400)  Acc@5: 100.0000 (98.6800)  time: 0.1824  data: 0.0001  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1870 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1656  Acc@1: 87.5000 (87.8400)  Acc@5: 100.0000 (98.6800)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:48  Loss: 1.0409 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.3454  data: 0.1499  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0421 (1.0442)  ASR: 0.0000 (0.0000)  time: 0.2052  data: 0.0138  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0420 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0413 (1.0433)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0436 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0436 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Loss: 1.0429 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Loss: 1.0429 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Loss: 1.0462 (1.0436)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Loss: 1.0411 (1.0434)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0411 (1.0433)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0427 (1.0433)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0423 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0423 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0432 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0426 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0413 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0420 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0427 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0427 (1.0432)  ASR: 0.0000 (0.0000)  time: 0.1903  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0410 (1.0431)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0406 (1.0430)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0407 (1.0429)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Loss: 1.0416 (1.0428)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0409 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0419 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0434 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0428 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0410 (1.0426)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0391 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0384 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0394 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0402 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Loss: 1.0402 (1.0424)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:41  Lr: 0.001875  Loss: 0.1233  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3231  data: 0.1349  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.0144  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (99.4318)  time: 0.1988  data: 0.0124  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: -0.1931  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (98.8095)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.2418  Acc@1: 93.7500 (90.1210)  Acc@5: 100.0000 (98.9919)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0247  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (98.9329)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.1218  Acc@1: 93.7500 (89.4608)  Acc@5: 100.0000 (98.7745)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2702  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (98.4631)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2042  Acc@1: 87.5000 (89.2606)  Acc@5: 100.0000 (98.5915)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.4463  Acc@1: 87.5000 (89.2747)  Acc@5: 100.0000 (98.6883)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3182  Acc@1: 87.5000 (89.1484)  Acc@5: 100.0000 (98.7637)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3811  Acc@1: 87.5000 (89.1089)  Acc@5: 100.0000 (98.7624)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0612  Acc@1: 81.2500 (88.6824)  Acc@5: 100.0000 (98.8739)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1200  Acc@1: 81.2500 (88.6880)  Acc@5: 100.0000 (98.8120)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.1354  Acc@1: 93.7500 (88.8836)  Acc@5: 100.0000 (98.8073)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1277  Acc@1: 93.7500 (89.0514)  Acc@5: 100.0000 (98.8918)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0344  Acc@1: 87.5000 (89.1556)  Acc@5: 100.0000 (98.8825)  time: 0.1861  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2239  Acc@1: 87.5000 (89.0528)  Acc@5: 100.0000 (98.8354)  time: 0.1861  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2597  Acc@1: 87.5000 (88.9620)  Acc@5: 100.0000 (98.7573)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0612  Acc@1: 87.5000 (88.7776)  Acc@5: 100.0000 (98.7914)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2141  Acc@1: 87.5000 (88.8089)  Acc@5: 100.0000 (98.8220)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0884  Acc@1: 93.7500 (88.8682)  Acc@5: 100.0000 (98.8184)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.4255  Acc@1: 87.5000 (88.8626)  Acc@5: 100.0000 (98.8152)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.4545  Acc@1: 93.7500 (89.0837)  Acc@5: 100.0000 (98.8405)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0581  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.8636)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.1420  Acc@1: 93.7500 (89.3413)  Acc@5: 100.0000 (98.9108)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0356  Acc@1: 87.5000 (89.2430)  Acc@5: 100.0000 (98.8546)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.1082  Acc@1: 93.7500 (89.4397)  Acc@5: 100.0000 (98.8745)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.4245  Acc@1: 93.7500 (89.4603)  Acc@5: 100.0000 (98.8699)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0844  Acc@1: 87.5000 (89.4351)  Acc@5: 100.0000 (98.8657)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0225  Acc@1: 87.5000 (89.4330)  Acc@5: 100.0000 (98.8402)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.1174  Acc@1: 87.5000 (89.3065)  Acc@5: 100.0000 (98.8372)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1177  Acc@1: 87.5000 (89.1680)  Acc@5: 100.0000 (98.8545)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2111  Acc@1: 87.5000 (89.1800)  Acc@5: 100.0000 (98.8600)  time: 0.1822  data: 0.0001  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1869 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2111  Acc@1: 87.5000 (89.1800)  Acc@5: 100.0000 (98.8600)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:56  Loss: 1.0391 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.3725  data: 0.1755  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0390 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.2073  data: 0.0161  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0410 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0407 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0385 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0382 (1.0403)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0420 (1.0407)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0430 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0400 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0385 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0385 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0381 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0377 (1.0403)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0387 (1.0403)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0413 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0399 (1.0404)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0408 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0412 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0396 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0394 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0395 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0395 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0398 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Loss: 1.0398 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0392 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0390 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0391 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0409 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0409 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0410 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0411 (1.0406)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0434 (1.0407)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0441 (1.0407)  ASR: 0.0000 (0.0000)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1921 s / it)
Averaged stats: Loss: 1.0441 (1.0407)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:01  Lr: 0.001875  Loss: 0.1378  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3885  data: 0.1985  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: -0.0536  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (99.4318)  time: 0.2044  data: 0.0181  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.1786  Acc@1: 87.5000 (86.9048)  Acc@5: 100.0000 (99.1071)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0476  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.9919)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.0457  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (99.0854)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.0391  Acc@1: 87.5000 (87.7451)  Acc@5: 100.0000 (99.1422)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.2132  Acc@1: 93.7500 (88.2172)  Acc@5: 100.0000 (99.2828)  time: 0.1861  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2033  Acc@1: 87.5000 (88.4683)  Acc@5: 100.0000 (99.1197)  time: 0.1862  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.0629  Acc@1: 87.5000 (88.8889)  Acc@5: 100.0000 (99.2284)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0594  Acc@1: 93.7500 (89.2170)  Acc@5: 100.0000 (99.1071)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1219  Acc@1: 93.7500 (89.2327)  Acc@5: 100.0000 (99.0718)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3062  Acc@1: 87.5000 (89.3018)  Acc@5: 100.0000 (98.9865)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1889  Acc@1: 93.7500 (89.3595)  Acc@5: 100.0000 (99.0186)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4178  Acc@1: 87.5000 (89.3607)  Acc@5: 100.0000 (98.8550)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0958  Acc@1: 87.5000 (89.2287)  Acc@5: 100.0000 (98.9362)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3184  Acc@1: 87.5000 (89.2798)  Acc@5: 100.0000 (98.9652)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1183  Acc@1: 87.5000 (89.2469)  Acc@5: 100.0000 (98.9130)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0502  Acc@1: 87.5000 (89.3640)  Acc@5: 100.0000 (98.9401)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.6380  Acc@1: 87.5000 (89.2265)  Acc@5: 100.0000 (98.8950)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0152  Acc@1: 87.5000 (89.2016)  Acc@5: 100.0000 (98.8220)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0673  Acc@1: 93.7500 (89.2724)  Acc@5: 100.0000 (98.6629)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0549  Acc@1: 93.7500 (89.3661)  Acc@5: 100.0000 (98.6374)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0292  Acc@1: 87.5000 (89.2534)  Acc@5: 100.0000 (98.6708)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0439  Acc@1: 87.5000 (89.2587)  Acc@5: 100.0000 (98.6742)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3444  Acc@1: 93.7500 (89.3932)  Acc@5: 100.0000 (98.6774)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0396  Acc@1: 93.7500 (89.3675)  Acc@5: 100.0000 (98.6803)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4600  Acc@1: 87.5000 (89.3199)  Acc@5: 100.0000 (98.7069)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0660  Acc@1: 93.7500 (89.3911)  Acc@5: 100.0000 (98.7315)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0662  Acc@1: 93.7500 (89.4795)  Acc@5: 100.0000 (98.7767)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0158  Acc@1: 93.7500 (89.5189)  Acc@5: 100.0000 (98.7973)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.2193  Acc@1: 93.7500 (89.5556)  Acc@5: 100.0000 (98.8164)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0779  Acc@1: 93.7500 (89.5699)  Acc@5: 100.0000 (98.8143)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1876  Acc@1: 93.7500 (89.5600)  Acc@5: 100.0000 (98.8200)  time: 0.1824  data: 0.0001  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:03 (0.2042 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1876  Acc@1: 93.7500 (89.5600)  Acc@5: 100.0000 (98.8200)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:59  Loss: 1.0500 (1.0500)  ASR: 0.0000 (0.0000)  time: 0.3830  data: 0.1889  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0376 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.2084  data: 0.0174  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0388 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0398 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0398 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0384 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0378 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0375 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0385 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0389 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0371 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0375 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0393 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1901  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0398 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0388 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0380 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0380 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0396 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0383 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0381 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0392 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0394 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0394 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Loss: 1.0383 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0383 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0380 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0381 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0397 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0396 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0384 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0361 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0357 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0357 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1877  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Loss: 1.0357 (1.0393)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:06  Lr: 0.001875  Loss: 0.1949  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4044  data: 0.2122  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Lr: 0.001875  Loss: 0.3749  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  time: 0.2069  data: 0.0194  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.0392  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (98.8095)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1994  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (99.1935)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.6127  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (99.0854)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.1955  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (99.1422)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1248  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (99.1803)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: -0.0571  Acc@1: 87.5000 (88.3803)  Acc@5: 100.0000 (98.9437)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1853  Acc@1: 93.7500 (89.1975)  Acc@5: 100.0000 (99.0741)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.2753  Acc@1: 93.7500 (89.3544)  Acc@5: 100.0000 (99.0385)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0339  Acc@1: 93.7500 (89.7277)  Acc@5: 100.0000 (99.0718)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3995  Acc@1: 87.5000 (89.4144)  Acc@5: 100.0000 (99.0991)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1781  Acc@1: 87.5000 (89.7211)  Acc@5: 100.0000 (99.1219)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0062  Acc@1: 93.7500 (89.6947)  Acc@5: 100.0000 (99.0935)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3055  Acc@1: 93.7500 (89.8493)  Acc@5: 100.0000 (99.1135)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.1552  Acc@1: 93.7500 (89.7765)  Acc@5: 100.0000 (99.0894)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0262  Acc@1: 93.7500 (89.8292)  Acc@5: 100.0000 (99.0295)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1812  Acc@1: 93.7500 (89.6930)  Acc@5: 100.0000 (98.7939)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1377  Acc@1: 93.7500 (89.9862)  Acc@5: 100.0000 (98.8605)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0298  Acc@1: 93.7500 (90.0524)  Acc@5: 100.0000 (98.8874)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1612  Acc@1: 87.5000 (89.8632)  Acc@5: 100.0000 (98.8806)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0947  Acc@1: 87.5000 (89.8400)  Acc@5: 100.0000 (98.9040)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0411  Acc@1: 87.5000 (89.8190)  Acc@5: 100.0000 (98.8971)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1698  Acc@1: 87.5000 (89.8268)  Acc@5: 100.0000 (98.9177)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.1224  Acc@1: 87.5000 (89.7303)  Acc@5: 100.0000 (98.8849)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.0048  Acc@1: 93.7500 (89.9402)  Acc@5: 100.0000 (98.9044)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0548  Acc@1: 93.7500 (89.7989)  Acc@5: 100.0000 (98.8745)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2220  Acc@1: 87.5000 (89.7371)  Acc@5: 100.0000 (98.8469)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1047  Acc@1: 93.7500 (89.7464)  Acc@5: 100.0000 (98.8657)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0471  Acc@1: 93.7500 (89.7122)  Acc@5: 100.0000 (98.8617)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1968  Acc@1: 87.5000 (89.7633)  Acc@5: 100.0000 (98.8580)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0561  Acc@1: 87.5000 (89.7709)  Acc@5: 100.0000 (98.8545)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1770  Acc@1: 93.7500 (89.7600)  Acc@5: 100.0000 (98.8600)  time: 0.1821  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1872 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.1770  Acc@1: 93.7500 (89.7600)  Acc@5: 100.0000 (98.8600)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:54  Loss: 1.0361 (1.0361)  ASR: 0.0000 (0.0000)  time: 0.3644  data: 0.1645  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0390 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.2076  data: 0.0152  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0387 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0387 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0399 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0387 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0388 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0394 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0388 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0388 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0395 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0403 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0386 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0384 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0384 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0358 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0389 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0380 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0370 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0384 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0379 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0387 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0411 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Loss: 1.0386 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0386 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0380 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0354 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0377 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0382 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0379 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0379 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0379 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0379 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Loss: 1.0379 (1.0389)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:17  Loss: 0.6634 (0.6634)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2856  data: 0.1668  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.6269 (0.5664)  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (97.7273)  time: 0.1318  data: 0.0154  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.6505 (0.6275)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (97.0238)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.6046 (0.5946)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (97.7823)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.5208 (0.5803)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.1707)  time: 0.1168  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.5170 (0.5652)  Acc@1: 87.5000 (87.9902)  Acc@5: 100.0000 (98.2843)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4734 (0.5506)  Acc@1: 87.5000 (88.3197)  Acc@5: 100.0000 (98.3607)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4730 (0.5485)  Acc@1: 93.7500 (88.5000)  Acc@5: 100.0000 (98.4000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 88.500 Acc@5 98.400 loss 0.549
Test: [Task 1]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 0.8739 (0.8739)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2614  data: 0.1407  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 86.6667 (88.4615)  Loss: 0.9781 (1.0629)  Acc@1: 81.2500 (78.9773)  Acc@5: 87.5000 (88.6364)  time: 0.1307  data: 0.0130  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 87.5000 (87.9195)  Loss: 1.0800 (1.0792)  Acc@1: 81.2500 (78.2738)  Acc@5: 87.5000 (87.2024)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 86.6667 (87.9271)  Loss: 1.0800 (1.0636)  Acc@1: 81.2500 (78.0242)  Acc@5: 87.5000 (87.7016)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (88.1849)  Loss: 0.9191 (1.0409)  Acc@1: 81.2500 (78.6585)  Acc@5: 93.7500 (88.5671)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (88.2434)  Loss: 0.9072 (1.0495)  Acc@1: 81.2500 (78.4314)  Acc@5: 93.7500 (88.2353)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (88.3908)  Loss: 0.7421 (1.0086)  Acc@1: 81.2500 (79.0984)  Acc@5: 93.7500 (89.0369)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (88.5778)  Loss: 0.7152 (0.9956)  Acc@1: 81.2500 (79.4000)  Acc@5: 93.7500 (89.2000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1199 s / it)
* Acc@1 79.400 Acc@5 89.200 loss 0.996
* Acc@1 nan ASR 88.578
Test: [Task 2]  [ 0/63]  eta: 0:00:17  Loss: 0.9401 (0.9401)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2779  data: 0.1607  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  Loss: 0.7788 (0.7756)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.7273)  time: 0.1311  data: 0.0149  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.7788 (0.8369)  Acc@1: 87.5000 (81.8452)  Acc@5: 100.0000 (97.0238)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.8202 (0.8251)  Acc@1: 81.2500 (82.0565)  Acc@5: 100.0000 (96.7742)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.8188 (0.8083)  Acc@1: 81.2500 (82.4695)  Acc@5: 100.0000 (96.9512)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.8124 (0.8110)  Acc@1: 81.2500 (81.8627)  Acc@5: 100.0000 (96.9363)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.7073 (0.7912)  Acc@1: 81.2500 (82.2746)  Acc@5: 100.0000 (97.4385)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.7003 (0.7825)  Acc@1: 81.2500 (82.4000)  Acc@5: 100.0000 (97.5000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1190 s / it)
* Acc@1 82.400 Acc@5 97.500 loss 0.783
Test: [Task 2]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 76.9231 (76.9231)  Loss: 1.6087 (1.6087)  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.2660  data: 0.1441  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  ACC: 84.6154 (84.1060)  Loss: 1.3167 (1.3319)  Acc@1: 75.0000 (72.7273)  Acc@5: 87.5000 (86.9318)  time: 0.1313  data: 0.0134  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 84.6154 (81.2287)  Loss: 1.3122 (1.3301)  Acc@1: 68.7500 (71.4286)  Acc@5: 87.5000 (87.5000)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 83.3333 (81.4220)  Loss: 1.0786 (1.3065)  Acc@1: 68.7500 (71.9758)  Acc@5: 87.5000 (87.5000)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 83.3333 (82.2107)  Loss: 1.2886 (1.2719)  Acc@1: 75.0000 (72.8659)  Acc@5: 87.5000 (87.6524)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 81.2500 (81.8811)  Loss: 1.2664 (1.2584)  Acc@1: 75.0000 (72.7941)  Acc@5: 87.5000 (87.6225)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (82.4683)  Loss: 1.1467 (1.2279)  Acc@1: 75.0000 (73.4631)  Acc@5: 87.5000 (88.1148)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (82.5450)  Loss: 1.0322 (1.2210)  Acc@1: 75.0000 (73.5000)  Acc@5: 93.7500 (88.2000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1200 s / it)
* Acc@1 73.500 Acc@5 88.200 loss 1.221
* Acc@1 nan ASR 82.545
Test: [Task 3]  [ 0/63]  eta: 0:00:19  Loss: 0.3129 (0.3129)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3086  data: 0.1896  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  Loss: 0.5699 (0.6420)  Acc@1: 87.5000 (84.6591)  Acc@5: 93.7500 (96.0227)  time: 0.1338  data: 0.0175  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.6955 (0.6479)  Acc@1: 81.2500 (83.9286)  Acc@5: 93.7500 (96.4286)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  Loss: 0.6732 (0.6535)  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (96.9758)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.5958 (0.6298)  Acc@1: 81.2500 (84.1463)  Acc@5: 100.0000 (97.4085)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.5707 (0.6304)  Acc@1: 87.5000 (84.5588)  Acc@5: 100.0000 (97.1814)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.7012 (0.6407)  Acc@1: 81.2500 (83.7090)  Acc@5: 100.0000 (97.3361)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7126 (0.6509)  Acc@1: 81.2500 (83.2000)  Acc@5: 100.0000 (97.3000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 83.200 Acc@5 97.300 loss 0.651
Test: [Task 3]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 92.3077 (92.3077)  Loss: 0.9407 (0.9407)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.2940  data: 0.1722  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 86.6667 (85.2564)  Loss: 1.0573 (1.1226)  Acc@1: 75.0000 (75.5682)  Acc@5: 87.5000 (85.7955)  time: 0.1338  data: 0.0159  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 81.2500 (83.6601)  Loss: 0.9966 (1.0459)  Acc@1: 75.0000 (76.1905)  Acc@5: 87.5000 (88.0952)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 78.5714 (82.7815)  Loss: 0.9966 (1.0265)  Acc@1: 68.7500 (75.6048)  Acc@5: 93.7500 (88.7097)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 80.0000 (83.8063)  Loss: 0.9902 (1.0078)  Acc@1: 75.0000 (76.5244)  Acc@5: 93.7500 (89.1768)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (84.3876)  Loss: 0.9902 (1.0024)  Acc@1: 81.2500 (76.9608)  Acc@5: 87.5000 (89.2157)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 83.3333 (83.8782)  Loss: 0.9223 (1.0121)  Acc@1: 75.0000 (76.3320)  Acc@5: 87.5000 (89.2418)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (83.3883)  Loss: 1.0164 (1.0206)  Acc@1: 75.0000 (75.9000)  Acc@5: 87.5000 (89.2000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1206 s / it)
* Acc@1 75.900 Acc@5 89.200 loss 1.021
* Acc@1 nan ASR 83.388
Test: [Task 4]  [ 0/63]  eta: 0:00:18  Loss: 0.7798 (0.7798)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2935  data: 0.1753  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  Loss: 0.7798 (0.7434)  Acc@1: 81.2500 (80.1136)  Acc@5: 93.7500 (95.4545)  time: 0.1328  data: 0.0162  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  Loss: 0.7095 (0.7450)  Acc@1: 81.2500 (80.0595)  Acc@5: 93.7500 (95.5357)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  Loss: 0.6816 (0.7203)  Acc@1: 81.2500 (81.4516)  Acc@5: 93.7500 (95.5645)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  Loss: 0.3902 (0.6460)  Acc@1: 93.7500 (83.6890)  Acc@5: 100.0000 (96.4939)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  Loss: 0.4129 (0.6620)  Acc@1: 93.7500 (84.1912)  Acc@5: 100.0000 (96.4461)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6563 (0.6586)  Acc@1: 87.5000 (84.4262)  Acc@5: 100.0000 (96.3115)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6963 (0.6616)  Acc@1: 87.5000 (84.4000)  Acc@5: 100.0000 (96.4000)  time: 0.1135  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 84.400 Acc@5 96.400 loss 0.662
Test: [Task 4]  [ 0/63]  eta: 0:00:18  ASR: nan (nan)  ACC: 81.2500 (81.2500)  Loss: 0.7798 (0.7798)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2916  data: 0.1712  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 80.0000 (80.0000)  Loss: 1.1920 (1.1794)  Acc@1: 75.0000 (72.7273)  Acc@5: 87.5000 (86.3636)  time: 0.1337  data: 0.0158  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 78.5714 (80.1325)  Loss: 1.2219 (1.2107)  Acc@1: 68.7500 (72.0238)  Acc@5: 87.5000 (85.4167)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (81.6327)  Loss: 1.2171 (1.2110)  Acc@1: 75.0000 (72.5806)  Acc@5: 81.2500 (85.0806)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.3077 (83.8710)  Loss: 0.9529 (1.1049)  Acc@1: 81.2500 (75.3049)  Acc@5: 87.5000 (86.8902)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.8571 (84.3537)  Loss: 0.9358 (1.0979)  Acc@1: 81.2500 (75.9804)  Acc@5: 87.5000 (87.2549)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (84.5980)  Loss: 1.0174 (1.0746)  Acc@1: 81.2500 (76.6393)  Acc@5: 87.5000 (87.6025)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (84.5133)  Loss: 1.0042 (1.0763)  Acc@1: 81.2500 (76.5000)  Acc@5: 87.5000 (87.6000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1203 s / it)
* Acc@1 76.500 Acc@5 87.600 loss 1.076
* Acc@1 nan ASR 84.513
Test: [Task 5]  [ 0/63]  eta: 0:00:16  Loss: 0.2617 (0.2617)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2654  data: 0.1448  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:06  Loss: 0.5041 (0.5586)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (97.7273)  time: 0.1303  data: 0.0135  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  Loss: 0.5041 (0.5320)  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (98.2143)  time: 0.1167  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  Loss: 0.4883 (0.5415)  Acc@1: 93.7500 (91.1290)  Acc@5: 100.0000 (98.3871)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  Loss: 0.4508 (0.5306)  Acc@1: 87.5000 (91.1585)  Acc@5: 100.0000 (98.1707)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  Loss: 0.5348 (0.5313)  Acc@1: 87.5000 (90.9314)  Acc@5: 100.0000 (98.4069)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5382 (0.5406)  Acc@1: 87.5000 (90.2664)  Acc@5: 100.0000 (98.4631)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5429 (0.5598)  Acc@1: 87.5000 (89.7000)  Acc@5: 100.0000 (98.4000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1187 s / it)
* Acc@1 89.700 Acc@5 98.400 loss 0.560
Test: [Task 5]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 0.4864 (0.4864)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.2806  data: 0.1609  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 93.7500 (90.7895)  Loss: 1.2509 (1.1908)  Acc@1: 81.2500 (78.4091)  Acc@5: 87.5000 (85.2273)  time: 0.1324  data: 0.0148  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 93.7500 (91.8919)  Loss: 1.0327 (1.0666)  Acc@1: 81.2500 (80.9524)  Acc@5: 87.5000 (87.2024)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 93.3333 (90.7449)  Loss: 0.7596 (1.0373)  Acc@1: 81.2500 (81.0484)  Acc@5: 93.7500 (88.3065)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 87.5000 (90.7217)  Loss: 1.0231 (1.0535)  Acc@1: 81.2500 (80.4878)  Acc@5: 87.5000 (87.5000)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (90.6593)  Loss: 0.9890 (1.0143)  Acc@1: 75.0000 (81.1275)  Acc@5: 87.5000 (88.6029)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (90.3448)  Loss: 0.9890 (1.0166)  Acc@1: 75.0000 (80.7377)  Acc@5: 93.7500 (88.6270)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (89.7982)  Loss: 1.0545 (1.0260)  Acc@1: 75.0000 (80.3000)  Acc@5: 93.7500 (88.7000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 80.300 Acc@5 88.700 loss 1.026
* Acc@1 nan ASR 89.798
Test: [Task 6]  [ 0/63]  eta: 0:00:24  Loss: 0.4236 (0.4236)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3954  data: 0.2781  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:07  Loss: 0.6499 (0.5906)  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (97.7273)  time: 0.1418  data: 0.0255  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  Loss: 0.6522 (0.6451)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (98.2143)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  Loss: 0.5987 (0.6449)  Acc@1: 87.5000 (83.0645)  Acc@5: 100.0000 (98.5887)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  Loss: 0.5987 (0.6849)  Acc@1: 81.2500 (81.0976)  Acc@5: 100.0000 (97.7134)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  Loss: 0.6564 (0.6711)  Acc@1: 81.2500 (81.8627)  Acc@5: 93.7500 (97.6716)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.6249 (0.6858)  Acc@1: 81.2500 (81.8648)  Acc@5: 100.0000 (97.6434)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6249 (0.6814)  Acc@1: 81.2500 (82.0000)  Acc@5: 100.0000 (97.7000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1209 s / it)
* Acc@1 82.000 Acc@5 97.700 loss 0.681
Test: [Task 6]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 0.7276 (0.7276)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2648  data: 0.1425  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 86.6667 (83.5443)  Loss: 0.9548 (1.0337)  Acc@1: 81.2500 (76.7045)  Acc@5: 93.7500 (90.3409)  time: 0.1311  data: 0.0132  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 84.6154 (82.9508)  Loss: 0.9548 (1.0304)  Acc@1: 75.0000 (76.4881)  Acc@5: 93.7500 (90.7738)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (83.5189)  Loss: 0.9054 (1.0383)  Acc@1: 75.0000 (76.4113)  Acc@5: 93.7500 (90.9274)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 83.3333 (81.7259)  Loss: 1.1495 (1.1079)  Acc@1: 75.0000 (74.2378)  Acc@5: 87.5000 (89.1768)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 81.2500 (82.3848)  Loss: 1.1786 (1.0785)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (89.5833)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (82.1670)  Loss: 1.0113 (1.0776)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (89.8566)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (82.2882)  Loss: 0.9270 (1.0673)  Acc@1: 75.0000 (75.2000)  Acc@5: 93.7500 (90.0000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1198 s / it)
* Acc@1 75.200 Acc@5 90.000 loss 1.067
* Acc@1 nan ASR 82.288
Test: [Task 7]  [ 0/63]  eta: 0:00:17  Loss: 0.6746 (0.6746)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2800  data: 0.1621  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:06  Loss: 0.6737 (0.6558)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (98.2955)  time: 0.1314  data: 0.0150  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  Loss: 0.6570 (0.6760)  Acc@1: 81.2500 (82.7381)  Acc@5: 100.0000 (96.7262)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  Loss: 0.6058 (0.6690)  Acc@1: 81.2500 (83.0645)  Acc@5: 100.0000 (96.7742)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  Loss: 0.5861 (0.6586)  Acc@1: 81.2500 (83.6890)  Acc@5: 100.0000 (96.7988)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  Loss: 0.6080 (0.6783)  Acc@1: 81.2500 (83.4559)  Acc@5: 93.7500 (96.4461)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6080 (0.6611)  Acc@1: 87.5000 (84.2213)  Acc@5: 100.0000 (96.7213)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6260 (0.6582)  Acc@1: 81.2500 (84.3000)  Acc@5: 100.0000 (96.7000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1190 s / it)
* Acc@1 84.300 Acc@5 96.700 loss 0.658
Test: [Task 7]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  ACC: 84.6154 (84.6154)  Loss: 1.5928 (1.5928)  Acc@1: 68.7500 (68.7500)  Acc@5: 81.2500 (81.2500)  time: 0.3103  data: 0.1898  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 84.6154 (84.4156)  Loss: 1.2756 (1.1783)  Acc@1: 68.7500 (73.8636)  Acc@5: 87.5000 (86.3636)  time: 0.1353  data: 0.0175  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (84.3333)  Loss: 1.2083 (1.1054)  Acc@1: 75.0000 (75.2976)  Acc@5: 87.5000 (86.6071)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 84.6154 (84.3182)  Loss: 1.0934 (1.1276)  Acc@1: 81.2500 (74.7984)  Acc@5: 87.5000 (86.0887)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 81.2500 (84.2466)  Loss: 1.1523 (1.1232)  Acc@1: 68.7500 (75.0000)  Acc@5: 87.5000 (86.2805)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 80.0000 (84.0000)  Loss: 1.1712 (1.1393)  Acc@1: 75.0000 (74.6324)  Acc@5: 87.5000 (86.2745)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (84.5800)  Loss: 1.0517 (1.1135)  Acc@1: 75.0000 (75.4098)  Acc@5: 87.5000 (86.9877)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (84.6413)  Loss: 1.0517 (1.1092)  Acc@1: 81.2500 (75.6000)  Acc@5: 87.5000 (87.1000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1205 s / it)
* Acc@1 75.600 Acc@5 87.100 loss 1.109
* Acc@1 nan ASR 84.641
Test: [Task 8]  [ 0/63]  eta: 0:00:19  Loss: 0.5216 (0.5216)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3054  data: 0.1888  max mem: 2386
Test: [Task 8]  [10/63]  eta: 0:00:07  Loss: 0.5216 (0.5434)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (97.7273)  time: 0.1335  data: 0.0174  max mem: 2386
Test: [Task 8]  [20/63]  eta: 0:00:05  Loss: 0.5356 (0.5944)  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (97.9167)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 8]  [30/63]  eta: 0:00:04  Loss: 0.5356 (0.5810)  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (97.9839)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 8]  [40/63]  eta: 0:00:02  Loss: 0.5355 (0.5882)  Acc@1: 87.5000 (86.2805)  Acc@5: 100.0000 (97.5610)  time: 0.1166  data: 0.0002  max mem: 2386
Test: [Task 8]  [50/63]  eta: 0:00:01  Loss: 0.5908 (0.5921)  Acc@1: 81.2500 (85.6618)  Acc@5: 93.7500 (97.5490)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.6945 (0.6104)  Acc@1: 81.2500 (85.3484)  Acc@5: 93.7500 (96.9262)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.6022 (0.6021)  Acc@1: 81.2500 (85.5000)  Acc@5: 93.7500 (97.0000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 8] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 85.500 Acc@5 97.000 loss 0.602
Test: [Task 8]  [ 0/63]  eta: 0:00:21  ASR: 0.0000 (0.0000)  ACC: 93.3333 (93.3333)  Loss: 0.9023 (0.9023)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.3416  data: 0.2197  max mem: 2386
Test: [Task 8]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 92.8571 (88.8199)  Loss: 1.0079 (0.9809)  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (89.2045)  time: 0.1379  data: 0.0202  max mem: 2386
Test: [Task 8]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 86.6667 (86.4687)  Loss: 1.0249 (1.0877)  Acc@1: 75.0000 (77.9762)  Acc@5: 87.5000 (88.0952)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 8]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 86.6667 (86.7117)  Loss: 1.1023 (1.1033)  Acc@1: 75.0000 (77.6210)  Acc@5: 87.5000 (87.7016)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 8]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (86.4549)  Loss: 0.8680 (1.0331)  Acc@1: 81.2500 (78.8110)  Acc@5: 93.7500 (88.8720)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 8]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 81.2500 (85.9269)  Loss: 0.9174 (1.0633)  Acc@1: 75.0000 (77.8186)  Acc@5: 87.5000 (88.2353)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 8]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (85.6341)  Loss: 0.9658 (1.0441)  Acc@1: 75.0000 (78.1762)  Acc@5: 87.5000 (88.4221)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 8]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 86.6667 (85.7768)  Loss: 0.8876 (1.0281)  Acc@1: 81.2500 (78.4000)  Acc@5: 87.5000 (88.6000)  time: 0.1146  data: 0.0002  max mem: 2386
Test: [Task 8] Total time: 0:00:07 (0.1209 s / it)
* Acc@1 78.400 Acc@5 88.600 loss 1.028
* Acc@1 nan ASR 85.777
[Average accuracy till task8]	Acc@1: 76.8500	Acc@5: 88.5750	Loss: 1.0680	Forgetting: 5.3143	Backward: -5.2286
Train: Epoch[1/5]  [  0/313]  eta: 0:01:59  Lr: 0.001875  Loss: 2.0978  Acc@1: 6.2500 (6.2500)  Acc@5: 56.2500 (56.2500)  time: 0.3829  data: 0.1931  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.6395  Acc@1: 56.2500 (50.0000)  Acc@5: 87.5000 (84.6591)  time: 0.2040  data: 0.0177  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.2906  Acc@1: 62.5000 (63.6905)  Acc@5: 93.7500 (86.3095)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.8851  Acc@1: 81.2500 (70.7661)  Acc@5: 93.7500 (89.9194)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.6202  Acc@1: 87.5000 (74.0854)  Acc@5: 100.0000 (91.7683)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.5944  Acc@1: 87.5000 (76.7157)  Acc@5: 100.0000 (92.6471)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.8511  Acc@1: 87.5000 (78.2787)  Acc@5: 100.0000 (93.4426)  time: 0.1860  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.7146  Acc@1: 87.5000 (79.4894)  Acc@5: 100.0000 (94.0141)  time: 0.1860  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.4870  Acc@1: 87.5000 (81.2500)  Acc@5: 100.0000 (94.5988)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.2823  Acc@1: 93.7500 (81.9368)  Acc@5: 100.0000 (95.0549)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.6086  Acc@1: 87.5000 (82.6114)  Acc@5: 100.0000 (95.4208)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1355  Acc@1: 87.5000 (83.3333)  Acc@5: 100.0000 (95.6644)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1225  Acc@1: 87.5000 (83.7293)  Acc@5: 100.0000 (95.8678)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2188  Acc@1: 81.2500 (83.5401)  Acc@5: 100.0000 (95.7538)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.3389  Acc@1: 81.2500 (83.6879)  Acc@5: 100.0000 (95.9663)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.5624  Acc@1: 87.5000 (84.1474)  Acc@5: 100.0000 (96.1507)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2822  Acc@1: 87.5000 (84.3556)  Acc@5: 100.0000 (96.2733)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.3998  Acc@1: 87.5000 (84.6857)  Acc@5: 100.0000 (96.4181)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2902  Acc@1: 87.5000 (84.9448)  Acc@5: 100.0000 (96.5470)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1719  Acc@1: 87.5000 (85.1440)  Acc@5: 100.0000 (96.5969)  time: 0.1861  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3889  Acc@1: 87.5000 (85.2923)  Acc@5: 100.0000 (96.7662)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2179  Acc@1: 87.5000 (85.2192)  Acc@5: 100.0000 (96.7713)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.0701  Acc@1: 87.5000 (85.4638)  Acc@5: 100.0000 (96.8609)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1056  Acc@1: 93.7500 (85.8225)  Acc@5: 100.0000 (96.9968)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0221  Acc@1: 93.7500 (85.8921)  Acc@5: 100.0000 (97.0695)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3345  Acc@1: 87.5000 (85.9562)  Acc@5: 100.0000 (97.1116)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1952  Acc@1: 87.5000 (86.1111)  Acc@5: 100.0000 (97.1743)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0887  Acc@1: 93.7500 (86.3930)  Acc@5: 100.0000 (97.2555)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1765  Acc@1: 93.7500 (86.5214)  Acc@5: 100.0000 (97.2420)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.4237  Acc@1: 93.7500 (86.6409)  Acc@5: 100.0000 (97.2723)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3830  Acc@1: 93.7500 (86.7317)  Acc@5: 100.0000 (97.3007)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0235  Acc@1: 87.5000 (86.7363)  Acc@5: 100.0000 (97.3473)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1262  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (97.3600)  time: 0.1820  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:00:58 (0.1870 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1262  Acc@1: 87.5000 (86.7800)  Acc@5: 100.0000 (97.3600)
Train: Epoch[1/5]  [  0/313]  eta: 0:01:59  Loss: 1.0664 (1.0664)  ASR: 0.0000 (0.0000)  time: 0.3828  data: 0.1857  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0640 (1.0630)  ASR: 0.0000 (0.0000)  time: 0.2087  data: 0.0171  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0589 (1.0598)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0535 (1.0576)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0528 (1.0561)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0498 (1.0549)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0492 (1.0541)  ASR: 0.0000 (0.0000)  time: 0.1903  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0490 (1.0534)  ASR: 0.0000 (0.0000)  time: 0.1901  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0487 (1.0527)  ASR: 0.0000 (0.0000)  time: 0.1898  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Loss: 1.0475 (1.0521)  ASR: 0.0000 (0.0000)  time: 0.1900  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0469 (1.0516)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0001  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0466 (1.0511)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0460 (1.0510)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0457 (1.0505)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0449 (1.0501)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0452 (1.0499)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0462 (1.0497)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0445 (1.0493)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0436 (1.0491)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0456 (1.0489)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0448 (1.0487)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0443 (1.0485)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Loss: 1.0426 (1.0482)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Loss: 1.0431 (1.0481)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0449 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0456 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0456 (1.0478)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0444 (1.0477)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0446 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0438 (1.0474)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0434 (1.0473)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0433 (1.0472)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0430 (1.0471)  ASR: 0.0000 (0.0000)  time: 0.1860  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1917 s / it)
Averaged stats: Loss: 1.0430 (1.0471)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.1104  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3611  data: 0.1718  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.4196  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (99.4318)  time: 0.2024  data: 0.0157  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.0804  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (99.7024)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0189  Acc@1: 93.7500 (91.3306)  Acc@5: 100.0000 (99.5968)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.2008  Acc@1: 87.5000 (91.1585)  Acc@5: 100.0000 (99.3902)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.0967  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (99.2647)  time: 0.1861  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0576  Acc@1: 93.7500 (91.3934)  Acc@5: 100.0000 (99.3852)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0501  Acc@1: 87.5000 (90.8451)  Acc@5: 100.0000 (99.2958)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.0339  Acc@1: 87.5000 (90.4321)  Acc@5: 100.0000 (99.3056)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.2209  Acc@1: 87.5000 (90.3159)  Acc@5: 100.0000 (99.2445)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.2099  Acc@1: 87.5000 (89.7277)  Acc@5: 100.0000 (99.1337)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1689  Acc@1: 87.5000 (89.8086)  Acc@5: 100.0000 (99.1554)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0141  Acc@1: 87.5000 (90.0826)  Acc@5: 100.0000 (99.1736)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2955  Acc@1: 93.7500 (89.9809)  Acc@5: 100.0000 (99.2366)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1986  Acc@1: 87.5000 (89.9823)  Acc@5: 100.0000 (99.2908)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.5822  Acc@1: 87.5000 (89.8179)  Acc@5: 100.0000 (99.2964)  time: 0.1871  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0901  Acc@1: 87.5000 (89.6351)  Acc@5: 100.0000 (99.2624)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1643  Acc@1: 87.5000 (89.5102)  Acc@5: 100.0000 (99.1959)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.2947  Acc@1: 93.7500 (89.6754)  Acc@5: 100.0000 (99.1713)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2090  Acc@1: 93.7500 (89.8887)  Acc@5: 100.0000 (99.1492)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.0623  Acc@1: 93.7500 (90.0187)  Acc@5: 100.0000 (99.1915)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0647  Acc@1: 93.7500 (90.0178)  Acc@5: 100.0000 (99.2002)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2809  Acc@1: 93.7500 (90.0452)  Acc@5: 100.0000 (99.1516)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0662  Acc@1: 93.7500 (90.1515)  Acc@5: 100.0000 (99.1342)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0152  Acc@1: 93.7500 (90.1971)  Acc@5: 100.0000 (99.1183)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2293  Acc@1: 93.7500 (90.1892)  Acc@5: 100.0000 (99.1036)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0623  Acc@1: 87.5000 (90.0383)  Acc@5: 100.0000 (99.0900)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0749  Acc@1: 87.5000 (90.2214)  Acc@5: 100.0000 (99.1236)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0661  Acc@1: 93.7500 (90.2580)  Acc@5: 100.0000 (99.1103)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1056  Acc@1: 93.7500 (90.3995)  Acc@5: 100.0000 (99.1409)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.2101  Acc@1: 93.7500 (90.3447)  Acc@5: 100.0000 (99.1071)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1672  Acc@1: 93.7500 (90.3939)  Acc@5: 100.0000 (99.1359)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0306  Acc@1: 93.7500 (90.4200)  Acc@5: 100.0000 (99.1400)  time: 0.1818  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1871 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0306  Acc@1: 93.7500 (90.4200)  Acc@5: 100.0000 (99.1400)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:11  Loss: 1.0409 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.4210  data: 0.2213  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:04  Loss: 1.0415 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.2126  data: 0.0203  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0415 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0422 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0429 (1.0425)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0435 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0419 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0416 (1.0424)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0417 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0422 (1.0423)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0396 (1.0421)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0398 (1.0419)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0409 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0389 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0415 (1.0416)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0403 (1.0415)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0386 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0401 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0423 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0398 (1.0414)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0389 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0389 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0413 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:16  Loss: 1.0413 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0401 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0400 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0399 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0403 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0411 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0398 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0395 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0417 (1.0413)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0405 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:01:00 (0.1926 s / it)
Averaged stats: Loss: 1.0405 (1.0412)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:48  Lr: 0.001875  Loss: -0.0911  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3456  data: 0.1560  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0020  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (99.4318)  time: 0.2016  data: 0.0144  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.2148  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (99.1071)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0887  Acc@1: 93.7500 (91.1290)  Acc@5: 100.0000 (99.3952)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0867  Acc@1: 93.7500 (91.9207)  Acc@5: 100.0000 (99.3902)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1043  Acc@1: 93.7500 (91.7892)  Acc@5: 100.0000 (99.1422)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: -0.1069  Acc@1: 93.7500 (91.7008)  Acc@5: 100.0000 (98.7705)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1242  Acc@1: 87.5000 (91.3732)  Acc@5: 100.0000 (98.5035)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.0784  Acc@1: 87.5000 (91.2809)  Acc@5: 100.0000 (98.3796)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.1299  Acc@1: 87.5000 (90.7967)  Acc@5: 100.0000 (98.4890)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1729  Acc@1: 93.7500 (91.2129)  Acc@5: 100.0000 (98.4530)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.0005  Acc@1: 93.7500 (91.4977)  Acc@5: 100.0000 (98.5923)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0942  Acc@1: 87.5000 (91.0640)  Acc@5: 100.0000 (98.3988)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0650  Acc@1: 87.5000 (91.0305)  Acc@5: 100.0000 (98.4733)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.2447  Acc@1: 87.5000 (90.4255)  Acc@5: 100.0000 (98.4929)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0704  Acc@1: 87.5000 (90.5629)  Acc@5: 100.0000 (98.5927)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0247  Acc@1: 93.7500 (90.7609)  Acc@5: 100.0000 (98.6801)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1384  Acc@1: 93.7500 (90.6798)  Acc@5: 100.0000 (98.6842)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.0581  Acc@1: 93.7500 (90.7459)  Acc@5: 100.0000 (98.6878)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1544  Acc@1: 93.7500 (90.6741)  Acc@5: 100.0000 (98.7238)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1811  Acc@1: 87.5000 (90.7338)  Acc@5: 100.0000 (98.7251)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0421  Acc@1: 93.7500 (90.8175)  Acc@5: 100.0000 (98.6967)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1326  Acc@1: 87.5000 (90.6957)  Acc@5: 100.0000 (98.7557)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0199  Acc@1: 87.5000 (90.7197)  Acc@5: 100.0000 (98.8095)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.1568  Acc@1: 93.7500 (90.8714)  Acc@5: 100.0000 (98.8589)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1015  Acc@1: 93.7500 (90.8367)  Acc@5: 100.0000 (98.8546)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.0599  Acc@1: 93.7500 (90.8525)  Acc@5: 100.0000 (98.8745)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0373  Acc@1: 93.7500 (90.8441)  Acc@5: 100.0000 (98.8699)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.1810  Acc@1: 93.7500 (90.8363)  Acc@5: 100.0000 (98.8657)  time: 0.1870  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0681  Acc@1: 93.7500 (90.9364)  Acc@5: 100.0000 (98.8832)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.0127  Acc@1: 93.7500 (90.9676)  Acc@5: 100.0000 (98.8787)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3250  Acc@1: 87.5000 (90.8963)  Acc@5: 100.0000 (98.8947)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.6551  Acc@1: 87.5000 (90.8800)  Acc@5: 100.0000 (98.8800)  time: 0.1824  data: 0.0001  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1871 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.6551  Acc@1: 87.5000 (90.8800)  Acc@5: 100.0000 (98.8800)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:46  Loss: 1.0353 (1.0353)  ASR: 0.0000 (0.0000)  time: 0.3411  data: 0.1450  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0379 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.2054  data: 0.0133  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0385 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0418 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1906  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0423 (1.0402)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0423 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0419 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0397 (1.0405)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0384 (1.0403)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0375 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0365 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0395 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0383 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0389 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0412 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0368 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0368 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0364 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0380 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0411 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0380 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0373 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0381 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1932  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Loss: 1.0365 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0368 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0393 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0395 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0372 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0365 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0373 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0377 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0382 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0382 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1862  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1923 s / it)
Averaged stats: Loss: 1.0382 (1.0391)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:40  Lr: 0.001875  Loss: 0.1163  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3226  data: 0.1337  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.0367  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (99.4318)  time: 0.1990  data: 0.0123  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: -0.1740  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (99.7024)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0638  Acc@1: 93.7500 (89.7177)  Acc@5: 100.0000 (98.9919)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.0129  Acc@1: 93.7500 (90.7012)  Acc@5: 100.0000 (98.6280)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1893  Acc@1: 93.7500 (91.1765)  Acc@5: 100.0000 (98.6520)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.1687  Acc@1: 93.7500 (91.0861)  Acc@5: 100.0000 (98.8730)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.2652  Acc@1: 93.7500 (91.1092)  Acc@5: 100.0000 (98.6796)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.0918  Acc@1: 93.7500 (90.9722)  Acc@5: 100.0000 (98.6111)  time: 0.1862  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5971  Acc@1: 87.5000 (90.7280)  Acc@5: 100.0000 (98.7637)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.1327  Acc@1: 87.5000 (90.5322)  Acc@5: 100.0000 (98.5767)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.3018  Acc@1: 93.7500 (90.7095)  Acc@5: 100.0000 (98.6486)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0144  Acc@1: 93.7500 (90.7025)  Acc@5: 100.0000 (98.7087)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0428  Acc@1: 93.7500 (90.7920)  Acc@5: 100.0000 (98.8073)  time: 0.1863  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.5454  Acc@1: 93.7500 (90.5585)  Acc@5: 100.0000 (98.7589)  time: 0.1867  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1098  Acc@1: 87.5000 (90.3974)  Acc@5: 100.0000 (98.7997)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0304  Acc@1: 87.5000 (90.5280)  Acc@5: 100.0000 (98.7578)  time: 0.1869  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0548  Acc@1: 93.7500 (90.7529)  Acc@5: 100.0000 (98.7573)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: -0.1597  Acc@1: 93.7500 (90.8494)  Acc@5: 100.0000 (98.7914)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2243  Acc@1: 87.5000 (90.5432)  Acc@5: 100.0000 (98.8547)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.2237  Acc@1: 87.5000 (90.4229)  Acc@5: 100.0000 (98.7873)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.3026  Acc@1: 87.5000 (90.5213)  Acc@5: 100.0000 (98.8152)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.1629  Acc@1: 93.7500 (90.4695)  Acc@5: 100.0000 (98.8405)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.1708  Acc@1: 87.5000 (90.3950)  Acc@5: 100.0000 (98.8907)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0666  Acc@1: 87.5000 (90.3786)  Acc@5: 100.0000 (98.9108)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1903  Acc@1: 87.5000 (90.3884)  Acc@5: 100.0000 (98.8795)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2671  Acc@1: 93.7500 (90.4933)  Acc@5: 100.0000 (98.8745)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0136  Acc@1: 87.5000 (90.3828)  Acc@5: 100.0000 (98.8007)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0551  Acc@1: 87.5000 (90.3247)  Acc@5: 100.0000 (98.8212)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.0907  Acc@1: 87.5000 (90.2921)  Acc@5: 100.0000 (98.8402)  time: 0.1862  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.2086  Acc@1: 93.7500 (90.4693)  Acc@5: 100.0000 (98.8372)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1087  Acc@1: 93.7500 (90.5748)  Acc@5: 100.0000 (98.8545)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1016  Acc@1: 100.0000 (90.6200)  Acc@5: 100.0000 (98.8600)  time: 0.1819  data: 0.0001  max mem: 2386
Train: Epoch[4/5] Total time: 0:00:58 (0.1869 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1016  Acc@1: 100.0000 (90.6200)  Acc@5: 100.0000 (98.8600)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:58  Loss: 1.0361 (1.0361)  ASR: 0.0000 (0.0000)  time: 0.3783  data: 0.1777  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0411 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.2090  data: 0.0164  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0390 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0375 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0374 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0384 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0384 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0402 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0372 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0367 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0410 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0410 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1907  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0388 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0001  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0388 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0391 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0400 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0400 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0386 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0370 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0383 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0372 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Loss: 1.0369 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Loss: 1.0377 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Loss: 1.0373 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0365 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0356 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0360 (1.0386)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0374 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0370 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0380 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0384 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1911  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0373 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0373 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1859  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Loss: 1.0373 (1.0384)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:45  Lr: 0.001875  Loss: -0.1067  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3372  data: 0.1474  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: -0.0255  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (98.8636)  time: 0.2005  data: 0.0136  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 0.0616  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (99.4048)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0410  Acc@1: 93.7500 (89.7177)  Acc@5: 100.0000 (98.7903)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1409  Acc@1: 87.5000 (89.7866)  Acc@5: 100.0000 (98.7805)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: -0.1002  Acc@1: 93.7500 (90.4412)  Acc@5: 100.0000 (98.8971)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.0927  Acc@1: 93.7500 (90.3689)  Acc@5: 100.0000 (98.9754)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.4747  Acc@1: 93.7500 (90.6690)  Acc@5: 100.0000 (98.9437)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:43  Lr: 0.001875  Loss: -0.1765  Acc@1: 93.7500 (91.1265)  Acc@5: 100.0000 (98.9969)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0166  Acc@1: 93.7500 (91.3462)  Acc@5: 100.0000 (99.0385)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.1717  Acc@1: 93.7500 (91.5842)  Acc@5: 100.0000 (99.0099)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1034  Acc@1: 93.7500 (91.6104)  Acc@5: 100.0000 (98.8739)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.3126  Acc@1: 93.7500 (91.5289)  Acc@5: 100.0000 (98.9153)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.1431  Acc@1: 87.5000 (91.3168)  Acc@5: 100.0000 (98.8550)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.1892  Acc@1: 87.5000 (91.3121)  Acc@5: 100.0000 (98.8032)  time: 0.1864  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.1004  Acc@1: 87.5000 (91.1010)  Acc@5: 100.0000 (98.8411)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1002  Acc@1: 87.5000 (90.9938)  Acc@5: 100.0000 (98.8742)  time: 0.1866  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2709  Acc@1: 87.5000 (91.0088)  Acc@5: 100.0000 (98.8304)  time: 0.1865  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.1145  Acc@1: 93.7500 (90.9876)  Acc@5: 100.0000 (98.8260)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.1630  Acc@1: 93.7500 (91.2631)  Acc@5: 100.0000 (98.8547)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0774  Acc@1: 93.7500 (91.3868)  Acc@5: 100.0000 (98.9117)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0217  Acc@1: 93.7500 (91.4100)  Acc@5: 100.0000 (98.9040)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1263  Acc@1: 93.7500 (91.4876)  Acc@5: 100.0000 (98.8971)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.1913  Acc@1: 93.7500 (91.4232)  Acc@5: 100.0000 (98.8907)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.5762  Acc@1: 93.7500 (91.3900)  Acc@5: 100.0000 (98.8330)  time: 0.1863  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.1549  Acc@1: 93.7500 (91.5588)  Acc@5: 100.0000 (98.7799)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.2233  Acc@1: 93.7500 (91.4511)  Acc@5: 100.0000 (98.8266)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0036  Acc@1: 87.5000 (91.3515)  Acc@5: 100.0000 (98.8469)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.0778  Acc@1: 87.5000 (91.2367)  Acc@5: 100.0000 (98.8212)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1607  Acc@1: 93.7500 (91.3230)  Acc@5: 100.0000 (98.7973)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.1344  Acc@1: 93.7500 (91.3621)  Acc@5: 100.0000 (98.7957)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0762  Acc@1: 93.7500 (91.3384)  Acc@5: 100.0000 (98.8143)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1970  Acc@1: 93.7500 (91.3600)  Acc@5: 100.0000 (98.8200)  time: 0.1823  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1871 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1970  Acc@1: 93.7500 (91.3600)  Acc@5: 100.0000 (98.8200)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:56  Loss: 1.0284 (1.0284)  ASR: 0.0000 (0.0000)  time: 0.3718  data: 0.1703  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0339 (1.0358)  ASR: 0.0000 (0.0000)  time: 0.2087  data: 0.0157  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0359 (1.0365)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0359 (1.0363)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0361 (1.0363)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0362 (1.0361)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0380 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0380 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0362 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0393 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0379 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0372 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1905  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0373 (1.0373)  ASR: 0.0000 (0.0000)  time: 0.1904  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0370 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0330 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0355 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0004  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0403 (1.0374)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0397 (1.0373)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0359 (1.0373)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0374 (1.0374)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0366 (1.0373)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0362 (1.0373)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0366 (1.0374)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Loss: 1.0366 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0353 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0353 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0364 (1.0372)  ASR: 0.0000 (0.0000)  time: 0.1917  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0364 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0358 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0362 (1.0371)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0368 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0353 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0342 (1.0370)  ASR: 0.0000 (0.0000)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1921 s / it)
Averaged stats: Loss: 1.0342 (1.0370)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:18  Loss: 0.8503 (0.8503)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2871  data: 0.1700  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.6708 (0.6120)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (97.7273)  time: 0.1319  data: 0.0157  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.6842 (0.6628)  Acc@1: 81.2500 (84.2262)  Acc@5: 100.0000 (97.9167)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.6694 (0.6456)  Acc@1: 81.2500 (84.4758)  Acc@5: 100.0000 (98.3871)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.5217 (0.6221)  Acc@1: 81.2500 (85.6707)  Acc@5: 100.0000 (98.4756)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.5104 (0.6058)  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (98.4069)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.4908 (0.5893)  Acc@1: 87.5000 (86.4754)  Acc@5: 100.0000 (98.3607)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.4884 (0.5841)  Acc@1: 93.7500 (86.6000)  Acc@5: 100.0000 (98.4000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 86.600 Acc@5 98.400 loss 0.584
Test: [Task 1]  [ 0/63]  eta: 0:00:18  ASR: nan (nan)  ACC: 81.2500 (81.2500)  Loss: 0.8503 (0.8503)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2860  data: 0.1666  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 85.7143 (87.0968)  Loss: 1.0374 (1.0540)  Acc@1: 81.2500 (76.7045)  Acc@5: 87.5000 (87.5000)  time: 0.1331  data: 0.0154  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (85.5219)  Loss: 1.0374 (1.0747)  Acc@1: 75.0000 (75.5952)  Acc@5: 93.7500 (88.0952)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 81.2500 (85.0000)  Loss: 0.9737 (1.0866)  Acc@1: 75.0000 (75.4032)  Acc@5: 93.7500 (88.3065)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 84.6154 (85.8603)  Loss: 0.8790 (1.0462)  Acc@1: 75.0000 (76.8293)  Acc@5: 87.5000 (88.8720)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (86.1833)  Loss: 0.8790 (1.0403)  Acc@1: 81.2500 (77.2059)  Acc@5: 87.5000 (88.8480)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.3077 (86.6286)  Loss: 0.9407 (1.0184)  Acc@1: 81.2500 (77.6639)  Acc@5: 87.5000 (89.0369)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (86.7336)  Loss: 0.8914 (1.0140)  Acc@1: 81.2500 (77.8000)  Acc@5: 87.5000 (89.1000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1202 s / it)
* Acc@1 77.800 Acc@5 89.100 loss 1.014
* Acc@1 nan ASR 86.734
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Loss: 1.0106 (1.0106)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3112  data: 0.1941  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:07  Loss: 0.7629 (0.7902)  Acc@1: 87.5000 (81.8182)  Acc@5: 100.0000 (96.5909)  time: 0.1342  data: 0.0179  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.7734 (0.8552)  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (96.4286)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.8509 (0.8331)  Acc@1: 81.2500 (80.2419)  Acc@5: 100.0000 (96.3710)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.7618 (0.8204)  Acc@1: 81.2500 (80.1829)  Acc@5: 100.0000 (96.4939)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.7682 (0.8119)  Acc@1: 81.2500 (80.6373)  Acc@5: 100.0000 (96.4461)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.7377 (0.7905)  Acc@1: 81.2500 (81.1475)  Acc@5: 100.0000 (97.0287)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.6892 (0.7820)  Acc@1: 81.2500 (81.2000)  Acc@5: 100.0000 (97.1000)  time: 0.1135  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 81.200 Acc@5 97.100 loss 0.782
Test: [Task 2]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  ACC: 78.5714 (78.5714)  Loss: 1.2035 (1.2035)  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.3204  data: 0.1956  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 84.6154 (81.4570)  Loss: 1.3556 (1.3555)  Acc@1: 68.7500 (69.8864)  Acc@5: 87.5000 (83.5227)  time: 0.1366  data: 0.0181  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 80.0000 (78.9116)  Loss: 1.3856 (1.3438)  Acc@1: 68.7500 (69.0476)  Acc@5: 87.5000 (84.5238)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 80.0000 (80.4545)  Loss: 1.3121 (1.2716)  Acc@1: 75.0000 (71.3710)  Acc@5: 87.5000 (85.6855)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 80.0000 (80.0687)  Loss: 1.1466 (1.2704)  Acc@1: 75.0000 (71.0366)  Acc@5: 87.5000 (85.8232)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 81.2500 (80.4709)  Loss: 1.1738 (1.2722)  Acc@1: 68.7500 (71.2010)  Acc@5: 87.5000 (85.5392)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (81.0563)  Loss: 1.0431 (1.2272)  Acc@1: 75.0000 (72.3361)  Acc@5: 93.7500 (86.7828)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (81.0326)  Loss: 1.0621 (1.2352)  Acc@1: 75.0000 (72.2000)  Acc@5: 87.5000 (86.7000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1209 s / it)
* Acc@1 72.200 Acc@5 86.700 loss 1.235
* Acc@1 nan ASR 81.033
Test: [Task 3]  [ 0/63]  eta: 0:00:18  Loss: 0.3206 (0.3206)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.2899  data: 0.1691  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  Loss: 0.5987 (0.6282)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.5909)  time: 0.1322  data: 0.0156  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.6923 (0.6462)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.0238)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  Loss: 0.6923 (0.6602)  Acc@1: 81.2500 (80.6452)  Acc@5: 100.0000 (96.9758)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.5984 (0.6371)  Acc@1: 81.2500 (81.5549)  Acc@5: 100.0000 (97.2561)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.6300 (0.6413)  Acc@1: 81.2500 (82.4755)  Acc@5: 100.0000 (96.9363)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.6792 (0.6517)  Acc@1: 81.2500 (82.3770)  Acc@5: 93.7500 (96.9262)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7111 (0.6562)  Acc@1: 81.2500 (82.2000)  Acc@5: 93.7500 (96.9000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 82.200 Acc@5 96.900 loss 0.656
Test: [Task 3]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 85.7143 (85.7143)  Loss: 0.8871 (0.8871)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.2982  data: 0.1769  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 81.2500 (80.2395)  Loss: 0.8824 (0.8926)  Acc@1: 75.0000 (76.1364)  Acc@5: 93.7500 (91.4773)  time: 0.1343  data: 0.0164  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 81.2500 (81.7891)  Loss: 0.9661 (0.9669)  Acc@1: 81.2500 (76.1905)  Acc@5: 93.7500 (91.0714)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 81.2500 (80.6167)  Loss: 1.0876 (1.0275)  Acc@1: 75.0000 (73.9919)  Acc@5: 87.5000 (89.9194)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 81.2500 (81.3445)  Loss: 1.0876 (1.0438)  Acc@1: 75.0000 (74.0854)  Acc@5: 87.5000 (89.4817)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 85.7143 (82.7027)  Loss: 0.9988 (1.0326)  Acc@1: 75.0000 (75.3676)  Acc@5: 87.5000 (89.3382)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 83.3333 (82.4859)  Loss: 1.0787 (1.0534)  Acc@1: 75.0000 (75.2049)  Acc@5: 87.5000 (89.3443)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 80.0000 (82.2687)  Loss: 1.0096 (1.0493)  Acc@1: 75.0000 (75.2000)  Acc@5: 87.5000 (89.5000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1205 s / it)
* Acc@1 75.200 Acc@5 89.500 loss 1.049
* Acc@1 nan ASR 82.269
Test: [Task 4]  [ 0/63]  eta: 0:00:17  Loss: 0.8199 (0.8199)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2787  data: 0.1597  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:06  Loss: 0.8156 (0.7598)  Acc@1: 81.2500 (80.6818)  Acc@5: 93.7500 (94.8864)  time: 0.1313  data: 0.0148  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  Loss: 0.7473 (0.7502)  Acc@1: 81.2500 (79.4643)  Acc@5: 93.7500 (95.5357)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  Loss: 0.6637 (0.7193)  Acc@1: 81.2500 (80.8468)  Acc@5: 93.7500 (95.7661)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  Loss: 0.4266 (0.6463)  Acc@1: 93.7500 (83.5366)  Acc@5: 100.0000 (96.6463)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  Loss: 0.4432 (0.6621)  Acc@1: 87.5000 (83.3333)  Acc@5: 100.0000 (96.4461)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.5769 (0.6631)  Acc@1: 81.2500 (83.5041)  Acc@5: 93.7500 (96.3115)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6130 (0.6638)  Acc@1: 81.2500 (83.5000)  Acc@5: 100.0000 (96.3000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 83.500 Acc@5 96.300 loss 0.664
Test: [Task 4]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  ACC: 84.6154 (84.6154)  Loss: 1.2253 (1.2253)  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.3185  data: 0.1973  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 81.2500 (81.9355)  Loss: 1.1789 (1.1897)  Acc@1: 75.0000 (72.7273)  Acc@5: 87.5000 (85.2273)  time: 0.1358  data: 0.0182  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 80.0000 (78.8591)  Loss: 1.0755 (1.2049)  Acc@1: 75.0000 (70.2381)  Acc@5: 87.5000 (86.3095)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 80.0000 (80.1354)  Loss: 1.0159 (1.1472)  Acc@1: 75.0000 (72.3790)  Acc@5: 87.5000 (87.5000)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.0000 (nan)  ACC: 92.3077 (82.7350)  Loss: 0.9200 (1.0771)  Acc@1: 81.2500 (75.1524)  Acc@5: 93.7500 (88.7195)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (82.9436)  Loss: 0.9397 (1.1008)  Acc@1: 81.2500 (75.1225)  Acc@5: 87.5000 (88.2353)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (83.1035)  Loss: 1.2144 (1.1070)  Acc@1: 75.0000 (75.3074)  Acc@5: 87.5000 (87.9098)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (83.0528)  Loss: 1.2416 (1.1204)  Acc@1: 75.0000 (75.2000)  Acc@5: 87.5000 (87.8000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1207 s / it)
* Acc@1 75.200 Acc@5 87.800 loss 1.120
* Acc@1 nan ASR 83.053
Test: [Task 5]  [ 0/63]  eta: 0:00:17  Loss: 0.3127 (0.3127)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2725  data: 0.1550  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:06  Loss: 0.4814 (0.6012)  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (97.1591)  time: 0.1307  data: 0.0143  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  Loss: 0.4814 (0.5750)  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (97.3214)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  Loss: 0.5043 (0.5819)  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (97.3790)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  Loss: 0.4865 (0.5677)  Acc@1: 87.5000 (89.6341)  Acc@5: 100.0000 (97.4085)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  Loss: 0.5064 (0.5734)  Acc@1: 87.5000 (89.4608)  Acc@5: 100.0000 (97.4265)  time: 0.1166  data: 0.0002  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5706 (0.5798)  Acc@1: 87.5000 (88.9344)  Acc@5: 100.0000 (97.5410)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5723 (0.5964)  Acc@1: 87.5000 (88.6000)  Acc@5: 100.0000 (97.3000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 88.600 Acc@5 97.300 loss 0.596
Test: [Task 5]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 1.3061 (1.3061)  Acc@1: 81.2500 (81.2500)  Acc@5: 81.2500 (81.2500)  time: 0.2795  data: 0.1516  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 92.3077 (88.6667)  Loss: 1.3061 (1.3025)  Acc@1: 75.0000 (75.5682)  Acc@5: 81.2500 (84.0909)  time: 0.1326  data: 0.0140  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 87.5000 (89.6667)  Loss: 0.9145 (1.0930)  Acc@1: 75.0000 (80.0595)  Acc@5: 87.5000 (87.5000)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.3077 (90.1602)  Loss: 0.8892 (1.1193)  Acc@1: 81.2500 (79.4355)  Acc@5: 93.7500 (87.0968)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (90.3448)  Loss: 1.2044 (1.0920)  Acc@1: 75.0000 (80.0305)  Acc@5: 87.5000 (87.5000)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 91.6667 (90.0976)  Loss: 1.1777 (1.1266)  Acc@1: 75.0000 (79.2892)  Acc@5: 87.5000 (86.8873)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (89.4186)  Loss: 1.1573 (1.1271)  Acc@1: 81.2500 (78.9959)  Acc@5: 87.5000 (87.1926)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (88.9898)  Loss: 1.1642 (1.1372)  Acc@1: 75.0000 (78.6000)  Acc@5: 87.5000 (86.9000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 78.600 Acc@5 86.900 loss 1.137
* Acc@1 nan ASR 88.990
Test: [Task 6]  [ 0/63]  eta: 0:00:17  Loss: 0.4567 (0.4567)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.2813  data: 0.1645  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:06  Loss: 0.6300 (0.6083)  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (97.7273)  time: 0.1315  data: 0.0152  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  Loss: 0.6513 (0.6763)  Acc@1: 81.2500 (83.3333)  Acc@5: 100.0000 (97.9167)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  Loss: 0.6080 (0.6689)  Acc@1: 81.2500 (83.6694)  Acc@5: 100.0000 (98.5887)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  Loss: 0.6603 (0.6991)  Acc@1: 81.2500 (81.8598)  Acc@5: 100.0000 (98.3232)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  Loss: 0.7849 (0.6964)  Acc@1: 75.0000 (81.8627)  Acc@5: 100.0000 (98.4069)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7579 (0.7121)  Acc@1: 81.2500 (81.5574)  Acc@5: 100.0000 (98.1557)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.7335 (0.7079)  Acc@1: 81.2500 (81.7000)  Acc@5: 100.0000 (98.2000)  time: 0.1135  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1189 s / it)
* Acc@1 81.700 Acc@5 98.200 loss 0.708
Test: [Task 6]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 0.6297 (0.6297)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2964  data: 0.1744  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 86.6667 (85.8974)  Loss: 0.9381 (0.9975)  Acc@1: 81.2500 (77.8409)  Acc@5: 93.7500 (90.9091)  time: 0.1343  data: 0.0161  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 80.0000 (83.1126)  Loss: 0.9697 (1.0589)  Acc@1: 75.0000 (75.5952)  Acc@5: 87.5000 (90.4762)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 81.2500 (83.4101)  Loss: 1.1748 (1.1740)  Acc@1: 75.0000 (73.7903)  Acc@5: 87.5000 (88.9113)  time: 0.1179  data: 0.0002  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 78.5714 (81.9757)  Loss: 1.3694 (1.1950)  Acc@1: 68.7500 (72.8659)  Acc@5: 87.5000 (88.8720)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 78.5714 (81.7558)  Loss: 0.9611 (1.1424)  Acc@1: 75.0000 (73.6520)  Acc@5: 93.7500 (89.9510)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (81.5490)  Loss: 0.9416 (1.1306)  Acc@1: 75.0000 (73.8730)  Acc@5: 93.7500 (90.1639)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (81.7778)  Loss: 0.8990 (1.1216)  Acc@1: 75.0000 (74.1000)  Acc@5: 93.7500 (90.2000)  time: 0.1146  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1204 s / it)
* Acc@1 74.100 Acc@5 90.200 loss 1.122
* Acc@1 nan ASR 81.778
Test: [Task 7]  [ 0/63]  eta: 0:00:19  Loss: 0.7039 (0.7039)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3051  data: 0.1875  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:07  Loss: 0.6266 (0.6321)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (98.2955)  time: 0.1335  data: 0.0173  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  Loss: 0.6266 (0.6722)  Acc@1: 81.2500 (83.6310)  Acc@5: 100.0000 (97.0238)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  Loss: 0.6174 (0.6634)  Acc@1: 81.2500 (83.8710)  Acc@5: 100.0000 (96.9758)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  Loss: 0.5947 (0.6500)  Acc@1: 87.5000 (84.7561)  Acc@5: 100.0000 (96.9512)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  Loss: 0.5947 (0.6728)  Acc@1: 87.5000 (84.0686)  Acc@5: 93.7500 (96.4461)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6508 (0.6615)  Acc@1: 81.2500 (84.4262)  Acc@5: 100.0000 (96.6189)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6970 (0.6639)  Acc@1: 81.2500 (84.3000)  Acc@5: 100.0000 (96.7000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1193 s / it)
* Acc@1 84.300 Acc@5 96.700 loss 0.664
Test: [Task 7]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 80.0000 (80.0000)  Loss: 0.8274 (0.8274)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.2580  data: 0.1377  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 84.6154 (82.2785)  Loss: 1.0034 (1.0846)  Acc@1: 75.0000 (73.8636)  Acc@5: 87.5000 (89.2045)  time: 0.1304  data: 0.0127  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (82.9431)  Loss: 1.0269 (1.1597)  Acc@1: 75.0000 (73.8095)  Acc@5: 87.5000 (86.6071)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (83.5586)  Loss: 0.9943 (1.1255)  Acc@1: 81.2500 (74.7984)  Acc@5: 87.5000 (86.8952)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (84.6154)  Loss: 0.7578 (1.0408)  Acc@1: 81.2500 (77.1341)  Acc@5: 93.7500 (88.4146)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 85.7143 (84.0756)  Loss: 0.8980 (1.0677)  Acc@1: 75.0000 (76.3480)  Acc@5: 93.7500 (87.8676)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (84.4244)  Loss: 1.1160 (1.0576)  Acc@1: 75.0000 (76.6393)  Acc@5: 87.5000 (88.1148)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (84.2684)  Loss: 1.1160 (1.0577)  Acc@1: 75.0000 (76.6000)  Acc@5: 87.5000 (88.3000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1198 s / it)
* Acc@1 76.600 Acc@5 88.300 loss 1.058
* Acc@1 nan ASR 84.268
Test: [Task 8]  [ 0/63]  eta: 0:00:18  Loss: 0.4393 (0.4393)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.2979  data: 0.1804  max mem: 2386
Test: [Task 8]  [10/63]  eta: 0:00:07  Loss: 0.5160 (0.5987)  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (97.7273)  time: 0.1329  data: 0.0166  max mem: 2386
Test: [Task 8]  [20/63]  eta: 0:00:05  Loss: 0.5634 (0.6408)  Acc@1: 87.5000 (83.9286)  Acc@5: 100.0000 (97.0238)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 8]  [30/63]  eta: 0:00:04  Loss: 0.5249 (0.6216)  Acc@1: 87.5000 (84.2742)  Acc@5: 100.0000 (97.5806)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 8]  [40/63]  eta: 0:00:02  Loss: 0.5236 (0.6247)  Acc@1: 87.5000 (84.7561)  Acc@5: 100.0000 (97.2561)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 8]  [50/63]  eta: 0:00:01  Loss: 0.6451 (0.6312)  Acc@1: 81.2500 (83.9461)  Acc@5: 93.7500 (97.0588)  time: 0.1167  data: 0.0003  max mem: 2386
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.7811 (0.6635)  Acc@1: 81.2500 (82.9918)  Acc@5: 93.7500 (96.4139)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.7397 (0.6557)  Acc@1: 81.2500 (83.1000)  Acc@5: 93.7500 (96.5000)  time: 0.1138  data: 0.0002  max mem: 2386
Test: [Task 8] Total time: 0:00:07 (0.1193 s / it)
* Acc@1 83.100 Acc@5 96.500 loss 0.656
Test: [Task 8]  [ 0/63]  eta: 0:00:19  ASR: nan (nan)  ACC: 93.7500 (93.7500)  Loss: 0.4393 (0.4393)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3141  data: 0.1939  max mem: 2386
Test: [Task 8]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 86.6667 (84.2767)  Loss: 1.0734 (1.0331)  Acc@1: 81.2500 (76.1364)  Acc@5: 87.5000 (88.6364)  time: 0.1358  data: 0.0179  max mem: 2386
Test: [Task 8]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 86.6667 (83.7662)  Loss: 1.0734 (1.0123)  Acc@1: 81.2500 (76.7857)  Acc@5: 87.5000 (88.9881)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 8]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 86.6667 (84.2920)  Loss: 0.9838 (1.0171)  Acc@1: 81.2500 (76.8145)  Acc@5: 87.5000 (88.9113)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 8]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (85.0420)  Loss: 1.0378 (1.0333)  Acc@1: 81.2500 (77.1341)  Acc@5: 87.5000 (88.1098)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 8]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 85.7143 (84.3750)  Loss: 1.0378 (1.0362)  Acc@1: 75.0000 (76.2255)  Acc@5: 87.5000 (87.9902)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 8]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (83.5414)  Loss: 0.9853 (1.0538)  Acc@1: 75.0000 (75.5123)  Acc@5: 87.5000 (87.5000)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 8]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (83.6102)  Loss: 0.9387 (1.0431)  Acc@1: 75.0000 (75.6000)  Acc@5: 87.5000 (87.6000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 8] Total time: 0:00:07 (0.1206 s / it)
* Acc@1 75.600 Acc@5 87.600 loss 1.043
* Acc@1 nan ASR 83.610
Test: [Task 9]  [ 0/63]  eta: 0:00:19  Loss: 0.1061 (0.1061)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3170  data: 0.1997  max mem: 2386
Test: [Task 9]  [10/63]  eta: 0:00:07  Loss: 0.3826 (0.4258)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (98.8636)  time: 0.1346  data: 0.0184  max mem: 2386
Test: [Task 9]  [20/63]  eta: 0:00:05  Loss: 0.3807 (0.4438)  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (98.5119)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 9]  [30/63]  eta: 0:00:04  Loss: 0.3090 (0.4196)  Acc@1: 87.5000 (90.5242)  Acc@5: 100.0000 (98.9919)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 9]  [40/63]  eta: 0:00:02  Loss: 0.3182 (0.4163)  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (98.9329)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 9]  [50/63]  eta: 0:00:01  Loss: 0.3862 (0.4234)  Acc@1: 87.5000 (89.9510)  Acc@5: 100.0000 (98.6520)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 9]  [60/63]  eta: 0:00:00  Loss: 0.2718 (0.4020)  Acc@1: 93.7500 (90.7787)  Acc@5: 100.0000 (98.7705)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.2671 (0.3956)  Acc@1: 93.7500 (90.9000)  Acc@5: 100.0000 (98.8000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 9] Total time: 0:00:07 (0.1196 s / it)
* Acc@1 90.900 Acc@5 98.800 loss 0.396
Test: [Task 9]  [ 0/63]  eta: 0:00:18  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 0.5194 (0.5194)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  time: 0.2967  data: 0.1746  max mem: 2386
Test: [Task 9]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 93.3333 (91.6129)  Loss: 0.9304 (1.0248)  Acc@1: 81.2500 (80.6818)  Acc@5: 87.5000 (86.9318)  time: 0.1346  data: 0.0162  max mem: 2386
Test: [Task 9]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 86.6667 (89.8990)  Loss: 0.9069 (1.0140)  Acc@1: 81.2500 (79.4643)  Acc@5: 87.5000 (86.9048)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 9]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.3077 (91.1765)  Loss: 0.9069 (0.9593)  Acc@1: 81.2500 (81.4516)  Acc@5: 87.5000 (88.3065)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 9]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (90.7057)  Loss: 0.9526 (0.9842)  Acc@1: 81.2500 (80.4878)  Acc@5: 87.5000 (87.8049)  time: 0.1182  data: 0.0003  max mem: 2386
Test: [Task 9]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 92.3077 (90.4828)  Loss: 0.9707 (0.9812)  Acc@1: 81.2500 (80.5147)  Acc@5: 87.5000 (87.8676)  time: 0.1182  data: 0.0003  max mem: 2386
Test: [Task 9]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (91.1494)  Loss: 0.9341 (0.9508)  Acc@1: 81.2500 (81.3525)  Acc@5: 87.5000 (88.2172)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 9]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.3333 (91.2261)  Loss: 0.9341 (0.9711)  Acc@1: 81.2500 (81.2000)  Acc@5: 87.5000 (88.0000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 9] Total time: 0:00:07 (0.1207 s / it)
* Acc@1 81.200 Acc@5 88.000 loss 0.971
* Acc@1 nan ASR 91.226
[Average accuracy till task9]	Acc@1: 76.2778	Acc@5: 88.2333	Loss: 1.0833	Forgetting: 5.8375	Backward: -5.7625
Train: Epoch[1/5]  [  0/313]  eta: 0:01:55  Lr: 0.001875  Loss: 2.0849  Acc@1: 0.0000 (0.0000)  Acc@5: 68.7500 (68.7500)  time: 0.3706  data: 0.1819  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.7893  Acc@1: 68.7500 (57.3864)  Acc@5: 87.5000 (86.9318)  time: 0.2037  data: 0.0167  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 1.2828  Acc@1: 75.0000 (70.2381)  Acc@5: 93.7500 (91.6667)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 1.0485  Acc@1: 87.5000 (75.6048)  Acc@5: 100.0000 (93.1452)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.8818  Acc@1: 87.5000 (78.6585)  Acc@5: 100.0000 (94.0549)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.7861  Acc@1: 93.7500 (81.2500)  Acc@5: 100.0000 (94.6078)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.7540  Acc@1: 93.7500 (82.7869)  Acc@5: 100.0000 (95.2869)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1933  Acc@1: 93.7500 (84.2430)  Acc@5: 100.0000 (95.8627)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4130  Acc@1: 93.7500 (84.9537)  Acc@5: 100.0000 (96.2191)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.3006  Acc@1: 87.5000 (85.5082)  Acc@5: 100.0000 (96.5659)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.3500  Acc@1: 87.5000 (86.1386)  Acc@5: 100.0000 (96.7203)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.2606  Acc@1: 87.5000 (86.5428)  Acc@5: 100.0000 (96.9032)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0851  Acc@1: 93.7500 (87.0868)  Acc@5: 100.0000 (97.0558)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.2202  Acc@1: 87.5000 (87.2615)  Acc@5: 100.0000 (97.0420)  time: 0.1879  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.6035  Acc@1: 87.5000 (87.3227)  Acc@5: 100.0000 (97.1188)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0233  Acc@1: 93.7500 (87.5414)  Acc@5: 100.0000 (97.3096)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.1722  Acc@1: 93.7500 (87.8106)  Acc@5: 100.0000 (97.3602)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1515  Acc@1: 93.7500 (88.1579)  Acc@5: 100.0000 (97.4781)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.0173  Acc@1: 93.7500 (88.3633)  Acc@5: 100.0000 (97.5829)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.0123  Acc@1: 93.7500 (88.5798)  Acc@5: 100.0000 (97.7094)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0387  Acc@1: 93.7500 (88.7127)  Acc@5: 100.0000 (97.7301)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0297  Acc@1: 93.7500 (88.9218)  Acc@5: 100.0000 (97.7784)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2184  Acc@1: 93.7500 (89.0554)  Acc@5: 100.0000 (97.8507)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0631  Acc@1: 93.7500 (89.1775)  Acc@5: 100.0000 (97.8355)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3143  Acc@1: 93.7500 (89.2376)  Acc@5: 100.0000 (97.9253)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.2543  Acc@1: 93.7500 (89.2679)  Acc@5: 100.0000 (98.0080)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4016  Acc@1: 87.5000 (89.2481)  Acc@5: 100.0000 (98.0603)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.2221  Acc@1: 87.5000 (89.3220)  Acc@5: 100.0000 (98.1089)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0447  Acc@1: 93.7500 (89.3683)  Acc@5: 100.0000 (98.0872)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.1929  Acc@1: 93.7500 (89.3041)  Acc@5: 100.0000 (98.1314)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0814  Acc@1: 87.5000 (89.3688)  Acc@5: 100.0000 (98.1728)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1264  Acc@1: 93.7500 (89.4695)  Acc@5: 100.0000 (98.1913)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1950  Acc@1: 93.7500 (89.5000)  Acc@5: 100.0000 (98.2000)  time: 0.1822  data: 0.0002  max mem: 2386
Train: Epoch[1/5] Total time: 0:00:58 (0.1876 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1950  Acc@1: 93.7500 (89.5000)  Acc@5: 100.0000 (98.2000)
Train: Epoch[1/5]  [  0/313]  eta: 0:01:58  Loss: 1.0630 (1.0630)  ASR: 0.0000 (0.0000)  time: 0.3775  data: 0.1779  max mem: 2386
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0605 (1.0602)  ASR: 0.0000 (0.0000)  time: 0.2098  data: 0.0164  max mem: 2386
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0569 (1.0580)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0546 (1.0566)  ASR: 0.0000 (0.0000)  time: 0.1943  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:54  Loss: 1.0520 (1.0549)  ASR: 0.0000 (0.0000)  time: 0.1937  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0505 (1.0541)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0493 (1.0531)  ASR: 0.0000 (0.0000)  time: 0.1936  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0468 (1.0523)  ASR: 0.0000 (0.0000)  time: 0.1938  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0474 (1.0520)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0470 (1.0513)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Loss: 1.0457 (1.0509)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Loss: 1.0478 (1.0507)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Loss: 1.0486 (1.0504)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Loss: 1.0454 (1.0501)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Loss: 1.0450 (1.0498)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Loss: 1.0450 (1.0495)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Loss: 1.0455 (1.0492)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Loss: 1.0454 (1.0490)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Loss: 1.0455 (1.0488)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Loss: 1.0450 (1.0486)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Loss: 1.0433 (1.0484)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Loss: 1.0439 (1.0482)  ASR: 0.0000 (0.0000)  time: 0.1932  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [220/313]  eta: 0:00:18  Loss: 1.0452 (1.0481)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [230/313]  eta: 0:00:16  Loss: 1.0461 (1.0481)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Loss: 1.0461 (1.0479)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Loss: 1.0441 (1.0478)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Loss: 1.0429 (1.0476)  ASR: 0.0000 (0.0000)  time: 0.1910  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Loss: 1.0434 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Loss: 1.0423 (1.0473)  ASR: 0.0000 (0.0000)  time: 0.1941  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Loss: 1.0423 (1.0472)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Loss: 1.0427 (1.0471)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Loss: 1.0442 (1.0470)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Loss: 1.0442 (1.0470)  ASR: 0.0000 (0.0000)  time: 0.1880  data: 0.0003  max mem: 2386
Train: Epoch[1/5] Total time: 0:01:00 (0.1933 s / it)
Averaged stats: Loss: 1.0442 (1.0470)  ASR: 0.0000 (0.0000)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.0384  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3666  data: 0.1784  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0289  Acc@1: 93.7500 (95.4545)  Acc@5: 100.0000 (100.0000)  time: 0.2035  data: 0.0164  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.0898  Acc@1: 93.7500 (93.4524)  Acc@5: 100.0000 (99.4048)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: -0.0855  Acc@1: 87.5000 (92.5403)  Acc@5: 100.0000 (99.3952)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1211  Acc@1: 93.7500 (92.2256)  Acc@5: 100.0000 (99.2378)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: -0.0395  Acc@1: 93.7500 (92.5245)  Acc@5: 100.0000 (99.2647)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.0253  Acc@1: 93.7500 (92.8279)  Acc@5: 100.0000 (99.3852)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1679  Acc@1: 93.7500 (92.6937)  Acc@5: 100.0000 (99.2958)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1751  Acc@1: 87.5000 (92.1296)  Acc@5: 100.0000 (99.0741)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: -0.0670  Acc@1: 93.7500 (92.3077)  Acc@5: 100.0000 (98.9698)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.0919  Acc@1: 93.7500 (92.0173)  Acc@5: 100.0000 (98.9480)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0841  Acc@1: 87.5000 (91.6667)  Acc@5: 100.0000 (98.9865)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.1479  Acc@1: 93.7500 (91.6839)  Acc@5: 100.0000 (98.9669)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: -0.0967  Acc@1: 93.7500 (91.9370)  Acc@5: 100.0000 (98.9504)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0981  Acc@1: 93.7500 (91.7996)  Acc@5: 100.0000 (98.9805)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0740  Acc@1: 93.7500 (91.8874)  Acc@5: 100.0000 (99.0066)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.0340  Acc@1: 93.7500 (91.7702)  Acc@5: 100.0000 (98.9907)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.2448  Acc@1: 93.7500 (91.9591)  Acc@5: 100.0000 (98.9766)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2899  Acc@1: 93.7500 (91.9544)  Acc@5: 100.0000 (98.9296)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.1085  Acc@1: 93.7500 (92.1466)  Acc@5: 100.0000 (98.9856)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0080  Acc@1: 93.7500 (92.1642)  Acc@5: 100.0000 (98.9739)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.0038  Acc@1: 93.7500 (92.2393)  Acc@5: 100.0000 (99.0225)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.2050  Acc@1: 93.7500 (92.2229)  Acc@5: 100.0000 (98.9819)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.0353  Acc@1: 93.7500 (92.2078)  Acc@5: 100.0000 (99.0260)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3725  Acc@1: 93.7500 (92.1680)  Acc@5: 100.0000 (99.0664)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0867  Acc@1: 93.7500 (92.0817)  Acc@5: 100.0000 (99.1036)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.0604  Acc@1: 93.7500 (92.0738)  Acc@5: 100.0000 (99.1140)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.5386  Acc@1: 93.7500 (92.0895)  Acc@5: 100.0000 (99.1236)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.1063  Acc@1: 93.7500 (92.0596)  Acc@5: 100.0000 (99.1326)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1241  Acc@1: 93.7500 (92.1177)  Acc@5: 100.0000 (99.1624)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1335  Acc@1: 93.7500 (92.0473)  Acc@5: 100.0000 (99.1902)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2055  Acc@1: 93.7500 (92.0418)  Acc@5: 100.0000 (99.1760)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.0045  Acc@1: 87.5000 (92.0400)  Acc@5: 100.0000 (99.1800)  time: 0.1823  data: 0.0002  max mem: 2386
Train: Epoch[2/5] Total time: 0:00:58 (0.1876 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.0045  Acc@1: 87.5000 (92.0400)  Acc@5: 100.0000 (99.1800)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:58  Loss: 1.0422 (1.0422)  ASR: 0.0000 (0.0000)  time: 0.3801  data: 0.1722  max mem: 2386
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0422 (1.0436)  ASR: 0.0000 (0.0000)  time: 0.2093  data: 0.0159  max mem: 2386
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0417 (1.0427)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0408 (1.0417)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0401 (1.0415)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0438 (1.0418)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0422 (1.0415)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0393 (1.0412)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0383 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0377 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Loss: 1.0413 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Loss: 1.0413 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Loss: 1.0408 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Loss: 1.0408 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Loss: 1.0413 (1.0411)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Loss: 1.0391 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1937  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Loss: 1.0404 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1935  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Loss: 1.0410 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Loss: 1.0411 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1932  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Loss: 1.0411 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1932  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Loss: 1.0407 (1.0410)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Loss: 1.0397 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Loss: 1.0383 (1.0409)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [230/313]  eta: 0:00:16  Loss: 1.0382 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Loss: 1.0398 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Loss: 1.0406 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1932  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Loss: 1.0385 (1.0407)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Loss: 1.0392 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1932  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Loss: 1.0400 (1.0407)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Loss: 1.0405 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Loss: 1.0403 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Loss: 1.0400 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Loss: 1.0387 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.1881  data: 0.0003  max mem: 2386
Train: Epoch[2/5] Total time: 0:01:00 (0.1932 s / it)
Averaged stats: Loss: 1.0387 (1.0408)  ASR: 0.0000 (0.0000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:53  Lr: 0.001875  Loss: 0.2158  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3615  data: 0.1731  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.1465  Acc@1: 87.5000 (92.6136)  Acc@5: 100.0000 (99.4318)  time: 0.2030  data: 0.0160  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: -0.0343  Acc@1: 87.5000 (91.3690)  Acc@5: 100.0000 (98.8095)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.0291  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (99.1935)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.0731  Acc@1: 93.7500 (92.0732)  Acc@5: 100.0000 (99.2378)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.1447  Acc@1: 93.7500 (92.0343)  Acc@5: 100.0000 (99.2647)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.1468  Acc@1: 93.7500 (91.8033)  Acc@5: 100.0000 (99.2828)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: -0.1773  Acc@1: 93.7500 (92.5176)  Acc@5: 100.0000 (99.3838)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.2039  Acc@1: 100.0000 (92.9012)  Acc@5: 100.0000 (99.4599)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0932  Acc@1: 93.7500 (92.7198)  Acc@5: 100.0000 (99.4505)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: -0.1451  Acc@1: 87.5000 (92.5743)  Acc@5: 100.0000 (99.4431)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0907  Acc@1: 93.7500 (92.9054)  Acc@5: 100.0000 (99.3806)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.0068  Acc@1: 93.7500 (92.9236)  Acc@5: 100.0000 (99.4318)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0474  Acc@1: 93.7500 (92.6050)  Acc@5: 100.0000 (99.3798)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0996  Acc@1: 93.7500 (92.8191)  Acc@5: 100.0000 (99.3794)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.0035  Acc@1: 93.7500 (92.8394)  Acc@5: 100.0000 (99.3377)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1116  Acc@1: 93.7500 (92.7019)  Acc@5: 100.0000 (99.3401)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0291  Acc@1: 93.7500 (92.7997)  Acc@5: 100.0000 (99.3787)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.1835  Acc@1: 93.7500 (92.7141)  Acc@5: 100.0000 (99.4130)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: -0.1411  Acc@1: 93.7500 (92.8665)  Acc@5: 100.0000 (99.4437)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.1737  Acc@1: 93.7500 (92.8794)  Acc@5: 100.0000 (99.4403)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.1349  Acc@1: 93.7500 (92.9799)  Acc@5: 100.0000 (99.4372)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.0680  Acc@1: 93.7500 (93.0713)  Acc@5: 100.0000 (99.4627)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0570  Acc@1: 93.7500 (93.0465)  Acc@5: 100.0000 (99.4318)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: -0.1909  Acc@1: 93.7500 (92.9201)  Acc@5: 100.0000 (99.4035)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.1607  Acc@1: 93.7500 (92.9034)  Acc@5: 100.0000 (99.3775)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: -0.0781  Acc@1: 93.7500 (93.0316)  Acc@5: 100.0000 (99.3774)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: -0.0116  Acc@1: 93.7500 (92.8736)  Acc@5: 100.0000 (99.4004)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.2121  Acc@1: 93.7500 (92.9715)  Acc@5: 100.0000 (99.3772)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0513  Acc@1: 93.7500 (93.0412)  Acc@5: 100.0000 (99.3986)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.1449  Acc@1: 93.7500 (93.0440)  Acc@5: 100.0000 (99.3771)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1258  Acc@1: 93.7500 (92.9863)  Acc@5: 100.0000 (99.3971)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1389  Acc@1: 93.7500 (93.0000)  Acc@5: 100.0000 (99.4000)  time: 0.1827  data: 0.0002  max mem: 2386
Train: Epoch[3/5] Total time: 0:00:58 (0.1877 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1389  Acc@1: 93.7500 (93.0000)  Acc@5: 100.0000 (99.4000)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:50  Loss: 1.0475 (1.0475)  ASR: 0.0000 (0.0000)  time: 0.3517  data: 0.1537  max mem: 2386
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Loss: 1.0406 (1.0408)  ASR: 0.0000 (0.0000)  time: 0.2076  data: 0.0143  max mem: 2386
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0397 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0385 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0385 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0411 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0404 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0394 (1.0399)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0394 (1.0400)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0407 (1.0401)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Loss: 1.0390 (1.0398)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Loss: 1.0374 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Loss: 1.0372 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Loss: 1.0369 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Loss: 1.0381 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Loss: 1.0399 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Loss: 1.0406 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Loss: 1.0370 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Loss: 1.0370 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Loss: 1.0404 (1.0397)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Loss: 1.0399 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Loss: 1.0387 (1.0396)  ASR: 0.0000 (0.0000)  time: 0.1941  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Loss: 1.0386 (1.0395)  ASR: 0.0000 (0.0000)  time: 0.1940  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [230/313]  eta: 0:00:16  Loss: 1.0369 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1936  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Loss: 1.0362 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Loss: 1.0382 (1.0394)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Loss: 1.0372 (1.0393)  ASR: 0.0000 (0.0000)  time: 0.1930  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Loss: 1.0364 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Loss: 1.0378 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Loss: 1.0384 (1.0392)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Loss: 1.0357 (1.0391)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Loss: 1.0347 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0003  max mem: 2386
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Loss: 1.0357 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1888  data: 0.0003  max mem: 2386
Train: Epoch[3/5] Total time: 0:01:00 (0.1933 s / it)
Averaged stats: Loss: 1.0357 (1.0390)  ASR: 0.0000 (0.0000)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:07  Lr: 0.001875  Loss: 0.4246  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.4086  data: 0.2169  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:02  Lr: 0.001875  Loss: -0.0986  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (100.0000)  time: 0.2076  data: 0.0200  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.1000  Acc@1: 93.7500 (93.1548)  Acc@5: 100.0000 (99.7024)  time: 0.1875  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.001875  Loss: -0.0592  Acc@1: 93.7500 (92.9435)  Acc@5: 100.0000 (99.7984)  time: 0.1872  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: 0.1055  Acc@1: 93.7500 (93.1402)  Acc@5: 100.0000 (99.8476)  time: 0.1873  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.0086  Acc@1: 93.7500 (93.0147)  Acc@5: 100.0000 (99.7549)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: 0.3508  Acc@1: 93.7500 (92.4180)  Acc@5: 100.0000 (99.5902)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: -0.1984  Acc@1: 87.5000 (91.9014)  Acc@5: 100.0000 (99.4718)  time: 0.1871  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.2274  Acc@1: 87.5000 (91.4352)  Acc@5: 100.0000 (99.3827)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0042  Acc@1: 93.7500 (91.6896)  Acc@5: 100.0000 (99.3819)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.1803  Acc@1: 93.7500 (91.8317)  Acc@5: 100.0000 (99.3812)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.0560  Acc@1: 93.7500 (91.7793)  Acc@5: 100.0000 (99.3806)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.1630  Acc@1: 93.7500 (91.8388)  Acc@5: 100.0000 (99.3802)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0742  Acc@1: 93.7500 (92.0802)  Acc@5: 100.0000 (99.4275)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: -0.0289  Acc@1: 93.7500 (92.1986)  Acc@5: 100.0000 (99.4681)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.0917  Acc@1: 93.7500 (92.4255)  Acc@5: 100.0000 (99.5033)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.1900  Acc@1: 93.7500 (92.6242)  Acc@5: 100.0000 (99.4953)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.0142  Acc@1: 93.7500 (92.3611)  Acc@5: 100.0000 (99.3421)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.3695  Acc@1: 93.7500 (92.4033)  Acc@5: 100.0000 (99.3094)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.0865  Acc@1: 93.7500 (92.3102)  Acc@5: 100.0000 (99.3455)  time: 0.1875  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.1933  Acc@1: 93.7500 (92.2264)  Acc@5: 100.0000 (99.3470)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.1409  Acc@1: 93.7500 (92.3282)  Acc@5: 100.0000 (99.3780)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1082  Acc@1: 93.7500 (92.3925)  Acc@5: 100.0000 (99.3213)  time: 0.1881  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: 0.2345  Acc@1: 93.7500 (92.2890)  Acc@5: 100.0000 (99.3506)  time: 0.1881  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.0305  Acc@1: 93.7500 (92.3237)  Acc@5: 100.0000 (99.3776)  time: 0.1877  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.3570  Acc@1: 93.7500 (92.2560)  Acc@5: 100.0000 (99.4024)  time: 0.1874  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.1415  Acc@1: 93.7500 (92.1935)  Acc@5: 100.0000 (99.3774)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0295  Acc@1: 93.7500 (92.2048)  Acc@5: 100.0000 (99.4004)  time: 0.1873  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: 0.0963  Acc@1: 93.7500 (92.1931)  Acc@5: 100.0000 (99.3995)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.0892  Acc@1: 87.5000 (92.2036)  Acc@5: 100.0000 (99.4201)  time: 0.1876  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: -0.0550  Acc@1: 93.7500 (92.2135)  Acc@5: 100.0000 (99.4394)  time: 0.1877  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1752  Acc@1: 93.7500 (92.1624)  Acc@5: 100.0000 (99.4172)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: -0.1067  Acc@1: 93.7500 (92.1400)  Acc@5: 100.0000 (99.4200)  time: 0.1831  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:00:58 (0.1880 s / it)
Averaged stats: Lr: 0.001875  Loss: -0.1067  Acc@1: 93.7500 (92.1400)  Acc@5: 100.0000 (99.4200)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:58  Loss: 1.0336 (1.0336)  ASR: 0.0000 (0.0000)  time: 0.3790  data: 0.1792  max mem: 2386
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0372 (1.0376)  ASR: 0.0000 (0.0000)  time: 0.2102  data: 0.0166  max mem: 2386
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Loss: 1.0383 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1935  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Loss: 1.0384 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1937  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:54  Loss: 1.0384 (1.0390)  ASR: 0.0000 (0.0000)  time: 0.1938  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0375 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1945  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0379 (1.0389)  ASR: 0.0000 (0.0000)  time: 0.1942  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0378 (1.0388)  ASR: 0.0000 (0.0000)  time: 0.1936  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0378 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1953  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0388 (1.0387)  ASR: 0.0000 (0.0000)  time: 0.1947  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Loss: 1.0363 (1.0385)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Loss: 1.0357 (1.0384)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Loss: 1.0359 (1.0383)  ASR: 0.0000 (0.0000)  time: 0.1935  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Loss: 1.0345 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1947  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Loss: 1.0360 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1935  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Loss: 1.0373 (1.0382)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Loss: 1.0376 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Loss: 1.0367 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Loss: 1.0358 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Loss: 1.0374 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1931  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Loss: 1.0397 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1934  data: 0.0004  max mem: 2386
Train: Epoch[4/5]  [210/313]  eta: 0:00:20  Loss: 1.0380 (1.0381)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [220/313]  eta: 0:00:18  Loss: 1.0365 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [230/313]  eta: 0:00:16  Loss: 1.0349 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Loss: 1.0337 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1921  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Loss: 1.0378 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Loss: 1.0384 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Loss: 1.0388 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Loss: 1.0360 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Loss: 1.0355 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1933  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Loss: 1.0378 (1.0379)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0003  max mem: 2386
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Loss: 1.0380 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Loss: 1.0394 (1.0380)  ASR: 0.0000 (0.0000)  time: 0.1880  data: 0.0002  max mem: 2386
Train: Epoch[4/5] Total time: 0:01:00 (0.1937 s / it)
Averaged stats: Loss: 1.0394 (1.0380)  ASR: 0.0000 (0.0000)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:54  Lr: 0.001875  Loss: 0.0297  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  time: 0.3656  data: 0.1763  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.0732  Acc@1: 87.5000 (90.9091)  Acc@5: 100.0000 (100.0000)  time: 0.2031  data: 0.0162  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.0713  Acc@1: 93.7500 (91.0714)  Acc@5: 100.0000 (100.0000)  time: 0.1875  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.1884  Acc@1: 93.7500 (91.7339)  Acc@5: 100.0000 (100.0000)  time: 0.1882  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.001875  Loss: -0.1421  Acc@1: 93.7500 (92.5305)  Acc@5: 100.0000 (99.8476)  time: 0.1879  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.001875  Loss: 0.4999  Acc@1: 93.7500 (92.5245)  Acc@5: 100.0000 (99.6324)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.001875  Loss: -0.1221  Acc@1: 93.7500 (93.0328)  Acc@5: 100.0000 (99.6926)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.1147  Acc@1: 93.7500 (92.8697)  Acc@5: 100.0000 (99.7359)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.001875  Loss: -0.1378  Acc@1: 93.7500 (92.9784)  Acc@5: 100.0000 (99.6142)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.0284  Acc@1: 93.7500 (93.2692)  Acc@5: 100.0000 (99.5879)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.0648  Acc@1: 93.7500 (93.2550)  Acc@5: 100.0000 (99.6287)  time: 0.1868  data: 0.0001  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.001875  Loss: -0.1349  Acc@1: 93.7500 (93.3559)  Acc@5: 100.0000 (99.5495)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.001875  Loss: -0.0135  Acc@1: 93.7500 (93.3884)  Acc@5: 100.0000 (99.5351)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.0996  Acc@1: 93.7500 (93.2252)  Acc@5: 100.0000 (99.3798)  time: 0.1865  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.1774  Acc@1: 93.7500 (93.2181)  Acc@5: 100.0000 (99.3351)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.001875  Loss: -0.1700  Acc@1: 93.7500 (93.0877)  Acc@5: 100.0000 (99.3791)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.001875  Loss: -0.2087  Acc@1: 93.7500 (93.0901)  Acc@5: 100.0000 (99.3789)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:26  Lr: 0.001875  Loss: -0.0363  Acc@1: 93.7500 (93.0921)  Acc@5: 100.0000 (99.3421)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.0497  Acc@1: 93.7500 (93.0939)  Acc@5: 100.0000 (99.3094)  time: 0.1866  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2967  Acc@1: 93.7500 (93.1283)  Acc@5: 100.0000 (99.3128)  time: 0.1867  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.001875  Loss: -0.0620  Acc@1: 93.7500 (93.1592)  Acc@5: 100.0000 (99.3470)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.001875  Loss: -0.0860  Acc@1: 93.7500 (93.0687)  Acc@5: 100.0000 (99.2891)  time: 0.1870  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.001875  Loss: -0.1634  Acc@1: 93.7500 (92.9864)  Acc@5: 100.0000 (99.2647)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.001875  Loss: -0.0743  Acc@1: 93.7500 (92.9924)  Acc@5: 100.0000 (99.2965)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.3412  Acc@1: 93.7500 (92.9201)  Acc@5: 100.0000 (99.3257)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: -0.0234  Acc@1: 93.7500 (93.0030)  Acc@5: 100.0000 (99.3277)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.7582  Acc@1: 93.7500 (92.9837)  Acc@5: 100.0000 (99.3056)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.001875  Loss: 0.0812  Acc@1: 93.7500 (93.0120)  Acc@5: 100.0000 (99.3312)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.001875  Loss: -0.1414  Acc@1: 93.7500 (93.0383)  Acc@5: 100.0000 (99.3105)  time: 0.1868  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: -0.1310  Acc@1: 93.7500 (93.0627)  Acc@5: 100.0000 (99.2483)  time: 0.1872  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.1325  Acc@1: 93.7500 (93.0440)  Acc@5: 100.0000 (99.2733)  time: 0.1871  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1504  Acc@1: 93.7500 (93.0064)  Acc@5: 100.0000 (99.2564)  time: 0.1869  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.0013  Acc@1: 87.5000 (93.0200)  Acc@5: 100.0000 (99.2600)  time: 0.1824  data: 0.0001  max mem: 2386
Train: Epoch[5/5] Total time: 0:00:58 (0.1874 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.0013  Acc@1: 87.5000 (93.0200)  Acc@5: 100.0000 (99.2600)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:57  Loss: 1.0332 (1.0332)  ASR: 0.0000 (0.0000)  time: 0.3758  data: 0.1793  max mem: 2386
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Loss: 1.0338 (1.0351)  ASR: 0.0000 (0.0000)  time: 0.2080  data: 0.0165  max mem: 2386
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Loss: 1.0337 (1.0348)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Loss: 1.0363 (1.0356)  ASR: 0.0000 (0.0000)  time: 0.1914  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Loss: 1.0375 (1.0361)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Loss: 1.0375 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Loss: 1.0364 (1.0365)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Loss: 1.0349 (1.0365)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Loss: 1.0372 (1.0364)  ASR: 0.0000 (0.0000)  time: 0.1927  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Loss: 1.0379 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1925  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Loss: 1.0380 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Loss: 1.0366 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Loss: 1.0353 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1924  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Loss: 1.0367 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1926  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Loss: 1.0381 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1928  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Loss: 1.0360 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1923  data: 0.0003  max mem: 2386
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Loss: 1.0340 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Loss: 1.0361 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1912  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Loss: 1.0369 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Loss: 1.0364 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Loss: 1.0354 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Loss: 1.0360 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1922  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Loss: 1.0362 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1929  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [230/313]  eta: 0:00:16  Loss: 1.0367 (1.0368)  ASR: 0.0000 (0.0000)  time: 0.1920  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Loss: 1.0345 (1.0367)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Loss: 1.0319 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1909  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Loss: 1.0325 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1913  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Loss: 1.0346 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1916  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Loss: 1.0344 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1918  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Loss: 1.0347 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1919  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Loss: 1.0347 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1915  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Loss: 1.0364 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1908  data: 0.0002  max mem: 2386
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Loss: 1.0364 (1.0366)  ASR: 0.0000 (0.0000)  time: 0.1864  data: 0.0002  max mem: 2386
Train: Epoch[5/5] Total time: 0:01:00 (0.1923 s / it)
Averaged stats: Loss: 1.0364 (1.0366)  ASR: 0.0000 (0.0000)
Test: [Task 1]  [ 0/63]  eta: 0:00:16  Loss: 0.7991 (0.7991)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  time: 0.2681  data: 0.1466  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:06  Loss: 0.6740 (0.6424)  Acc@1: 81.2500 (83.5227)  Acc@5: 100.0000 (97.1591)  time: 0.1305  data: 0.0137  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  Loss: 0.7153 (0.6836)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (96.7262)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  Loss: 0.7388 (0.6661)  Acc@1: 81.2500 (84.4758)  Acc@5: 100.0000 (97.5806)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  Loss: 0.5568 (0.6526)  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (97.7134)  time: 0.1166  data: 0.0002  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  Loss: 0.5386 (0.6390)  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (97.7941)  time: 0.1166  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  Loss: 0.5185 (0.6166)  Acc@1: 87.5000 (86.2705)  Acc@5: 100.0000 (97.8484)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  Loss: 0.5145 (0.6125)  Acc@1: 87.5000 (86.4000)  Acc@5: 100.0000 (97.9000)  time: 0.1135  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1188 s / it)
* Acc@1 86.400 Acc@5 97.900 loss 0.612
Test: [Task 1]  [ 0/63]  eta: 0:00:24  ASR: 0.0000 (0.0000)  ACC: 80.0000 (80.0000)  Loss: 1.2600 (1.2600)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  time: 0.3888  data: 0.2676  max mem: 2386
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  ACC: 80.0000 (82.1656)  Loss: 1.1745 (1.1469)  Acc@1: 75.0000 (73.2955)  Acc@5: 87.5000 (88.0682)  time: 0.1424  data: 0.0246  max mem: 2386
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 80.0000 (81.3954)  Loss: 1.0654 (1.1579)  Acc@1: 68.7500 (72.9167)  Acc@5: 87.5000 (88.0952)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 81.2500 (82.9596)  Loss: 0.9656 (1.1235)  Acc@1: 75.0000 (74.7984)  Acc@5: 93.7500 (89.3145)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (84.4332)  Loss: 0.9238 (1.0827)  Acc@1: 81.2500 (76.2195)  Acc@5: 93.7500 (89.3293)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (84.7203)  Loss: 0.8883 (1.0743)  Acc@1: 81.2500 (76.2255)  Acc@5: 87.5000 (89.3382)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 87.5000 (85.3907)  Loss: 0.8883 (1.0305)  Acc@1: 75.0000 (77.3566)  Acc@5: 93.7500 (89.8566)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 87.5000 (85.5568)  Loss: 0.7846 (1.0132)  Acc@1: 81.2500 (77.7000)  Acc@5: 93.7500 (90.1000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 1] Total time: 0:00:07 (0.1218 s / it)
* Acc@1 77.700 Acc@5 90.100 loss 1.013
* Acc@1 nan ASR 85.557
Test: [Task 2]  [ 0/63]  eta: 0:00:17  Loss: 1.0522 (1.0522)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.2813  data: 0.1648  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:06  Loss: 0.7467 (0.7859)  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (96.5909)  time: 0.1316  data: 0.0152  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  Loss: 0.7467 (0.8438)  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (96.4286)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  Loss: 0.8573 (0.8314)  Acc@1: 75.0000 (78.8306)  Acc@5: 93.7500 (96.1694)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  Loss: 0.7839 (0.8193)  Acc@1: 75.0000 (78.8110)  Acc@5: 93.7500 (96.4939)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  Loss: 0.7699 (0.8080)  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (96.5686)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  Loss: 0.7244 (0.7886)  Acc@1: 81.2500 (79.7131)  Acc@5: 100.0000 (96.9262)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  Loss: 0.7155 (0.7854)  Acc@1: 81.2500 (79.5000)  Acc@5: 100.0000 (97.0000)  time: 0.1137  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1190 s / it)
* Acc@1 79.500 Acc@5 97.000 loss 0.785
Test: [Task 2]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  ACC: 73.3333 (73.3333)  Loss: 1.2731 (1.2731)  Acc@1: 68.7500 (68.7500)  Acc@5: 87.5000 (87.5000)  time: 0.3084  data: 0.1872  max mem: 2386
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 86.6667 (83.9506)  Loss: 1.1200 (1.1082)  Acc@1: 75.0000 (77.2727)  Acc@5: 87.5000 (89.2045)  time: 0.1351  data: 0.0172  max mem: 2386
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 85.7143 (80.5281)  Loss: 1.1206 (1.2181)  Acc@1: 75.0000 (72.6190)  Acc@5: 87.5000 (87.5000)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 75.0000 (79.4702)  Loss: 1.1206 (1.1675)  Acc@1: 68.7500 (72.5806)  Acc@5: 87.5000 (88.1048)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 78.5714 (79.5681)  Loss: 1.0779 (1.1418)  Acc@1: 75.0000 (73.0183)  Acc@5: 87.5000 (88.7195)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 80.0000 (80.1342)  Loss: 1.1119 (1.1479)  Acc@1: 75.0000 (73.1618)  Acc@5: 87.5000 (88.3578)  time: 0.1181  data: 0.0003  max mem: 2386
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 85.7143 (80.8774)  Loss: 1.1196 (1.1373)  Acc@1: 75.0000 (73.6680)  Acc@5: 87.5000 (88.4221)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 84.6154 (80.6381)  Loss: 1.1197 (1.1495)  Acc@1: 75.0000 (73.3000)  Acc@5: 87.5000 (88.3000)  time: 0.1150  data: 0.0002  max mem: 2386
Test: [Task 2] Total time: 0:00:07 (0.1208 s / it)
* Acc@1 73.300 Acc@5 88.300 loss 1.149
* Acc@1 nan ASR 80.638
Test: [Task 3]  [ 0/63]  eta: 0:00:19  Loss: 0.2537 (0.2537)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3099  data: 0.1930  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  Loss: 0.6672 (0.6243)  Acc@1: 81.2500 (85.2273)  Acc@5: 100.0000 (97.1591)  time: 0.1339  data: 0.0178  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  Loss: 0.6672 (0.6337)  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (97.3214)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  Loss: 0.6215 (0.6396)  Acc@1: 75.0000 (82.8629)  Acc@5: 100.0000 (97.1774)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  Loss: 0.6131 (0.6321)  Acc@1: 81.2500 (83.5366)  Acc@5: 100.0000 (97.4085)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  Loss: 0.6729 (0.6409)  Acc@1: 87.5000 (83.9461)  Acc@5: 93.7500 (96.8137)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  Loss: 0.6999 (0.6469)  Acc@1: 81.2500 (83.6066)  Acc@5: 93.7500 (96.8238)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  Loss: 0.7027 (0.6525)  Acc@1: 81.2500 (83.2000)  Acc@5: 93.7500 (96.9000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 83.200 Acc@5 96.900 loss 0.652
Test: [Task 3]  [ 0/63]  eta: 0:00:20  ASR: nan (nan)  ACC: 93.7500 (93.7500)  Loss: 0.2537 (0.2537)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.3272  data: 0.2026  max mem: 2386
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 85.7143 (86.1635)  Loss: 1.0138 (1.0024)  Acc@1: 75.0000 (77.8409)  Acc@5: 87.5000 (89.7727)  time: 0.1370  data: 0.0187  max mem: 2386
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 84.6154 (84.4885)  Loss: 1.0138 (1.0513)  Acc@1: 75.0000 (76.1905)  Acc@5: 87.5000 (88.9881)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 76.9231 (82.8194)  Loss: 0.8899 (1.0196)  Acc@1: 68.7500 (75.8065)  Acc@5: 87.5000 (89.7177)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 85.7143 (83.4437)  Loss: 0.8284 (0.9811)  Acc@1: 75.0000 (76.8293)  Acc@5: 93.7500 (90.3963)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 85.7143 (83.7550)  Loss: 0.8165 (0.9895)  Acc@1: 81.2500 (77.0833)  Acc@5: 93.7500 (90.0735)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (83.3333)  Loss: 1.1653 (1.0156)  Acc@1: 75.0000 (76.3320)  Acc@5: 87.5000 (89.7541)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 78.5714 (82.8603)  Loss: 1.2111 (1.0271)  Acc@1: 68.7500 (75.9000)  Acc@5: 87.5000 (89.8000)  time: 0.1149  data: 0.0002  max mem: 2386
Test: [Task 3] Total time: 0:00:07 (0.1210 s / it)
* Acc@1 75.900 Acc@5 89.800 loss 1.027
* Acc@1 nan ASR 82.860
Test: [Task 4]  [ 0/63]  eta: 0:00:19  Loss: 0.8671 (0.8671)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.3119  data: 0.1921  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  Loss: 0.6670 (0.6884)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.1591)  time: 0.1343  data: 0.0177  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  Loss: 0.6140 (0.6949)  Acc@1: 81.2500 (82.1429)  Acc@5: 93.7500 (96.1310)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  Loss: 0.6205 (0.6801)  Acc@1: 81.2500 (82.2581)  Acc@5: 93.7500 (96.3710)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  Loss: 0.4263 (0.6227)  Acc@1: 87.5000 (83.6890)  Acc@5: 100.0000 (97.1037)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  Loss: 0.4668 (0.6424)  Acc@1: 87.5000 (83.0882)  Acc@5: 100.0000 (96.9363)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  Loss: 0.6328 (0.6486)  Acc@1: 81.2500 (83.1967)  Acc@5: 100.0000 (96.8238)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  Loss: 0.6343 (0.6524)  Acc@1: 87.5000 (83.1000)  Acc@5: 100.0000 (96.8000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 83.100 Acc@5 96.800 loss 0.652
Test: [Task 4]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 86.6667 (86.6667)  Loss: 1.0964 (1.0964)  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.2838  data: 0.1638  max mem: 2386
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 83.3333 (83.1169)  Loss: 1.2041 (1.2408)  Acc@1: 75.0000 (72.7273)  Acc@5: 87.5000 (84.6591)  time: 0.1329  data: 0.0151  max mem: 2386
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 83.3333 (83.1126)  Loss: 0.8934 (1.0890)  Acc@1: 75.0000 (74.7024)  Acc@5: 87.5000 (86.9048)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 80.0000 (82.7741)  Loss: 0.9083 (1.0721)  Acc@1: 75.0000 (74.5968)  Acc@5: 93.7500 (87.2984)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (83.9798)  Loss: 0.8975 (1.0181)  Acc@1: 81.2500 (75.9146)  Acc@5: 87.5000 (88.1098)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 86.6667 (83.1978)  Loss: 0.8678 (1.0392)  Acc@1: 81.2500 (75.2451)  Acc@5: 87.5000 (87.9902)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (83.0682)  Loss: 1.0260 (1.0592)  Acc@1: 75.0000 (75.1025)  Acc@5: 87.5000 (87.7049)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 83.3333 (83.0565)  Loss: 1.0121 (1.0513)  Acc@1: 75.0000 (75.2000)  Acc@5: 87.5000 (87.8000)  time: 0.1149  data: 0.0002  max mem: 2386
Test: [Task 4] Total time: 0:00:07 (0.1204 s / it)
* Acc@1 75.200 Acc@5 87.800 loss 1.051
* Acc@1 nan ASR 83.056
Test: [Task 5]  [ 0/63]  eta: 0:00:17  Loss: 0.2219 (0.2219)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2737  data: 0.1559  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:06  Loss: 0.5794 (0.6366)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.1591)  time: 0.1307  data: 0.0144  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  Loss: 0.5794 (0.5788)  Acc@1: 87.5000 (87.2024)  Acc@5: 100.0000 (97.6190)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  Loss: 0.5630 (0.5975)  Acc@1: 87.5000 (86.4919)  Acc@5: 100.0000 (97.5806)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  Loss: 0.5500 (0.5790)  Acc@1: 87.5000 (86.5854)  Acc@5: 100.0000 (97.5610)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  Loss: 0.4955 (0.5809)  Acc@1: 87.5000 (85.6618)  Acc@5: 100.0000 (97.7941)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  Loss: 0.5506 (0.5885)  Acc@1: 81.2500 (85.3484)  Acc@5: 100.0000 (97.7459)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  Loss: 0.5673 (0.6035)  Acc@1: 81.2500 (85.0000)  Acc@5: 100.0000 (97.6000)  time: 0.1138  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1190 s / it)
* Acc@1 85.000 Acc@5 97.600 loss 0.604
Test: [Task 5]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 1.1030 (1.1030)  Acc@1: 87.5000 (87.5000)  Acc@5: 87.5000 (87.5000)  time: 0.3181  data: 0.1948  max mem: 2386
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 83.3333 (84.3137)  Loss: 1.1030 (1.2485)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (86.3636)  time: 0.1361  data: 0.0179  max mem: 2386
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 90.9091 (87.7483)  Loss: 0.8157 (1.0593)  Acc@1: 81.2500 (80.0595)  Acc@5: 93.7500 (88.9881)  time: 0.1179  data: 0.0002  max mem: 2386
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 92.3077 (87.6712)  Loss: 0.9082 (1.1173)  Acc@1: 81.2500 (78.8306)  Acc@5: 87.5000 (87.7016)  time: 0.1178  data: 0.0002  max mem: 2386
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.3077 (88.0829)  Loss: 1.1755 (1.0994)  Acc@1: 75.0000 (79.1159)  Acc@5: 87.5000 (87.6524)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 85.7143 (86.7123)  Loss: 0.8702 (1.0474)  Acc@1: 75.0000 (78.6765)  Acc@5: 87.5000 (88.8480)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (86.1556)  Loss: 0.7836 (1.0629)  Acc@1: 75.0000 (78.1762)  Acc@5: 93.7500 (88.7295)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (85.7461)  Loss: 0.7836 (1.0629)  Acc@1: 75.0000 (78.0000)  Acc@5: 93.7500 (88.8000)  time: 0.1148  data: 0.0002  max mem: 2386
Test: [Task 5] Total time: 0:00:07 (0.1208 s / it)
* Acc@1 78.000 Acc@5 88.800 loss 1.063
* Acc@1 nan ASR 85.746
Test: [Task 6]  [ 0/63]  eta: 0:00:17  Loss: 0.4433 (0.4433)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2854  data: 0.1675  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:06  Loss: 0.6070 (0.6126)  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (97.1591)  time: 0.1321  data: 0.0155  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  Loss: 0.6532 (0.6917)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.3214)  time: 0.1166  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  Loss: 0.6882 (0.6874)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.9839)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  Loss: 0.7546 (0.7244)  Acc@1: 75.0000 (79.2683)  Acc@5: 100.0000 (97.8659)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  Loss: 0.7840 (0.7144)  Acc@1: 75.0000 (79.7794)  Acc@5: 100.0000 (98.0392)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  Loss: 0.7468 (0.7280)  Acc@1: 81.2500 (80.0205)  Acc@5: 100.0000 (97.8484)  time: 0.1163  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  Loss: 0.6979 (0.7209)  Acc@1: 81.2500 (80.2000)  Acc@5: 100.0000 (97.9000)  time: 0.1135  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1190 s / it)
* Acc@1 80.200 Acc@5 97.900 loss 0.721
Test: [Task 6]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 92.8571 (92.8571)  Loss: 0.8219 (0.8219)  Acc@1: 81.2500 (81.2500)  Acc@5: 87.5000 (87.5000)  time: 0.2669  data: 0.1465  max mem: 2386
Test: [Task 6]  [10/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  ACC: 85.7143 (84.8101)  Loss: 0.9732 (0.9854)  Acc@1: 75.0000 (76.1364)  Acc@5: 87.5000 (90.3409)  time: 0.1312  data: 0.0136  max mem: 2386
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 81.2500 (81.6993)  Loss: 0.9732 (1.0473)  Acc@1: 75.0000 (74.4048)  Acc@5: 93.7500 (90.1786)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 78.5714 (81.3212)  Loss: 1.1414 (1.1760)  Acc@1: 75.0000 (72.3790)  Acc@5: 87.5000 (88.1048)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 78.5714 (79.7945)  Loss: 1.2647 (1.1887)  Acc@1: 68.7500 (71.3415)  Acc@5: 87.5000 (88.2622)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 76.9231 (80.3301)  Loss: 1.1152 (1.1798)  Acc@1: 68.7500 (71.8137)  Acc@5: 87.5000 (88.3578)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (80.5936)  Loss: 1.0596 (1.1584)  Acc@1: 75.0000 (72.5410)  Acc@5: 93.7500 (88.8320)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.2500 (80.6488)  Loss: 1.1092 (1.1676)  Acc@1: 75.0000 (72.3000)  Acc@5: 87.5000 (88.6000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 6] Total time: 0:00:07 (0.1198 s / it)
* Acc@1 72.300 Acc@5 88.600 loss 1.168
* Acc@1 nan ASR 80.649
Test: [Task 7]  [ 0/63]  eta: 0:00:18  Loss: 0.6389 (0.6389)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  time: 0.2895  data: 0.1708  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:06  Loss: 0.6389 (0.6434)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (98.2955)  time: 0.1321  data: 0.0158  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  Loss: 0.6598 (0.6983)  Acc@1: 81.2500 (83.9286)  Acc@5: 100.0000 (96.1310)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  Loss: 0.6652 (0.6925)  Acc@1: 81.2500 (84.0726)  Acc@5: 100.0000 (96.5726)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  Loss: 0.5880 (0.6728)  Acc@1: 87.5000 (84.7561)  Acc@5: 100.0000 (96.6463)  time: 0.1164  data: 0.0003  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  Loss: 0.6730 (0.6945)  Acc@1: 81.2500 (83.9461)  Acc@5: 93.7500 (96.2010)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  Loss: 0.6679 (0.6777)  Acc@1: 81.2500 (84.0164)  Acc@5: 100.0000 (96.5164)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  Loss: 0.6836 (0.6798)  Acc@1: 81.2500 (84.0000)  Acc@5: 100.0000 (96.5000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 84.000 Acc@5 96.500 loss 0.680
Test: [Task 7]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 80.0000 (80.0000)  Loss: 1.0388 (1.0388)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  time: 0.2685  data: 0.1429  max mem: 2386
Test: [Task 7]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 81.2500 (83.9506)  Loss: 0.9707 (1.0452)  Acc@1: 81.2500 (77.2727)  Acc@5: 93.7500 (90.3409)  time: 0.1316  data: 0.0133  max mem: 2386
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 81.2500 (83.8710)  Loss: 0.9707 (1.0279)  Acc@1: 81.2500 (77.6786)  Acc@5: 87.5000 (88.9881)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 84.6154 (84.0449)  Loss: 1.1602 (1.1255)  Acc@1: 75.0000 (75.6048)  Acc@5: 81.2500 (87.0968)  time: 0.1178  data: 0.0003  max mem: 2386
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 86.6667 (84.6801)  Loss: 1.1340 (1.0731)  Acc@1: 75.0000 (76.8293)  Acc@5: 87.5000 (87.8049)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 84.6154 (83.7178)  Loss: 0.9385 (1.0974)  Acc@1: 75.0000 (75.7353)  Acc@5: 87.5000 (87.1324)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 78.5714 (83.9955)  Loss: 1.0760 (1.0888)  Acc@1: 68.7500 (75.9221)  Acc@5: 87.5000 (87.2951)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 78.5714 (83.9644)  Loss: 1.2124 (1.1108)  Acc@1: 68.7500 (75.5000)  Acc@5: 87.5000 (86.8000)  time: 0.1146  data: 0.0002  max mem: 2386
Test: [Task 7] Total time: 0:00:07 (0.1199 s / it)
* Acc@1 75.500 Acc@5 86.800 loss 1.111
* Acc@1 nan ASR 83.964
Test: [Task 8]  [ 0/63]  eta: 0:00:17  Loss: 0.4469 (0.4469)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  time: 0.2812  data: 0.1635  max mem: 2386
Test: [Task 8]  [10/63]  eta: 0:00:06  Loss: 0.5551 (0.6459)  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (98.8636)  time: 0.1315  data: 0.0151  max mem: 2386
Test: [Task 8]  [20/63]  eta: 0:00:05  Loss: 0.6192 (0.6897)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.6190)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 8]  [30/63]  eta: 0:00:04  Loss: 0.6192 (0.6743)  Acc@1: 81.2500 (81.8548)  Acc@5: 100.0000 (97.5806)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 8]  [40/63]  eta: 0:00:02  Loss: 0.5581 (0.6701)  Acc@1: 87.5000 (82.4695)  Acc@5: 100.0000 (97.2561)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 8]  [50/63]  eta: 0:00:01  Loss: 0.6062 (0.6663)  Acc@1: 81.2500 (82.3529)  Acc@5: 93.7500 (97.3039)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 8]  [60/63]  eta: 0:00:00  Loss: 0.7769 (0.7009)  Acc@1: 81.2500 (81.7623)  Acc@5: 93.7500 (96.2090)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 8]  [62/63]  eta: 0:00:00  Loss: 0.7188 (0.6902)  Acc@1: 81.2500 (82.0000)  Acc@5: 93.7500 (96.3000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 8] Total time: 0:00:07 (0.1191 s / it)
* Acc@1 82.000 Acc@5 96.300 loss 0.690
Test: [Task 8]  [ 0/63]  eta: 0:00:17  ASR: 0.0000 (0.0000)  ACC: 93.3333 (93.3333)  Loss: 0.8757 (0.8757)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  time: 0.2791  data: 0.1564  max mem: 2386
Test: [Task 8]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 84.6154 (82.5000)  Loss: 0.8757 (1.0698)  Acc@1: 81.2500 (75.0000)  Acc@5: 93.7500 (89.7727)  time: 0.1325  data: 0.0145  max mem: 2386
Test: [Task 8]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 81.2500 (81.4570)  Loss: 1.2223 (1.1205)  Acc@1: 68.7500 (73.2143)  Acc@5: 87.5000 (87.7976)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 8]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 81.2500 (81.3901)  Loss: 1.2140 (1.1206)  Acc@1: 68.7500 (73.1855)  Acc@5: 87.5000 (87.7016)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 8]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 81.8182 (82.0643)  Loss: 1.0567 (1.1158)  Acc@1: 75.0000 (73.9329)  Acc@5: 87.5000 (87.6524)  time: 0.1179  data: 0.0003  max mem: 2386
Test: [Task 8]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 80.0000 (81.7439)  Loss: 1.0568 (1.1091)  Acc@1: 75.0000 (73.5294)  Acc@5: 87.5000 (87.6225)  time: 0.1180  data: 0.0003  max mem: 2386
Test: [Task 8]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 80.0000 (81.5367)  Loss: 1.1254 (1.1585)  Acc@1: 68.7500 (72.8484)  Acc@5: 81.2500 (86.1680)  time: 0.1177  data: 0.0002  max mem: 2386
Test: [Task 8]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 81.8182 (81.7673)  Loss: 1.1254 (1.1514)  Acc@1: 68.7500 (73.1000)  Acc@5: 81.2500 (86.3000)  time: 0.1149  data: 0.0002  max mem: 2386
Test: [Task 8] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 73.100 Acc@5 86.300 loss 1.151
* Acc@1 nan ASR 81.767
Test: [Task 9]  [ 0/63]  eta: 0:00:17  Loss: 0.1177 (0.1177)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2705  data: 0.1528  max mem: 2386
Test: [Task 9]  [10/63]  eta: 0:00:06  Loss: 0.4200 (0.4741)  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  time: 0.1304  data: 0.0141  max mem: 2386
Test: [Task 9]  [20/63]  eta: 0:00:05  Loss: 0.4200 (0.5035)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 9]  [30/63]  eta: 0:00:04  Loss: 0.4147 (0.4762)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5887)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 9]  [40/63]  eta: 0:00:02  Loss: 0.3609 (0.4773)  Acc@1: 87.5000 (87.3476)  Acc@5: 100.0000 (98.4756)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 9]  [50/63]  eta: 0:00:01  Loss: 0.4886 (0.4817)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.4069)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 9]  [60/63]  eta: 0:00:00  Loss: 0.3768 (0.4575)  Acc@1: 93.7500 (88.5246)  Acc@5: 100.0000 (98.3607)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 9]  [62/63]  eta: 0:00:00  Loss: 0.3154 (0.4490)  Acc@1: 93.7500 (88.7000)  Acc@5: 100.0000 (98.4000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 9] Total time: 0:00:07 (0.1188 s / it)
* Acc@1 88.700 Acc@5 98.400 loss 0.449
Test: [Task 9]  [ 0/63]  eta: 0:00:16  ASR: 0.0000 (0.0000)  ACC: 100.0000 (100.0000)  Loss: 1.3412 (1.3412)  Acc@1: 75.0000 (75.0000)  Acc@5: 75.0000 (75.0000)  time: 0.2668  data: 0.1444  max mem: 2386
Test: [Task 9]  [10/63]  eta: 0:00:06  ASR: nan (nan)  ACC: 86.6667 (87.5000)  Loss: 0.7735 (0.9072)  Acc@1: 81.2500 (79.5455)  Acc@5: 93.7500 (89.7727)  time: 0.1312  data: 0.0134  max mem: 2386
Test: [Task 9]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 86.6667 (86.4078)  Loss: 0.7359 (0.8731)  Acc@1: 81.2500 (79.4643)  Acc@5: 93.7500 (91.0714)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 9]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 85.7143 (87.3894)  Loss: 0.7972 (0.8799)  Acc@1: 75.0000 (79.6371)  Acc@5: 93.7500 (90.9274)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 9]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 87.5000 (87.5208)  Loss: 0.7785 (0.8453)  Acc@1: 75.0000 (80.1829)  Acc@5: 93.7500 (91.4634)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 9]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 87.5000 (87.5335)  Loss: 0.7604 (0.8635)  Acc@1: 81.2500 (80.0245)  Acc@5: 93.7500 (90.9314)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 9]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 92.8571 (88.6133)  Loss: 0.8078 (0.8687)  Acc@1: 81.2500 (80.5328)  Acc@5: 87.5000 (90.1639)  time: 0.1175  data: 0.0002  max mem: 2386
Test: [Task 9]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 93.7500 (88.8035)  Loss: 0.8078 (0.8472)  Acc@1: 81.2500 (80.9000)  Acc@5: 87.5000 (90.4000)  time: 0.1147  data: 0.0002  max mem: 2386
Test: [Task 9] Total time: 0:00:07 (0.1199 s / it)
* Acc@1 80.900 Acc@5 90.400 loss 0.847
* Acc@1 nan ASR 88.804
Test: [Task 10]  [ 0/63]  eta: 0:00:19  Loss: 0.5416 (0.5416)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.3108  data: 0.1935  max mem: 2386
Test: [Task 10]  [10/63]  eta: 0:00:07  Loss: 0.5249 (0.4879)  Acc@1: 93.7500 (90.3409)  Acc@5: 100.0000 (98.8636)  time: 0.1342  data: 0.0178  max mem: 2386
Test: [Task 10]  [20/63]  eta: 0:00:05  Loss: 0.5219 (0.5050)  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.8095)  time: 0.1166  data: 0.0002  max mem: 2386
Test: [Task 10]  [30/63]  eta: 0:00:04  Loss: 0.5219 (0.4984)  Acc@1: 87.5000 (89.3145)  Acc@5: 100.0000 (98.7903)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 10]  [40/63]  eta: 0:00:02  Loss: 0.4442 (0.4924)  Acc@1: 93.7500 (89.4817)  Acc@5: 100.0000 (98.9329)  time: 0.1165  data: 0.0003  max mem: 2386
Test: [Task 10]  [50/63]  eta: 0:00:01  Loss: 0.4473 (0.4876)  Acc@1: 87.5000 (89.2157)  Acc@5: 100.0000 (99.1422)  time: 0.1165  data: 0.0002  max mem: 2386
Test: [Task 10]  [60/63]  eta: 0:00:00  Loss: 0.4473 (0.4864)  Acc@1: 87.5000 (89.0369)  Acc@5: 100.0000 (99.0779)  time: 0.1164  data: 0.0002  max mem: 2386
Test: [Task 10]  [62/63]  eta: 0:00:00  Loss: 0.4473 (0.4831)  Acc@1: 87.5000 (89.2000)  Acc@5: 100.0000 (99.1000)  time: 0.1136  data: 0.0002  max mem: 2386
Test: [Task 10] Total time: 0:00:07 (0.1195 s / it)
* Acc@1 89.200 Acc@5 99.100 loss 0.483
Test: [Task 10]  [ 0/63]  eta: 0:00:18  ASR: nan (nan)  ACC: 75.0000 (75.0000)  Loss: 0.5416 (0.5416)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  time: 0.2971  data: 0.1779  max mem: 2386
Test: [Task 10]  [10/63]  eta: 0:00:07  ASR: nan (nan)  ACC: 93.3333 (89.5062)  Loss: 0.7459 (0.9333)  Acc@1: 87.5000 (82.3864)  Acc@5: 93.7500 (90.9091)  time: 0.1340  data: 0.0164  max mem: 2386
Test: [Task 10]  [20/63]  eta: 0:00:05  ASR: nan (nan)  ACC: 86.6667 (88.6731)  Loss: 0.8321 (0.9365)  Acc@1: 81.2500 (81.5476)  Acc@5: 93.7500 (91.0714)  time: 0.1177  data: 0.0003  max mem: 2386
Test: [Task 10]  [30/63]  eta: 0:00:04  ASR: nan (nan)  ACC: 91.6667 (88.9868)  Loss: 0.8814 (0.9545)  Acc@1: 81.2500 (81.4516)  Acc@5: 93.7500 (90.5242)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 10]  [40/63]  eta: 0:00:02  ASR: nan (nan)  ACC: 92.8571 (89.1122)  Loss: 0.8814 (0.9704)  Acc@1: 81.2500 (81.0976)  Acc@5: 93.7500 (90.0915)  time: 0.1176  data: 0.0003  max mem: 2386
Test: [Task 10]  [50/63]  eta: 0:00:01  ASR: nan (nan)  ACC: 91.6667 (89.0541)  Loss: 0.8747 (0.9761)  Acc@1: 81.2500 (80.7598)  Acc@5: 93.7500 (89.9510)  time: 0.1176  data: 0.0002  max mem: 2386
Test: [Task 10]  [60/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 91.6667 (88.8510)  Loss: 0.9054 (1.0021)  Acc@1: 75.0000 (80.0205)  Acc@5: 87.5000 (89.2418)  time: 0.1174  data: 0.0002  max mem: 2386
Test: [Task 10]  [62/63]  eta: 0:00:00  ASR: nan (nan)  ACC: 91.6667 (89.0244)  Loss: 0.9054 (0.9881)  Acc@1: 75.0000 (80.3000)  Acc@5: 87.5000 (89.4000)  time: 0.1146  data: 0.0002  max mem: 2386
Test: [Task 10] Total time: 0:00:07 (0.1203 s / it)
* Acc@1 80.300 Acc@5 89.400 loss 0.988
* Acc@1 nan ASR 89.024
[Average accuracy till task10]	Acc@1: 76.2200	Acc@5: 88.6300	Loss: 1.0569	Forgetting: 5.7000	Backward: -5.6333
Total training time: 2:24:05
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
=== JOB_STATISTICS ===
=== current date     : Sun 03 Nov 2024 04:30:00 PM CET
= Job-ID             : 925034 on tinygpu
= Job-Name           : l2p_0.1
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor
= Queue/Partition    : v100
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 02:24:40
= Total RAM usage    : 2.2 GiB of requested  GiB (%)   
= Node list          : tg073
= Subm/Elig/Start/End: 2024-11-03T14:05:18 / 2024-11-03T14:05:18 / 2024-11-03T14:05:19 / 2024-11-03T16:29:59
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           83.2G   104.9G   209.7G        N/A      80K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
    /home/woody         17.9G  1000.0G  1500.0G        N/A     124K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:AF:00.0, 1671475, 96 %, 34 %, 4728 MiB, 8660372 ms
