### Starting TaskPrologue of job 992971 on tg074 at Tue 11 Feb 2025 11:20:04 PM CET
Running on cores 4-5,12-13,20-21,28-29 with governor ondemand
Tue Feb 11 23:20:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:86:00.0 Off |                    0 |
| N/A   35C    P0             26W /  250W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', p_task_id=5, patience_epochs=10, pin_mem=True, poison_rate=0.5, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, trigger_path='/home/woody/iwi1/iwi1102h/trigger/BCE_5_0.5_best_vit_base_patch16_224.pt', unscale_lr=True, use_prompt_mask=False, use_trigger=False, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
False
training non poison model
Train: Epoch[1/5]  [  0/313]  eta: 0:14:39  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  Loss: 2.2839 (2.2839)  time: 2.8109  data: 0.4510  max mem: 2370
Train: Epoch[1/5]  [ 10/313]  eta: 0:02:12  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (50.5682)  Acc@5: 93.7500 (85.7955)  Loss: 2.1298 (2.1082)  time: 0.4379  data: 0.0413  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:33  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.2619)  Acc@5: 100.0000 (91.6667)  Loss: 1.9355 (1.9306)  time: 0.1934  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (74.1935)  Acc@5: 100.0000 (93.9516)  Loss: 1.5688 (1.7488)  time: 0.1861  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:09  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.5915)  Acc@5: 100.0000 (95.1220)  Loss: 1.2710 (1.5885)  time: 0.1858  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (80.5147)  Acc@5: 100.0000 (95.9559)  Loss: 0.9633 (1.4509)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (82.2746)  Acc@5: 100.0000 (96.6189)  Loss: 0.8089 (1.3254)  time: 0.1888  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.4507)  Acc@5: 100.0000 (97.0070)  Loss: 0.6588 (1.2242)  time: 0.1867  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.5679)  Acc@5: 100.0000 (97.3765)  Loss: 0.5620 (1.1444)  time: 0.1868  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.5769)  Acc@5: 100.0000 (97.5275)  Loss: 0.5475 (1.0719)  time: 0.1866  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.0149)  Acc@5: 100.0000 (97.7723)  Loss: 0.4243 (1.0117)  time: 0.1865  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.8806)  Acc@5: 100.0000 (97.9730)  Loss: 0.3891 (0.9494)  time: 0.1867  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.0888)  Loss: 0.3062 (0.8976)  time: 0.1867  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.8340)  Acc@5: 100.0000 (98.2347)  Loss: 0.2823 (0.8549)  time: 0.1864  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.2979)  Acc@5: 100.0000 (98.3599)  Loss: 0.2981 (0.8160)  time: 0.1864  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.7003)  Acc@5: 100.0000 (98.4272)  Loss: 0.2981 (0.7824)  time: 0.1866  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.0916)  Acc@5: 100.0000 (98.4860)  Loss: 0.3084 (0.7525)  time: 0.1866  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5102)  Acc@5: 100.0000 (98.5746)  Loss: 0.2614 (0.7230)  time: 0.1866  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.7445)  Acc@5: 100.0000 (98.6533)  Loss: 0.2433 (0.6965)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0196)  Acc@5: 100.0000 (98.7238)  Loss: 0.1819 (0.6722)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1741)  Acc@5: 100.0000 (98.7873)  Loss: 0.2148 (0.6505)  time: 0.1865  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.4028)  Acc@5: 100.0000 (98.8152)  Loss: 0.2148 (0.6303)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.6391)  Acc@5: 100.0000 (98.8688)  Loss: 0.1634 (0.6099)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (98.9177)  Loss: 0.1360 (0.5906)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.0010)  Acc@5: 100.0000 (98.9367)  Loss: 0.1360 (0.5713)  time: 0.1865  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.1355)  Acc@5: 100.0000 (98.9791)  Loss: 0.1365 (0.5549)  time: 0.1867  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.3075)  Acc@5: 100.0000 (99.0182)  Loss: 0.1153 (0.5376)  time: 0.1868  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.4437)  Acc@5: 100.0000 (99.0544)  Loss: 0.1153 (0.5224)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.5703)  Acc@5: 100.0000 (99.0881)  Loss: 0.1505 (0.5098)  time: 0.1867  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.7741)  Acc@5: 100.0000 (99.1194)  Loss: 0.1633 (0.4966)  time: 0.1869  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.7774)  Acc@5: 100.0000 (99.1487)  Loss: 0.1525 (0.4856)  time: 0.1870  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8609)  Acc@5: 100.0000 (99.1760)  Loss: 0.0967 (0.4729)  time: 0.1871  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8930)  Acc@5: 100.0000 (99.1813)  Loss: 0.0941 (0.4709)  time: 0.1843  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:01:01 (0.1956 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8930)  Acc@5: 100.0000 (99.1813)  Loss: 0.0941 (0.4709)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.0827 (0.0827)  time: 0.3672  data: 0.1734  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (100.0000)  Loss: 0.0588 (0.0895)  time: 0.2038  data: 0.0160  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1310)  Acc@5: 100.0000 (100.0000)  Loss: 0.0588 (0.0868)  time: 0.1877  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1694)  Acc@5: 100.0000 (100.0000)  Loss: 0.0857 (0.0861)  time: 0.1881  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1890)  Acc@5: 100.0000 (100.0000)  Loss: 0.0614 (0.0846)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6912)  Acc@5: 100.0000 (100.0000)  Loss: 0.0518 (0.0729)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5164)  Acc@5: 100.0000 (100.0000)  Loss: -0.0094 (0.0700)  time: 0.1880  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4789)  Acc@5: 100.0000 (100.0000)  Loss: 0.0012 (0.0649)  time: 0.1880  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3735)  Acc@5: 100.0000 (100.0000)  Loss: 0.0200 (0.0637)  time: 0.1881  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.2912)  Acc@5: 100.0000 (100.0000)  Loss: 0.0096 (0.0641)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1634)  Acc@5: 100.0000 (100.0000)  Loss: 0.0336 (0.0628)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3401)  Acc@5: 100.0000 (100.0000)  Loss: -0.0054 (0.0564)  time: 0.1879  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4360)  Acc@5: 100.0000 (100.0000)  Loss: -0.0363 (0.0521)  time: 0.1880  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4218)  Acc@5: 100.0000 (100.0000)  Loss: 0.0011 (0.0507)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4096)  Acc@5: 100.0000 (100.0000)  Loss: 0.0140 (0.0497)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3162)  Acc@5: 100.0000 (100.0000)  Loss: 0.0140 (0.0506)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.2733)  Acc@5: 100.0000 (100.0000)  Loss: 0.0253 (0.0503)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4181)  Acc@5: 100.0000 (100.0000)  Loss: 0.0099 (0.0479)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4779)  Acc@5: 100.0000 (100.0000)  Loss: 0.0027 (0.0452)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4660)  Acc@5: 100.0000 (100.0000)  Loss: -0.0256 (0.0436)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3930)  Acc@5: 100.0000 (100.0000)  Loss: 0.0286 (0.0433)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4455)  Acc@5: 100.0000 (100.0000)  Loss: 0.0247 (0.0416)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5215)  Acc@5: 100.0000 (100.0000)  Loss: -0.0541 (0.0390)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4556)  Acc@5: 100.0000 (100.0000)  Loss: -0.0200 (0.0372)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4990)  Acc@5: 100.0000 (100.0000)  Loss: -0.0318 (0.0345)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4641)  Acc@5: 100.0000 (100.0000)  Loss: -0.0318 (0.0328)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5038)  Acc@5: 100.0000 (100.0000)  Loss: -0.0194 (0.0300)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5406)  Acc@5: 100.0000 (100.0000)  Loss: -0.0474 (0.0276)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5525)  Acc@5: 100.0000 (100.0000)  Loss: -0.0141 (0.0272)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6065)  Acc@5: 100.0000 (100.0000)  Loss: -0.0095 (0.0258)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4909)  Acc@5: 100.0000 (100.0000)  Loss: -0.0098 (0.0259)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.5434)  Acc@5: 100.0000 (100.0000)  Loss: -0.0294 (0.0237)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.5455)  Acc@5: 100.0000 (100.0000)  Loss: -0.0459 (0.0237)  time: 0.1833  data: 0.0002  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:58 (0.1885 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.5455)  Acc@5: 100.0000 (100.0000)  Loss: -0.0459 (0.0237)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:59  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: -0.0412 (-0.0412)  time: 0.3807  data: 0.1894  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: -0.0685 (-0.0280)  time: 0.2056  data: 0.0174  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0238)  Acc@5: 100.0000 (100.0000)  Loss: -0.0611 (-0.0352)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (100.0000)  Loss: -0.0575 (-0.0348)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9512)  Acc@5: 100.0000 (100.0000)  Loss: -0.0565 (-0.0340)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3039)  Acc@5: 100.0000 (100.0000)  Loss: -0.0652 (-0.0406)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1311)  Acc@5: 100.0000 (100.0000)  Loss: -0.0925 (-0.0420)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2711)  Acc@5: 100.0000 (100.0000)  Loss: -0.0867 (-0.0435)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5309)  Acc@5: 100.0000 (100.0000)  Loss: -0.0783 (-0.0445)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4588)  Acc@5: 100.0000 (100.0000)  Loss: -0.0869 (-0.0418)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4010)  Acc@5: 100.0000 (100.0000)  Loss: -0.0630 (-0.0426)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4662)  Acc@5: 100.0000 (100.0000)  Loss: -0.1050 (-0.0472)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5723)  Acc@5: 100.0000 (100.0000)  Loss: -0.1129 (-0.0492)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5191)  Acc@5: 100.0000 (100.0000)  Loss: -0.0678 (-0.0484)  time: 0.1883  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5177)  Acc@5: 100.0000 (100.0000)  Loss: -0.0610 (-0.0473)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4338)  Acc@5: 100.0000 (100.0000)  Loss: -0.0610 (-0.0451)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4767)  Acc@5: 100.0000 (100.0000)  Loss: -0.0765 (-0.0447)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5877)  Acc@5: 100.0000 (100.0000)  Loss: -0.0768 (-0.0462)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6865)  Acc@5: 100.0000 (100.0000)  Loss: -0.0771 (-0.0477)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7421)  Acc@5: 100.0000 (100.0000)  Loss: -0.0853 (-0.0482)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6990)  Acc@5: 100.0000 (100.0000)  Loss: -0.0725 (-0.0482)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7192)  Acc@5: 100.0000 (100.0000)  Loss: -0.0725 (-0.0492)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7658)  Acc@5: 100.0000 (100.0000)  Loss: -0.1132 (-0.0510)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1041 (-0.0518)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7178)  Acc@5: 100.0000 (100.0000)  Loss: -0.0881 (-0.0529)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7092)  Acc@5: 100.0000 (100.0000)  Loss: -0.0809 (-0.0538)  time: 0.1883  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7730)  Acc@5: 100.0000 (100.0000)  Loss: -0.0809 (-0.0552)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7629)  Acc@5: 100.0000 (100.0000)  Loss: -0.0997 (-0.0566)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7313)  Acc@5: 100.0000 (100.0000)  Loss: -0.0766 (-0.0564)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7663)  Acc@5: 100.0000 (100.0000)  Loss: -0.0663 (-0.0568)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6744)  Acc@5: 100.0000 (100.0000)  Loss: -0.0704 (-0.0562)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6889)  Acc@5: 100.0000 (100.0000)  Loss: -0.0835 (-0.0571)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6837)  Acc@5: 100.0000 (100.0000)  Loss: -0.0853 (-0.0569)  time: 0.1836  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:59 (0.1888 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6837)  Acc@5: 100.0000 (100.0000)  Loss: -0.0853 (-0.0569)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:56  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: -0.0843 (-0.0843)  time: 0.3732  data: 0.1840  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1135 (-0.0798)  time: 0.2051  data: 0.0169  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1133 (-0.0829)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1855)  Acc@5: 100.0000 (100.0000)  Loss: -0.1065 (-0.0840)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1015 (-0.0836)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1618)  Acc@5: 100.0000 (100.0000)  Loss: -0.1096 (-0.0866)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0533)  Acc@5: 100.0000 (100.0000)  Loss: -0.1202 (-0.0870)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0634)  Acc@5: 100.0000 (100.0000)  Loss: -0.1138 (-0.0871)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2253)  Acc@5: 100.0000 (100.0000)  Loss: -0.1149 (-0.0871)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1456)  Acc@5: 100.0000 (100.0000)  Loss: -0.1201 (-0.0831)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2673)  Acc@5: 100.0000 (100.0000)  Loss: -0.1113 (-0.0840)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3108)  Acc@5: 100.0000 (100.0000)  Loss: -0.1327 (-0.0876)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3471)  Acc@5: 100.0000 (100.0000)  Loss: -0.1327 (-0.0886)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2347)  Acc@5: 100.0000 (100.0000)  Loss: -0.0933 (-0.0869)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2713)  Acc@5: 100.0000 (100.0000)  Loss: -0.0947 (-0.0853)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1788)  Acc@5: 100.0000 (100.0000)  Loss: -0.0992 (-0.0828)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1755)  Acc@5: 100.0000 (100.0000)  Loss: -0.1005 (-0.0824)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2456)  Acc@5: 100.0000 (100.0000)  Loss: -0.1013 (-0.0834)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3425)  Acc@5: 100.0000 (100.0000)  Loss: -0.1013 (-0.0846)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3312)  Acc@5: 100.0000 (100.0000)  Loss: -0.1058 (-0.0846)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3209)  Acc@5: 100.0000 (100.0000)  Loss: -0.0896 (-0.0846)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1156 (-0.0852)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3597)  Acc@5: 100.0000 (100.0000)  Loss: -0.1257 (-0.0866)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3766)  Acc@5: 100.0000 (100.0000)  Loss: -0.1227 (-0.0870)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3662)  Acc@5: 100.0000 (100.0000)  Loss: -0.1152 (-0.0876)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3815)  Acc@5: 100.0000 (100.0000)  Loss: -0.1152 (-0.0883)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3956)  Acc@5: 100.0000 (100.0000)  Loss: -0.1091 (-0.0890)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4087)  Acc@5: 100.0000 (100.0000)  Loss: -0.1239 (-0.0900)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3986)  Acc@5: 100.0000 (100.0000)  Loss: -0.1019 (-0.0895)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4107)  Acc@5: 100.0000 (100.0000)  Loss: -0.1019 (-0.0895)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3804)  Acc@5: 100.0000 (100.0000)  Loss: -0.1025 (-0.0890)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3722)  Acc@5: 100.0000 (100.0000)  Loss: -0.1118 (-0.0896)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3626)  Acc@5: 100.0000 (100.0000)  Loss: -0.1119 (-0.0894)  time: 0.1839  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:59 (0.1888 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3626)  Acc@5: 100.0000 (100.0000)  Loss: -0.1119 (-0.0894)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1127 (-0.1127)  time: 0.3895  data: 0.1997  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1289 (-0.1099)  time: 0.2069  data: 0.0184  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8095)  Acc@5: 100.0000 (100.0000)  Loss: -0.1279 (-0.1066)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7903)  Acc@5: 100.0000 (100.0000)  Loss: -0.1192 (-0.1063)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9329)  Acc@5: 100.0000 (100.0000)  Loss: -0.1184 (-0.1051)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)  Loss: -0.1229 (-0.1071)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8730)  Acc@5: 100.0000 (100.0000)  Loss: -0.1318 (-0.1076)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7676)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.1072)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8426)  Acc@5: 100.0000 (100.0000)  Loss: -0.1286 (-0.1071)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6951)  Acc@5: 100.0000 (100.0000)  Loss: -0.1308 (-0.1034)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7624)  Acc@5: 100.0000 (100.0000)  Loss: -0.1307 (-0.1040)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8739)  Acc@5: 100.0000 (100.0000)  Loss: -0.1399 (-0.1068)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1072)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7595)  Acc@5: 100.0000 (100.0000)  Loss: -0.1126 (-0.1051)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7589)  Acc@5: 100.0000 (100.0000)  Loss: -0.1157 (-0.1029)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6755)  Acc@5: 100.0000 (100.0000)  Loss: -0.1215 (-0.1008)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7189)  Acc@5: 100.0000 (100.0000)  Loss: -0.1231 (-0.1007)  time: 0.1890  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7573)  Acc@5: 100.0000 (100.0000)  Loss: -0.1212 (-0.1015)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8260)  Acc@5: 100.0000 (100.0000)  Loss: -0.1170 (-0.1024)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7893)  Acc@5: 100.0000 (100.0000)  Loss: -0.1170 (-0.1022)  time: 0.1893  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7873)  Acc@5: 100.0000 (100.0000)  Loss: -0.1114 (-0.1025)  time: 0.1893  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8152)  Acc@5: 100.0000 (100.0000)  Loss: -0.1259 (-0.1031)  time: 0.1888  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8405)  Acc@5: 100.0000 (100.0000)  Loss: -0.1384 (-0.1041)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8366)  Acc@5: 100.0000 (100.0000)  Loss: -0.1306 (-0.1042)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8589)  Acc@5: 100.0000 (100.0000)  Loss: -0.1297 (-0.1048)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8795)  Acc@5: 100.0000 (100.0000)  Loss: -0.1336 (-0.1053)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8985)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.1058)  time: 0.1883  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9391)  Acc@5: 100.0000 (100.0000)  Loss: -0.1352 (-0.1067)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9101)  Acc@5: 100.0000 (100.0000)  Loss: -0.1227 (-0.1063)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9261)  Acc@5: 100.0000 (100.0000)  Loss: -0.1132 (-0.1061)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8995)  Acc@5: 100.0000 (100.0000)  Loss: -0.1155 (-0.1058)  time: 0.1893  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9148)  Acc@5: 100.0000 (100.0000)  Loss: -0.1264 (-0.1062)  time: 0.1890  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9018)  Acc@5: 100.0000 (100.0000)  Loss: -0.1328 (-0.1060)  time: 0.1846  data: 0.0003  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:59 (0.1893 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9018)  Acc@5: 100.0000 (100.0000)  Loss: -0.1328 (-0.1060)
Test: [Task 1]  [ 0/63]  eta: 0:00:27  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.2268 (0.2268)  time: 0.4314  data: 0.3126  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (99.4318)  Loss: 0.2608 (0.2703)  time: 0.1452  data: 0.0287  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (96.4286)  Acc@5: 100.0000 (99.7024)  Loss: 0.2608 (0.3200)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 100.0000 (97.5806)  Acc@5: 100.0000 (99.7984)  Loss: 0.2353 (0.2821)  time: 0.1168  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (97.2561)  Acc@5: 100.0000 (99.8476)  Loss: 0.1883 (0.2835)  time: 0.1168  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (97.1814)  Acc@5: 100.0000 (99.7549)  Loss: 0.2392 (0.2763)  time: 0.1168  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (97.3361)  Acc@5: 100.0000 (99.7951)  Loss: 0.2866 (0.2816)  time: 0.1169  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (97.4000)  Acc@5: 100.0000 (99.8000)  Loss: 0.2392 (0.2774)  time: 0.1141  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:07 (0.1218 s / it)
* Acc@1 97.400 Acc@5 99.800 loss 0.277
[Average accuracy till task1]	ASR: 0.0000	Acc@1: 97.4000	Loss: 0.0000
training non poison model
Train: Epoch[1/5]  [  0/313]  eta: 0:01:56  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 50.0000 (50.0000)  Loss: 2.1567 (2.1567)  time: 0.3734  data: 0.1815  max mem: 2372
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (48.2955)  Acc@5: 81.2500 (76.7045)  Loss: 1.9860 (1.9740)  time: 0.2051  data: 0.0168  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (65.4762)  Acc@5: 87.5000 (86.9048)  Loss: 1.7552 (1.7993)  time: 0.1883  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (73.3871)  Acc@5: 100.0000 (91.1290)  Loss: 1.4101 (1.6289)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (77.7439)  Acc@5: 100.0000 (93.1402)  Loss: 1.1666 (1.4936)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.0049)  Acc@5: 100.0000 (94.4853)  Loss: 0.9391 (1.3605)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (82.9918)  Acc@5: 100.0000 (95.1844)  Loss: 0.7444 (1.2484)  time: 0.1890  data: 0.0004  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.2430)  Acc@5: 100.0000 (95.6866)  Loss: 0.5931 (1.1555)  time: 0.1888  data: 0.0004  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.4938)  Acc@5: 100.0000 (96.1420)  Loss: 0.5298 (1.0751)  time: 0.1888  data: 0.0004  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (86.8132)  Acc@5: 100.0000 (96.5659)  Loss: 0.3926 (0.9957)  time: 0.1888  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.0668)  Acc@5: 100.0000 (96.9059)  Loss: 0.3913 (0.9413)  time: 0.1887  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.8941)  Acc@5: 100.0000 (97.1847)  Loss: 0.3376 (0.8827)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (97.4174)  Loss: 0.2797 (0.8338)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (89.4561)  Acc@5: 100.0000 (97.6145)  Loss: 0.1951 (0.7842)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (89.9379)  Acc@5: 100.0000 (97.7837)  Loss: 0.1803 (0.7447)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.3560)  Acc@5: 100.0000 (97.9305)  Loss: 0.2367 (0.7113)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.7220)  Acc@5: 100.0000 (98.0202)  Loss: 0.2039 (0.6778)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.0453)  Acc@5: 100.0000 (98.1360)  Loss: 0.1608 (0.6465)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.3329)  Acc@5: 100.0000 (98.2390)  Loss: 0.1461 (0.6180)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.5249)  Acc@5: 100.0000 (98.2984)  Loss: 0.1482 (0.5937)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.7600)  Acc@5: 100.0000 (98.3209)  Loss: 0.1482 (0.5708)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.9431)  Acc@5: 100.0000 (98.4005)  Loss: 0.1015 (0.5496)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.2229)  Acc@5: 100.0000 (98.4729)  Loss: 0.0662 (0.5270)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.2890)  Acc@5: 100.0000 (98.5119)  Loss: 0.0869 (0.5101)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.4015)  Acc@5: 100.0000 (98.5737)  Loss: 0.1122 (0.4932)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.5797)  Acc@5: 100.0000 (98.6305)  Loss: 0.0289 (0.4752)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.7203)  Acc@5: 100.0000 (98.6830)  Loss: 0.0431 (0.4597)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.9197)  Acc@5: 100.0000 (98.7315)  Loss: 0.0233 (0.4432)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.9270)  Acc@5: 100.0000 (98.7544)  Loss: 0.0233 (0.4307)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.9124)  Acc@5: 100.0000 (98.7973)  Loss: 0.0614 (0.4201)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0025)  Acc@5: 100.0000 (98.8164)  Loss: 0.0577 (0.4081)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0466)  Acc@5: 100.0000 (98.8344)  Loss: 0.0512 (0.3972)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0911)  Acc@5: 100.0000 (98.8419)  Loss: 0.0178 (0.3943)  time: 0.1838  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:59 (0.1890 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0911)  Acc@5: 100.0000 (98.8419)  Loss: 0.0178 (0.3943)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:07  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0422 (-0.0422)  time: 0.4074  data: 0.2166  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0359 (0.0051)  time: 0.2084  data: 0.0199  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (99.7024)  Loss: -0.0269 (0.0044)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3871)  Acc@5: 100.0000 (99.7984)  Loss: -0.0410 (-0.0136)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7134)  Acc@5: 100.0000 (99.8476)  Loss: -0.0410 (-0.0012)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6716)  Acc@5: 100.0000 (99.8775)  Loss: -0.0324 (-0.0043)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2336)  Acc@5: 100.0000 (99.6926)  Loss: -0.0498 (0.0009)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.7430)  Acc@5: 100.0000 (99.7359)  Loss: -0.0154 (0.0032)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7593)  Acc@5: 100.0000 (99.7685)  Loss: -0.0157 (0.0012)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9093)  Acc@5: 100.0000 (99.7940)  Loss: -0.0538 (-0.0037)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6584)  Acc@5: 100.0000 (99.8144)  Loss: -0.0085 (0.0031)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.6779)  Acc@5: 100.0000 (99.8311)  Loss: -0.0056 (-0.0009)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6942)  Acc@5: 100.0000 (99.8450)  Loss: -0.0617 (-0.0013)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.8989)  Acc@5: 100.0000 (99.8569)  Loss: -0.0714 (-0.0058)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9858)  Acc@5: 100.0000 (99.8670)  Loss: -0.0664 (-0.0084)  time: 0.1888  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0199)  Acc@5: 100.0000 (99.8758)  Loss: -0.0548 (-0.0088)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0497)  Acc@5: 100.0000 (99.8835)  Loss: -0.0447 (-0.0105)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0395)  Acc@5: 100.0000 (99.8904)  Loss: -0.0447 (-0.0121)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1340)  Acc@5: 100.0000 (99.8964)  Loss: -0.0707 (-0.0142)  time: 0.1888  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1531)  Acc@5: 100.0000 (99.8691)  Loss: -0.0486 (-0.0151)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1704)  Acc@5: 100.0000 (99.8756)  Loss: -0.0460 (-0.0152)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1268)  Acc@5: 100.0000 (99.8815)  Loss: -0.0769 (-0.0162)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2002)  Acc@5: 100.0000 (99.8869)  Loss: -0.0919 (-0.0189)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1861)  Acc@5: 100.0000 (99.8647)  Loss: -0.0485 (-0.0187)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1732)  Acc@5: 100.0000 (99.8703)  Loss: -0.0338 (-0.0189)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1614)  Acc@5: 100.0000 (99.8755)  Loss: -0.0791 (-0.0206)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1743)  Acc@5: 100.0000 (99.8803)  Loss: -0.0777 (-0.0215)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2555)  Acc@5: 100.0000 (99.8847)  Loss: -0.0810 (-0.0240)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1975)  Acc@5: 100.0000 (99.8888)  Loss: -0.0966 (-0.0233)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1220)  Acc@5: 100.0000 (99.8926)  Loss: -0.0212 (-0.0221)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.0930)  Acc@5: 100.0000 (99.8962)  Loss: -0.0329 (-0.0224)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.0659)  Acc@5: 100.0000 (99.8995)  Loss: -0.0390 (-0.0226)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.0847)  Acc@5: 100.0000 (99.9002)  Loss: -0.0477 (-0.0232)  time: 0.1841  data: 0.0002  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:59 (0.1893 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.0847)  Acc@5: 100.0000 (99.9002)  Loss: -0.0477 (-0.0232)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1290 (-0.1290)  time: 0.3831  data: 0.1944  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1006 (-0.0667)  time: 0.2062  data: 0.0179  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.1045 (-0.0664)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3871)  Acc@5: 100.0000 (100.0000)  Loss: -0.1107 (-0.0793)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1079 (-0.0714)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.0984 (-0.0733)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7459)  Acc@5: 100.0000 (100.0000)  Loss: -0.1015 (-0.0686)  time: 0.1888  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6232)  Acc@5: 100.0000 (100.0000)  Loss: -0.0736 (-0.0664)  time: 0.1887  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7623)  Acc@5: 100.0000 (100.0000)  Loss: -0.0736 (-0.0685)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8709)  Acc@5: 100.0000 (100.0000)  Loss: -0.1110 (-0.0705)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7104)  Acc@5: 100.0000 (100.0000)  Loss: -0.0784 (-0.0652)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8041)  Acc@5: 100.0000 (100.0000)  Loss: -0.0558 (-0.0676)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7789)  Acc@5: 100.0000 (100.0000)  Loss: -0.1130 (-0.0677)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9485)  Acc@5: 100.0000 (100.0000)  Loss: -0.1130 (-0.0703)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0496)  Acc@5: 100.0000 (100.0000)  Loss: -0.1059 (-0.0721)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1374)  Acc@5: 100.0000 (100.0000)  Loss: -0.1051 (-0.0722)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1366)  Acc@5: 100.0000 (100.0000)  Loss: -0.1073 (-0.0729)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0629)  Acc@5: 100.0000 (100.0000)  Loss: -0.1008 (-0.0734)  time: 0.1890  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1008)  Acc@5: 100.0000 (100.0000)  Loss: -0.1029 (-0.0749)  time: 0.1893  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1021)  Acc@5: 100.0000 (100.0000)  Loss: -0.1083 (-0.0752)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0721)  Acc@5: 100.0000 (100.0000)  Loss: -0.0996 (-0.0744)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0450)  Acc@5: 100.0000 (100.0000)  Loss: -0.1081 (-0.0745)  time: 0.1881  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0769)  Acc@5: 100.0000 (100.0000)  Loss: -0.1160 (-0.0765)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0790)  Acc@5: 100.0000 (100.0000)  Loss: -0.1060 (-0.0760)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0550)  Acc@5: 100.0000 (100.0000)  Loss: -0.0880 (-0.0758)  time: 0.1879  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0578)  Acc@5: 100.0000 (100.0000)  Loss: -0.1129 (-0.0768)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0603)  Acc@5: 100.0000 (100.0000)  Loss: -0.1130 (-0.0769)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1089)  Acc@5: 100.0000 (100.0000)  Loss: -0.1130 (-0.0785)  time: 0.1883  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0649)  Acc@5: 100.0000 (100.0000)  Loss: -0.1202 (-0.0776)  time: 0.1881  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0455)  Acc@5: 100.0000 (100.0000)  Loss: -0.0709 (-0.0764)  time: 0.1881  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0482)  Acc@5: 100.0000 (100.0000)  Loss: -0.0782 (-0.0761)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0305)  Acc@5: 100.0000 (100.0000)  Loss: -0.0786 (-0.0760)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0431)  Acc@5: 100.0000 (100.0000)  Loss: -0.0786 (-0.0764)  time: 0.1835  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:59 (0.1890 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0431)  Acc@5: 100.0000 (100.0000)  Loss: -0.0786 (-0.0764)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1453 (-0.1453)  time: 0.3804  data: 0.1904  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1253 (-0.0951)  time: 0.2059  data: 0.0175  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1247 (-0.0941)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5887)  Acc@5: 100.0000 (100.0000)  Loss: -0.1279 (-0.1046)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4756)  Acc@5: 100.0000 (100.0000)  Loss: -0.1378 (-0.0994)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4069)  Acc@5: 100.0000 (100.0000)  Loss: -0.1211 (-0.1013)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2582)  Acc@5: 100.0000 (100.0000)  Loss: -0.1214 (-0.0982)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0634)  Acc@5: 100.0000 (100.0000)  Loss: -0.0991 (-0.0961)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2253)  Acc@5: 100.0000 (100.0000)  Loss: -0.1094 (-0.0980)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3516)  Acc@5: 100.0000 (100.0000)  Loss: -0.1291 (-0.0990)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3292)  Acc@5: 100.0000 (100.0000)  Loss: -0.1095 (-0.0950)  time: 0.1883  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4797)  Acc@5: 100.0000 (100.0000)  Loss: -0.0975 (-0.0969)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3988)  Acc@5: 100.0000 (100.0000)  Loss: -0.1322 (-0.0969)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5210)  Acc@5: 100.0000 (100.0000)  Loss: -0.1323 (-0.0990)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5816)  Acc@5: 100.0000 (100.0000)  Loss: -0.1297 (-0.1002)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6341)  Acc@5: 100.0000 (100.0000)  Loss: -0.1251 (-0.1003)  time: 0.1883  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6025)  Acc@5: 100.0000 (100.0000)  Loss: -0.1251 (-0.1007)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5746)  Acc@5: 100.0000 (100.0000)  Loss: -0.1169 (-0.1010)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6188)  Acc@5: 100.0000 (100.0000)  Loss: -0.1264 (-0.1024)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6257)  Acc@5: 100.0000 (100.0000)  Loss: -0.1329 (-0.1027)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1210 (-0.1015)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6078)  Acc@5: 100.0000 (100.0000)  Loss: -0.1198 (-0.1016)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6708)  Acc@5: 100.0000 (100.0000)  Loss: -0.1379 (-0.1031)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6742)  Acc@5: 100.0000 (100.0000)  Loss: -0.1181 (-0.1028)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6774)  Acc@5: 100.0000 (100.0000)  Loss: -0.1155 (-0.1026)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6803)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.1032)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6830)  Acc@5: 100.0000 (100.0000)  Loss: -0.1243 (-0.1033)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7085)  Acc@5: 100.0000 (100.0000)  Loss: -0.1243 (-0.1044)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6655)  Acc@5: 100.0000 (100.0000)  Loss: -0.1298 (-0.1038)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6469)  Acc@5: 100.0000 (100.0000)  Loss: -0.1023 (-0.1030)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6503)  Acc@5: 100.0000 (100.0000)  Loss: -0.1029 (-0.1027)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6535)  Acc@5: 100.0000 (100.0000)  Loss: -0.1086 (-0.1027)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6621)  Acc@5: 100.0000 (100.0000)  Loss: -0.1103 (-0.1030)  time: 0.1834  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:59 (0.1888 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6621)  Acc@5: 100.0000 (100.0000)  Loss: -0.1103 (-0.1030)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1505 (-0.1505)  time: 0.3540  data: 0.1646  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.1433 (-0.1164)  time: 0.2033  data: 0.0152  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8095)  Acc@5: 100.0000 (100.0000)  Loss: -0.1341 (-0.1142)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1935)  Acc@5: 100.0000 (100.0000)  Loss: -0.1404 (-0.1216)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0854)  Acc@5: 100.0000 (100.0000)  Loss: -0.1466 (-0.1180)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1422)  Acc@5: 100.0000 (100.0000)  Loss: -0.1324 (-0.1196)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1803)  Acc@5: 100.0000 (100.0000)  Loss: -0.1325 (-0.1173)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0317)  Acc@5: 100.0000 (100.0000)  Loss: -0.1191 (-0.1160)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0741)  Acc@5: 100.0000 (100.0000)  Loss: -0.1321 (-0.1180)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1071)  Acc@5: 100.0000 (100.0000)  Loss: -0.1426 (-0.1181)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1337)  Acc@5: 100.0000 (100.0000)  Loss: -0.1265 (-0.1151)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2117)  Acc@5: 100.0000 (100.0000)  Loss: -0.1205 (-0.1164)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1219)  Acc@5: 100.0000 (100.0000)  Loss: -0.1406 (-0.1161)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1889)  Acc@5: 100.0000 (100.0000)  Loss: -0.1406 (-0.1177)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2021)  Acc@5: 100.0000 (100.0000)  Loss: -0.1385 (-0.1185)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2550)  Acc@5: 100.0000 (100.0000)  Loss: -0.1350 (-0.1187)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2624)  Acc@5: 100.0000 (100.0000)  Loss: -0.1350 (-0.1189)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3056)  Acc@5: 100.0000 (100.0000)  Loss: -0.1251 (-0.1191)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3094)  Acc@5: 100.0000 (100.0000)  Loss: -0.1422 (-0.1203)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2801)  Acc@5: 100.0000 (100.0000)  Loss: -0.1422 (-0.1206)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2537)  Acc@5: 100.0000 (100.0000)  Loss: -0.1388 (-0.1194)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2299)  Acc@5: 100.0000 (100.0000)  Loss: -0.1314 (-0.1195)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)  Loss: -0.1437 (-0.1206)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2695)  Acc@5: 100.0000 (100.0000)  Loss: -0.1324 (-0.1204)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2739)  Acc@5: 100.0000 (100.0000)  Loss: -0.1287 (-0.1203)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2530)  Acc@5: 100.0000 (100.0000)  Loss: -0.1427 (-0.1207)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2577)  Acc@5: 100.0000 (100.0000)  Loss: -0.1342 (-0.1207)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2620)  Acc@5: 100.0000 (100.0000)  Loss: -0.1342 (-0.1216)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2215)  Acc@5: 100.0000 (100.0000)  Loss: -0.1346 (-0.1213)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2268)  Acc@5: 100.0000 (100.0000)  Loss: -0.1255 (-0.1207)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2110)  Acc@5: 100.0000 (100.0000)  Loss: -0.1220 (-0.1204)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2162)  Acc@5: 100.0000 (100.0000)  Loss: -0.1199 (-0.1204)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2212)  Acc@5: 100.0000 (100.0000)  Loss: -0.1269 (-0.1206)  time: 0.1830  data: 0.0002  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:58 (0.1885 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2212)  Acc@5: 100.0000 (100.0000)  Loss: -0.1269 (-0.1206)
Test: [Task 1]  [ 0/63]  eta: 0:00:22  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.2459 (0.2459)  time: 0.3580  data: 0.2397  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (98.8636)  Loss: 0.3619 (0.3553)  time: 0.1386  data: 0.0221  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (91.6667)  Acc@5: 100.0000 (99.4048)  Loss: 0.3619 (0.3870)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (92.3387)  Acc@5: 100.0000 (99.5968)  Loss: 0.3172 (0.3618)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (91.7683)  Acc@5: 100.0000 (99.6951)  Loss: 0.3190 (0.3647)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (92.5245)  Acc@5: 100.0000 (99.6324)  Loss: 0.2810 (0.3487)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (92.7254)  Acc@5: 100.0000 (99.6926)  Loss: 0.2879 (0.3487)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (92.9000)  Acc@5: 100.0000 (99.7000)  Loss: 0.2615 (0.3444)  time: 0.1139  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:07 (0.1208 s / it)
* Acc@1 92.900 Acc@5 99.700 loss 0.344
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4263 (0.4263)  time: 0.3118  data: 0.1949  max mem: 2372
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (99.4318)  Loss: 0.2708 (0.3511)  time: 0.1344  data: 0.0180  max mem: 2372
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (93.1548)  Acc@5: 100.0000 (98.8095)  Loss: 0.3685 (0.4486)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (92.5403)  Acc@5: 100.0000 (99.1935)  Loss: 0.4360 (0.4552)  time: 0.1168  data: 0.0003  max mem: 2372
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (99.0854)  Loss: 0.3848 (0.4304)  time: 0.1168  data: 0.0004  max mem: 2372
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.3824)  Acc@5: 100.0000 (99.1422)  Loss: 0.3196 (0.4240)  time: 0.1168  data: 0.0003  max mem: 2372
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (93.9549)  Acc@5: 100.0000 (99.2828)  Loss: 0.2855 (0.3969)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (94.1000)  Acc@5: 100.0000 (99.3000)  Loss: 0.2805 (0.3883)  time: 0.1138  data: 0.0003  max mem: 2372
Test: [Task 2] Total time: 0:00:07 (0.1199 s / it)
* Acc@1 94.100 Acc@5 99.300 loss 0.388
[Average accuracy till task2]	ASR: 0.0000	Acc@1: 93.5000	Loss: 0.0000	Forgetting: 0.0000	Backward: 0.0000
training non poison model
Train: Epoch[1/5]  [  0/313]  eta: 0:02:03  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  Loss: 2.1469 (2.1469)  time: 0.3937  data: 0.2009  max mem: 2372
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (53.9773)  Acc@5: 81.2500 (83.5227)  Loss: 1.9365 (1.9490)  time: 0.2073  data: 0.0186  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.3452)  Acc@5: 93.7500 (90.1786)  Loss: 1.6116 (1.7142)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (74.7984)  Acc@5: 100.0000 (92.9435)  Loss: 1.2293 (1.5198)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (79.7256)  Acc@5: 100.0000 (94.6646)  Loss: 0.9154 (1.3371)  time: 0.1878  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.9853)  Acc@5: 100.0000 (95.5882)  Loss: 0.6541 (1.1975)  time: 0.1877  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.2213)  Acc@5: 100.0000 (96.3115)  Loss: 0.5393 (1.0778)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.7394)  Acc@5: 100.0000 (96.8310)  Loss: 0.4060 (0.9756)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.4969)  Acc@5: 100.0000 (97.1451)  Loss: 0.3508 (0.9003)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.2940)  Acc@5: 100.0000 (97.4588)  Loss: 0.2937 (0.8299)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.9332)  Acc@5: 100.0000 (97.7104)  Loss: 0.2368 (0.7704)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.5698)  Acc@5: 100.0000 (97.9167)  Loss: 0.2089 (0.7221)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.8430)  Acc@5: 100.0000 (98.0372)  Loss: 0.1873 (0.6785)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.2653)  Acc@5: 100.0000 (98.1393)  Loss: 0.1727 (0.6394)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.6720)  Acc@5: 100.0000 (98.2713)  Loss: 0.1664 (0.6043)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.9007)  Acc@5: 100.0000 (98.3858)  Loss: 0.1562 (0.5743)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.2174)  Acc@5: 100.0000 (98.4472)  Loss: 0.1054 (0.5469)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.4605)  Acc@5: 100.0000 (98.5015)  Loss: 0.0743 (0.5219)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.6423)  Acc@5: 100.0000 (98.5843)  Loss: 0.0664 (0.4984)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.9031)  Acc@5: 100.0000 (98.5929)  Loss: 0.0754 (0.4786)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.1692)  Acc@5: 100.0000 (98.6629)  Loss: 0.0599 (0.4586)  time: 0.1870  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.3211)  Acc@5: 100.0000 (98.7263)  Loss: 0.0832 (0.4419)  time: 0.1870  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.5724)  Acc@5: 100.0000 (98.7839)  Loss: 0.0832 (0.4246)  time: 0.1871  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.8290)  Acc@5: 100.0000 (98.8095)  Loss: 0.0294 (0.4074)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8568)  Acc@5: 100.0000 (98.8330)  Loss: 0.0447 (0.3937)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.9572)  Acc@5: 100.0000 (98.8795)  Loss: 0.0518 (0.3800)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.1456)  Acc@5: 100.0000 (98.9224)  Loss: 0.0318 (0.3661)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.2509)  Acc@5: 100.0000 (98.9391)  Loss: 0.0397 (0.3535)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.4155)  Acc@5: 100.0000 (98.9769)  Loss: 0.0389 (0.3416)  time: 0.1869  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.5687)  Acc@5: 100.0000 (99.0120)  Loss: -0.0456 (0.3296)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.6910)  Acc@5: 100.0000 (99.0449)  Loss: -0.0258 (0.3189)  time: 0.1871  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.8658)  Acc@5: 100.0000 (99.0756)  Loss: -0.0176 (0.3082)  time: 0.1870  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.8514)  Acc@5: 100.0000 (99.0815)  Loss: -0.0176 (0.3069)  time: 0.1826  data: 0.0001  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:58 (0.1882 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.8514)  Acc@5: 100.0000 (99.0815)  Loss: -0.0176 (0.3069)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1286 (-0.1286)  time: 0.4163  data: 0.2258  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (100.0000)  Loss: 0.0037 (0.0224)  time: 0.2076  data: 0.0206  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1310)  Acc@5: 100.0000 (100.0000)  Loss: -0.0048 (-0.0091)  time: 0.1869  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7661)  Acc@5: 100.0000 (100.0000)  Loss: -0.0227 (0.0016)  time: 0.1871  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7317)  Acc@5: 100.0000 (100.0000)  Loss: -0.0089 (-0.0049)  time: 0.1867  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.4657)  Acc@5: 100.0000 (100.0000)  Loss: -0.0089 (-0.0039)  time: 0.1865  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.4918)  Acc@5: 100.0000 (100.0000)  Loss: -0.0350 (-0.0081)  time: 0.1867  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7746)  Acc@5: 100.0000 (100.0000)  Loss: -0.0368 (-0.0131)  time: 0.1871  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9105)  Acc@5: 100.0000 (100.0000)  Loss: -0.0298 (-0.0124)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0165)  Acc@5: 100.0000 (100.0000)  Loss: -0.0298 (-0.0128)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.8540)  Acc@5: 100.0000 (100.0000)  Loss: -0.0250 (-0.0112)  time: 0.1871  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (100.0000)  Loss: -0.0131 (-0.0098)  time: 0.1870  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7128)  Acc@5: 100.0000 (99.9483)  Loss: -0.0033 (-0.0075)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.6584)  Acc@5: 100.0000 (99.9523)  Loss: -0.0212 (-0.0092)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.6560)  Acc@5: 100.0000 (99.9557)  Loss: -0.0567 (-0.0107)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.6540)  Acc@5: 100.0000 (99.9586)  Loss: -0.0366 (-0.0092)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7686)  Acc@5: 100.0000 (99.9612)  Loss: -0.0437 (-0.0104)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7602)  Acc@5: 100.0000 (99.9269)  Loss: -0.0673 (-0.0107)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7873)  Acc@5: 100.0000 (99.9309)  Loss: -0.0724 (-0.0109)  time: 0.1871  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7461)  Acc@5: 100.0000 (99.9018)  Loss: -0.0524 (-0.0096)  time: 0.1870  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.8022)  Acc@5: 100.0000 (99.9067)  Loss: -0.0524 (-0.0113)  time: 0.1869  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.8531)  Acc@5: 100.0000 (99.9111)  Loss: -0.0443 (-0.0124)  time: 0.1868  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9276)  Acc@5: 100.0000 (99.9152)  Loss: -0.0446 (-0.0142)  time: 0.1869  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (99.9188)  Loss: -0.0732 (-0.0165)  time: 0.1870  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.9803)  Acc@5: 100.0000 (99.9222)  Loss: -0.0753 (-0.0167)  time: 0.1871  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0657)  Acc@5: 100.0000 (99.9253)  Loss: -0.0405 (-0.0177)  time: 0.1870  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1446)  Acc@5: 100.0000 (99.9282)  Loss: -0.0454 (-0.0194)  time: 0.1869  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2177)  Acc@5: 100.0000 (99.9077)  Loss: -0.0524 (-0.0205)  time: 0.1870  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2856)  Acc@5: 100.0000 (99.9110)  Loss: -0.0652 (-0.0222)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3488)  Acc@5: 100.0000 (99.9141)  Loss: -0.1065 (-0.0241)  time: 0.1872  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3663)  Acc@5: 100.0000 (99.9169)  Loss: -0.1065 (-0.0254)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4228)  Acc@5: 100.0000 (99.9196)  Loss: -0.0844 (-0.0272)  time: 0.1871  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3858)  Acc@5: 100.0000 (99.9201)  Loss: -0.0844 (-0.0270)  time: 0.1827  data: 0.0001  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:58 (0.1878 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3858)  Acc@5: 100.0000 (99.9201)  Loss: -0.0844 (-0.0270)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1589 (-0.1589)  time: 0.4156  data: 0.2254  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (100.0000)  Loss: -0.0628 (-0.0456)  time: 0.2081  data: 0.0206  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (100.0000)  Loss: -0.0656 (-0.0682)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1774)  Acc@5: 100.0000 (100.0000)  Loss: -0.0821 (-0.0597)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (100.0000)  Loss: -0.0730 (-0.0642)  time: 0.1872  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3039)  Acc@5: 100.0000 (100.0000)  Loss: -0.0730 (-0.0632)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3361)  Acc@5: 100.0000 (100.0000)  Loss: -0.0818 (-0.0653)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4472)  Acc@5: 100.0000 (100.0000)  Loss: -0.0885 (-0.0683)  time: 0.1872  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5309)  Acc@5: 100.0000 (100.0000)  Loss: -0.0723 (-0.0679)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3901)  Acc@5: 100.0000 (100.0000)  Loss: -0.0725 (-0.0671)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3391)  Acc@5: 100.0000 (100.0000)  Loss: -0.0725 (-0.0640)  time: 0.1871  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2410)  Acc@5: 100.0000 (100.0000)  Loss: -0.0564 (-0.0624)  time: 0.1869  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.0558)  Acc@5: 100.0000 (100.0000)  Loss: -0.0559 (-0.0592)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1374)  Acc@5: 100.0000 (100.0000)  Loss: -0.0691 (-0.0610)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1631)  Acc@5: 100.0000 (100.0000)  Loss: -0.0971 (-0.0620)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1440)  Acc@5: 100.0000 (100.0000)  Loss: -0.0969 (-0.0593)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1661)  Acc@5: 100.0000 (100.0000)  Loss: -0.0739 (-0.0602)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1491)  Acc@5: 100.0000 (100.0000)  Loss: -0.1106 (-0.0601)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1340)  Acc@5: 100.0000 (100.0000)  Loss: -0.1106 (-0.0594)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.0550)  Acc@5: 100.0000 (100.0000)  Loss: -0.0795 (-0.0574)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1393)  Acc@5: 100.0000 (100.0000)  Loss: -0.0716 (-0.0587)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1860)  Acc@5: 100.0000 (100.0000)  Loss: -0.0770 (-0.0597)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2285)  Acc@5: 100.0000 (100.0000)  Loss: -0.0924 (-0.0609)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2673)  Acc@5: 100.0000 (100.0000)  Loss: -0.1005 (-0.0625)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2251)  Acc@5: 100.0000 (100.0000)  Loss: -0.1053 (-0.0626)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2610)  Acc@5: 100.0000 (100.0000)  Loss: -0.0811 (-0.0630)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3180)  Acc@5: 100.0000 (100.0000)  Loss: -0.0879 (-0.0642)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3478)  Acc@5: 100.0000 (99.9769)  Loss: -0.0945 (-0.0648)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3977)  Acc@5: 100.0000 (99.9778)  Loss: -0.0953 (-0.0659)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4442)  Acc@5: 100.0000 (99.9785)  Loss: -0.1192 (-0.0672)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4668)  Acc@5: 100.0000 (99.9792)  Loss: -0.1257 (-0.0681)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5080)  Acc@5: 100.0000 (99.9799)  Loss: -0.1127 (-0.0693)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5040)  Acc@5: 100.0000 (99.9800)  Loss: -0.1110 (-0.0692)  time: 0.1830  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:58 (0.1882 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5040)  Acc@5: 100.0000 (99.9800)  Loss: -0.1110 (-0.0692)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1664 (-0.1664)  time: 0.4272  data: 0.2361  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.0914 (-0.0797)  time: 0.2096  data: 0.0216  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.0995 (-0.0955)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9839)  Acc@5: 100.0000 (100.0000)  Loss: -0.1080 (-0.0880)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1707)  Acc@5: 100.0000 (100.0000)  Loss: -0.1042 (-0.0917)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2843)  Acc@5: 100.0000 (100.0000)  Loss: -0.1036 (-0.0917)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2582)  Acc@5: 100.0000 (100.0000)  Loss: -0.1052 (-0.0930)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3275)  Acc@5: 100.0000 (100.0000)  Loss: -0.1117 (-0.0947)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3796)  Acc@5: 100.0000 (100.0000)  Loss: -0.1003 (-0.0944)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.0987 (-0.0938)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0817)  Acc@5: 100.0000 (100.0000)  Loss: -0.0945 (-0.0905)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0293)  Acc@5: 100.0000 (100.0000)  Loss: -0.0831 (-0.0893)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8822)  Acc@5: 100.0000 (100.0000)  Loss: -0.0940 (-0.0865)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0439)  Acc@5: 100.0000 (100.0000)  Loss: -0.1064 (-0.0882)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0940)  Acc@5: 100.0000 (100.0000)  Loss: -0.1166 (-0.0890)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0132)  Acc@5: 100.0000 (100.0000)  Loss: -0.1137 (-0.0861)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0590)  Acc@5: 100.0000 (100.0000)  Loss: -0.0884 (-0.0870)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9898)  Acc@5: 100.0000 (100.0000)  Loss: -0.1301 (-0.0868)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9972)  Acc@5: 100.0000 (100.0000)  Loss: -0.1301 (-0.0859)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9058)  Acc@5: 100.0000 (100.0000)  Loss: -0.1069 (-0.0840)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9478)  Acc@5: 100.0000 (100.0000)  Loss: -0.1036 (-0.0850)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9858)  Acc@5: 100.0000 (100.0000)  Loss: -0.1078 (-0.0859)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0204)  Acc@5: 100.0000 (100.0000)  Loss: -0.1116 (-0.0867)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0519)  Acc@5: 100.0000 (100.0000)  Loss: -0.1185 (-0.0881)  time: 0.1878  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0290)  Acc@5: 100.0000 (100.0000)  Loss: -0.1197 (-0.0882)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0329)  Acc@5: 100.0000 (100.0000)  Loss: -0.0982 (-0.0882)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0843)  Acc@5: 100.0000 (100.0000)  Loss: -0.1114 (-0.0893)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1089)  Acc@5: 100.0000 (99.9769)  Loss: -0.1106 (-0.0895)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1762)  Acc@5: 100.0000 (99.9778)  Loss: -0.1117 (-0.0904)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2388)  Acc@5: 100.0000 (99.9785)  Loss: -0.1302 (-0.0914)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2766)  Acc@5: 100.0000 (99.9792)  Loss: -0.1345 (-0.0921)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3119)  Acc@5: 100.0000 (99.9799)  Loss: -0.1226 (-0.0931)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (99.9800)  Loss: -0.1206 (-0.0931)  time: 0.1831  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:58 (0.1885 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (99.9800)  Loss: -0.1206 (-0.0931)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1700 (-0.1700)  time: 0.3741  data: 0.1841  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1080 (-0.1049)  time: 0.2045  data: 0.0169  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4048)  Acc@5: 100.0000 (100.0000)  Loss: -0.1108 (-0.1142)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1935)  Acc@5: 100.0000 (100.0000)  Loss: -0.1283 (-0.1066)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0854)  Acc@5: 100.0000 (100.0000)  Loss: -0.1195 (-0.1092)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1422)  Acc@5: 100.0000 (100.0000)  Loss: -0.1195 (-0.1096)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1803)  Acc@5: 100.0000 (100.0000)  Loss: -0.1232 (-0.1108)  time: 0.1880  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0317)  Acc@5: 100.0000 (100.0000)  Loss: -0.1241 (-0.1114)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9969)  Acc@5: 100.0000 (100.0000)  Loss: -0.1174 (-0.1113)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8324)  Acc@5: 100.0000 (100.0000)  Loss: -0.1134 (-0.1106)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6386)  Acc@5: 100.0000 (100.0000)  Loss: -0.1038 (-0.1077)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5923)  Acc@5: 100.0000 (100.0000)  Loss: -0.1039 (-0.1068)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4504)  Acc@5: 100.0000 (100.0000)  Loss: -0.1191 (-0.1043)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5687)  Acc@5: 100.0000 (100.0000)  Loss: -0.1232 (-0.1059)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5816)  Acc@5: 100.0000 (100.0000)  Loss: -0.1281 (-0.1065)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4685)  Acc@5: 100.0000 (100.0000)  Loss: -0.1247 (-0.1037)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5637)  Acc@5: 100.0000 (100.0000)  Loss: -0.1095 (-0.1045)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5015)  Acc@5: 100.0000 (100.0000)  Loss: -0.1338 (-0.1044)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5152)  Acc@5: 100.0000 (100.0000)  Loss: -0.1370 (-0.1034)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4620)  Acc@5: 100.0000 (100.0000)  Loss: -0.1190 (-0.1018)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5386)  Acc@5: 100.0000 (100.0000)  Loss: -0.1190 (-0.1025)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5486)  Acc@5: 100.0000 (100.0000)  Loss: -0.1276 (-0.1032)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5577)  Acc@5: 100.0000 (100.0000)  Loss: -0.1220 (-0.1039)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5931)  Acc@5: 100.0000 (100.0000)  Loss: -0.1294 (-0.1051)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6255)  Acc@5: 100.0000 (100.0000)  Loss: -0.1296 (-0.1053)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6305)  Acc@5: 100.0000 (100.0000)  Loss: -0.1162 (-0.1052)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6830)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.1061)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6854)  Acc@5: 100.0000 (100.0000)  Loss: -0.1235 (-0.1062)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7322)  Acc@5: 100.0000 (100.0000)  Loss: -0.1244 (-0.1068)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7758)  Acc@5: 100.0000 (100.0000)  Loss: -0.1383 (-0.1077)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7957)  Acc@5: 100.0000 (100.0000)  Loss: -0.1416 (-0.1082)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8344)  Acc@5: 100.0000 (100.0000)  Loss: -0.1321 (-0.1089)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1295 (-0.1090)  time: 0.1831  data: 0.0001  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:58 (0.1885 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1295 (-0.1090)
Test: [Task 1]  [ 0/63]  eta: 0:00:18  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.2891 (0.2891)  time: 0.3001  data: 0.1829  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  Loss: 0.4135 (0.4390)  time: 0.1333  data: 0.0169  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (99.1071)  Loss: 0.4135 (0.4416)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (88.1048)  Acc@5: 100.0000 (99.3952)  Loss: 0.3598 (0.4245)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (88.8720)  Acc@5: 100.0000 (99.3902)  Loss: 0.3138 (0.4114)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (90.1961)  Acc@5: 100.0000 (99.3873)  Loss: 0.3089 (0.3943)  time: 0.1164  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (90.2664)  Acc@5: 100.0000 (99.3852)  Loss: 0.3089 (0.3935)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (90.4000)  Acc@5: 100.0000 (99.4000)  Loss: 0.2899 (0.3888)  time: 0.1136  data: 0.0002  max mem: 2372
Test: [Task 1] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 90.400 Acc@5 99.400 loss 0.389
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5325 (0.5325)  time: 0.3041  data: 0.1873  max mem: 2372
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.8636)  Loss: 0.3682 (0.4284)  time: 0.1335  data: 0.0173  max mem: 2372
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (98.2143)  Loss: 0.4148 (0.5315)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (89.5161)  Acc@5: 100.0000 (97.9839)  Loss: 0.5306 (0.5301)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (90.5488)  Acc@5: 100.0000 (98.1707)  Loss: 0.4828 (0.5116)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (98.1618)  Loss: 0.4039 (0.5022)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (91.8033)  Acc@5: 100.0000 (98.3607)  Loss: 0.3666 (0.4763)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (92.0000)  Acc@5: 100.0000 (98.4000)  Loss: 0.3553 (0.4665)  time: 0.1136  data: 0.0002  max mem: 2372
Test: [Task 2] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 92.000 Acc@5 98.400 loss 0.466
Test: [Task 3]  [ 0/63]  eta: 0:00:20  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1188 (0.1188)  time: 0.3229  data: 0.2026  max mem: 2372
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (98.2955)  Loss: 0.3264 (0.4004)  time: 0.1354  data: 0.0188  max mem: 2372
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (92.5595)  Acc@5: 100.0000 (98.5119)  Loss: 0.3264 (0.4037)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (98.7903)  Loss: 0.3273 (0.3883)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (91.4634)  Acc@5: 100.0000 (98.7805)  Loss: 0.4207 (0.4025)  time: 0.1167  data: 0.0004  max mem: 2372
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (91.7892)  Acc@5: 100.0000 (98.7745)  Loss: 0.3918 (0.4111)  time: 0.1166  data: 0.0004  max mem: 2372
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (91.0861)  Acc@5: 100.0000 (98.9754)  Loss: 0.3700 (0.4211)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (90.9000)  Acc@5: 100.0000 (99.0000)  Loss: 0.3700 (0.4262)  time: 0.1137  data: 0.0002  max mem: 2372
Test: [Task 3] Total time: 0:00:07 (0.1200 s / it)
* Acc@1 90.900 Acc@5 99.000 loss 0.426
[Average accuracy till task3]	ASR: 0.0000	Acc@1: 91.1000	Loss: 0.0000	Forgetting: 0.0000	Backward: 0.0000
training non poison model
Train: Epoch[1/5]  [  0/313]  eta: 0:02:03  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  Loss: 2.1753 (2.1753)  time: 0.3960  data: 0.2051  max mem: 2372
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.6364)  Acc@5: 93.7500 (88.0682)  Loss: 1.9354 (1.8921)  time: 0.2065  data: 0.0188  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.3810)  Acc@5: 100.0000 (92.8571)  Loss: 1.6038 (1.6296)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (82.4597)  Acc@5: 100.0000 (94.9597)  Loss: 1.1212 (1.4025)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.7561)  Acc@5: 100.0000 (96.1890)  Loss: 0.8021 (1.2311)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.3775)  Acc@5: 100.0000 (96.9363)  Loss: 0.4916 (1.0731)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (88.7295)  Acc@5: 100.0000 (97.3361)  Loss: 0.3737 (0.9558)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (89.7887)  Acc@5: 100.0000 (97.6232)  Loss: 0.2682 (0.8569)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (90.6636)  Acc@5: 100.0000 (97.9167)  Loss: 0.1950 (0.7769)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.4148)  Acc@5: 100.0000 (98.1456)  Loss: 0.1468 (0.7070)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.9554)  Acc@5: 100.0000 (98.3292)  Loss: 0.1188 (0.6500)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.5113)  Acc@5: 100.0000 (98.4797)  Loss: 0.0852 (0.5987)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.0269)  Acc@5: 100.0000 (98.6054)  Loss: 0.0852 (0.5569)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2729)  Acc@5: 100.0000 (98.7118)  Loss: 0.0946 (0.5198)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.3954)  Acc@5: 100.0000 (98.7589)  Loss: 0.0946 (0.4921)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.6672)  Acc@5: 100.0000 (98.8411)  Loss: 0.0607 (0.4621)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.9053)  Acc@5: 100.0000 (98.9130)  Loss: 0.0207 (0.4360)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.0058)  Acc@5: 100.0000 (98.9766)  Loss: 0.0271 (0.4136)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.1989)  Acc@5: 100.0000 (98.9986)  Loss: 0.0340 (0.3937)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.2408)  Acc@5: 100.0000 (99.0183)  Loss: 0.0189 (0.3746)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.3408)  Acc@5: 100.0000 (99.0361)  Loss: -0.0104 (0.3569)  time: 0.1872  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.4609)  Acc@5: 100.0000 (99.0818)  Loss: -0.0591 (0.3382)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.5419)  Acc@5: 100.0000 (99.1233)  Loss: -0.0337 (0.3242)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.5076)  Acc@5: 100.0000 (99.1613)  Loss: -0.0178 (0.3130)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.6577)  Acc@5: 100.0000 (99.1961)  Loss: -0.0497 (0.2975)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.7958)  Acc@5: 100.0000 (99.2281)  Loss: -0.0590 (0.2839)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.8276)  Acc@5: 100.0000 (99.2337)  Loss: -0.0319 (0.2733)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.8570)  Acc@5: 100.0000 (99.2620)  Loss: 0.0041 (0.2642)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.0178)  Acc@5: 100.0000 (99.2883)  Loss: -0.0358 (0.2532)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.0816)  Acc@5: 100.0000 (99.3127)  Loss: -0.0372 (0.2447)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.1620)  Acc@5: 100.0000 (99.3355)  Loss: -0.0288 (0.2358)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.2170)  Acc@5: 100.0000 (99.3569)  Loss: -0.0628 (0.2269)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.2476)  Acc@5: 100.0000 (99.3610)  Loss: -0.0655 (0.2250)  time: 0.1828  data: 0.0001  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:58 (0.1883 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.2476)  Acc@5: 100.0000 (99.3610)  Loss: -0.0655 (0.2250)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1417 (-0.1417)  time: 0.3789  data: 0.1871  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0764 (-0.0682)  time: 0.2049  data: 0.0171  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8095)  Acc@5: 100.0000 (100.0000)  Loss: -0.0651 (-0.0628)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1855)  Acc@5: 100.0000 (100.0000)  Loss: -0.0762 (-0.0604)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7134)  Acc@5: 100.0000 (100.0000)  Loss: -0.0831 (-0.0551)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1618)  Acc@5: 100.0000 (100.0000)  Loss: -0.1068 (-0.0682)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9508)  Acc@5: 100.0000 (100.0000)  Loss: -0.1193 (-0.0641)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9754)  Acc@5: 100.0000 (100.0000)  Loss: -0.1126 (-0.0672)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1481)  Acc@5: 100.0000 (100.0000)  Loss: -0.1297 (-0.0741)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1456)  Acc@5: 100.0000 (100.0000)  Loss: -0.1297 (-0.0760)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2054)  Acc@5: 100.0000 (100.0000)  Loss: -0.1021 (-0.0782)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2545)  Acc@5: 100.0000 (100.0000)  Loss: -0.1254 (-0.0814)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.1022 (-0.0827)  time: 0.1872  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2824)  Acc@5: 100.0000 (100.0000)  Loss: -0.0983 (-0.0838)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1383)  Acc@5: 100.0000 (99.9557)  Loss: -0.0764 (-0.0799)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0960)  Acc@5: 100.0000 (99.9586)  Loss: -0.0578 (-0.0814)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1755)  Acc@5: 100.0000 (99.9612)  Loss: -0.1205 (-0.0828)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0994)  Acc@5: 100.0000 (99.9635)  Loss: -0.1144 (-0.0815)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1008)  Acc@5: 100.0000 (99.9655)  Loss: -0.0913 (-0.0801)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1021)  Acc@5: 100.0000 (99.9673)  Loss: -0.0906 (-0.0800)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1343)  Acc@5: 100.0000 (99.9689)  Loss: -0.1021 (-0.0806)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1931)  Acc@5: 100.0000 (99.9704)  Loss: -0.1450 (-0.0825)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1900)  Acc@5: 100.0000 (99.9717)  Loss: -0.1242 (-0.0819)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0790)  Acc@5: 100.0000 (99.9729)  Loss: -0.1051 (-0.0801)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1068)  Acc@5: 100.0000 (99.9741)  Loss: -0.1338 (-0.0822)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1823)  Acc@5: 100.0000 (99.9751)  Loss: -0.1381 (-0.0838)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1561)  Acc@5: 100.0000 (99.9761)  Loss: -0.1136 (-0.0838)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1089)  Acc@5: 100.0000 (99.9769)  Loss: -0.0926 (-0.0832)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1539)  Acc@5: 100.0000 (99.9778)  Loss: -0.1122 (-0.0845)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1959)  Acc@5: 100.0000 (99.9785)  Loss: -0.1104 (-0.0845)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1935)  Acc@5: 100.0000 (99.9792)  Loss: -0.1007 (-0.0848)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1913)  Acc@5: 100.0000 (99.9799)  Loss: -0.1257 (-0.0855)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2029)  Acc@5: 100.0000 (99.9800)  Loss: -0.1257 (-0.0858)  time: 0.1829  data: 0.0001  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:58 (0.1882 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2029)  Acc@5: 100.0000 (99.9800)  Loss: -0.1257 (-0.0858)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1654 (-0.1654)  time: 0.3689  data: 0.1771  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.1263 (-0.1193)  time: 0.2053  data: 0.0164  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1071)  Acc@5: 100.0000 (100.0000)  Loss: -0.1214 (-0.1153)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7903)  Acc@5: 100.0000 (100.0000)  Loss: -0.1241 (-0.1130)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3232)  Acc@5: 100.0000 (100.0000)  Loss: -0.1241 (-0.1079)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6520)  Acc@5: 100.0000 (100.0000)  Loss: -0.1466 (-0.1168)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3607)  Acc@5: 100.0000 (100.0000)  Loss: -0.1492 (-0.1104)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5035)  Acc@5: 100.0000 (100.0000)  Loss: -0.1418 (-0.1126)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6883)  Acc@5: 100.0000 (100.0000)  Loss: -0.1516 (-0.1178)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6951)  Acc@5: 100.0000 (100.0000)  Loss: -0.1546 (-0.1185)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8243)  Acc@5: 100.0000 (100.0000)  Loss: -0.1422 (-0.1202)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9302)  Acc@5: 100.0000 (100.0000)  Loss: -0.1467 (-0.1222)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9153)  Acc@5: 100.0000 (100.0000)  Loss: -0.1426 (-0.1223)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9504)  Acc@5: 100.0000 (100.0000)  Loss: -0.1369 (-0.1229)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7589)  Acc@5: 100.0000 (100.0000)  Loss: -0.1196 (-0.1191)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7583)  Acc@5: 100.0000 (100.0000)  Loss: -0.0922 (-0.1199)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7966)  Acc@5: 100.0000 (100.0000)  Loss: -0.1488 (-0.1210)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7208)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1197)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6878)  Acc@5: 100.0000 (100.0000)  Loss: -0.1266 (-0.1181)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6584)  Acc@5: 100.0000 (100.0000)  Loss: -0.1266 (-0.1180)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6629)  Acc@5: 100.0000 (100.0000)  Loss: -0.1417 (-0.1182)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6967)  Acc@5: 100.0000 (100.0000)  Loss: -0.1603 (-0.1194)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7274)  Acc@5: 100.0000 (100.0000)  Loss: -0.1471 (-0.1187)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6742)  Acc@5: 100.0000 (100.0000)  Loss: -0.1335 (-0.1171)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7033)  Acc@5: 100.0000 (100.0000)  Loss: -0.1487 (-0.1184)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7550)  Acc@5: 100.0000 (100.0000)  Loss: -0.1536 (-0.1194)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7548)  Acc@5: 100.0000 (100.0000)  Loss: -0.1310 (-0.1193)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7315)  Acc@5: 100.0000 (100.0000)  Loss: -0.1311 (-0.1187)  time: 0.1878  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7544)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1195)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7758)  Acc@5: 100.0000 (100.0000)  Loss: -0.1344 (-0.1197)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7957)  Acc@5: 100.0000 (100.0000)  Loss: -0.1327 (-0.1197)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8344)  Acc@5: 100.0000 (100.0000)  Loss: -0.1397 (-0.1202)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1203)  time: 0.1836  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:58 (0.1883 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1203)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1703 (-0.1703)  time: 0.3676  data: 0.1772  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1457 (-0.1411)  time: 0.2041  data: 0.0162  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7024)  Acc@5: 100.0000 (100.0000)  Loss: -0.1443 (-0.1369)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5968)  Acc@5: 100.0000 (100.0000)  Loss: -0.1424 (-0.1361)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3902)  Acc@5: 100.0000 (100.0000)  Loss: -0.1424 (-0.1321)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)  Loss: -0.1579 (-0.1381)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0779)  Acc@5: 100.0000 (100.0000)  Loss: -0.1613 (-0.1317)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1197)  Acc@5: 100.0000 (100.0000)  Loss: -0.1522 (-0.1333)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2284)  Acc@5: 100.0000 (100.0000)  Loss: -0.1621 (-0.1373)  time: 0.1872  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2445)  Acc@5: 100.0000 (100.0000)  Loss: -0.1638 (-0.1377)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3193)  Acc@5: 100.0000 (100.0000)  Loss: -0.1531 (-0.1391)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3806)  Acc@5: 100.0000 (100.0000)  Loss: -0.1582 (-0.1406)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3802)  Acc@5: 100.0000 (100.0000)  Loss: -0.1529 (-0.1402)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3798)  Acc@5: 100.0000 (100.0000)  Loss: -0.1466 (-0.1407)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3351)  Acc@5: 100.0000 (100.0000)  Loss: -0.1415 (-0.1375)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2964)  Acc@5: 100.0000 (100.0000)  Loss: -0.1297 (-0.1380)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3012)  Acc@5: 100.0000 (100.0000)  Loss: -0.1616 (-0.1389)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2690)  Acc@5: 100.0000 (100.0000)  Loss: -0.1587 (-0.1380)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2749)  Acc@5: 100.0000 (100.0000)  Loss: -0.1472 (-0.1367)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2474)  Acc@5: 100.0000 (100.0000)  Loss: -0.1502 (-0.1368)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2537)  Acc@5: 100.0000 (100.0000)  Loss: -0.1572 (-0.1371)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2595)  Acc@5: 100.0000 (100.0000)  Loss: -0.1666 (-0.1380)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)  Loss: -0.1560 (-0.1373)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2154)  Acc@5: 100.0000 (100.0000)  Loss: -0.1486 (-0.1360)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2220)  Acc@5: 100.0000 (100.0000)  Loss: -0.1513 (-0.1369)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2530)  Acc@5: 100.0000 (100.0000)  Loss: -0.1624 (-0.1376)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2577)  Acc@5: 100.0000 (100.0000)  Loss: -0.1452 (-0.1374)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2620)  Acc@5: 100.0000 (100.0000)  Loss: -0.1459 (-0.1370)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2883)  Acc@5: 100.0000 (100.0000)  Loss: -0.1483 (-0.1376)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3127)  Acc@5: 100.0000 (100.0000)  Loss: -0.1514 (-0.1378)  time: 0.1875  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3355)  Acc@5: 100.0000 (100.0000)  Loss: -0.1470 (-0.1377)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3569)  Acc@5: 100.0000 (100.0000)  Loss: -0.1481 (-0.1380)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3610)  Acc@5: 100.0000 (100.0000)  Loss: -0.1481 (-0.1381)  time: 0.1832  data: 0.0001  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:58 (0.1880 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3610)  Acc@5: 100.0000 (100.0000)  Loss: -0.1481 (-0.1381)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1721 (-0.1721)  time: 0.3921  data: 0.1944  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1575 (-0.1544)  time: 0.2066  data: 0.0178  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7024)  Acc@5: 100.0000 (100.0000)  Loss: -0.1559 (-0.1499)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7984)  Acc@5: 100.0000 (100.0000)  Loss: -0.1520 (-0.1493)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6951)  Acc@5: 100.0000 (100.0000)  Loss: -0.1487 (-0.1453)  time: 0.1888  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7549)  Acc@5: 100.0000 (100.0000)  Loss: -0.1634 (-0.1497)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4877)  Acc@5: 100.0000 (100.0000)  Loss: -0.1642 (-0.1442)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5599)  Acc@5: 100.0000 (100.0000)  Loss: -0.1577 (-0.1456)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6142)  Acc@5: 100.0000 (100.0000)  Loss: -0.1677 (-0.1488)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6566)  Acc@5: 100.0000 (100.0000)  Loss: -0.1679 (-0.1490)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6906)  Acc@5: 100.0000 (100.0000)  Loss: -0.1580 (-0.1502)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7185)  Acc@5: 100.0000 (100.0000)  Loss: -0.1643 (-0.1512)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7417)  Acc@5: 100.0000 (100.0000)  Loss: -0.1555 (-0.1508)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7615)  Acc@5: 100.0000 (100.0000)  Loss: -0.1531 (-0.1512)  time: 0.1882  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6897)  Acc@5: 100.0000 (100.0000)  Loss: -0.1474 (-0.1487)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6275)  Acc@5: 100.0000 (100.0000)  Loss: -0.1465 (-0.1490)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6506)  Acc@5: 100.0000 (100.0000)  Loss: -0.1665 (-0.1498)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6345)  Acc@5: 100.0000 (100.0000)  Loss: -0.1643 (-0.1492)  time: 0.1878  data: 0.0001  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6202)  Acc@5: 100.0000 (100.0000)  Loss: -0.1555 (-0.1483)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6401)  Acc@5: 100.0000 (100.0000)  Loss: -0.1593 (-0.1484)  time: 0.1878  data: 0.0001  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6580)  Acc@5: 100.0000 (100.0000)  Loss: -0.1630 (-0.1487)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6445)  Acc@5: 100.0000 (100.0000)  Loss: -0.1688 (-0.1493)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6324)  Acc@5: 100.0000 (100.0000)  Loss: -0.1631 (-0.1488)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5942)  Acc@5: 100.0000 (100.0000)  Loss: -0.1567 (-0.1478)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6110)  Acc@5: 100.0000 (100.0000)  Loss: -0.1579 (-0.1485)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6265)  Acc@5: 100.0000 (100.0000)  Loss: -0.1675 (-0.1490)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6408)  Acc@5: 100.0000 (100.0000)  Loss: -0.1533 (-0.1489)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6541)  Acc@5: 100.0000 (100.0000)  Loss: -0.1533 (-0.1486)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6664)  Acc@5: 100.0000 (100.0000)  Loss: -0.1548 (-0.1489)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6778)  Acc@5: 100.0000 (100.0000)  Loss: -0.1578 (-0.1491)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6885)  Acc@5: 100.0000 (100.0000)  Loss: -0.1548 (-0.1490)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6986)  Acc@5: 100.0000 (100.0000)  Loss: -0.1602 (-0.1492)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7005)  Acc@5: 100.0000 (100.0000)  Loss: -0.1602 (-0.1493)  time: 0.1832  data: 0.0001  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:59 (0.1885 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7005)  Acc@5: 100.0000 (100.0000)  Loss: -0.1602 (-0.1493)
Test: [Task 1]  [ 0/63]  eta: 0:00:21  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5407 (0.5407)  time: 0.3365  data: 0.2178  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.8636)  Loss: 0.4370 (0.4326)  time: 0.1365  data: 0.0201  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (99.4048)  Loss: 0.4370 (0.4770)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (87.7016)  Acc@5: 100.0000 (99.3952)  Loss: 0.4277 (0.4535)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (88.2622)  Acc@5: 100.0000 (99.2378)  Loss: 0.3831 (0.4480)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (89.5833)  Acc@5: 100.0000 (99.2647)  Loss: 0.3093 (0.4230)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (89.5492)  Acc@5: 100.0000 (99.2828)  Loss: 0.2947 (0.4227)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (89.6000)  Acc@5: 100.0000 (99.3000)  Loss: 0.2728 (0.4202)  time: 0.1138  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:07 (0.1203 s / it)
* Acc@1 89.600 Acc@5 99.300 loss 0.420
Test: [Task 2]  [ 0/63]  eta: 0:00:21  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.5972 (0.5972)  time: 0.3416  data: 0.2244  max mem: 2372
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (97.7273)  Loss: 0.4688 (0.4701)  time: 0.1370  data: 0.0207  max mem: 2372
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (97.3214)  Loss: 0.4900 (0.5609)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.1774)  Loss: 0.5595 (0.5616)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (88.1098)  Acc@5: 100.0000 (97.4085)  Loss: 0.5035 (0.5410)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (97.6716)  Loss: 0.4404 (0.5343)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (88.9344)  Acc@5: 100.0000 (97.9508)  Loss: 0.3751 (0.5058)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (89.2000)  Acc@5: 100.0000 (98.0000)  Loss: 0.3706 (0.4961)  time: 0.1136  data: 0.0002  max mem: 2372
Test: [Task 2] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 89.200 Acc@5 98.000 loss 0.496
Test: [Task 3]  [ 0/63]  eta: 0:00:18  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1915 (0.1915)  time: 0.2994  data: 0.1817  max mem: 2372
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (88.6364)  Acc@5: 100.0000 (98.8636)  Loss: 0.4359 (0.4925)  time: 0.1330  data: 0.0167  max mem: 2372
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.8095)  Loss: 0.4450 (0.4820)  time: 0.1164  data: 0.0003  max mem: 2372
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (99.1935)  Loss: 0.4521 (0.4666)  time: 0.1164  data: 0.0003  max mem: 2372
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (88.2622)  Acc@5: 100.0000 (99.0854)  Loss: 0.4913 (0.4818)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (88.3578)  Acc@5: 100.0000 (98.8971)  Loss: 0.5253 (0.4936)  time: 0.1162  data: 0.0002  max mem: 2372
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (88.1148)  Acc@5: 100.0000 (98.9754)  Loss: 0.4605 (0.5056)  time: 0.1162  data: 0.0002  max mem: 2372
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (88.0000)  Acc@5: 100.0000 (98.9000)  Loss: 0.5170 (0.5141)  time: 0.1135  data: 0.0002  max mem: 2372
Test: [Task 3] Total time: 0:00:07 (0.1194 s / it)
* Acc@1 88.000 Acc@5 98.900 loss 0.514
Test: [Task 4]  [ 0/63]  eta: 0:00:19  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4867 (0.4867)  time: 0.3068  data: 0.1885  max mem: 2372
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.8636)  Loss: 0.3556 (0.3735)  time: 0.1337  data: 0.0174  max mem: 2372
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (98.2143)  Loss: 0.3495 (0.3987)  time: 0.1164  data: 0.0003  max mem: 2372
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (91.5323)  Acc@5: 100.0000 (98.1855)  Loss: 0.3457 (0.3942)  time: 0.1163  data: 0.0002  max mem: 2372
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.6829)  Acc@5: 100.0000 (98.4756)  Loss: 0.2484 (0.3571)  time: 0.1164  data: 0.0003  max mem: 2372
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (92.1569)  Acc@5: 100.0000 (98.7745)  Loss: 0.2487 (0.3612)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (91.4959)  Acc@5: 100.0000 (98.5656)  Loss: 0.3130 (0.3745)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (91.6000)  Acc@5: 100.0000 (98.5000)  Loss: 0.2898 (0.3680)  time: 0.1136  data: 0.0002  max mem: 2372
Test: [Task 4] Total time: 0:00:07 (0.1195 s / it)
* Acc@1 91.600 Acc@5 98.500 loss 0.368
[Average accuracy till task4]	ASR: 0.0000	Acc@1: 89.6000	Loss: 0.0000	Forgetting: 0.0000	Backward: 0.0000
training non poison model
Train: Epoch[1/5]  [  0/313]  eta: 0:02:00  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 68.7500 (68.7500)  Loss: 2.1198 (2.1198)  time: 0.3842  data: 0.1938  max mem: 2372
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (55.6818)  Acc@5: 93.7500 (88.0682)  Loss: 1.9229 (1.9312)  time: 0.2053  data: 0.0178  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.2381)  Acc@5: 100.0000 (93.4524)  Loss: 1.6582 (1.7160)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.2177)  Acc@5: 100.0000 (95.1613)  Loss: 1.3449 (1.5306)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.8598)  Acc@5: 100.0000 (96.3415)  Loss: 1.0165 (1.3638)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.0686)  Acc@5: 100.0000 (96.8137)  Loss: 0.7276 (1.2247)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.3730)  Acc@5: 100.0000 (97.3361)  Loss: 0.4816 (1.0918)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (97.7113)  Loss: 0.3697 (0.9926)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.5031)  Acc@5: 100.0000 (97.9938)  Loss: 0.3622 (0.9074)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.8736)  Acc@5: 100.0000 (98.2143)  Loss: 0.3250 (0.8514)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4802)  Acc@5: 100.0000 (98.3292)  Loss: 0.2833 (0.7883)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.9212)  Acc@5: 100.0000 (98.4797)  Loss: 0.1715 (0.7358)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.5475)  Acc@5: 100.0000 (98.6054)  Loss: 0.1662 (0.6882)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.1737)  Acc@5: 100.0000 (98.7118)  Loss: 0.1191 (0.6431)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.6223)  Acc@5: 100.0000 (98.7589)  Loss: 0.1191 (0.6064)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.8460)  Acc@5: 100.0000 (98.8411)  Loss: 0.0732 (0.5720)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.9255)  Acc@5: 100.0000 (98.9130)  Loss: 0.0816 (0.5448)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.0687)  Acc@5: 100.0000 (98.9401)  Loss: 0.0845 (0.5179)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.3343)  Acc@5: 100.0000 (98.9986)  Loss: 0.0543 (0.4925)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.6702)  Acc@5: 100.0000 (99.0510)  Loss: 0.0157 (0.4672)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.8483)  Acc@5: 100.0000 (99.0983)  Loss: -0.0019 (0.4470)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.8910)  Acc@5: 100.0000 (99.1114)  Loss: 0.0466 (0.4292)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.8733)  Acc@5: 100.0000 (99.1233)  Loss: 0.0829 (0.4140)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.9654)  Acc@5: 100.0000 (99.1342)  Loss: 0.0404 (0.3978)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0498)  Acc@5: 100.0000 (99.1701)  Loss: 0.0108 (0.3835)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2022)  Acc@5: 100.0000 (99.2032)  Loss: 0.0108 (0.3676)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.3908)  Acc@5: 100.0000 (99.2337)  Loss: -0.0378 (0.3539)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.5194)  Acc@5: 100.0000 (99.2620)  Loss: -0.0462 (0.3407)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.6610)  Acc@5: 100.0000 (99.2883)  Loss: -0.0465 (0.3272)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.8144)  Acc@5: 100.0000 (99.3127)  Loss: -0.0551 (0.3141)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.9161)  Acc@5: 100.0000 (99.3355)  Loss: -0.0524 (0.3034)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.9309)  Acc@5: 100.0000 (99.3368)  Loss: -0.0232 (0.2952)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.9696)  Acc@5: 100.0000 (99.3411)  Loss: -0.0263 (0.2929)  time: 0.1833  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:58 (0.1884 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.9696)  Acc@5: 100.0000 (99.3411)  Loss: -0.0263 (0.2929)
Train: Epoch[2/5]  [  0/313]  eta: 0:01:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0277 (-0.0277)  time: 0.3653  data: 0.1729  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0291 (-0.0134)  time: 0.2056  data: 0.0160  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (99.7024)  Loss: -0.0517 (-0.0098)  time: 0.1893  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9758)  Acc@5: 100.0000 (99.7984)  Loss: -0.0407 (-0.0083)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2561)  Acc@5: 100.0000 (99.8476)  Loss: -0.0514 (-0.0173)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9363)  Acc@5: 100.0000 (99.7549)  Loss: -0.0525 (-0.0100)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1311)  Acc@5: 100.0000 (99.7951)  Loss: -0.0535 (-0.0196)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2711)  Acc@5: 100.0000 (99.8239)  Loss: -0.0936 (-0.0257)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5309)  Acc@5: 100.0000 (99.8457)  Loss: -0.0762 (-0.0323)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1154)  Acc@5: 100.0000 (99.8626)  Loss: -0.0683 (-0.0189)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0916)  Acc@5: 100.0000 (99.8762)  Loss: -0.0470 (-0.0231)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0721)  Acc@5: 100.0000 (99.8874)  Loss: -0.0673 (-0.0240)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (99.8967)  Loss: -0.0680 (-0.0251)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3282)  Acc@5: 100.0000 (99.9046)  Loss: -0.0846 (-0.0302)  time: 0.1870  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3848)  Acc@5: 100.0000 (99.9113)  Loss: -0.0935 (-0.0336)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3924)  Acc@5: 100.0000 (99.9172)  Loss: -0.1002 (-0.0368)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (99.9224)  Loss: -0.0933 (-0.0361)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3684)  Acc@5: 100.0000 (99.9269)  Loss: -0.0507 (-0.0373)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4102)  Acc@5: 100.0000 (99.9309)  Loss: -0.0951 (-0.0396)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5131)  Acc@5: 100.0000 (99.9346)  Loss: -0.1023 (-0.0430)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4813)  Acc@5: 100.0000 (99.9378)  Loss: -0.1123 (-0.0433)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.4526)  Acc@5: 100.0000 (99.9408)  Loss: -0.0830 (-0.0441)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.3416)  Acc@5: 100.0000 (99.9434)  Loss: -0.0740 (-0.0436)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.2944)  Acc@5: 100.0000 (99.9459)  Loss: -0.0844 (-0.0440)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2510)  Acc@5: 100.0000 (99.9481)  Loss: -0.0844 (-0.0439)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2859)  Acc@5: 100.0000 (99.9502)  Loss: -0.0867 (-0.0460)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3180)  Acc@5: 100.0000 (99.9521)  Loss: -0.1107 (-0.0469)  time: 0.1875  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3708)  Acc@5: 100.0000 (99.9539)  Loss: -0.1134 (-0.0484)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4422)  Acc@5: 100.0000 (99.9555)  Loss: -0.1179 (-0.0506)  time: 0.1872  data: 0.0001  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4871)  Acc@5: 100.0000 (99.9570)  Loss: -0.1181 (-0.0527)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5291)  Acc@5: 100.0000 (99.9585)  Loss: -0.1226 (-0.0536)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4879)  Acc@5: 100.0000 (99.9397)  Loss: -0.1053 (-0.0528)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5040)  Acc@5: 100.0000 (99.9401)  Loss: -0.1053 (-0.0533)  time: 0.1838  data: 0.0002  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:58 (0.1885 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5040)  Acc@5: 100.0000 (99.9401)  Loss: -0.1053 (-0.0533)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1126 (-0.1126)  time: 0.4116  data: 0.2223  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1026 (-0.0825)  time: 0.2082  data: 0.0204  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.1122 (-0.0751)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1855)  Acc@5: 100.0000 (100.0000)  Loss: -0.1122 (-0.0747)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1707)  Acc@5: 100.0000 (100.0000)  Loss: -0.1222 (-0.0811)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (100.0000)  Loss: -0.0998 (-0.0740)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1557)  Acc@5: 100.0000 (100.0000)  Loss: -0.1049 (-0.0792)  time: 0.1878  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1514)  Acc@5: 100.0000 (100.0000)  Loss: -0.1275 (-0.0835)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3796)  Acc@5: 100.0000 (100.0000)  Loss: -0.1194 (-0.0881)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0082)  Acc@5: 100.0000 (100.0000)  Loss: -0.1146 (-0.0755)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1436)  Acc@5: 100.0000 (100.0000)  Loss: -0.1025 (-0.0783)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1086 (-0.0790)  time: 0.1875  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1405)  Acc@5: 100.0000 (100.0000)  Loss: -0.1086 (-0.0781)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2347)  Acc@5: 100.0000 (100.0000)  Loss: -0.1196 (-0.0814)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2713)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.0837)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3030)  Acc@5: 100.0000 (100.0000)  Loss: -0.1379 (-0.0861)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2531)  Acc@5: 100.0000 (100.0000)  Loss: -0.1240 (-0.0849)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2456)  Acc@5: 100.0000 (100.0000)  Loss: -0.0886 (-0.0850)  time: 0.1875  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2390)  Acc@5: 100.0000 (100.0000)  Loss: -0.1241 (-0.0863)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3312)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.0887)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3209)  Acc@5: 100.0000 (100.0000)  Loss: -0.1361 (-0.0891)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3116)  Acc@5: 100.0000 (100.0000)  Loss: -0.1240 (-0.0899)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2749)  Acc@5: 100.0000 (100.0000)  Loss: -0.1065 (-0.0893)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2413)  Acc@5: 100.0000 (100.0000)  Loss: -0.1118 (-0.0890)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2106)  Acc@5: 100.0000 (100.0000)  Loss: -0.1218 (-0.0886)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2072)  Acc@5: 100.0000 (100.0000)  Loss: -0.1212 (-0.0900)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2280)  Acc@5: 100.0000 (100.0000)  Loss: -0.1343 (-0.0904)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2472)  Acc@5: 100.0000 (100.0000)  Loss: -0.1343 (-0.0913)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3096)  Acc@5: 100.0000 (100.0000)  Loss: -0.1328 (-0.0927)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3247)  Acc@5: 100.0000 (100.0000)  Loss: -0.1359 (-0.0941)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3596)  Acc@5: 100.0000 (100.0000)  Loss: -0.1403 (-0.0942)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3119)  Acc@5: 100.0000 (99.9799)  Loss: -0.1250 (-0.0934)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (99.9800)  Loss: -0.1250 (-0.0937)  time: 0.1831  data: 0.0001  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:58 (0.1884 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (99.9800)  Loss: -0.1250 (-0.0937)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1404 (-0.1404)  time: 0.3688  data: 0.1798  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1307 (-0.1124)  time: 0.2045  data: 0.0165  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5119)  Acc@5: 100.0000 (100.0000)  Loss: -0.1307 (-0.1056)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7903)  Acc@5: 100.0000 (100.0000)  Loss: -0.1254 (-0.1044)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6280)  Acc@5: 100.0000 (100.0000)  Loss: -0.1399 (-0.1098)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5294)  Acc@5: 100.0000 (100.0000)  Loss: -0.1348 (-0.1046)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6680)  Acc@5: 100.0000 (100.0000)  Loss: -0.1348 (-0.1077)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6796)  Acc@5: 100.0000 (100.0000)  Loss: -0.1389 (-0.1107)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8426)  Acc@5: 100.0000 (100.0000)  Loss: -0.1413 (-0.1140)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6264)  Acc@5: 100.0000 (100.0000)  Loss: -0.1283 (-0.1032)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7624)  Acc@5: 100.0000 (100.0000)  Loss: -0.1211 (-0.1054)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7613)  Acc@5: 100.0000 (100.0000)  Loss: -0.1248 (-0.1064)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7087)  Acc@5: 100.0000 (100.0000)  Loss: -0.1248 (-0.1051)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7595)  Acc@5: 100.0000 (100.0000)  Loss: -0.1350 (-0.1073)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7589)  Acc@5: 100.0000 (100.0000)  Loss: -0.1444 (-0.1092)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7583)  Acc@5: 100.0000 (100.0000)  Loss: -0.1474 (-0.1109)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7189)  Acc@5: 100.0000 (100.0000)  Loss: -0.1350 (-0.1097)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6842)  Acc@5: 100.0000 (100.0000)  Loss: -0.1088 (-0.1094)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7569)  Acc@5: 100.0000 (100.0000)  Loss: -0.1355 (-0.1102)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8220)  Acc@5: 100.0000 (100.0000)  Loss: -0.1446 (-0.1120)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7873)  Acc@5: 100.0000 (100.0000)  Loss: -0.1472 (-0.1130)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8152)  Acc@5: 100.0000 (100.0000)  Loss: -0.1383 (-0.1137)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8122)  Acc@5: 100.0000 (100.0000)  Loss: -0.1253 (-0.1132)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7825)  Acc@5: 100.0000 (100.0000)  Loss: -0.1370 (-0.1127)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7552)  Acc@5: 100.0000 (100.0000)  Loss: -0.1384 (-0.1120)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8048)  Acc@5: 100.0000 (100.0000)  Loss: -0.1384 (-0.1130)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8266)  Acc@5: 100.0000 (100.0000)  Loss: -0.1437 (-0.1131)  time: 0.1875  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8469)  Acc@5: 100.0000 (100.0000)  Loss: -0.1407 (-0.1139)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8879)  Acc@5: 100.0000 (100.0000)  Loss: -0.1431 (-0.1149)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8832)  Acc@5: 100.0000 (100.0000)  Loss: -0.1443 (-0.1159)  time: 0.1873  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8995)  Acc@5: 100.0000 (100.0000)  Loss: -0.1480 (-0.1158)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8344)  Acc@5: 100.0000 (100.0000)  Loss: -0.1390 (-0.1151)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1390 (-0.1154)  time: 0.1836  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:58 (0.1883 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1390 (-0.1154)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1524 (-0.1524)  time: 0.4032  data: 0.2149  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1448 (-0.1290)  time: 0.2074  data: 0.0197  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5119)  Acc@5: 100.0000 (100.0000)  Loss: -0.1448 (-0.1247)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9919)  Acc@5: 100.0000 (100.0000)  Loss: -0.1309 (-0.1223)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0854)  Acc@5: 100.0000 (100.0000)  Loss: -0.1472 (-0.1273)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8971)  Acc@5: 100.0000 (100.0000)  Loss: -0.1498 (-0.1234)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9754)  Acc@5: 100.0000 (100.0000)  Loss: -0.1434 (-0.1253)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0317)  Acc@5: 100.0000 (100.0000)  Loss: -0.1456 (-0.1275)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1512)  Acc@5: 100.0000 (100.0000)  Loss: -0.1504 (-0.1299)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9698)  Acc@5: 100.0000 (100.0000)  Loss: -0.1401 (-0.1207)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0718)  Acc@5: 100.0000 (100.0000)  Loss: -0.1256 (-0.1224)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0991)  Acc@5: 100.0000 (100.0000)  Loss: -0.1364 (-0.1234)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0186)  Acc@5: 100.0000 (100.0000)  Loss: -0.1364 (-0.1219)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0935)  Acc@5: 100.0000 (100.0000)  Loss: -0.1436 (-0.1235)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1578)  Acc@5: 100.0000 (100.0000)  Loss: -0.1524 (-0.1251)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2136)  Acc@5: 100.0000 (100.0000)  Loss: -0.1528 (-0.1264)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1460)  Acc@5: 100.0000 (100.0000)  Loss: -0.1404 (-0.1253)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1594)  Acc@5: 100.0000 (100.0000)  Loss: -0.1210 (-0.1249)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2058)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1256)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2474)  Acc@5: 100.0000 (100.0000)  Loss: -0.1513 (-0.1270)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2537)  Acc@5: 100.0000 (100.0000)  Loss: -0.1552 (-0.1281)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2891)  Acc@5: 100.0000 (100.0000)  Loss: -0.1494 (-0.1287)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)  Loss: -0.1436 (-0.1284)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2424)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1277)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1961)  Acc@5: 100.0000 (100.0000)  Loss: -0.1462 (-0.1270)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2281)  Acc@5: 100.0000 (100.0000)  Loss: -0.1498 (-0.1277)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2337)  Acc@5: 100.0000 (100.0000)  Loss: -0.1509 (-0.1276)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2620)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1283)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2883)  Acc@5: 100.0000 (100.0000)  Loss: -0.1505 (-0.1291)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2912)  Acc@5: 100.0000 (100.0000)  Loss: -0.1526 (-0.1298)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2940)  Acc@5: 100.0000 (100.0000)  Loss: -0.1526 (-0.1295)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2363)  Acc@5: 100.0000 (100.0000)  Loss: -0.1455 (-0.1291)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1455 (-0.1293)  time: 0.1831  data: 0.0002  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:59 (0.1886 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1455 (-0.1293)
Test: [Task 1]  [ 0/63]  eta: 0:00:20  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5752 (0.5752)  time: 0.3290  data: 0.2124  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  Loss: 0.4831 (0.4861)  time: 0.1358  data: 0.0196  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (85.1190)  Acc@5: 100.0000 (99.1071)  Loss: 0.4831 (0.5274)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (86.2903)  Acc@5: 100.0000 (99.1935)  Loss: 0.3965 (0.4950)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (99.2378)  Loss: 0.4111 (0.4875)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (99.2647)  Loss: 0.3770 (0.4660)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (87.8074)  Acc@5: 100.0000 (99.2828)  Loss: 0.3243 (0.4552)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (87.9000)  Acc@5: 100.0000 (99.3000)  Loss: 0.3145 (0.4544)  time: 0.1136  data: 0.0002  max mem: 2372
Test: [Task 1] Total time: 0:00:07 (0.1198 s / it)
* Acc@1 87.900 Acc@5 99.300 loss 0.454
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.7251 (0.7251)  time: 0.3168  data: 0.1995  max mem: 2372
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (88.0682)  Acc@5: 100.0000 (98.2955)  Loss: 0.4672 (0.5213)  time: 0.1350  data: 0.0185  max mem: 2372
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (97.0238)  Loss: 0.5254 (0.5903)  time: 0.1167  data: 0.0004  max mem: 2372
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (85.6855)  Acc@5: 100.0000 (96.7742)  Loss: 0.6090 (0.6177)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (97.2561)  Loss: 0.5536 (0.5979)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (86.5196)  Acc@5: 100.0000 (97.4265)  Loss: 0.4946 (0.5839)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (87.3975)  Acc@5: 100.0000 (97.6434)  Loss: 0.4043 (0.5537)  time: 0.1166  data: 0.0003  max mem: 2372
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (97.7000)  Loss: 0.3884 (0.5452)  time: 0.1138  data: 0.0003  max mem: 2372
Test: [Task 2] Total time: 0:00:07 (0.1199 s / it)
* Acc@1 87.500 Acc@5 97.700 loss 0.545
Test: [Task 3]  [ 0/63]  eta: 0:00:19  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.3843 (0.3843)  time: 0.3022  data: 0.1855  max mem: 2372
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (98.2955)  Loss: 0.5192 (0.5885)  time: 0.1336  data: 0.0171  max mem: 2372
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (98.5119)  Loss: 0.5662 (0.5721)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (98.5887)  Loss: 0.5358 (0.5515)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (84.1463)  Acc@5: 100.0000 (98.3232)  Loss: 0.5358 (0.5767)  time: 0.1168  data: 0.0003  max mem: 2372
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (84.3137)  Acc@5: 100.0000 (98.1618)  Loss: 0.5671 (0.5854)  time: 0.1167  data: 0.0003  max mem: 2372
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (84.7336)  Acc@5: 100.0000 (98.4631)  Loss: 0.4625 (0.5787)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (84.4000)  Acc@5: 100.0000 (98.5000)  Loss: 0.4839 (0.5846)  time: 0.1135  data: 0.0002  max mem: 2372
Test: [Task 3] Total time: 0:00:07 (0.1195 s / it)
* Acc@1 84.400 Acc@5 98.500 loss 0.585
Test: [Task 4]  [ 0/63]  eta: 0:00:18  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5870 (0.5870)  time: 0.2968  data: 0.1796  max mem: 2372
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (90.9091)  Acc@5: 100.0000 (98.8636)  Loss: 0.3807 (0.4393)  time: 0.1327  data: 0.0166  max mem: 2372
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.5119)  Loss: 0.3807 (0.4738)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (88.5081)  Acc@5: 100.0000 (98.1855)  Loss: 0.3899 (0.4709)  time: 0.1163  data: 0.0002  max mem: 2372
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (90.0915)  Acc@5: 100.0000 (98.4756)  Loss: 0.3007 (0.4248)  time: 0.1163  data: 0.0002  max mem: 2372
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (89.7059)  Acc@5: 100.0000 (98.6520)  Loss: 0.3176 (0.4345)  time: 0.1163  data: 0.0003  max mem: 2372
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (89.6516)  Acc@5: 100.0000 (98.5656)  Loss: 0.4287 (0.4462)  time: 0.1162  data: 0.0002  max mem: 2372
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (89.8000)  Acc@5: 100.0000 (98.5000)  Loss: 0.3352 (0.4400)  time: 0.1135  data: 0.0002  max mem: 2372
Test: [Task 4] Total time: 0:00:07 (0.1193 s / it)
* Acc@1 89.800 Acc@5 98.500 loss 0.440
Test: [Task 5]  [ 0/63]  eta: 0:00:21  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1325 (0.1325)  time: 0.3373  data: 0.2173  max mem: 2372
Test: [Task 5]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.2955)  Loss: 0.3483 (0.4715)  time: 0.1367  data: 0.0200  max mem: 2372
Test: [Task 5]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (99.1071)  Loss: 0.3305 (0.3931)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 5]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (98.9919)  Loss: 0.3010 (0.4006)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 5]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.3780)  Acc@5: 100.0000 (99.2378)  Loss: 0.3062 (0.3909)  time: 0.1165  data: 0.0003  max mem: 2372
Test: [Task 5]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (91.9118)  Acc@5: 100.0000 (99.0196)  Loss: 0.3517 (0.3961)  time: 0.1164  data: 0.0002  max mem: 2372
Test: [Task 5]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (91.3934)  Acc@5: 100.0000 (99.0779)  Loss: 0.3517 (0.4037)  time: 0.1163  data: 0.0002  max mem: 2372
Test: [Task 5]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (91.1000)  Acc@5: 100.0000 (99.1000)  Loss: 0.3869 (0.4199)  time: 0.1135  data: 0.0002  max mem: 2372
Test: [Task 5] Total time: 0:00:07 (0.1201 s / it)
* Acc@1 91.100 Acc@5 99.100 loss 0.420
[Average accuracy till task5]	ASR: 0.0000	Acc@1: 88.1400	Loss: 0.0000	Forgetting: 0.0000	Backward: 0.0000
saving model
;;;;;0
clean or triggered training model
Train: Epoch[1/5]  [  0/313]  eta: 0:02:12  Lr: 0.0019 (0.0019)  Acc@1: 12.5000 (12.5000)  Acc@5: 50.0000 (50.0000)  Loss: 2.1646 (2.1646)  time: 0.4220  data: 0.2331  max mem: 2372
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (56.8182)  Acc@5: 87.5000 (83.5227)  Loss: 1.9426 (1.9110)  time: 0.2088  data: 0.0213  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (69.9405)  Acc@5: 100.0000 (91.3690)  Loss: 1.6255 (1.6718)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.2177)  Acc@5: 100.0000 (94.1532)  Loss: 1.1720 (1.4580)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (80.9451)  Acc@5: 100.0000 (95.4268)  Loss: 0.8474 (1.2758)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (83.3333)  Acc@5: 100.0000 (96.2010)  Loss: 0.6130 (1.1280)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.0410)  Acc@5: 100.0000 (96.8238)  Loss: 0.4393 (1.0059)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.4437)  Acc@5: 100.0000 (97.2711)  Loss: 0.3087 (0.9060)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (87.8086)  Acc@5: 100.0000 (97.6080)  Loss: 0.2344 (0.8241)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.5302)  Acc@5: 100.0000 (97.8709)  Loss: 0.2153 (0.7547)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.9851)  Acc@5: 100.0000 (98.0198)  Loss: 0.1950 (0.6989)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.6396)  Acc@5: 100.0000 (98.1419)  Loss: 0.1256 (0.6480)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (90.2893)  Acc@5: 100.0000 (98.2955)  Loss: 0.0831 (0.6018)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.5057)  Acc@5: 100.0000 (98.4256)  Loss: 0.1146 (0.5665)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.0461)  Acc@5: 100.0000 (98.5372)  Loss: 0.0935 (0.5292)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.2666)  Acc@5: 100.0000 (98.5927)  Loss: 0.0603 (0.5052)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.6537)  Acc@5: 100.0000 (98.6801)  Loss: 0.0827 (0.4783)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.8494)  Acc@5: 100.0000 (98.7208)  Loss: 0.0464 (0.4539)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.0580)  Acc@5: 100.0000 (98.7914)  Loss: 0.0304 (0.4330)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.1793)  Acc@5: 100.0000 (98.8547)  Loss: 0.0352 (0.4129)  time: 0.1875  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.1642)  Acc@5: 100.0000 (98.9117)  Loss: 0.0541 (0.3966)  time: 0.1878  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.4171)  Acc@5: 100.0000 (98.9633)  Loss: 0.0356 (0.3803)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.3360)  Acc@5: 100.0000 (99.0102)  Loss: 0.0356 (0.3664)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.3972)  Acc@5: 100.0000 (99.0530)  Loss: 0.0427 (0.3528)  time: 0.1874  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.6089)  Acc@5: 100.0000 (99.0923)  Loss: 0.0036 (0.3371)  time: 0.1873  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.6295)  Acc@5: 100.0000 (99.1285)  Loss: -0.0202 (0.3258)  time: 0.1874  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.7921)  Acc@5: 100.0000 (99.1619)  Loss: -0.0307 (0.3126)  time: 0.1876  data: 0.0001  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.8736)  Acc@5: 100.0000 (99.1928)  Loss: -0.0313 (0.3007)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.9715)  Acc@5: 100.0000 (99.2215)  Loss: -0.0134 (0.2900)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0627)  Acc@5: 100.0000 (99.2483)  Loss: -0.0065 (0.2817)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0648)  Acc@5: 100.0000 (99.2733)  Loss: -0.0241 (0.2722)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2275)  Acc@5: 100.0000 (99.2966)  Loss: -0.0953 (0.2618)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2308)  Acc@5: 100.0000 (99.3011)  Loss: -0.0543 (0.2605)  time: 0.1832  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:58 (0.1883 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2308)  Acc@5: 100.0000 (99.3011)  Loss: -0.0543 (0.2605)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:01  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.0308 (0.0308)  time: 0.3871  data: 0.1912  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (100.0000)  Loss: 0.0409 (0.0308)  time: 0.2058  data: 0.0176  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1310)  Acc@5: 100.0000 (99.7024)  Loss: -0.0745 (-0.0155)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7661)  Acc@5: 100.0000 (99.7984)  Loss: -0.0821 (-0.0141)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7317)  Acc@5: 100.0000 (99.6951)  Loss: -0.0762 (-0.0116)  time: 0.1882  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7108)  Acc@5: 100.0000 (99.7549)  Loss: -0.0683 (-0.0114)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7992)  Acc@5: 100.0000 (99.7951)  Loss: -0.0563 (-0.0146)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7746)  Acc@5: 100.0000 (99.8239)  Loss: -0.0563 (-0.0183)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9105)  Acc@5: 100.0000 (99.8457)  Loss: -0.0807 (-0.0220)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9478)  Acc@5: 100.0000 (99.8626)  Loss: -0.0913 (-0.0247)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.6064)  Acc@5: 100.0000 (99.8144)  Loss: -0.0387 (-0.0232)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.6644)  Acc@5: 100.0000 (99.8311)  Loss: -0.0498 (-0.0251)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9711)  Acc@5: 100.0000 (99.8450)  Loss: -0.1098 (-0.0314)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9924)  Acc@5: 100.0000 (99.8569)  Loss: -0.0674 (-0.0321)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1436)  Acc@5: 100.0000 (99.8670)  Loss: -0.0676 (-0.0359)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1507)  Acc@5: 100.0000 (99.8758)  Loss: -0.0797 (-0.0337)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3121)  Acc@5: 100.0000 (99.8835)  Loss: -0.0664 (-0.0355)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3085)  Acc@5: 100.0000 (99.8904)  Loss: -0.0772 (-0.0364)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3398)  Acc@5: 100.0000 (99.8964)  Loss: -0.0667 (-0.0362)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3351)  Acc@5: 100.0000 (99.9018)  Loss: -0.0629 (-0.0362)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1754)  Acc@5: 100.0000 (99.9067)  Loss: -0.0469 (-0.0345)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2678)  Acc@5: 100.0000 (99.9111)  Loss: -0.0665 (-0.0351)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1821)  Acc@5: 100.0000 (99.9152)  Loss: -0.0612 (-0.0344)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1580)  Acc@5: 100.0000 (99.9188)  Loss: -0.0405 (-0.0344)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1878)  Acc@5: 100.0000 (99.9222)  Loss: -0.0941 (-0.0364)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1653)  Acc@5: 100.0000 (99.9253)  Loss: -0.0912 (-0.0354)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1925)  Acc@5: 100.0000 (99.9282)  Loss: -0.0912 (-0.0374)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1946)  Acc@5: 100.0000 (99.9308)  Loss: -0.0995 (-0.0386)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2411)  Acc@5: 100.0000 (99.9333)  Loss: -0.0818 (-0.0395)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1985)  Acc@5: 100.0000 (99.9356)  Loss: -0.0633 (-0.0384)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1586)  Acc@5: 100.0000 (99.9377)  Loss: -0.0633 (-0.0391)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2621)  Acc@5: 100.0000 (99.9397)  Loss: -0.1323 (-0.0412)  time: 0.1876  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2660)  Acc@5: 100.0000 (99.9401)  Loss: -0.1231 (-0.0411)  time: 0.1831  data: 0.0001  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:59 (0.1886 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2660)  Acc@5: 100.0000 (99.9401)  Loss: -0.1231 (-0.0411)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: -0.0486 (-0.0486)  time: 0.3622  data: 0.1686  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (100.0000)  Loss: -0.0326 (-0.0398)  time: 0.2039  data: 0.0155  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6190)  Acc@5: 100.0000 (100.0000)  Loss: -0.1000 (-0.0689)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9758)  Acc@5: 100.0000 (100.0000)  Loss: -0.1260 (-0.0644)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1037)  Acc@5: 100.0000 (100.0000)  Loss: -0.1186 (-0.0608)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (100.0000)  Loss: -0.1152 (-0.0595)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0287)  Acc@5: 100.0000 (100.0000)  Loss: -0.0992 (-0.0612)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0951)  Acc@5: 100.0000 (100.0000)  Loss: -0.1012 (-0.0633)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0679)  Acc@5: 100.0000 (100.0000)  Loss: -0.1183 (-0.0648)  time: 0.1886  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0467)  Acc@5: 100.0000 (100.0000)  Loss: -0.1183 (-0.0664)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.8441)  Acc@5: 100.0000 (100.0000)  Loss: -0.0801 (-0.0653)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9032)  Acc@5: 100.0000 (100.0000)  Loss: -0.0980 (-0.0664)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1074)  Acc@5: 100.0000 (100.0000)  Loss: -0.1395 (-0.0715)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0897)  Acc@5: 100.0000 (100.0000)  Loss: -0.1093 (-0.0726)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2074)  Acc@5: 100.0000 (100.0000)  Loss: -0.1029 (-0.0754)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1854)  Acc@5: 100.0000 (100.0000)  Loss: -0.1167 (-0.0737)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:28  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (100.0000)  Loss: -0.1091 (-0.0751)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3684)  Acc@5: 100.0000 (100.0000)  Loss: -0.1031 (-0.0755)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3412)  Acc@5: 100.0000 (100.0000)  Loss: -0.0985 (-0.0747)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2840)  Acc@5: 100.0000 (100.0000)  Loss: -0.0939 (-0.0745)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1393)  Acc@5: 100.0000 (100.0000)  Loss: -0.0939 (-0.0729)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2156)  Acc@5: 100.0000 (100.0000)  Loss: -0.0980 (-0.0732)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1719)  Acc@5: 100.0000 (100.0000)  Loss: -0.0950 (-0.0726)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: -0.0750 (-0.0723)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1732)  Acc@5: 100.0000 (100.0000)  Loss: -0.1281 (-0.0735)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1365)  Acc@5: 100.0000 (100.0000)  Loss: -0.1221 (-0.0720)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1743)  Acc@5: 100.0000 (100.0000)  Loss: -0.1132 (-0.0734)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1863)  Acc@5: 100.0000 (100.0000)  Loss: -0.1123 (-0.0742)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2198)  Acc@5: 100.0000 (100.0000)  Loss: -0.1123 (-0.0749)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1649)  Acc@5: 100.0000 (100.0000)  Loss: -0.0976 (-0.0736)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1553)  Acc@5: 100.0000 (100.0000)  Loss: -0.0987 (-0.0741)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2267)  Acc@5: 100.0000 (100.0000)  Loss: -0.1410 (-0.0756)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2244)  Acc@5: 100.0000 (100.0000)  Loss: -0.1375 (-0.0756)  time: 0.1837  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:59 (0.1887 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2244)  Acc@5: 100.0000 (100.0000)  Loss: -0.1375 (-0.0756)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0901 (-0.0901)  time: 0.4161  data: 0.2256  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0701 (-0.0760)  time: 0.2092  data: 0.0207  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1113 (-0.0948)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (100.0000)  Loss: -0.1397 (-0.0895)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (100.0000)  Loss: -0.1355 (-0.0864)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4265)  Acc@5: 100.0000 (100.0000)  Loss: -0.1242 (-0.0848)  time: 0.1884  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (100.0000)  Loss: -0.1214 (-0.0856)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4472)  Acc@5: 100.0000 (100.0000)  Loss: -0.1258 (-0.0867)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4537)  Acc@5: 100.0000 (100.0000)  Loss: -0.1234 (-0.0868)  time: 0.1885  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5275)  Acc@5: 100.0000 (100.0000)  Loss: -0.1230 (-0.0880)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3391)  Acc@5: 100.0000 (100.0000)  Loss: -0.0989 (-0.0876)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4099)  Acc@5: 100.0000 (100.0000)  Loss: -0.1237 (-0.0883)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5723)  Acc@5: 100.0000 (100.0000)  Loss: -0.1441 (-0.0924)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7099)  Acc@5: 100.0000 (100.0000)  Loss: -0.1249 (-0.0939)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7837)  Acc@5: 100.0000 (100.0000)  Loss: -0.1299 (-0.0962)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8063)  Acc@5: 100.0000 (100.0000)  Loss: -0.1309 (-0.0950)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9425)  Acc@5: 100.0000 (100.0000)  Loss: -0.1252 (-0.0962)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9532)  Acc@5: 100.0000 (100.0000)  Loss: -0.1243 (-0.0963)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8936)  Acc@5: 100.0000 (100.0000)  Loss: -0.1172 (-0.0955)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8730)  Acc@5: 100.0000 (100.0000)  Loss: -0.1180 (-0.0957)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7301)  Acc@5: 100.0000 (100.0000)  Loss: -0.1197 (-0.0944)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8081)  Acc@5: 100.0000 (100.0000)  Loss: -0.1112 (-0.0944)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7658)  Acc@5: 100.0000 (100.0000)  Loss: -0.1088 (-0.0941)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7543)  Acc@5: 100.0000 (100.0000)  Loss: -0.0968 (-0.0936)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7438)  Acc@5: 100.0000 (100.0000)  Loss: -0.1398 (-0.0944)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7341)  Acc@5: 100.0000 (100.0000)  Loss: -0.1363 (-0.0928)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7490)  Acc@5: 100.0000 (100.0000)  Loss: -0.1274 (-0.0938)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7860)  Acc@5: 100.0000 (100.0000)  Loss: -0.1323 (-0.0944)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8203)  Acc@5: 100.0000 (100.0000)  Loss: -0.1249 (-0.0949)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7878)  Acc@5: 100.0000 (100.0000)  Loss: -0.1043 (-0.0935)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7990)  Acc@5: 100.0000 (100.0000)  Loss: -0.1284 (-0.0939)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8497)  Acc@5: 100.0000 (100.0000)  Loss: -0.1450 (-0.0952)  time: 0.1877  data: 0.0001  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8634)  Acc@5: 100.0000 (100.0000)  Loss: -0.1446 (-0.0953)  time: 0.1833  data: 0.0001  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:59 (0.1889 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8634)  Acc@5: 100.0000 (100.0000)  Loss: -0.1446 (-0.0953)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1153 (-0.1153)  time: 0.5005  data: 0.3091  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.1012 (-0.1007)  time: 0.2165  data: 0.0283  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5119)  Acc@5: 100.0000 (100.0000)  Loss: -0.1255 (-0.1127)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7823)  Acc@5: 100.0000 (100.0000)  Loss: -0.1462 (-0.1081)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1376 (-0.1047)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.1355 (-0.1033)  time: 0.1877  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8484)  Acc@5: 100.0000 (100.0000)  Loss: -0.1191 (-0.1035)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7993)  Acc@5: 100.0000 (100.0000)  Loss: -0.1390 (-0.1034)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7623)  Acc@5: 100.0000 (100.0000)  Loss: -0.1304 (-0.1027)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8022)  Acc@5: 100.0000 (100.0000)  Loss: -0.1278 (-0.1035)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7104)  Acc@5: 100.0000 (100.0000)  Loss: -0.1149 (-0.1036)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8041)  Acc@5: 100.0000 (100.0000)  Loss: -0.1348 (-0.1039)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9855)  Acc@5: 100.0000 (100.0000)  Loss: -0.1465 (-0.1072)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1393)  Acc@5: 100.0000 (100.0000)  Loss: -0.1403 (-0.1088)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1826)  Acc@5: 100.0000 (100.0000)  Loss: -0.1403 (-0.1106)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1788)  Acc@5: 100.0000 (100.0000)  Loss: -0.1390 (-0.1097)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2919)  Acc@5: 100.0000 (100.0000)  Loss: -0.1313 (-0.1106)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2822)  Acc@5: 100.0000 (100.0000)  Loss: -0.1356 (-0.1106)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2390)  Acc@5: 100.0000 (100.0000)  Loss: -0.1279 (-0.1100)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2330)  Acc@5: 100.0000 (100.0000)  Loss: -0.1302 (-0.1104)  time: 0.1881  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1343)  Acc@5: 100.0000 (100.0000)  Loss: -0.1374 (-0.1094)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1931)  Acc@5: 100.0000 (100.0000)  Loss: -0.1216 (-0.1094)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2466)  Acc@5: 100.0000 (100.0000)  Loss: -0.1174 (-0.1093)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2413)  Acc@5: 100.0000 (100.0000)  Loss: -0.1130 (-0.1087)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2365)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1093)  time: 0.1883  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2321)  Acc@5: 100.0000 (100.0000)  Loss: -0.1433 (-0.1075)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2280)  Acc@5: 100.0000 (100.0000)  Loss: -0.1375 (-0.1083)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2472)  Acc@5: 100.0000 (100.0000)  Loss: -0.1378 (-0.1087)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2651)  Acc@5: 100.0000 (100.0000)  Loss: -0.1272 (-0.1091)  time: 0.1878  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2388)  Acc@5: 100.0000 (100.0000)  Loss: -0.1159 (-0.1077)  time: 0.1880  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2766)  Acc@5: 100.0000 (100.0000)  Loss: -0.1355 (-0.1080)  time: 0.1882  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3119)  Acc@5: 100.0000 (100.0000)  Loss: -0.1477 (-0.1091)  time: 0.1879  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (100.0000)  Loss: -0.1477 (-0.1091)  time: 0.1833  data: 0.0001  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:59 (0.1891 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (100.0000)  Loss: -0.1477 (-0.1091)
getting best images to poison
;;;;;1
generating trigger
[rank0]: Traceback (most recent call last):
[rank0]:   File "main.py", line 178, in <module>
[rank0]:     main(args)
[rank0]:   File "main.py", line 139, in main
[rank0]:     train_and_evaluate(model, model_without_ddp, original_model,
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_sleeper/engine.py", line 535, in train_and_evaluate
[rank0]:     train_stats,backdoor = train_one_epoch(model=model, original_model=original_model, criterion=criterion_trigger,
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_sleeper/engine.py", line 119, in train_one_epoch
[rank0]:     loss = backdoor.calculate_loss(criterion,original_model, model, input,target, task_id, class_mask,index)
[rank0]:   File "/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_sleeper/backdoor.py", line 328, in calculate_loss
[rank0]:     checker_loss = criterion(logits_checker, self.target_p)
[rank0]:   File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1553, in _wrapped_call_impl
[rank0]:     return self._call_impl(*args, **kwargs)
[rank0]:   File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1562, in _call_impl
[rank0]:     return forward_call(*args, **kwargs)
[rank0]:   File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/nn/modules/loss.py", line 621, in forward
[rank0]:     return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
[rank0]:   File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/nn/functional.py", line 3163, in binary_cross_entropy
[rank0]:     raise ValueError(
[rank0]: ValueError: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 100])) is deprecated. Please ensure they have the same size.
[rank0]:[W211 23:54:56.431604403 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
E0211 23:54:58.804237 139726565898048 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 3087988) of binary: /home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/bin/python
Traceback (most recent call last):
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
main.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-02-11_23:54:58
  host      : tg074.rrze.uni-erlangen.de
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3087988)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
=== JOB_STATISTICS ===
=== current date     : Tue 11 Feb 2025 11:54:59 PM CET
= Job-ID             : 992971 on tinygpu
= Job-Name           : trigger_5_0.5_vit_base_patch16_224_bestselect
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_sleeper/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_sleeper
= Queue/Partition    : v100
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:35:12
= Total RAM usage    : 2.2 GiB of requested  GiB (%)   
= Node list          : tg074
= Subm/Elig/Start/End: 2025-02-11T23:14:01 / 2025-02-11T23:14:01 / 2025-02-11T23:19:47 / 2025-02-11T23:54:59
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           95.7G   104.9G   209.7G        N/A      87K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
    /home/woody         53.5G  1000.0G  1500.0G        N/A     269K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:86:00.0, 3087988, 92 %, 32 %, 7464 MiB, 2078401 ms
