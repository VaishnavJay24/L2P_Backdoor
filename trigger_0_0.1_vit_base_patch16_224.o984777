### Starting TaskPrologue of job 984777 on tg073 at Wed 29 Jan 2025 07:24:48 PM CET
Running on cores 0-1,8-9,16-17,24-25 with governor ondemand
Wed Jan 29 19:24:48 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-PCIE-32GB           On  |   00000000:18:00.0 Off |                    0 |
| N/A   36C    P0             28W /  250W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', p_task_id=0, patience_epochs=10, pin_mem=True, poison_rate=0.5, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, trigger_path='/home/woody/iwi1/iwi1102h/trigger/trigger_0_0.1_vit_base_patch16_224.pt', unscale_lr=True, use_prompt_mask=False, use_trigger=False, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
False
;;;;;0
clean or triggered training model
Train: Epoch[1/5]  [  0/313]  eta: 0:16:54  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  Loss: 2.2839 (2.2839)  time: 3.2402  data: 0.5287  max mem: 2370
Train: Epoch[1/5]  [ 10/313]  eta: 0:02:25  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (50.5682)  Acc@5: 93.7500 (85.7955)  Loss: 2.1298 (2.1082)  time: 0.4794  data: 0.0484  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:39  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.2619)  Acc@5: 100.0000 (91.6667)  Loss: 1.9355 (1.9306)  time: 0.1958  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (74.1935)  Acc@5: 100.0000 (93.9516)  Loss: 1.5688 (1.7488)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:12  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.5915)  Acc@5: 100.0000 (95.1220)  Loss: 1.2710 (1.5885)  time: 0.1884  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (80.5147)  Acc@5: 100.0000 (95.9559)  Loss: 0.9633 (1.4509)  time: 0.1917  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:01  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (82.2746)  Acc@5: 100.0000 (96.6189)  Loss: 0.8089 (1.3254)  time: 0.1919  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.4507)  Acc@5: 100.0000 (97.0070)  Loss: 0.6588 (1.2242)  time: 0.1887  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.5679)  Acc@5: 100.0000 (97.3765)  Loss: 0.5620 (1.1444)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.5769)  Acc@5: 100.0000 (97.5275)  Loss: 0.5475 (1.0719)  time: 0.1885  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.0149)  Acc@5: 100.0000 (97.7723)  Loss: 0.4243 (1.0117)  time: 0.1886  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.8806)  Acc@5: 100.0000 (97.9730)  Loss: 0.3891 (0.9494)  time: 0.1888  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.0888)  Loss: 0.3062 (0.8976)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.8340)  Acc@5: 100.0000 (98.2347)  Loss: 0.2823 (0.8549)  time: 0.1889  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.2979)  Acc@5: 100.0000 (98.3599)  Loss: 0.2981 (0.8160)  time: 0.1891  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.7003)  Acc@5: 100.0000 (98.4272)  Loss: 0.2981 (0.7824)  time: 0.1893  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.0916)  Acc@5: 100.0000 (98.4860)  Loss: 0.3084 (0.7525)  time: 0.1894  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5102)  Acc@5: 100.0000 (98.5746)  Loss: 0.2614 (0.7230)  time: 0.1893  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.7445)  Acc@5: 100.0000 (98.6533)  Loss: 0.2433 (0.6965)  time: 0.1896  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0196)  Acc@5: 100.0000 (98.7238)  Loss: 0.1819 (0.6722)  time: 0.1898  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1741)  Acc@5: 100.0000 (98.7873)  Loss: 0.2148 (0.6505)  time: 0.1896  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.4028)  Acc@5: 100.0000 (98.8152)  Loss: 0.2148 (0.6303)  time: 0.1896  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.6391)  Acc@5: 100.0000 (98.8688)  Loss: 0.1634 (0.6099)  time: 0.1898  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.7738)  Acc@5: 100.0000 (98.9177)  Loss: 0.1360 (0.5906)  time: 0.1898  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.0010)  Acc@5: 100.0000 (98.9367)  Loss: 0.1360 (0.5713)  time: 0.1898  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.1355)  Acc@5: 100.0000 (98.9791)  Loss: 0.1365 (0.5549)  time: 0.1899  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.3075)  Acc@5: 100.0000 (99.0182)  Loss: 0.1153 (0.5376)  time: 0.1899  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.4437)  Acc@5: 100.0000 (99.0544)  Loss: 0.1153 (0.5224)  time: 0.1901  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.5703)  Acc@5: 100.0000 (99.0881)  Loss: 0.1505 (0.5098)  time: 0.1902  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.7741)  Acc@5: 100.0000 (99.1194)  Loss: 0.1633 (0.4966)  time: 0.1902  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.7774)  Acc@5: 100.0000 (99.1487)  Loss: 0.1525 (0.4856)  time: 0.1902  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8609)  Acc@5: 100.0000 (99.1760)  Loss: 0.0967 (0.4729)  time: 0.1899  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8930)  Acc@5: 100.0000 (99.1813)  Loss: 0.0941 (0.4709)  time: 0.1872  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:01:02 (0.1998 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8930)  Acc@5: 100.0000 (99.1813)  Loss: 0.0941 (0.4709)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.0827 (0.0827)  time: 0.3925  data: 0.1983  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (100.0000)  Loss: 0.0588 (0.0895)  time: 0.2079  data: 0.0183  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1310)  Acc@5: 100.0000 (100.0000)  Loss: 0.0588 (0.0868)  time: 0.1900  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1694)  Acc@5: 100.0000 (100.0000)  Loss: 0.0857 (0.0861)  time: 0.1904  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1890)  Acc@5: 100.0000 (100.0000)  Loss: 0.0614 (0.0846)  time: 0.1900  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6912)  Acc@5: 100.0000 (100.0000)  Loss: 0.0518 (0.0729)  time: 0.1901  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5164)  Acc@5: 100.0000 (100.0000)  Loss: -0.0094 (0.0700)  time: 0.1906  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4789)  Acc@5: 100.0000 (100.0000)  Loss: 0.0012 (0.0649)  time: 0.1904  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3735)  Acc@5: 100.0000 (100.0000)  Loss: 0.0200 (0.0637)  time: 0.1903  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.2912)  Acc@5: 100.0000 (100.0000)  Loss: 0.0096 (0.0641)  time: 0.1905  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1634)  Acc@5: 100.0000 (100.0000)  Loss: 0.0336 (0.0628)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3401)  Acc@5: 100.0000 (100.0000)  Loss: -0.0054 (0.0564)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4360)  Acc@5: 100.0000 (100.0000)  Loss: -0.0363 (0.0521)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4218)  Acc@5: 100.0000 (100.0000)  Loss: 0.0011 (0.0507)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4096)  Acc@5: 100.0000 (100.0000)  Loss: 0.0140 (0.0497)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3162)  Acc@5: 100.0000 (100.0000)  Loss: 0.0140 (0.0506)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.2733)  Acc@5: 100.0000 (100.0000)  Loss: 0.0253 (0.0503)  time: 0.1906  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4181)  Acc@5: 100.0000 (100.0000)  Loss: 0.0099 (0.0479)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4779)  Acc@5: 100.0000 (100.0000)  Loss: 0.0027 (0.0452)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4660)  Acc@5: 100.0000 (100.0000)  Loss: -0.0256 (0.0436)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3930)  Acc@5: 100.0000 (100.0000)  Loss: 0.0286 (0.0433)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4455)  Acc@5: 100.0000 (100.0000)  Loss: 0.0247 (0.0416)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5215)  Acc@5: 100.0000 (100.0000)  Loss: -0.0541 (0.0390)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4556)  Acc@5: 100.0000 (100.0000)  Loss: -0.0200 (0.0372)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4990)  Acc@5: 100.0000 (100.0000)  Loss: -0.0318 (0.0345)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4641)  Acc@5: 100.0000 (100.0000)  Loss: -0.0318 (0.0328)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5038)  Acc@5: 100.0000 (100.0000)  Loss: -0.0194 (0.0300)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5406)  Acc@5: 100.0000 (100.0000)  Loss: -0.0474 (0.0276)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5525)  Acc@5: 100.0000 (100.0000)  Loss: -0.0141 (0.0272)  time: 0.1906  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6065)  Acc@5: 100.0000 (100.0000)  Loss: -0.0095 (0.0258)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4909)  Acc@5: 100.0000 (100.0000)  Loss: -0.0098 (0.0259)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.5434)  Acc@5: 100.0000 (100.0000)  Loss: -0.0294 (0.0237)  time: 0.1908  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.5455)  Acc@5: 100.0000 (100.0000)  Loss: -0.0459 (0.0237)  time: 0.1864  data: 0.0003  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:59 (0.1913 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.5455)  Acc@5: 100.0000 (100.0000)  Loss: -0.0459 (0.0237)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: -0.0412 (-0.0412)  time: 0.3587  data: 0.1627  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: -0.0685 (-0.0280)  time: 0.2065  data: 0.0151  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0238)  Acc@5: 100.0000 (100.0000)  Loss: -0.0611 (-0.0352)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (100.0000)  Loss: -0.0575 (-0.0348)  time: 0.1913  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9512)  Acc@5: 100.0000 (100.0000)  Loss: -0.0565 (-0.0340)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3039)  Acc@5: 100.0000 (100.0000)  Loss: -0.0652 (-0.0406)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1311)  Acc@5: 100.0000 (100.0000)  Loss: -0.0925 (-0.0420)  time: 0.1915  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2711)  Acc@5: 100.0000 (100.0000)  Loss: -0.0867 (-0.0435)  time: 0.1913  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5309)  Acc@5: 100.0000 (100.0000)  Loss: -0.0783 (-0.0445)  time: 0.1915  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4588)  Acc@5: 100.0000 (100.0000)  Loss: -0.0869 (-0.0418)  time: 0.1918  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4010)  Acc@5: 100.0000 (100.0000)  Loss: -0.0630 (-0.0426)  time: 0.1916  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4662)  Acc@5: 100.0000 (100.0000)  Loss: -0.1050 (-0.0472)  time: 0.1920  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5723)  Acc@5: 100.0000 (100.0000)  Loss: -0.1129 (-0.0492)  time: 0.1920  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5191)  Acc@5: 100.0000 (100.0000)  Loss: -0.0678 (-0.0484)  time: 0.1914  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5177)  Acc@5: 100.0000 (100.0000)  Loss: -0.0610 (-0.0473)  time: 0.1914  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4338)  Acc@5: 100.0000 (100.0000)  Loss: -0.0610 (-0.0451)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4767)  Acc@5: 100.0000 (100.0000)  Loss: -0.0765 (-0.0447)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5877)  Acc@5: 100.0000 (100.0000)  Loss: -0.0768 (-0.0462)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6865)  Acc@5: 100.0000 (100.0000)  Loss: -0.0771 (-0.0477)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7421)  Acc@5: 100.0000 (100.0000)  Loss: -0.0853 (-0.0482)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6990)  Acc@5: 100.0000 (100.0000)  Loss: -0.0725 (-0.0482)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7192)  Acc@5: 100.0000 (100.0000)  Loss: -0.0725 (-0.0492)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7658)  Acc@5: 100.0000 (100.0000)  Loss: -0.1132 (-0.0510)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1041 (-0.0518)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7178)  Acc@5: 100.0000 (100.0000)  Loss: -0.0881 (-0.0529)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7092)  Acc@5: 100.0000 (100.0000)  Loss: -0.0809 (-0.0538)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7730)  Acc@5: 100.0000 (100.0000)  Loss: -0.0809 (-0.0552)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7629)  Acc@5: 100.0000 (100.0000)  Loss: -0.0997 (-0.0566)  time: 0.1913  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7313)  Acc@5: 100.0000 (100.0000)  Loss: -0.0766 (-0.0564)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7663)  Acc@5: 100.0000 (100.0000)  Loss: -0.0663 (-0.0568)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6744)  Acc@5: 100.0000 (100.0000)  Loss: -0.0704 (-0.0562)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6889)  Acc@5: 100.0000 (100.0000)  Loss: -0.0835 (-0.0571)  time: 0.1912  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6837)  Acc@5: 100.0000 (100.0000)  Loss: -0.0853 (-0.0569)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[3/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6837)  Acc@5: 100.0000 (100.0000)  Loss: -0.0853 (-0.0569)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:56  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: -0.0843 (-0.0843)  time: 0.3718  data: 0.1773  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1135 (-0.0798)  time: 0.2081  data: 0.0164  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1133 (-0.0829)  time: 0.1918  data: 0.0004  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1855)  Acc@5: 100.0000 (100.0000)  Loss: -0.1065 (-0.0840)  time: 0.1917  data: 0.0004  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1015 (-0.0836)  time: 0.1916  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1618)  Acc@5: 100.0000 (100.0000)  Loss: -0.1096 (-0.0866)  time: 0.1917  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0533)  Acc@5: 100.0000 (100.0000)  Loss: -0.1202 (-0.0870)  time: 0.1917  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0634)  Acc@5: 100.0000 (100.0000)  Loss: -0.1138 (-0.0871)  time: 0.1915  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2253)  Acc@5: 100.0000 (100.0000)  Loss: -0.1149 (-0.0871)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1456)  Acc@5: 100.0000 (100.0000)  Loss: -0.1201 (-0.0831)  time: 0.1908  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2673)  Acc@5: 100.0000 (100.0000)  Loss: -0.1113 (-0.0840)  time: 0.1906  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3108)  Acc@5: 100.0000 (100.0000)  Loss: -0.1327 (-0.0876)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3471)  Acc@5: 100.0000 (100.0000)  Loss: -0.1327 (-0.0886)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2347)  Acc@5: 100.0000 (100.0000)  Loss: -0.0933 (-0.0869)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2713)  Acc@5: 100.0000 (100.0000)  Loss: -0.0947 (-0.0853)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1788)  Acc@5: 100.0000 (100.0000)  Loss: -0.0992 (-0.0828)  time: 0.1906  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1755)  Acc@5: 100.0000 (100.0000)  Loss: -0.1005 (-0.0824)  time: 0.1906  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2456)  Acc@5: 100.0000 (100.0000)  Loss: -0.1013 (-0.0834)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3425)  Acc@5: 100.0000 (100.0000)  Loss: -0.1013 (-0.0846)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3312)  Acc@5: 100.0000 (100.0000)  Loss: -0.1058 (-0.0846)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3209)  Acc@5: 100.0000 (100.0000)  Loss: -0.0896 (-0.0846)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1156 (-0.0852)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3597)  Acc@5: 100.0000 (100.0000)  Loss: -0.1257 (-0.0866)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3766)  Acc@5: 100.0000 (100.0000)  Loss: -0.1227 (-0.0870)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3662)  Acc@5: 100.0000 (100.0000)  Loss: -0.1152 (-0.0876)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3815)  Acc@5: 100.0000 (100.0000)  Loss: -0.1152 (-0.0883)  time: 0.1908  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3956)  Acc@5: 100.0000 (100.0000)  Loss: -0.1091 (-0.0890)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4087)  Acc@5: 100.0000 (100.0000)  Loss: -0.1239 (-0.0900)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3986)  Acc@5: 100.0000 (100.0000)  Loss: -0.1019 (-0.0895)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4107)  Acc@5: 100.0000 (100.0000)  Loss: -0.1019 (-0.0895)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3804)  Acc@5: 100.0000 (100.0000)  Loss: -0.1025 (-0.0890)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3722)  Acc@5: 100.0000 (100.0000)  Loss: -0.1118 (-0.0896)  time: 0.1910  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3626)  Acc@5: 100.0000 (100.0000)  Loss: -0.1119 (-0.0894)  time: 0.1865  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:59 (0.1917 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3626)  Acc@5: 100.0000 (100.0000)  Loss: -0.1119 (-0.0894)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1127 (-0.1127)  time: 0.3913  data: 0.1987  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1289 (-0.1099)  time: 0.2090  data: 0.0183  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8095)  Acc@5: 100.0000 (100.0000)  Loss: -0.1279 (-0.1066)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7903)  Acc@5: 100.0000 (100.0000)  Loss: -0.1192 (-0.1063)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9329)  Acc@5: 100.0000 (100.0000)  Loss: -0.1184 (-0.1051)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)  Loss: -0.1229 (-0.1071)  time: 0.1908  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8730)  Acc@5: 100.0000 (100.0000)  Loss: -0.1318 (-0.1076)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7676)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.1072)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8426)  Acc@5: 100.0000 (100.0000)  Loss: -0.1286 (-0.1071)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6951)  Acc@5: 100.0000 (100.0000)  Loss: -0.1308 (-0.1034)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7624)  Acc@5: 100.0000 (100.0000)  Loss: -0.1307 (-0.1040)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8739)  Acc@5: 100.0000 (100.0000)  Loss: -0.1399 (-0.1068)  time: 0.1907  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1072)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7595)  Acc@5: 100.0000 (100.0000)  Loss: -0.1126 (-0.1051)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7589)  Acc@5: 100.0000 (100.0000)  Loss: -0.1157 (-0.1029)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6755)  Acc@5: 100.0000 (100.0000)  Loss: -0.1215 (-0.1008)  time: 0.1908  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7189)  Acc@5: 100.0000 (100.0000)  Loss: -0.1231 (-0.1007)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7573)  Acc@5: 100.0000 (100.0000)  Loss: -0.1212 (-0.1015)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8260)  Acc@5: 100.0000 (100.0000)  Loss: -0.1170 (-0.1024)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7893)  Acc@5: 100.0000 (100.0000)  Loss: -0.1170 (-0.1022)  time: 0.1910  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7873)  Acc@5: 100.0000 (100.0000)  Loss: -0.1114 (-0.1025)  time: 0.1909  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8152)  Acc@5: 100.0000 (100.0000)  Loss: -0.1259 (-0.1031)  time: 0.1903  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8405)  Acc@5: 100.0000 (100.0000)  Loss: -0.1384 (-0.1041)  time: 0.1901  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8366)  Acc@5: 100.0000 (100.0000)  Loss: -0.1306 (-0.1042)  time: 0.1907  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8589)  Acc@5: 100.0000 (100.0000)  Loss: -0.1297 (-0.1048)  time: 0.1913  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8795)  Acc@5: 100.0000 (100.0000)  Loss: -0.1336 (-0.1053)  time: 0.1913  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8985)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.1058)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9391)  Acc@5: 100.0000 (100.0000)  Loss: -0.1352 (-0.1067)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9101)  Acc@5: 100.0000 (100.0000)  Loss: -0.1227 (-0.1063)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9261)  Acc@5: 100.0000 (100.0000)  Loss: -0.1132 (-0.1061)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8995)  Acc@5: 100.0000 (100.0000)  Loss: -0.1155 (-0.1058)  time: 0.1912  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9148)  Acc@5: 100.0000 (100.0000)  Loss: -0.1264 (-0.1062)  time: 0.1911  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9018)  Acc@5: 100.0000 (100.0000)  Loss: -0.1328 (-0.1060)  time: 0.1866  data: 0.0002  max mem: 2372
Train: Epoch[5/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9018)  Acc@5: 100.0000 (100.0000)  Loss: -0.1328 (-0.1060)
;;;;;1
generating trigger
Train: Epoch[1/5]  [  0/313]  eta: 0:28:42  ASR: 0.0625 (0.0625)  ACC: 1.0000 (1.0000)  Loss: 1.0850 (1.0850)  time: 5.5018  data: 0.1911  max mem: 7751
Train: Epoch[1/5]  [ 10/313]  eta: 0:14:45  ASR: 0.0625 (0.0909)  ACC: 1.0000 (0.9659)  Loss: 1.0863 (1.1009)  time: 2.9215  data: 0.0177  max mem: 8433
Train: Epoch[1/5]  [ 20/313]  eta: 0:11:40  ASR: 0.1250 (0.0982)  ACC: 1.0000 (0.9643)  Loss: 1.0863 (1.1010)  time: 2.2357  data: 0.0004  max mem: 8777
Train: Epoch[1/5]  [ 30/313]  eta: 0:08:35  ASR: 0.0625 (0.0927)  ACC: 0.9375 (0.9577)  Loss: 1.0806 (1.0953)  time: 1.2190  data: 0.0005  max mem: 8777
Train: Epoch[1/5]  [ 40/313]  eta: 0:07:20  ASR: 0.0625 (0.1006)  ACC: 0.9375 (0.9604)  Loss: 1.0622 (1.0877)  time: 0.7963  data: 0.0005  max mem: 8877
Train: Epoch[1/5]  [ 50/313]  eta: 0:06:13  ASR: 0.1250 (0.0993)  ACC: 1.0000 (0.9596)  Loss: 1.0657 (1.0886)  time: 0.7994  data: 0.0003  max mem: 8877
Train: Epoch[1/5]  [ 60/313]  eta: 0:05:25  ASR: 0.0625 (0.1014)  ACC: 1.0000 (0.9580)  Loss: 1.0555 (1.0816)  time: 0.6137  data: 0.0003  max mem: 8877
Train: Epoch[1/5]  [ 70/313]  eta: 0:04:50  ASR: 0.0625 (0.0995)  ACC: 1.0000 (0.9586)  Loss: 1.0669 (1.0852)  time: 0.6123  data: 0.0003  max mem: 8970
Train: Epoch[1/5]  [ 80/313]  eta: 0:04:21  ASR: 0.1250 (0.0995)  ACC: 1.0000 (0.9583)  Loss: 1.0915 (1.0855)  time: 0.6331  data: 0.0004  max mem: 9243
Train: Epoch[1/5]  [ 90/313]  eta: 0:03:58  ASR: 0.1250 (0.1016)  ACC: 1.0000 (0.9595)  Loss: 1.1195 (1.0925)  time: 0.6350  data: 0.0004  max mem: 9243
Train: Epoch[1/5]  [100/313]  eta: 0:03:38  ASR: 0.1250 (0.1027)  ACC: 1.0000 (0.9598)  Loss: 1.0960 (1.0906)  time: 0.6294  data: 0.0003  max mem: 9243
Train: Epoch[1/5]  [110/313]  eta: 0:03:20  ASR: 0.1250 (0.1042)  ACC: 0.9375 (0.9572)  Loss: 1.0671 (1.0888)  time: 0.6203  data: 0.0002  max mem: 9335
Train: Epoch[1/5]  [120/313]  eta: 0:03:05  ASR: 0.0625 (0.1028)  ACC: 0.9375 (0.9571)  Loss: 1.0671 (1.0903)  time: 0.6336  data: 0.0002  max mem: 9506
Train: Epoch[1/5]  [130/313]  eta: 0:02:51  ASR: 0.0625 (0.1045)  ACC: 0.9375 (0.9571)  Loss: 1.0770 (1.0902)  time: 0.6287  data: 0.0003  max mem: 9506
Train: Epoch[1/5]  [140/313]  eta: 0:02:38  ASR: 0.1250 (0.1042)  ACC: 0.9375 (0.9557)  Loss: 1.0558 (1.0865)  time: 0.6296  data: 0.0003  max mem: 9908
Train: Epoch[1/5]  [150/313]  eta: 0:02:25  ASR: 0.0625 (0.1031)  ACC: 0.9375 (0.9549)  Loss: 1.0558 (1.0853)  time: 0.6285  data: 0.0003  max mem: 9908
Train: Epoch[1/5]  [160/313]  eta: 0:02:14  ASR: 0.0625 (0.1025)  ACC: 0.9375 (0.9550)  Loss: 1.0723 (1.0850)  time: 0.6153  data: 0.0003  max mem: 10075
Train: Epoch[1/5]  [170/313]  eta: 0:02:03  ASR: 0.0625 (0.1001)  ACC: 0.9375 (0.9543)  Loss: 1.0717 (1.0835)  time: 0.6186  data: 0.0004  max mem: 10075
Train: Epoch[1/5]  [180/313]  eta: 0:01:52  ASR: 0.0625 (0.1036)  ACC: 0.9375 (0.9523)  Loss: 1.0890 (1.0857)  time: 0.6209  data: 0.0004  max mem: 10228
Train: Epoch[1/5]  [190/313]  eta: 0:01:43  ASR: 0.1250 (0.1037)  ACC: 0.9375 (0.9526)  Loss: 1.0911 (1.0841)  time: 0.6288  data: 0.0003  max mem: 10313
Train: Epoch[1/5]  [200/313]  eta: 0:01:33  ASR: 0.1250 (0.1035)  ACC: 0.9375 (0.9527)  Loss: 1.0555 (1.0832)  time: 0.6312  data: 0.0003  max mem: 10313
Train: Epoch[1/5]  [210/313]  eta: 0:01:24  ASR: 0.0625 (0.1013)  ACC: 0.9375 (0.9514)  Loss: 1.0574 (1.0838)  time: 0.6307  data: 0.0004  max mem: 10544
Train: Epoch[1/5]  [220/313]  eta: 0:01:18  ASR: 0.0625 (0.0993)  ACC: 0.9375 (0.9519)  Loss: 1.0977 (1.0861)  time: 0.9758  data: 0.0004  max mem: 10841
Train: Epoch[1/5]  [230/313]  eta: 0:01:09  ASR: 0.0625 (0.0993)  ACC: 0.9375 (0.9527)  Loss: 1.1163 (1.0865)  time: 1.0478  data: 0.0004  max mem: 10841
Train: Epoch[1/5]  [240/313]  eta: 0:01:00  ASR: 0.0625 (0.0988)  ACC: 1.0000 (0.9538)  Loss: 1.0858 (1.0867)  time: 0.6952  data: 0.0003  max mem: 10841
Train: Epoch[1/5]  [250/313]  eta: 0:00:51  ASR: 0.0625 (0.0986)  ACC: 1.0000 (0.9547)  Loss: 1.0767 (1.0864)  time: 0.6122  data: 0.0003  max mem: 10841
Train: Epoch[1/5]  [260/313]  eta: 0:00:43  ASR: 0.0625 (0.0989)  ACC: 0.9375 (0.9547)  Loss: 1.0937 (1.0861)  time: 0.6212  data: 0.0004  max mem: 10841
Train: Epoch[1/5]  [270/313]  eta: 0:00:34  ASR: 0.0625 (0.1001)  ACC: 0.9375 (0.9553)  Loss: 1.0627 (1.0843)  time: 0.6289  data: 0.0003  max mem: 10841
Train: Epoch[1/5]  [280/313]  eta: 0:00:26  ASR: 0.1250 (0.1025)  ACC: 0.9375 (0.9535)  Loss: 1.0698 (1.0838)  time: 0.6220  data: 0.0003  max mem: 10912
Train: Epoch[1/5]  [290/313]  eta: 0:00:18  ASR: 0.0625 (0.1016)  ACC: 0.9375 (0.9536)  Loss: 1.1167 (1.0847)  time: 0.6286  data: 0.0003  max mem: 11085
Train: Epoch[1/5]  [300/313]  eta: 0:00:10  ASR: 0.0625 (0.1011)  ACC: 0.9375 (0.9533)  Loss: 1.0682 (1.0836)  time: 0.6242  data: 0.0003  max mem: 11334
Train: Epoch[1/5]  [310/313]  eta: 0:00:02  ASR: 0.0625 (0.1019)  ACC: 0.9375 (0.9534)  Loss: 1.0542 (1.0825)  time: 0.6111  data: 0.0002  max mem: 11334
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  ASR: 0.0625 (0.1022)  ACC: 0.9375 (0.9533)  Loss: 1.0643 (1.0830)  time: 0.5948  data: 0.0002  max mem: 11334
Train: Epoch[1/5] Total time: 0:04:04 (0.7803 s / it)
Averaged stats: ASR: 0.0625 (0.1022)  ACC: 0.9375 (0.9533)  Loss: 1.0643 (1.0830)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:23  ASR: 0.0625 (0.0625)  ACC: 1.0000 (1.0000)  Loss: 0.9969 (0.9969)  time: 0.8410  data: 0.2039  max mem: 11334
Train: Epoch[2/5]  [ 10/313]  eta: 0:03:10  ASR: 0.0625 (0.0909)  ACC: 1.0000 (0.9659)  Loss: 0.9930 (1.0014)  time: 0.6299  data: 0.0188  max mem: 11334
Train: Epoch[2/5]  [ 20/313]  eta: 0:03:07  ASR: 0.1250 (0.0982)  ACC: 1.0000 (0.9643)  Loss: 0.9921 (1.0002)  time: 0.6301  data: 0.0003  max mem: 11521
Train: Epoch[2/5]  [ 30/313]  eta: 0:03:00  ASR: 0.0625 (0.0927)  ACC: 0.9375 (0.9577)  Loss: 0.9912 (0.9980)  time: 0.6400  data: 0.0003  max mem: 11521
Train: Epoch[2/5]  [ 40/313]  eta: 0:02:52  ASR: 0.0625 (0.1006)  ACC: 0.9375 (0.9604)  Loss: 0.9911 (0.9953)  time: 0.6251  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [ 50/313]  eta: 0:02:46  ASR: 0.1250 (0.0993)  ACC: 1.0000 (0.9596)  Loss: 0.9951 (0.9999)  time: 0.6294  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [ 60/313]  eta: 0:02:38  ASR: 0.0625 (0.1014)  ACC: 1.0000 (0.9580)  Loss: 1.0203 (0.9976)  time: 0.6140  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [ 70/313]  eta: 0:02:32  ASR: 0.0625 (0.0995)  ACC: 1.0000 (0.9586)  Loss: 0.9977 (1.0017)  time: 0.6102  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [ 80/313]  eta: 0:02:26  ASR: 0.1250 (0.0995)  ACC: 1.0000 (0.9583)  Loss: 0.9970 (0.9995)  time: 0.6295  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [ 90/313]  eta: 0:02:20  ASR: 0.1250 (0.1016)  ACC: 1.0000 (0.9595)  Loss: 0.9839 (1.0008)  time: 0.6313  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [100/313]  eta: 0:02:13  ASR: 0.1250 (0.1027)  ACC: 1.0000 (0.9598)  Loss: 0.9998 (1.0016)  time: 0.6269  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [110/313]  eta: 0:02:07  ASR: 0.1250 (0.1042)  ACC: 0.9375 (0.9572)  Loss: 1.0022 (1.0016)  time: 0.6192  data: 0.0002  max mem: 11522
Train: Epoch[2/5]  [120/313]  eta: 0:02:01  ASR: 0.0625 (0.1028)  ACC: 0.9375 (0.9571)  Loss: 1.0184 (1.0030)  time: 0.6330  data: 0.0002  max mem: 11522
Train: Epoch[2/5]  [130/313]  eta: 0:01:54  ASR: 0.0625 (0.1045)  ACC: 0.9375 (0.9571)  Loss: 1.0184 (1.0035)  time: 0.6283  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [140/313]  eta: 0:01:48  ASR: 0.1250 (0.1042)  ACC: 0.9375 (0.9557)  Loss: 0.9966 (1.0030)  time: 0.6277  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [150/313]  eta: 0:01:42  ASR: 0.0625 (0.1031)  ACC: 0.9375 (0.9549)  Loss: 0.9960 (1.0037)  time: 0.6273  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [160/313]  eta: 0:01:35  ASR: 0.0625 (0.1025)  ACC: 0.9375 (0.9550)  Loss: 1.0076 (1.0047)  time: 0.6157  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [170/313]  eta: 0:01:29  ASR: 0.0625 (0.1001)  ACC: 0.9375 (0.9543)  Loss: 1.0215 (1.0049)  time: 0.6192  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [180/313]  eta: 0:01:23  ASR: 0.0625 (0.1036)  ACC: 0.9375 (0.9523)  Loss: 0.9831 (1.0033)  time: 0.6210  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [190/313]  eta: 0:01:17  ASR: 0.1250 (0.1037)  ACC: 0.9375 (0.9526)  Loss: 1.0050 (1.0039)  time: 0.6273  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [200/313]  eta: 0:01:10  ASR: 0.1250 (0.1035)  ACC: 0.9375 (0.9527)  Loss: 1.0278 (1.0044)  time: 0.6288  data: 0.0003  max mem: 11522
Train: Epoch[2/5]  [210/313]  eta: 0:01:04  ASR: 0.0625 (0.1013)  ACC: 0.9375 (0.9514)  Loss: 1.0474 (1.0063)  time: 0.6290  data: 0.0004  max mem: 11522
Train: Epoch[2/5]  [220/313]  eta: 0:00:58  ASR: 0.0625 (0.0993)  ACC: 0.9375 (0.9519)  Loss: 1.0474 (1.0078)  time: 0.6340  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [230/313]  eta: 0:00:51  ASR: 0.0625 (0.0993)  ACC: 0.9375 (0.9527)  Loss: 1.0117 (1.0064)  time: 0.6180  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [240/313]  eta: 0:00:45  ASR: 0.0625 (0.0988)  ACC: 1.0000 (0.9538)  Loss: 1.0171 (1.0078)  time: 0.6073  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [250/313]  eta: 0:00:39  ASR: 0.0625 (0.0986)  ACC: 1.0000 (0.9547)  Loss: 1.0462 (1.0077)  time: 0.6129  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [260/313]  eta: 0:00:33  ASR: 0.0625 (0.0989)  ACC: 0.9375 (0.9547)  Loss: 1.0108 (1.0070)  time: 0.6214  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [270/313]  eta: 0:00:26  ASR: 0.0625 (0.1001)  ACC: 0.9375 (0.9553)  Loss: 0.9905 (1.0059)  time: 0.6304  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [280/313]  eta: 0:00:20  ASR: 0.1250 (0.1025)  ACC: 0.9375 (0.9535)  Loss: 0.9950 (1.0049)  time: 0.6235  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [290/313]  eta: 0:00:14  ASR: 0.0625 (0.1016)  ACC: 0.9375 (0.9536)  Loss: 1.0230 (1.0066)  time: 0.6270  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [300/313]  eta: 0:00:08  ASR: 0.0625 (0.1011)  ACC: 0.9375 (0.9533)  Loss: 1.0373 (1.0060)  time: 0.6235  data: 0.0004  max mem: 11725
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  ASR: 0.0625 (0.1019)  ACC: 0.9375 (0.9534)  Loss: 0.9854 (1.0048)  time: 0.6134  data: 0.0004  max mem: 11725
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  ASR: 0.0625 (0.1022)  ACC: 0.9375 (0.9533)  Loss: 1.0004 (1.0045)  time: 0.5977  data: 0.0003  max mem: 11725
Train: Epoch[2/5] Total time: 0:03:15 (0.6240 s / it)
Averaged stats: ASR: 0.0625 (0.1022)  ACC: 0.9375 (0.9533)  Loss: 1.0004 (1.0045)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:16  ASR: 0.0625 (0.0625)  ACC: 1.0000 (1.0000)  Loss: 0.9856 (0.9856)  time: 0.8207  data: 0.1888  max mem: 11725
Train: Epoch[3/5]  [ 10/313]  eta: 0:03:11  ASR: 0.0625 (0.0909)  ACC: 1.0000 (0.9659)  Loss: 0.9658 (0.9600)  time: 0.6315  data: 0.0175  max mem: 11725
Train: Epoch[3/5]  [ 20/313]  eta: 0:03:07  ASR: 0.1250 (0.0982)  ACC: 1.0000 (0.9643)  Loss: 0.9409 (0.9445)  time: 0.6326  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [ 30/313]  eta: 0:03:00  ASR: 0.0625 (0.0927)  ACC: 0.9375 (0.9577)  Loss: 0.9409 (0.9410)  time: 0.6411  data: 0.0005  max mem: 11725
Train: Epoch[3/5]  [ 40/313]  eta: 0:02:52  ASR: 0.0625 (0.1006)  ACC: 0.9375 (0.9604)  Loss: 0.9418 (0.9376)  time: 0.6244  data: 0.0005  max mem: 11725
Train: Epoch[3/5]  [ 50/313]  eta: 0:02:46  ASR: 0.1250 (0.0993)  ACC: 1.0000 (0.9596)  Loss: 0.9524 (0.9448)  time: 0.6282  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [ 60/313]  eta: 0:02:38  ASR: 0.0625 (0.1014)  ACC: 1.0000 (0.9580)  Loss: 0.9696 (0.9435)  time: 0.6150  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [ 70/313]  eta: 0:02:32  ASR: 0.0625 (0.0995)  ACC: 1.0000 (0.9586)  Loss: 0.9354 (0.9470)  time: 0.6117  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [ 80/313]  eta: 0:02:26  ASR: 0.1250 (0.0995)  ACC: 1.0000 (0.9583)  Loss: 0.9207 (0.9437)  time: 0.6313  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [ 90/313]  eta: 0:02:20  ASR: 0.1250 (0.1016)  ACC: 1.0000 (0.9595)  Loss: 0.9286 (0.9456)  time: 0.6351  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [100/313]  eta: 0:02:13  ASR: 0.1250 (0.1027)  ACC: 1.0000 (0.9598)  Loss: 0.9438 (0.9468)  time: 0.6322  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [110/313]  eta: 0:02:07  ASR: 0.1250 (0.1042)  ACC: 0.9375 (0.9572)  Loss: 0.9207 (0.9464)  time: 0.6218  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [120/313]  eta: 0:02:01  ASR: 0.0625 (0.1028)  ACC: 0.9375 (0.9571)  Loss: 0.9737 (0.9482)  time: 0.6336  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [130/313]  eta: 0:01:54  ASR: 0.0625 (0.1045)  ACC: 0.9375 (0.9571)  Loss: 0.9720 (0.9491)  time: 0.6302  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [140/313]  eta: 0:01:48  ASR: 0.1250 (0.1042)  ACC: 0.9375 (0.9557)  Loss: 0.9423 (0.9487)  time: 0.6313  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [150/313]  eta: 0:01:42  ASR: 0.0625 (0.1031)  ACC: 0.9375 (0.9549)  Loss: 0.9546 (0.9518)  time: 0.6300  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [160/313]  eta: 0:01:36  ASR: 0.0625 (0.1025)  ACC: 0.9375 (0.9550)  Loss: 0.9866 (0.9525)  time: 0.6153  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [170/313]  eta: 0:01:29  ASR: 0.0625 (0.1001)  ACC: 0.9375 (0.9543)  Loss: 0.9449 (0.9528)  time: 0.6185  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [180/313]  eta: 0:01:23  ASR: 0.0625 (0.1036)  ACC: 0.9375 (0.9523)  Loss: 0.9331 (0.9504)  time: 0.6222  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [190/313]  eta: 0:01:17  ASR: 0.1250 (0.1037)  ACC: 0.9375 (0.9526)  Loss: 0.9630 (0.9512)  time: 0.6308  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [200/313]  eta: 0:01:10  ASR: 0.1250 (0.1035)  ACC: 0.9375 (0.9527)  Loss: 0.9779 (0.9520)  time: 0.6330  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [210/313]  eta: 0:01:04  ASR: 0.0625 (0.1013)  ACC: 0.9375 (0.9514)  Loss: 1.0193 (0.9536)  time: 0.6307  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [220/313]  eta: 0:00:58  ASR: 0.0625 (0.0993)  ACC: 0.9375 (0.9519)  Loss: 1.0168 (0.9552)  time: 0.6349  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [230/313]  eta: 0:00:52  ASR: 0.0625 (0.0993)  ACC: 0.9375 (0.9527)  Loss: 0.9521 (0.9540)  time: 0.6209  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [240/313]  eta: 0:00:45  ASR: 0.0625 (0.0988)  ACC: 1.0000 (0.9538)  Loss: 1.0015 (0.9561)  time: 0.6105  data: 0.0004  max mem: 11725
Train: Epoch[3/5]  [250/313]  eta: 0:00:39  ASR: 0.0625 (0.0986)  ACC: 1.0000 (0.9547)  Loss: 1.0127 (0.9564)  time: 0.6149  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [260/313]  eta: 0:00:33  ASR: 0.0625 (0.0989)  ACC: 0.9375 (0.9547)  Loss: 0.9860 (0.9560)  time: 0.6223  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [270/313]  eta: 0:00:26  ASR: 0.0625 (0.1001)  ACC: 0.9375 (0.9553)  Loss: 0.9550 (0.9556)  time: 0.6310  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [280/313]  eta: 0:00:20  ASR: 0.1250 (0.1025)  ACC: 0.9375 (0.9535)  Loss: 0.9515 (0.9543)  time: 0.6233  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [290/313]  eta: 0:00:14  ASR: 0.0625 (0.1016)  ACC: 0.9375 (0.9536)  Loss: 1.0156 (0.9565)  time: 0.6281  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [300/313]  eta: 0:00:08  ASR: 0.0625 (0.1011)  ACC: 0.9375 (0.9533)  Loss: 1.0131 (0.9560)  time: 0.6236  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  ASR: 0.0625 (0.1019)  ACC: 0.9375 (0.9534)  Loss: 0.9530 (0.9543)  time: 0.6102  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  ASR: 0.0625 (0.1022)  ACC: 0.9375 (0.9533)  Loss: 0.9530 (0.9539)  time: 0.5943  data: 0.0002  max mem: 11725
Train: Epoch[3/5] Total time: 0:03:15 (0.6253 s / it)
Averaged stats: ASR: 0.0625 (0.1022)  ACC: 0.9375 (0.9533)  Loss: 0.9530 (0.9539)
Train: Epoch[1/5]  [  0/313]  eta: 0:45:52  Lr: 0.100000  Loss: 2.3132  ASR: 0.0000 (0.0000)  ACC: 0.0000 (0.0000)  time: 8.7951  data: 0.2592  max mem: 11725
Train: Epoch[1/5]  [ 10/313]  eta: 0:05:28  Lr: 0.100000  Loss: 2.1430  ASR: 0.0000 (0.0170)  ACC: 0.1250 (0.1818)  time: 1.0840  data: 0.0239  max mem: 11725
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:29  Lr: 0.100000  Loss: 1.8529  ASR: 0.0625 (0.1161)  ACC: 0.4375 (0.3482)  time: 0.3118  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [ 30/313]  eta: 0:02:45  Lr: 0.100000  Loss: 1.6612  ASR: 0.2500 (0.1613)  ACC: 0.5625 (0.4536)  time: 0.3109  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:21  Lr: 0.100000  Loss: 1.5953  ASR: 0.2500 (0.1966)  ACC: 0.6875 (0.5259)  time: 0.3122  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [ 50/313]  eta: 0:02:05  Lr: 0.100000  Loss: 1.7776  ASR: 0.3125 (0.2157)  ACC: 0.7500 (0.5699)  time: 0.3127  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:54  Lr: 0.100000  Loss: 1.3324  ASR: 0.2500 (0.2172)  ACC: 0.8125 (0.6127)  time: 0.3111  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:44  Lr: 0.100000  Loss: 1.1174  ASR: 0.2500 (0.2210)  ACC: 0.8125 (0.6364)  time: 0.3102  data: 0.0002  max mem: 11725
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:36  Lr: 0.100000  Loss: 0.8797  ASR: 0.2500 (0.2276)  ACC: 0.7500 (0.6535)  time: 0.3109  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:30  Lr: 0.100000  Loss: 1.3648  ASR: 0.2500 (0.2301)  ACC: 0.8125 (0.6710)  time: 0.3119  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [100/313]  eta: 0:01:24  Lr: 0.100000  Loss: 1.1586  ASR: 0.2500 (0.2370)  ACC: 0.8125 (0.6832)  time: 0.3130  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [110/313]  eta: 0:01:18  Lr: 0.100000  Loss: 0.7915  ASR: 0.2500 (0.2387)  ACC: 0.8125 (0.6971)  time: 0.3132  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [120/313]  eta: 0:01:13  Lr: 0.100000  Loss: 1.1892  ASR: 0.2500 (0.2381)  ACC: 0.8125 (0.7071)  time: 0.3133  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [130/313]  eta: 0:01:08  Lr: 0.100000  Loss: 1.1128  ASR: 0.2500 (0.2414)  ACC: 0.8125 (0.7137)  time: 0.3140  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [140/313]  eta: 0:01:04  Lr: 0.100000  Loss: 1.3921  ASR: 0.2500 (0.2429)  ACC: 0.7500 (0.7181)  time: 0.3137  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [150/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.9547  ASR: 0.1875 (0.2421)  ACC: 0.7500 (0.7235)  time: 0.3120  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [160/313]  eta: 0:00:55  Lr: 0.100000  Loss: 0.9688  ASR: 0.1875 (0.2426)  ACC: 0.7500 (0.7267)  time: 0.3120  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [170/313]  eta: 0:00:51  Lr: 0.100000  Loss: 1.0343  ASR: 0.1875 (0.2401)  ACC: 0.8125 (0.7314)  time: 0.3136  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [180/313]  eta: 0:00:47  Lr: 0.100000  Loss: 1.0881  ASR: 0.1875 (0.2417)  ACC: 0.8125 (0.7352)  time: 0.3125  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [190/313]  eta: 0:00:43  Lr: 0.100000  Loss: 0.8357  ASR: 0.1875 (0.2395)  ACC: 0.8125 (0.7418)  time: 0.3113  data: 0.0002  max mem: 11725
Train: Epoch[1/5]  [200/313]  eta: 0:00:40  Lr: 0.100000  Loss: 1.0299  ASR: 0.1875 (0.2369)  ACC: 0.8750 (0.7463)  time: 0.3117  data: 0.0002  max mem: 11725
Train: Epoch[1/5]  [210/313]  eta: 0:00:36  Lr: 0.100000  Loss: 1.0429  ASR: 0.1875 (0.2334)  ACC: 0.8750 (0.7503)  time: 0.3138  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [220/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.9439  ASR: 0.1250 (0.2299)  ACC: 0.8750 (0.7551)  time: 0.3147  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [230/313]  eta: 0:00:28  Lr: 0.100000  Loss: 0.6347  ASR: 0.1875 (0.2278)  ACC: 0.8750 (0.7589)  time: 0.3147  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [240/313]  eta: 0:00:25  Lr: 0.100000  Loss: 1.1522  ASR: 0.1875 (0.2254)  ACC: 0.8750 (0.7648)  time: 0.3141  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [250/313]  eta: 0:00:21  Lr: 0.100000  Loss: 0.8751  ASR: 0.1875 (0.2229)  ACC: 0.8750 (0.7694)  time: 0.3134  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [260/313]  eta: 0:00:18  Lr: 0.100000  Loss: 1.0160  ASR: 0.1250 (0.2222)  ACC: 0.8750 (0.7720)  time: 0.3145  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [270/313]  eta: 0:00:14  Lr: 0.100000  Loss: 0.9133  ASR: 0.1875 (0.2223)  ACC: 0.8750 (0.7751)  time: 0.3132  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [280/313]  eta: 0:00:11  Lr: 0.100000  Loss: 0.8087  ASR: 0.3125 (0.2260)  ACC: 0.8125 (0.7747)  time: 0.3110  data: 0.0002  max mem: 11725
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.2324  ASR: 0.2500 (0.2255)  ACC: 0.7500 (0.7758)  time: 0.3124  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.2143  ASR: 0.1875 (0.2259)  ACC: 0.8125 (0.7772)  time: 0.3148  data: 0.0004  max mem: 11725
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  Lr: 0.100000  Loss: 0.8069  ASR: 0.1875 (0.2249)  ACC: 0.8750 (0.7809)  time: 0.3151  data: 0.0003  max mem: 11725
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6583  ASR: 0.1875 (0.2252)  ACC: 0.8750 (0.7813)  time: 0.3075  data: 0.0003  max mem: 11725
Train: Epoch[1/5] Total time: 0:01:46 (0.3398 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.6583  ASR: 0.1875 (0.2252)  ACC: 0.8750 (0.7813)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:51  Lr: 0.100000  Loss: 1.0616  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  time: 0.5469  data: 0.2199  max mem: 11725
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.8125  ASR: 0.2500 (0.2330)  ACC: 0.8750 (0.8239)  time: 0.3348  data: 0.0202  max mem: 11725
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.6831  ASR: 0.2500 (0.2321)  ACC: 0.8125 (0.8244)  time: 0.3137  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:31  Lr: 0.100000  Loss: 0.6153  ASR: 0.1875 (0.2218)  ACC: 0.8125 (0.8266)  time: 0.3152  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.7441  ASR: 0.1875 (0.2332)  ACC: 0.8125 (0.8277)  time: 0.3161  data: 0.0004  max mem: 11725
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 1.1159  ASR: 0.1875 (0.2292)  ACC: 0.8750 (0.8321)  time: 0.3151  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.7193  ASR: 0.1875 (0.2264)  ACC: 0.8750 (0.8371)  time: 0.3146  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:18  Lr: 0.100000  Loss: 0.4615  ASR: 0.1250 (0.2183)  ACC: 0.8750 (0.8468)  time: 0.3254  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:14  Lr: 0.100000  Loss: 0.3713  ASR: 0.1875 (0.2160)  ACC: 0.8750 (0.8488)  time: 0.3251  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:11  Lr: 0.100000  Loss: 0.8936  ASR: 0.1875 (0.2136)  ACC: 0.8750 (0.8516)  time: 0.3137  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.7029  ASR: 0.1875 (0.2160)  ACC: 0.8750 (0.8496)  time: 0.3131  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.3567  ASR: 0.2500 (0.2162)  ACC: 0.8750 (0.8519)  time: 0.3129  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [120/313]  eta: 0:01:01  Lr: 0.100000  Loss: 0.9226  ASR: 0.1875 (0.2169)  ACC: 0.8750 (0.8507)  time: 0.3129  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [130/313]  eta: 0:00:58  Lr: 0.100000  Loss: 0.6614  ASR: 0.1875 (0.2190)  ACC: 0.8125 (0.8497)  time: 0.3129  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.1651  ASR: 0.2500 (0.2221)  ACC: 0.8125 (0.8466)  time: 0.3131  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.7502  ASR: 0.1875 (0.2219)  ACC: 0.8125 (0.8444)  time: 0.3138  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.7482  ASR: 0.1875 (0.2236)  ACC: 0.8125 (0.8405)  time: 0.3145  data: 0.0005  max mem: 11725
Train: Epoch[2/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.8071  ASR: 0.2500 (0.2248)  ACC: 0.8125 (0.8385)  time: 0.3141  data: 0.0005  max mem: 11725
Train: Epoch[2/5]  [180/313]  eta: 0:00:42  Lr: 0.100000  Loss: 0.8633  ASR: 0.2500 (0.2282)  ACC: 0.8125 (0.8360)  time: 0.3145  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.5964  ASR: 0.2500 (0.2271)  ACC: 0.8125 (0.8374)  time: 0.3151  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7851  ASR: 0.1875 (0.2261)  ACC: 0.8750 (0.8368)  time: 0.3142  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.8351  ASR: 0.1875 (0.2251)  ACC: 0.8125 (0.8353)  time: 0.3138  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.7046  ASR: 0.1875 (0.2223)  ACC: 0.8125 (0.8365)  time: 0.3138  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.4063  ASR: 0.1875 (0.2227)  ACC: 0.8125 (0.8360)  time: 0.3138  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [240/313]  eta: 0:00:23  Lr: 0.100000  Loss: 1.0229  ASR: 0.1875 (0.2217)  ACC: 0.8750 (0.8379)  time: 0.3138  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.7305  ASR: 0.1875 (0.2206)  ACC: 0.8750 (0.8396)  time: 0.3146  data: 0.0004  max mem: 11725
Train: Epoch[2/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.8217  ASR: 0.1875 (0.2213)  ACC: 0.8750 (0.8400)  time: 0.3154  data: 0.0004  max mem: 11725
Train: Epoch[2/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.7592  ASR: 0.2500 (0.2221)  ACC: 0.8750 (0.8404)  time: 0.3145  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.6218  ASR: 0.3125 (0.2269)  ACC: 0.8125 (0.8379)  time: 0.3150  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.0346  ASR: 0.3125 (0.2274)  ACC: 0.7500 (0.8363)  time: 0.3169  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.0340  ASR: 0.2500 (0.2284)  ACC: 0.7500 (0.8351)  time: 0.3156  data: 0.0003  max mem: 11725
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6500  ASR: 0.1875 (0.2277)  ACC: 0.8750 (0.8370)  time: 0.3128  data: 0.0002  max mem: 11725
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5092  ASR: 0.1875 (0.2280)  ACC: 0.8750 (0.8371)  time: 0.3052  data: 0.0002  max mem: 11725
Train: Epoch[2/5] Total time: 0:01:38 (0.3156 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.5092  ASR: 0.1875 (0.2280)  ACC: 0.8750 (0.8371)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:45  Lr: 0.100000  Loss: 0.9798  ASR: 0.1250 (0.1250)  ACC: 0.9375 (0.9375)  time: 0.5280  data: 0.2109  max mem: 11725
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.7003  ASR: 0.1875 (0.2330)  ACC: 0.8750 (0.8352)  time: 0.3342  data: 0.0195  max mem: 11725
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.5088  ASR: 0.2500 (0.2530)  ACC: 0.8125 (0.8125)  time: 0.3147  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:31  Lr: 0.100000  Loss: 0.5146  ASR: 0.2500 (0.2460)  ACC: 0.8125 (0.8105)  time: 0.3150  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.6045  ASR: 0.2500 (0.2546)  ACC: 0.8125 (0.8155)  time: 0.3145  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.8743  ASR: 0.2500 (0.2500)  ACC: 0.8750 (0.8211)  time: 0.3138  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6252  ASR: 0.1875 (0.2449)  ACC: 0.8750 (0.8279)  time: 0.3141  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:17  Lr: 0.100000  Loss: 0.3549  ASR: 0.1250 (0.2368)  ACC: 0.8750 (0.8354)  time: 0.3130  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2766  ASR: 0.1250 (0.2315)  ACC: 0.8750 (0.8410)  time: 0.3134  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.8058  ASR: 0.1250 (0.2273)  ACC: 0.8750 (0.8462)  time: 0.3153  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5842  ASR: 0.2500 (0.2308)  ACC: 0.8750 (0.8428)  time: 0.3147  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.2631  ASR: 0.2500 (0.2297)  ACC: 0.8125 (0.8463)  time: 0.3136  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.7998  ASR: 0.1875 (0.2283)  ACC: 0.8750 (0.8476)  time: 0.3131  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4490  ASR: 0.1875 (0.2295)  ACC: 0.8750 (0.8469)  time: 0.3132  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.0579  ASR: 0.2500 (0.2332)  ACC: 0.8125 (0.8426)  time: 0.3142  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.6299  ASR: 0.2500 (0.2330)  ACC: 0.7500 (0.8398)  time: 0.3141  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.6174  ASR: 0.2500 (0.2337)  ACC: 0.8125 (0.8370)  time: 0.3144  data: 0.0005  max mem: 11725
Train: Epoch[3/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.7005  ASR: 0.2500 (0.2346)  ACC: 0.8125 (0.8344)  time: 0.3157  data: 0.0005  max mem: 11725
Train: Epoch[3/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.7443  ASR: 0.2500 (0.2393)  ACC: 0.8125 (0.8305)  time: 0.3150  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.5144  ASR: 0.2500 (0.2389)  ACC: 0.8125 (0.8308)  time: 0.3126  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7074  ASR: 0.2500 (0.2379)  ACC: 0.8125 (0.8305)  time: 0.3120  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7458  ASR: 0.2500 (0.2382)  ACC: 0.8125 (0.8276)  time: 0.3119  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5563  ASR: 0.1875 (0.2361)  ACC: 0.8125 (0.8286)  time: 0.3124  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.3366  ASR: 0.1875 (0.2362)  ACC: 0.8750 (0.8274)  time: 0.3132  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.9525  ASR: 0.1875 (0.2347)  ACC: 0.8750 (0.8294)  time: 0.3131  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6630  ASR: 0.1875 (0.2338)  ACC: 0.8750 (0.8307)  time: 0.3137  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7178  ASR: 0.1875 (0.2342)  ACC: 0.8750 (0.8312)  time: 0.3145  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6553  ASR: 0.2500 (0.2357)  ACC: 0.8125 (0.8310)  time: 0.3152  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.5099  ASR: 0.3125 (0.2402)  ACC: 0.7500 (0.8287)  time: 0.3159  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.9491  ASR: 0.2500 (0.2399)  ACC: 0.8125 (0.8280)  time: 0.3160  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.8739  ASR: 0.2500 (0.2407)  ACC: 0.8125 (0.8270)  time: 0.3147  data: 0.0003  max mem: 11725
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5387  ASR: 0.1875 (0.2398)  ACC: 0.8750 (0.8292)  time: 0.3129  data: 0.0002  max mem: 11725
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4457  ASR: 0.1875 (0.2398)  ACC: 0.8750 (0.8295)  time: 0.3057  data: 0.0002  max mem: 11725
Train: Epoch[3/5] Total time: 0:01:38 (0.3146 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4457  ASR: 0.1875 (0.2398)  ACC: 0.8750 (0.8295)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:50  Lr: 0.100000  Loss: 0.9332  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  time: 0.5448  data: 0.2258  max mem: 11725
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.6077  ASR: 0.2500 (0.2443)  ACC: 0.8750 (0.8295)  time: 0.3338  data: 0.0207  max mem: 11725
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.4203  ASR: 0.2500 (0.2649)  ACC: 0.8125 (0.8095)  time: 0.3137  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.4534  ASR: 0.2500 (0.2621)  ACC: 0.8125 (0.7984)  time: 0.3139  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.5221  ASR: 0.2500 (0.2683)  ACC: 0.8125 (0.8064)  time: 0.3130  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.7162  ASR: 0.2500 (0.2598)  ACC: 0.8750 (0.8150)  time: 0.3137  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.5514  ASR: 0.1875 (0.2541)  ACC: 0.8750 (0.8217)  time: 0.3140  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2937  ASR: 0.1875 (0.2456)  ACC: 0.8750 (0.8292)  time: 0.3134  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2248  ASR: 0.1875 (0.2415)  ACC: 0.8750 (0.8349)  time: 0.3133  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7578  ASR: 0.1875 (0.2363)  ACC: 0.8750 (0.8407)  time: 0.3141  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5036  ASR: 0.1875 (0.2389)  ACC: 0.8750 (0.8373)  time: 0.3147  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.2041  ASR: 0.2500 (0.2370)  ACC: 0.8125 (0.8412)  time: 0.3145  data: 0.0004  max mem: 11725
Train: Epoch[4/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.7245  ASR: 0.1875 (0.2355)  ACC: 0.8750 (0.8425)  time: 0.3153  data: 0.0004  max mem: 11725
Train: Epoch[4/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.3602  ASR: 0.1875 (0.2385)  ACC: 0.8125 (0.8397)  time: 0.3152  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.9627  ASR: 0.2500 (0.2420)  ACC: 0.8125 (0.8355)  time: 0.3140  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.5475  ASR: 0.2500 (0.2405)  ACC: 0.8125 (0.8340)  time: 0.3132  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.5329  ASR: 0.1875 (0.2407)  ACC: 0.8125 (0.8319)  time: 0.3130  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.6297  ASR: 0.2500 (0.2416)  ACC: 0.8125 (0.8297)  time: 0.3141  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.6478  ASR: 0.2500 (0.2472)  ACC: 0.8125 (0.8253)  time: 0.3142  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4677  ASR: 0.2500 (0.2471)  ACC: 0.8125 (0.8249)  time: 0.3142  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.6413  ASR: 0.2500 (0.2453)  ACC: 0.8125 (0.8252)  time: 0.3143  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.6934  ASR: 0.2500 (0.2459)  ACC: 0.8125 (0.8223)  time: 0.3138  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.4761  ASR: 0.1875 (0.2438)  ACC: 0.8125 (0.8232)  time: 0.3139  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2980  ASR: 0.2500 (0.2451)  ACC: 0.8750 (0.8217)  time: 0.3137  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.8791  ASR: 0.1875 (0.2438)  ACC: 0.8750 (0.8231)  time: 0.3136  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6021  ASR: 0.1875 (0.2425)  ACC: 0.8750 (0.8245)  time: 0.3140  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6565  ASR: 0.1875 (0.2428)  ACC: 0.8125 (0.8247)  time: 0.3137  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5805  ASR: 0.2500 (0.2442)  ACC: 0.8125 (0.8247)  time: 0.3130  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.4303  ASR: 0.3750 (0.2489)  ACC: 0.7500 (0.8223)  time: 0.3126  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.8793  ASR: 0.3125 (0.2483)  ACC: 0.7500 (0.8215)  time: 0.3133  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.7518  ASR: 0.2500 (0.2488)  ACC: 0.8125 (0.8208)  time: 0.3136  data: 0.0003  max mem: 11725
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4898  ASR: 0.1875 (0.2484)  ACC: 0.8125 (0.8221)  time: 0.3125  data: 0.0002  max mem: 11725
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3952  ASR: 0.1875 (0.2486)  ACC: 0.8125 (0.8223)  time: 0.3050  data: 0.0002  max mem: 11725
Train: Epoch[4/5] Total time: 0:01:38 (0.3143 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.3952  ASR: 0.1875 (0.2486)  ACC: 0.8125 (0.8223)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:51  Lr: 0.100000  Loss: 0.8972  ASR: 0.1250 (0.1250)  ACC: 0.9375 (0.9375)  time: 0.5492  data: 0.2300  max mem: 11725
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.5255  ASR: 0.2500 (0.2443)  ACC: 0.8750 (0.8352)  time: 0.3366  data: 0.0212  max mem: 11725
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.3827  ASR: 0.2500 (0.2679)  ACC: 0.8125 (0.8095)  time: 0.3158  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:31  Lr: 0.100000  Loss: 0.4090  ASR: 0.2500 (0.2722)  ACC: 0.7500 (0.7944)  time: 0.3151  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.4568  ASR: 0.2500 (0.2820)  ACC: 0.7500 (0.7973)  time: 0.3149  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:24  Lr: 0.100000  Loss: 0.6194  ASR: 0.2500 (0.2721)  ACC: 0.8125 (0.8051)  time: 0.3148  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.5055  ASR: 0.1875 (0.2654)  ACC: 0.8750 (0.8135)  time: 0.3144  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:17  Lr: 0.100000  Loss: 0.2572  ASR: 0.2500 (0.2614)  ACC: 0.8125 (0.8169)  time: 0.3156  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:14  Lr: 0.100000  Loss: 0.1983  ASR: 0.2500 (0.2569)  ACC: 0.8125 (0.8225)  time: 0.3149  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7054  ASR: 0.1875 (0.2514)  ACC: 0.8750 (0.8290)  time: 0.3136  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.4511  ASR: 0.2500 (0.2543)  ACC: 0.8750 (0.8249)  time: 0.3141  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.1720  ASR: 0.2500 (0.2528)  ACC: 0.8125 (0.8283)  time: 0.3138  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [120/313]  eta: 0:01:01  Lr: 0.100000  Loss: 0.6571  ASR: 0.2500 (0.2515)  ACC: 0.8750 (0.8290)  time: 0.3133  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.2982  ASR: 0.2500 (0.2552)  ACC: 0.8125 (0.8259)  time: 0.3136  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.8792  ASR: 0.3125 (0.2571)  ACC: 0.8125 (0.8227)  time: 0.3137  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.4805  ASR: 0.2500 (0.2546)  ACC: 0.8125 (0.8224)  time: 0.3139  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.4638  ASR: 0.1875 (0.2547)  ACC: 0.8125 (0.8203)  time: 0.3130  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.5845  ASR: 0.2500 (0.2548)  ACC: 0.8125 (0.8183)  time: 0.3117  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.5834  ASR: 0.3125 (0.2604)  ACC: 0.7500 (0.8135)  time: 0.3120  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4421  ASR: 0.3125 (0.2598)  ACC: 0.7500 (0.8135)  time: 0.3138  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.5940  ASR: 0.2500 (0.2572)  ACC: 0.8125 (0.8141)  time: 0.3149  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.6582  ASR: 0.2500 (0.2568)  ACC: 0.8125 (0.8119)  time: 0.3143  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.4381  ASR: 0.1875 (0.2545)  ACC: 0.7500 (0.8128)  time: 0.3147  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2739  ASR: 0.2500 (0.2557)  ACC: 0.8125 (0.8111)  time: 0.3146  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.8540  ASR: 0.2500 (0.2547)  ACC: 0.8125 (0.8122)  time: 0.3132  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.5677  ASR: 0.1875 (0.2535)  ACC: 0.8750 (0.8137)  time: 0.3139  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6094  ASR: 0.2500 (0.2538)  ACC: 0.8125 (0.8139)  time: 0.3152  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5170  ASR: 0.2500 (0.2553)  ACC: 0.7500 (0.8139)  time: 0.3142  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.3712  ASR: 0.3750 (0.2598)  ACC: 0.7500 (0.8114)  time: 0.3133  data: 0.0002  max mem: 11725
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.8271  ASR: 0.3125 (0.2595)  ACC: 0.7500 (0.8104)  time: 0.3141  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.7325  ASR: 0.2500 (0.2598)  ACC: 0.8125 (0.8098)  time: 0.3146  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4205  ASR: 0.1875 (0.2594)  ACC: 0.8125 (0.8111)  time: 0.3145  data: 0.0003  max mem: 11725
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3779  ASR: 0.1875 (0.2596)  ACC: 0.8125 (0.8113)  time: 0.3072  data: 0.0003  max mem: 11725
Train: Epoch[5/5] Total time: 0:01:38 (0.3148 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.3779  ASR: 0.1875 (0.2596)  ACC: 0.8125 (0.8113)
clean or triggered training model
;;;;;2
generating trigger
Train: Epoch[1/5]  [  0/313]  eta: 0:04:28  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  Loss: 0.9824 (0.9824)  time: 0.8578  data: 0.2270  max mem: 12013
Train: Epoch[1/5]  [ 10/313]  eta: 0:03:12  ASR: 0.2500 (0.2443)  ACC: 0.8750 (0.8295)  Loss: 0.9824 (0.9792)  time: 0.6367  data: 0.0210  max mem: 12013
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:09  ASR: 0.2500 (0.2708)  ACC: 0.8125 (0.8036)  Loss: 0.9719 (0.9730)  time: 0.6346  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [ 30/313]  eta: 0:03:01  ASR: 0.2500 (0.2742)  ACC: 0.8125 (0.7903)  Loss: 0.9724 (0.9701)  time: 0.6427  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:53  ASR: 0.2500 (0.2774)  ACC: 0.8125 (0.7973)  Loss: 0.9596 (0.9661)  time: 0.6266  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [ 50/313]  eta: 0:02:47  ASR: 0.2500 (0.2672)  ACC: 0.8125 (0.8064)  Loss: 0.9605 (0.9677)  time: 0.6309  data: 0.0005  max mem: 12013
Train: Epoch[1/5]  [ 60/313]  eta: 0:02:39  ASR: 0.1875 (0.2623)  ACC: 0.8750 (0.8156)  Loss: 0.9815 (0.9670)  time: 0.6167  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [ 70/313]  eta: 0:02:33  ASR: 0.1875 (0.2579)  ACC: 0.8750 (0.8195)  Loss: 1.0021 (0.9704)  time: 0.6140  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [ 80/313]  eta: 0:02:26  ASR: 0.2500 (0.2531)  ACC: 0.8125 (0.8248)  Loss: 0.9938 (0.9716)  time: 0.6316  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [ 90/313]  eta: 0:02:20  ASR: 0.1875 (0.2493)  ACC: 0.8750 (0.8310)  Loss: 0.9907 (0.9713)  time: 0.6325  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [100/313]  eta: 0:02:14  ASR: 0.2500 (0.2525)  ACC: 0.8750 (0.8267)  Loss: 1.0067 (0.9719)  time: 0.6300  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [110/313]  eta: 0:02:07  ASR: 0.2500 (0.2517)  ACC: 0.8125 (0.8294)  Loss: 1.0067 (0.9715)  time: 0.6238  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [120/313]  eta: 0:02:01  ASR: 0.2500 (0.2495)  ACC: 0.8750 (0.8316)  Loss: 0.9644 (0.9711)  time: 0.6361  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [130/313]  eta: 0:01:55  ASR: 0.2500 (0.2524)  ACC: 0.8125 (0.8292)  Loss: 0.9805 (0.9715)  time: 0.6298  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [140/313]  eta: 0:01:49  ASR: 0.2500 (0.2527)  ACC: 0.8125 (0.8276)  Loss: 0.9870 (0.9709)  time: 0.6291  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [150/313]  eta: 0:01:42  ASR: 0.1875 (0.2500)  ACC: 0.8125 (0.8278)  Loss: 0.9582 (0.9687)  time: 0.6277  data: 0.0005  max mem: 12013
Train: Epoch[1/5]  [160/313]  eta: 0:01:36  ASR: 0.1875 (0.2492)  ACC: 0.8125 (0.8269)  Loss: 0.9582 (0.9678)  time: 0.6141  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [170/313]  eta: 0:01:29  ASR: 0.2500 (0.2489)  ACC: 0.8125 (0.8253)  Loss: 0.9800 (0.9685)  time: 0.6177  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [180/313]  eta: 0:01:23  ASR: 0.2500 (0.2548)  ACC: 0.7500 (0.8208)  Loss: 0.9735 (0.9685)  time: 0.6208  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [190/313]  eta: 0:01:17  ASR: 0.3125 (0.2549)  ACC: 0.8125 (0.8210)  Loss: 0.9735 (0.9696)  time: 0.6293  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [200/313]  eta: 0:01:11  ASR: 0.2500 (0.2531)  ACC: 0.8125 (0.8209)  Loss: 1.0042 (0.9706)  time: 0.6321  data: 0.0004  max mem: 12013
Train: Epoch[1/5]  [210/313]  eta: 0:01:04  ASR: 0.2500 (0.2524)  ACC: 0.8125 (0.8187)  Loss: 1.0140 (0.9720)  time: 0.6289  data: 0.0003  max mem: 12013
Train: Epoch[1/5]  [220/313]  eta: 0:00:58  ASR: 0.1875 (0.2506)  ACC: 0.8125 (0.8190)  Loss: 1.0115 (0.9734)  time: 0.6330  data: 0.0003  max mem: 12056
Train: Epoch[1/5]  [230/313]  eta: 0:00:52  ASR: 0.2500 (0.2514)  ACC: 0.8125 (0.8176)  Loss: 0.9958 (0.9718)  time: 0.6198  data: 0.0003  max mem: 12056
Train: Epoch[1/5]  [240/313]  eta: 0:00:45  ASR: 0.1875 (0.2505)  ACC: 0.8125 (0.8179)  Loss: 1.0133 (0.9736)  time: 0.6102  data: 0.0004  max mem: 12056
Train: Epoch[1/5]  [250/313]  eta: 0:00:39  ASR: 0.1875 (0.2498)  ACC: 0.8125 (0.8187)  Loss: 1.0226 (0.9738)  time: 0.6137  data: 0.0003  max mem: 12056
Train: Epoch[1/5]  [260/313]  eta: 0:00:33  ASR: 0.2500 (0.2502)  ACC: 0.8125 (0.8192)  Loss: 0.9952 (0.9737)  time: 0.6204  data: 0.0002  max mem: 12056
Train: Epoch[1/5]  [270/313]  eta: 0:00:26  ASR: 0.2500 (0.2521)  ACC: 0.8125 (0.8192)  Loss: 0.9639 (0.9721)  time: 0.6313  data: 0.0004  max mem: 12056
Train: Epoch[1/5]  [280/313]  eta: 0:00:20  ASR: 0.3750 (0.2567)  ACC: 0.7500 (0.8165)  Loss: 0.9622 (0.9711)  time: 0.6248  data: 0.0004  max mem: 12056
Train: Epoch[1/5]  [290/313]  eta: 0:00:14  ASR: 0.3125 (0.2558)  ACC: 0.7500 (0.8159)  Loss: 1.0155 (0.9727)  time: 0.6269  data: 0.0003  max mem: 12056
Train: Epoch[1/5]  [300/313]  eta: 0:00:08  ASR: 0.2500 (0.2564)  ACC: 0.8125 (0.8152)  Loss: 1.0164 (0.9726)  time: 0.6213  data: 0.0003  max mem: 12056
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  ASR: 0.1875 (0.2562)  ACC: 0.8125 (0.8163)  Loss: 0.9715 (0.9709)  time: 0.6100  data: 0.0002  max mem: 12056
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  ASR: 0.1875 (0.2564)  ACC: 0.8125 (0.8165)  Loss: 0.9715 (0.9704)  time: 0.5943  data: 0.0002  max mem: 12056
Train: Epoch[1/5] Total time: 0:03:15 (0.6253 s / it)
Averaged stats: ASR: 0.1875 (0.2564)  ACC: 0.8125 (0.8165)  Loss: 0.9715 (0.9704)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:23  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  Loss: 0.9588 (0.9588)  time: 0.8421  data: 0.2104  max mem: 12056
Train: Epoch[2/5]  [ 10/313]  eta: 0:03:11  ASR: 0.2500 (0.2443)  ACC: 0.8750 (0.8295)  Loss: 0.9433 (0.9447)  time: 0.6308  data: 0.0194  max mem: 12056
Train: Epoch[2/5]  [ 20/313]  eta: 0:03:07  ASR: 0.2500 (0.2708)  ACC: 0.8125 (0.8036)  Loss: 0.9212 (0.9307)  time: 0.6309  data: 0.0007  max mem: 12056
Train: Epoch[2/5]  [ 30/313]  eta: 0:03:00  ASR: 0.2500 (0.2742)  ACC: 0.8125 (0.7903)  Loss: 0.9237 (0.9290)  time: 0.6407  data: 0.0007  max mem: 12056
Train: Epoch[2/5]  [ 40/313]  eta: 0:02:52  ASR: 0.2500 (0.2774)  ACC: 0.8125 (0.7973)  Loss: 0.9201 (0.9257)  time: 0.6251  data: 0.0004  max mem: 12056
Train: Epoch[2/5]  [ 50/313]  eta: 0:02:46  ASR: 0.2500 (0.2672)  ACC: 0.8125 (0.8064)  Loss: 0.9201 (0.9300)  time: 0.6298  data: 0.0004  max mem: 12056
Train: Epoch[2/5]  [ 60/313]  eta: 0:02:38  ASR: 0.1875 (0.2623)  ACC: 0.8750 (0.8156)  Loss: 0.9276 (0.9294)  time: 0.6166  data: 0.0004  max mem: 12056
Train: Epoch[2/5]  [ 70/313]  eta: 0:02:32  ASR: 0.1875 (0.2579)  ACC: 0.8750 (0.8195)  Loss: 0.9205 (0.9323)  time: 0.6130  data: 0.0004  max mem: 12056
Train: Epoch[2/5]  [ 80/313]  eta: 0:02:26  ASR: 0.2500 (0.2531)  ACC: 0.8125 (0.8248)  Loss: 0.9198 (0.9316)  time: 0.6319  data: 0.0004  max mem: 12056
Train: Epoch[2/5]  [ 90/313]  eta: 0:02:20  ASR: 0.1875 (0.2493)  ACC: 0.8750 (0.8310)  Loss: 0.9201 (0.9321)  time: 0.6330  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [100/313]  eta: 0:02:13  ASR: 0.2500 (0.2525)  ACC: 0.8750 (0.8267)  Loss: 0.9377 (0.9322)  time: 0.6285  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [110/313]  eta: 0:02:07  ASR: 0.2500 (0.2517)  ACC: 0.8125 (0.8294)  Loss: 0.9146 (0.9318)  time: 0.6201  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [120/313]  eta: 0:02:01  ASR: 0.2500 (0.2495)  ACC: 0.8750 (0.8316)  Loss: 0.9335 (0.9325)  time: 0.6333  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [130/313]  eta: 0:01:54  ASR: 0.2500 (0.2524)  ACC: 0.8125 (0.8292)  Loss: 0.9335 (0.9333)  time: 0.6298  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [140/313]  eta: 0:01:48  ASR: 0.2500 (0.2527)  ACC: 0.8125 (0.8276)  Loss: 0.9319 (0.9322)  time: 0.6293  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [150/313]  eta: 0:01:42  ASR: 0.1875 (0.2500)  ACC: 0.8125 (0.8278)  Loss: 0.9068 (0.9309)  time: 0.6288  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [160/313]  eta: 0:01:36  ASR: 0.1875 (0.2492)  ACC: 0.8125 (0.8269)  Loss: 0.9234 (0.9307)  time: 0.6169  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [170/313]  eta: 0:01:29  ASR: 0.2500 (0.2489)  ACC: 0.8125 (0.8253)  Loss: 0.9298 (0.9311)  time: 0.6183  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [180/313]  eta: 0:01:23  ASR: 0.2500 (0.2548)  ACC: 0.7500 (0.8208)  Loss: 0.9183 (0.9297)  time: 0.6194  data: 0.0002  max mem: 12056
Train: Epoch[2/5]  [190/313]  eta: 0:01:17  ASR: 0.3125 (0.2549)  ACC: 0.8125 (0.8210)  Loss: 0.9183 (0.9310)  time: 0.6278  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [200/313]  eta: 0:01:10  ASR: 0.2500 (0.2531)  ACC: 0.8125 (0.8209)  Loss: 0.9390 (0.9319)  time: 0.6293  data: 0.0003  max mem: 12056
Train: Epoch[2/5]  [210/313]  eta: 0:01:04  ASR: 0.2500 (0.2524)  ACC: 0.8125 (0.8187)  Loss: 1.0011 (0.9341)  time: 0.6274  data: 0.0002  max mem: 12056
Train: Epoch[2/5]  [220/313]  eta: 0:00:58  ASR: 0.1875 (0.2506)  ACC: 0.8125 (0.8190)  Loss: 1.0017 (0.9361)  time: 0.6339  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [230/313]  eta: 0:00:52  ASR: 0.2500 (0.2514)  ACC: 0.8125 (0.8176)  Loss: 0.9609 (0.9345)  time: 0.6208  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [240/313]  eta: 0:00:45  ASR: 0.1875 (0.2505)  ACC: 0.8125 (0.8179)  Loss: 0.9987 (0.9370)  time: 0.6086  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [250/313]  eta: 0:00:39  ASR: 0.1875 (0.2498)  ACC: 0.8125 (0.8187)  Loss: 1.0122 (0.9381)  time: 0.6131  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [260/313]  eta: 0:00:33  ASR: 0.2500 (0.2502)  ACC: 0.8125 (0.8192)  Loss: 0.9285 (0.9378)  time: 0.6228  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [270/313]  eta: 0:00:26  ASR: 0.2500 (0.2521)  ACC: 0.8125 (0.8192)  Loss: 0.9180 (0.9361)  time: 0.6319  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [280/313]  eta: 0:00:20  ASR: 0.3750 (0.2567)  ACC: 0.7500 (0.8165)  Loss: 0.9019 (0.9344)  time: 0.6232  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [290/313]  eta: 0:00:14  ASR: 0.3125 (0.2558)  ACC: 0.7500 (0.8159)  Loss: 1.0038 (0.9367)  time: 0.6263  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [300/313]  eta: 0:00:08  ASR: 0.2500 (0.2564)  ACC: 0.8125 (0.8152)  Loss: 1.0136 (0.9365)  time: 0.6218  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  ASR: 0.1875 (0.2562)  ACC: 0.8125 (0.8163)  Loss: 0.9197 (0.9344)  time: 0.6098  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  ASR: 0.1875 (0.2564)  ACC: 0.8125 (0.8165)  Loss: 0.9197 (0.9339)  time: 0.5947  data: 0.0002  max mem: 12057
Train: Epoch[2/5] Total time: 0:03:15 (0.6246 s / it)
Averaged stats: ASR: 0.1875 (0.2564)  ACC: 0.8125 (0.8165)  Loss: 0.9197 (0.9339)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:45  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  Loss: 0.9248 (0.9248)  time: 0.9111  data: 0.2813  max mem: 12057
Train: Epoch[3/5]  [ 10/313]  eta: 0:03:12  ASR: 0.2500 (0.2443)  ACC: 0.8750 (0.8295)  Loss: 0.9248 (0.9289)  time: 0.6356  data: 0.0258  max mem: 12057
Train: Epoch[3/5]  [ 20/313]  eta: 0:03:08  ASR: 0.2500 (0.2708)  ACC: 0.8125 (0.8036)  Loss: 0.8882 (0.9087)  time: 0.6285  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 30/313]  eta: 0:03:00  ASR: 0.2500 (0.2742)  ACC: 0.8125 (0.7903)  Loss: 0.8882 (0.9088)  time: 0.6374  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 40/313]  eta: 0:02:52  ASR: 0.2500 (0.2774)  ACC: 0.8125 (0.7973)  Loss: 0.9023 (0.9053)  time: 0.6233  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 50/313]  eta: 0:02:46  ASR: 0.2500 (0.2672)  ACC: 0.8125 (0.8064)  Loss: 0.9043 (0.9102)  time: 0.6272  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [ 60/313]  eta: 0:02:38  ASR: 0.1875 (0.2623)  ACC: 0.8750 (0.8156)  Loss: 0.9066 (0.9099)  time: 0.6128  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 70/313]  eta: 0:02:32  ASR: 0.1875 (0.2579)  ACC: 0.8750 (0.8195)  Loss: 0.9010 (0.9126)  time: 0.6117  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 80/313]  eta: 0:02:26  ASR: 0.2500 (0.2531)  ACC: 0.8125 (0.8248)  Loss: 0.8961 (0.9113)  time: 0.6299  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 90/313]  eta: 0:02:19  ASR: 0.1875 (0.2493)  ACC: 0.8750 (0.8310)  Loss: 0.8972 (0.9120)  time: 0.6301  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [100/313]  eta: 0:02:13  ASR: 0.2500 (0.2525)  ACC: 0.8750 (0.8267)  Loss: 0.9139 (0.9122)  time: 0.6262  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [110/313]  eta: 0:02:07  ASR: 0.2500 (0.2517)  ACC: 0.8125 (0.8294)  Loss: 0.8922 (0.9118)  time: 0.6188  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [120/313]  eta: 0:02:01  ASR: 0.2500 (0.2495)  ACC: 0.8750 (0.8316)  Loss: 0.9016 (0.9121)  time: 0.6312  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [130/313]  eta: 0:01:54  ASR: 0.2500 (0.2524)  ACC: 0.8125 (0.8292)  Loss: 0.9165 (0.9133)  time: 0.6254  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [140/313]  eta: 0:01:48  ASR: 0.2500 (0.2527)  ACC: 0.8125 (0.8276)  Loss: 0.9165 (0.9119)  time: 0.6267  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [150/313]  eta: 0:01:42  ASR: 0.1875 (0.2500)  ACC: 0.8125 (0.8278)  Loss: 0.9039 (0.9108)  time: 0.6288  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [160/313]  eta: 0:01:35  ASR: 0.1875 (0.2492)  ACC: 0.8125 (0.8269)  Loss: 0.9143 (0.9120)  time: 0.6162  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [170/313]  eta: 0:01:29  ASR: 0.2500 (0.2489)  ACC: 0.8125 (0.8253)  Loss: 0.9111 (0.9121)  time: 0.6175  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [180/313]  eta: 0:01:23  ASR: 0.2500 (0.2548)  ACC: 0.7500 (0.8208)  Loss: 0.8870 (0.9102)  time: 0.6198  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [190/313]  eta: 0:01:16  ASR: 0.3125 (0.2549)  ACC: 0.8125 (0.8210)  Loss: 0.8943 (0.9112)  time: 0.6279  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [200/313]  eta: 0:01:10  ASR: 0.2500 (0.2531)  ACC: 0.8125 (0.8209)  Loss: 0.9188 (0.9122)  time: 0.6289  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [210/313]  eta: 0:01:04  ASR: 0.2500 (0.2524)  ACC: 0.8125 (0.8187)  Loss: 0.9959 (0.9147)  time: 0.6286  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [220/313]  eta: 0:00:58  ASR: 0.1875 (0.2506)  ACC: 0.8125 (0.8190)  Loss: 0.9876 (0.9168)  time: 0.6349  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [230/313]  eta: 0:00:51  ASR: 0.2500 (0.2514)  ACC: 0.8125 (0.8176)  Loss: 0.9134 (0.9151)  time: 0.6204  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [240/313]  eta: 0:00:45  ASR: 0.1875 (0.2505)  ACC: 0.8125 (0.8179)  Loss: 0.9930 (0.9177)  time: 0.6103  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [250/313]  eta: 0:00:39  ASR: 0.1875 (0.2498)  ACC: 0.8125 (0.8187)  Loss: 1.0012 (0.9181)  time: 0.6137  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [260/313]  eta: 0:00:33  ASR: 0.2500 (0.2502)  ACC: 0.8125 (0.8192)  Loss: 0.9163 (0.9179)  time: 0.6210  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [270/313]  eta: 0:00:26  ASR: 0.2500 (0.2521)  ACC: 0.8125 (0.8192)  Loss: 0.8900 (0.9159)  time: 0.6303  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [280/313]  eta: 0:00:20  ASR: 0.3750 (0.2567)  ACC: 0.7500 (0.8165)  Loss: 0.8799 (0.9139)  time: 0.6226  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [290/313]  eta: 0:00:14  ASR: 0.3125 (0.2558)  ACC: 0.7500 (0.8159)  Loss: 0.9888 (0.9164)  time: 0.6260  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [300/313]  eta: 0:00:08  ASR: 0.2500 (0.2564)  ACC: 0.8125 (0.8152)  Loss: 1.0073 (0.9162)  time: 0.6214  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  ASR: 0.1875 (0.2562)  ACC: 0.8125 (0.8163)  Loss: 0.8582 (0.9140)  time: 0.6101  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  ASR: 0.1875 (0.2564)  ACC: 0.8125 (0.8165)  Loss: 0.8582 (0.9134)  time: 0.5946  data: 0.0003  max mem: 12057
Train: Epoch[3/5] Total time: 0:03:22 (0.6459 s / it)
Averaged stats: ASR: 0.1875 (0.2564)  ACC: 0.8125 (0.8165)  Loss: 0.8582 (0.9134)
Train: Epoch[1/5]  [  0/313]  eta: 0:03:04  Lr: 0.100000  Loss: 2.2664  ASR: 0.0000 (0.0000)  ACC: 0.0000 (0.0000)  time: 0.5899  data: 0.2684  max mem: 12057
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 2.2027  ASR: 0.0000 (0.0000)  ACC: 0.1875 (0.2102)  time: 0.3343  data: 0.0246  max mem: 12057
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 1.8511  ASR: 0.0000 (0.0595)  ACC: 0.3750 (0.3720)  time: 0.3083  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:29  Lr: 0.100000  Loss: 1.6153  ASR: 0.1875 (0.0988)  ACC: 0.6250 (0.4879)  time: 0.3083  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 1.5411  ASR: 0.1875 (0.1372)  ACC: 0.7500 (0.5564)  time: 0.3099  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:22  Lr: 0.100000  Loss: 1.8028  ASR: 0.1875 (0.1520)  ACC: 0.8125 (0.6054)  time: 0.3121  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 1.4314  ASR: 0.1875 (0.1650)  ACC: 0.8125 (0.6404)  time: 0.3123  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 1.0775  ASR: 0.2500 (0.1752)  ACC: 0.8125 (0.6629)  time: 0.3110  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.9001  ASR: 0.1875 (0.1821)  ACC: 0.8125 (0.6821)  time: 0.3108  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:09  Lr: 0.100000  Loss: 1.4289  ASR: 0.2500 (0.1882)  ACC: 0.8125 (0.6964)  time: 0.3110  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [100/313]  eta: 0:01:06  Lr: 0.100000  Loss: 1.1472  ASR: 0.2500 (0.1980)  ACC: 0.8125 (0.7073)  time: 0.3115  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.8221  ASR: 0.2500 (0.2027)  ACC: 0.8125 (0.7196)  time: 0.3122  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.2815  ASR: 0.1875 (0.2025)  ACC: 0.8125 (0.7288)  time: 0.3131  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 1.0807  ASR: 0.2500 (0.2080)  ACC: 0.8125 (0.7347)  time: 0.3133  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.3407  ASR: 0.2500 (0.2123)  ACC: 0.8125 (0.7385)  time: 0.3126  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.9571  ASR: 0.2500 (0.2169)  ACC: 0.8125 (0.7392)  time: 0.3126  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [160/313]  eta: 0:00:47  Lr: 0.100000  Loss: 1.0009  ASR: 0.2500 (0.2201)  ACC: 0.7500 (0.7415)  time: 0.3131  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 1.0472  ASR: 0.2500 (0.2215)  ACC: 0.8125 (0.7442)  time: 0.3139  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.9902  ASR: 0.2500 (0.2279)  ACC: 0.8125 (0.7455)  time: 0.3146  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.7776  ASR: 0.2500 (0.2307)  ACC: 0.8125 (0.7487)  time: 0.3153  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.9750  ASR: 0.2500 (0.2320)  ACC: 0.8125 (0.7497)  time: 0.3148  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.9833  ASR: 0.2500 (0.2346)  ACC: 0.7500 (0.7482)  time: 0.3123  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 1.0045  ASR: 0.2500 (0.2330)  ACC: 0.7500 (0.7508)  time: 0.3116  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.7084  ASR: 0.1875 (0.2332)  ACC: 0.8125 (0.7535)  time: 0.3137  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.1959  ASR: 0.2500 (0.2339)  ACC: 0.8125 (0.7562)  time: 0.3138  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.8106  ASR: 0.1875 (0.2328)  ACC: 0.8750 (0.7605)  time: 0.3115  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.9736  ASR: 0.1875 (0.2335)  ACC: 0.8750 (0.7629)  time: 0.3100  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.8367  ASR: 0.2500 (0.2355)  ACC: 0.8125 (0.7648)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.9104  ASR: 0.3125 (0.2407)  ACC: 0.7500 (0.7633)  time: 0.3111  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.1706  ASR: 0.3125 (0.2410)  ACC: 0.7500 (0.7640)  time: 0.3109  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.0693  ASR: 0.2500 (0.2423)  ACC: 0.7500 (0.7641)  time: 0.3128  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6730  ASR: 0.2500 (0.2428)  ACC: 0.7500 (0.7667)  time: 0.3125  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6558  ASR: 0.2500 (0.2434)  ACC: 0.7500 (0.7668)  time: 0.3051  data: 0.0003  max mem: 12057
Train: Epoch[1/5] Total time: 0:01:37 (0.3128 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.6558  ASR: 0.2500 (0.2434)  ACC: 0.7500 (0.7668)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:55  Lr: 0.100000  Loss: 1.0822  ASR: 0.4375 (0.4375)  ACC: 0.6250 (0.6250)  time: 0.5591  data: 0.2399  max mem: 12057
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.7940  ASR: 0.3125 (0.3295)  ACC: 0.7500 (0.7386)  time: 0.3356  data: 0.0220  max mem: 12057
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.6475  ASR: 0.3125 (0.3274)  ACC: 0.7500 (0.7500)  time: 0.3126  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.6132  ASR: 0.3125 (0.3206)  ACC: 0.7500 (0.7520)  time: 0.3116  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.6566  ASR: 0.3125 (0.3262)  ACC: 0.7500 (0.7576)  time: 0.3130  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 1.1215  ASR: 0.3125 (0.3150)  ACC: 0.8125 (0.7672)  time: 0.3145  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.7742  ASR: 0.2500 (0.3074)  ACC: 0.8125 (0.7746)  time: 0.3145  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.4001  ASR: 0.2500 (0.3090)  ACC: 0.7500 (0.7720)  time: 0.3136  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3942  ASR: 0.3125 (0.3086)  ACC: 0.7500 (0.7724)  time: 0.3117  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 1.0368  ASR: 0.3125 (0.3070)  ACC: 0.7500 (0.7740)  time: 0.3120  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.8014  ASR: 0.3125 (0.3106)  ACC: 0.7500 (0.7717)  time: 0.3133  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.3432  ASR: 0.3125 (0.3148)  ACC: 0.7500 (0.7697)  time: 0.3121  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.9791  ASR: 0.3125 (0.3130)  ACC: 0.8125 (0.7712)  time: 0.3104  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.6443  ASR: 0.3125 (0.3177)  ACC: 0.7500 (0.7667)  time: 0.3100  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.1683  ASR: 0.3750 (0.3187)  ACC: 0.6875 (0.7651)  time: 0.3103  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.6822  ASR: 0.3125 (0.3191)  ACC: 0.6875 (0.7628)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.7732  ASR: 0.3125 (0.3207)  ACC: 0.6875 (0.7601)  time: 0.3133  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.8116  ASR: 0.3125 (0.3187)  ACC: 0.7500 (0.7606)  time: 0.3152  data: 0.0006  max mem: 12057
Train: Epoch[2/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.7278  ASR: 0.3125 (0.3246)  ACC: 0.7500 (0.7579)  time: 0.3142  data: 0.0006  max mem: 12057
Train: Epoch[2/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.5000  ASR: 0.3750 (0.3253)  ACC: 0.7500 (0.7575)  time: 0.3132  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7694  ASR: 0.3125 (0.3243)  ACC: 0.7500 (0.7575)  time: 0.3126  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7515  ASR: 0.3750 (0.3282)  ACC: 0.6875 (0.7512)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.7972  ASR: 0.3750 (0.3269)  ACC: 0.6875 (0.7506)  time: 0.3107  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.4978  ASR: 0.3125 (0.3279)  ACC: 0.7500 (0.7495)  time: 0.3125  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.0596  ASR: 0.3125 (0.3281)  ACC: 0.7500 (0.7495)  time: 0.3144  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6517  ASR: 0.3125 (0.3262)  ACC: 0.8125 (0.7512)  time: 0.3131  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7774  ASR: 0.3125 (0.3250)  ACC: 0.8125 (0.7529)  time: 0.3119  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6896  ASR: 0.3125 (0.3261)  ACC: 0.7500 (0.7530)  time: 0.3113  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.6855  ASR: 0.4375 (0.3307)  ACC: 0.7500 (0.7502)  time: 0.3118  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.9902  ASR: 0.3750 (0.3308)  ACC: 0.6875 (0.7491)  time: 0.3123  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.8712  ASR: 0.3125 (0.3310)  ACC: 0.6875 (0.7483)  time: 0.3118  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4977  ASR: 0.3125 (0.3300)  ACC: 0.7500 (0.7504)  time: 0.3110  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4883  ASR: 0.3125 (0.3301)  ACC: 0.7500 (0.7506)  time: 0.3035  data: 0.0002  max mem: 12057
Train: Epoch[2/5] Total time: 0:01:37 (0.3130 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4883  ASR: 0.3125 (0.3301)  ACC: 0.7500 (0.7506)
Train: Epoch[3/5]  [  0/313]  eta: 0:03:14  Lr: 0.100000  Loss: 1.0092  ASR: 0.5000 (0.5000)  ACC: 0.5625 (0.5625)  time: 0.6202  data: 0.3037  max mem: 12057
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:42  Lr: 0.100000  Loss: 0.6736  ASR: 0.3750 (0.3920)  ACC: 0.6875 (0.6818)  time: 0.3396  data: 0.0278  max mem: 12057
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.4839  ASR: 0.3750 (0.4107)  ACC: 0.6875 (0.6696)  time: 0.3118  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:31  Lr: 0.100000  Loss: 0.4677  ASR: 0.3750 (0.4052)  ACC: 0.6875 (0.6694)  time: 0.3134  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.5029  ASR: 0.3750 (0.3994)  ACC: 0.6875 (0.6860)  time: 0.3144  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.8938  ASR: 0.3750 (0.3922)  ACC: 0.6875 (0.6912)  time: 0.3136  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6880  ASR: 0.3125 (0.3801)  ACC: 0.7500 (0.7029)  time: 0.3118  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:17  Lr: 0.100000  Loss: 0.2930  ASR: 0.3125 (0.3820)  ACC: 0.6875 (0.7007)  time: 0.3114  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2971  ASR: 0.3750 (0.3796)  ACC: 0.6875 (0.7045)  time: 0.3118  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.9206  ASR: 0.3750 (0.3764)  ACC: 0.7500 (0.7088)  time: 0.3117  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.7373  ASR: 0.3750 (0.3781)  ACC: 0.7500 (0.7079)  time: 0.3122  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.2555  ASR: 0.3750 (0.3795)  ACC: 0.6875 (0.7089)  time: 0.3131  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.8417  ASR: 0.3750 (0.3781)  ACC: 0.6875 (0.7102)  time: 0.3142  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.5140  ASR: 0.3750 (0.3822)  ACC: 0.6875 (0.7071)  time: 0.3146  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.0539  ASR: 0.3750 (0.3816)  ACC: 0.6875 (0.7066)  time: 0.3148  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.5659  ASR: 0.3125 (0.3796)  ACC: 0.6875 (0.7065)  time: 0.3148  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.6699  ASR: 0.3125 (0.3800)  ACC: 0.6875 (0.7046)  time: 0.3144  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.7149  ASR: 0.3750 (0.3772)  ACC: 0.6875 (0.7058)  time: 0.3128  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.5969  ASR: 0.3750 (0.3819)  ACC: 0.6875 (0.7041)  time: 0.3117  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4137  ASR: 0.4375 (0.3819)  ACC: 0.6875 (0.7042)  time: 0.3130  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.6810  ASR: 0.3750 (0.3809)  ACC: 0.6875 (0.7040)  time: 0.3145  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.6998  ASR: 0.3750 (0.3877)  ACC: 0.6875 (0.6949)  time: 0.3140  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.6686  ASR: 0.4375 (0.3849)  ACC: 0.5625 (0.6960)  time: 0.3131  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.3868  ASR: 0.3750 (0.3858)  ACC: 0.7500 (0.6951)  time: 0.3123  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.9620  ASR: 0.3750 (0.3854)  ACC: 0.6875 (0.6955)  time: 0.3116  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.5821  ASR: 0.3750 (0.3842)  ACC: 0.6875 (0.6967)  time: 0.3120  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7273  ASR: 0.3750 (0.3841)  ACC: 0.6875 (0.6973)  time: 0.3119  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5953  ASR: 0.3750 (0.3845)  ACC: 0.7500 (0.6983)  time: 0.3111  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.5735  ASR: 0.4375 (0.3886)  ACC: 0.6875 (0.6957)  time: 0.3119  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.9035  ASR: 0.4375 (0.3881)  ACC: 0.6250 (0.6950)  time: 0.3140  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.7563  ASR: 0.3750 (0.3877)  ACC: 0.6875 (0.6952)  time: 0.3148  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4271  ASR: 0.3750 (0.3871)  ACC: 0.7500 (0.6969)  time: 0.3142  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4306  ASR: 0.3750 (0.3872)  ACC: 0.7500 (0.6971)  time: 0.3065  data: 0.0003  max mem: 12057
Train: Epoch[3/5] Total time: 0:01:38 (0.3139 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4306  ASR: 0.3750 (0.3872)  ACC: 0.7500 (0.6971)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:56  Lr: 0.100000  Loss: 0.9480  ASR: 0.5625 (0.5625)  ACC: 0.5000 (0.5000)  time: 0.5629  data: 0.2435  max mem: 12057
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.5803  ASR: 0.4375 (0.4318)  ACC: 0.6250 (0.6420)  time: 0.3351  data: 0.0224  max mem: 12057
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.4108  ASR: 0.4375 (0.4643)  ACC: 0.6250 (0.6190)  time: 0.3140  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.4037  ASR: 0.4375 (0.4637)  ACC: 0.5625 (0.6149)  time: 0.3136  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.4002  ASR: 0.4375 (0.4588)  ACC: 0.6250 (0.6280)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.7698  ASR: 0.4375 (0.4510)  ACC: 0.6250 (0.6348)  time: 0.3118  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6302  ASR: 0.3750 (0.4395)  ACC: 0.6875 (0.6465)  time: 0.3136  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2331  ASR: 0.3750 (0.4410)  ACC: 0.6875 (0.6444)  time: 0.3128  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2436  ASR: 0.4375 (0.4406)  ACC: 0.6250 (0.6458)  time: 0.3130  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.8365  ASR: 0.3750 (0.4348)  ACC: 0.6875 (0.6532)  time: 0.3150  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.6936  ASR: 0.3750 (0.4356)  ACC: 0.6875 (0.6528)  time: 0.3140  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.2063  ASR: 0.3750 (0.4330)  ACC: 0.6875 (0.6582)  time: 0.3141  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.7228  ASR: 0.3750 (0.4308)  ACC: 0.6875 (0.6601)  time: 0.3147  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4242  ASR: 0.3750 (0.4318)  ACC: 0.6875 (0.6598)  time: 0.3143  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.9515  ASR: 0.4375 (0.4313)  ACC: 0.6875 (0.6591)  time: 0.3140  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.5000  ASR: 0.3750 (0.4284)  ACC: 0.6875 (0.6602)  time: 0.3134  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.5892  ASR: 0.3750 (0.4301)  ACC: 0.6875 (0.6572)  time: 0.3129  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.6341  ASR: 0.4375 (0.4280)  ACC: 0.6250 (0.6575)  time: 0.3124  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.5104  ASR: 0.4375 (0.4327)  ACC: 0.6250 (0.6554)  time: 0.3130  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3393  ASR: 0.5000 (0.4349)  ACC: 0.6250 (0.6535)  time: 0.3140  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.6333  ASR: 0.4375 (0.4347)  ACC: 0.6250 (0.6527)  time: 0.3141  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.6693  ASR: 0.4375 (0.4408)  ACC: 0.5625 (0.6445)  time: 0.3133  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5819  ASR: 0.5000 (0.4369)  ACC: 0.5625 (0.6468)  time: 0.3123  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.3199  ASR: 0.3750 (0.4372)  ACC: 0.6875 (0.6466)  time: 0.3127  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.8624  ASR: 0.3750 (0.4367)  ACC: 0.6875 (0.6470)  time: 0.3141  data: 0.0004  max mem: 12057
Train: Epoch[4/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.5280  ASR: 0.3750 (0.4358)  ACC: 0.6875 (0.6479)  time: 0.3143  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6694  ASR: 0.4375 (0.4344)  ACC: 0.6875 (0.6494)  time: 0.3143  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5299  ASR: 0.4375 (0.4350)  ACC: 0.6875 (0.6506)  time: 0.3134  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.4909  ASR: 0.5000 (0.4384)  ACC: 0.6250 (0.6488)  time: 0.3119  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.8345  ASR: 0.4375 (0.4379)  ACC: 0.6250 (0.6480)  time: 0.3124  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.6710  ASR: 0.3750 (0.4375)  ACC: 0.6250 (0.6480)  time: 0.3133  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3938  ASR: 0.4375 (0.4373)  ACC: 0.6875 (0.6493)  time: 0.3126  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3971  ASR: 0.4375 (0.4379)  ACC: 0.6250 (0.6490)  time: 0.3049  data: 0.0002  max mem: 12057
Train: Epoch[4/5] Total time: 0:01:38 (0.3141 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.3971  ASR: 0.4375 (0.4379)  ACC: 0.6250 (0.6490)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:52  Lr: 0.100000  Loss: 0.8649  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  time: 0.5499  data: 0.2320  max mem: 12057
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.5173  ASR: 0.4375 (0.4602)  ACC: 0.6250 (0.6193)  time: 0.3351  data: 0.0214  max mem: 12057
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.3671  ASR: 0.4375 (0.4911)  ACC: 0.6250 (0.5952)  time: 0.3143  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:31  Lr: 0.100000  Loss: 0.3411  ASR: 0.4375 (0.4960)  ACC: 0.5625 (0.5847)  time: 0.3145  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.3468  ASR: 0.4375 (0.4878)  ACC: 0.5625 (0.6006)  time: 0.3143  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.6624  ASR: 0.4375 (0.4804)  ACC: 0.6250 (0.6066)  time: 0.3144  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6025  ASR: 0.3750 (0.4713)  ACC: 0.6875 (0.6168)  time: 0.3136  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:17  Lr: 0.100000  Loss: 0.1954  ASR: 0.4375 (0.4762)  ACC: 0.6250 (0.6109)  time: 0.3123  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2065  ASR: 0.5000 (0.4784)  ACC: 0.5625 (0.6096)  time: 0.3130  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7825  ASR: 0.4375 (0.4712)  ACC: 0.6250 (0.6188)  time: 0.3131  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.6359  ASR: 0.4375 (0.4697)  ACC: 0.6875 (0.6207)  time: 0.3119  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.1769  ASR: 0.4375 (0.4696)  ACC: 0.6250 (0.6233)  time: 0.3127  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.6405  ASR: 0.5000 (0.4685)  ACC: 0.6250 (0.6245)  time: 0.3133  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.3696  ASR: 0.5000 (0.4719)  ACC: 0.6250 (0.6221)  time: 0.3131  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.8701  ASR: 0.5000 (0.4730)  ACC: 0.5625 (0.6197)  time: 0.3139  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.4571  ASR: 0.4375 (0.4694)  ACC: 0.6250 (0.6209)  time: 0.3142  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.5417  ASR: 0.4375 (0.4701)  ACC: 0.6250 (0.6188)  time: 0.3124  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.5822  ASR: 0.4375 (0.4682)  ACC: 0.6250 (0.6188)  time: 0.3117  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.4382  ASR: 0.5000 (0.4724)  ACC: 0.6250 (0.6174)  time: 0.3123  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3123  ASR: 0.5625 (0.4748)  ACC: 0.5625 (0.6152)  time: 0.3126  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.5867  ASR: 0.4375 (0.4723)  ACC: 0.6250 (0.6166)  time: 0.3124  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.6428  ASR: 0.5000 (0.4787)  ACC: 0.5000 (0.6081)  time: 0.3133  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5197  ASR: 0.5000 (0.4748)  ACC: 0.5000 (0.6100)  time: 0.3143  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2902  ASR: 0.4375 (0.4751)  ACC: 0.6875 (0.6098)  time: 0.3128  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.7648  ASR: 0.3750 (0.4735)  ACC: 0.6875 (0.6113)  time: 0.3116  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.5127  ASR: 0.3750 (0.4726)  ACC: 0.6250 (0.6121)  time: 0.3126  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6247  ASR: 0.4375 (0.4710)  ACC: 0.6250 (0.6140)  time: 0.3127  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.4833  ASR: 0.4375 (0.4712)  ACC: 0.6250 (0.6155)  time: 0.3113  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.4304  ASR: 0.5000 (0.4746)  ACC: 0.6250 (0.6137)  time: 0.3125  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.7952  ASR: 0.5000 (0.4729)  ACC: 0.6250 (0.6143)  time: 0.3150  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.6124  ASR: 0.4375 (0.4726)  ACC: 0.6250 (0.6144)  time: 0.3143  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3705  ASR: 0.4375 (0.4717)  ACC: 0.6250 (0.6164)  time: 0.3134  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3764  ASR: 0.5000 (0.4724)  ACC: 0.6250 (0.6158)  time: 0.3058  data: 0.0002  max mem: 12057
Train: Epoch[5/5] Total time: 0:01:38 (0.3138 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.3764  ASR: 0.5000 (0.4724)  ACC: 0.6250 (0.6158)
clean or triggered training model
;;;;;3
generating trigger
Train: Epoch[1/5]  [  0/313]  eta: 0:04:37  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  Loss: 0.9492 (0.9492)  time: 0.8854  data: 0.2593  max mem: 12057
Train: Epoch[1/5]  [ 10/313]  eta: 0:03:12  ASR: 0.5000 (0.4886)  ACC: 0.5625 (0.5909)  Loss: 0.9659 (0.9607)  time: 0.6339  data: 0.0238  max mem: 12057
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:07  ASR: 0.5000 (0.5149)  ACC: 0.5625 (0.5744)  Loss: 0.9587 (0.9401)  time: 0.6287  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 30/313]  eta: 0:03:00  ASR: 0.5000 (0.5161)  ACC: 0.5625 (0.5645)  Loss: 0.9270 (0.9414)  time: 0.6374  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:52  ASR: 0.5000 (0.5030)  ACC: 0.5625 (0.5869)  Loss: 0.9296 (0.9337)  time: 0.6220  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 50/313]  eta: 0:02:46  ASR: 0.4375 (0.4914)  ACC: 0.6250 (0.5968)  Loss: 0.9274 (0.9347)  time: 0.6262  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 60/313]  eta: 0:02:38  ASR: 0.4375 (0.4846)  ACC: 0.6250 (0.6066)  Loss: 0.9466 (0.9329)  time: 0.6140  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 70/313]  eta: 0:02:32  ASR: 0.4375 (0.4886)  ACC: 0.6250 (0.6012)  Loss: 0.9523 (0.9364)  time: 0.6115  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 80/313]  eta: 0:02:26  ASR: 0.5000 (0.4892)  ACC: 0.5625 (0.6011)  Loss: 0.9231 (0.9352)  time: 0.6299  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 90/313]  eta: 0:02:19  ASR: 0.4375 (0.4815)  ACC: 0.6250 (0.6106)  Loss: 0.9322 (0.9369)  time: 0.6303  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [100/313]  eta: 0:02:13  ASR: 0.4375 (0.4796)  ACC: 0.6250 (0.6126)  Loss: 0.9662 (0.9375)  time: 0.6247  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [110/313]  eta: 0:02:07  ASR: 0.5000 (0.4780)  ACC: 0.6250 (0.6160)  Loss: 0.9688 (0.9374)  time: 0.6195  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [120/313]  eta: 0:02:01  ASR: 0.5000 (0.4757)  ACC: 0.6250 (0.6178)  Loss: 0.9394 (0.9384)  time: 0.6334  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [130/313]  eta: 0:01:54  ASR: 0.4375 (0.4757)  ACC: 0.6250 (0.6183)  Loss: 0.9620 (0.9396)  time: 0.6277  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [140/313]  eta: 0:01:48  ASR: 0.5000 (0.4778)  ACC: 0.5625 (0.6148)  Loss: 0.9415 (0.9397)  time: 0.6287  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [150/313]  eta: 0:01:42  ASR: 0.5000 (0.4743)  ACC: 0.5625 (0.6163)  Loss: 0.9401 (0.9396)  time: 0.6283  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [160/313]  eta: 0:01:35  ASR: 0.4375 (0.4752)  ACC: 0.6250 (0.6149)  Loss: 0.9369 (0.9392)  time: 0.6142  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [170/313]  eta: 0:01:29  ASR: 0.4375 (0.4719)  ACC: 0.6250 (0.6159)  Loss: 0.9359 (0.9401)  time: 0.6165  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [180/313]  eta: 0:01:23  ASR: 0.4375 (0.4751)  ACC: 0.6250 (0.6153)  Loss: 0.9359 (0.9386)  time: 0.6193  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [190/313]  eta: 0:01:16  ASR: 0.5625 (0.4768)  ACC: 0.5625 (0.6142)  Loss: 0.9507 (0.9396)  time: 0.6261  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [200/313]  eta: 0:01:10  ASR: 0.4375 (0.4745)  ACC: 0.6250 (0.6150)  Loss: 0.9617 (0.9404)  time: 0.6281  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [210/313]  eta: 0:01:04  ASR: 0.5000 (0.4796)  ACC: 0.5625 (0.6075)  Loss: 1.0010 (0.9427)  time: 0.6286  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [220/313]  eta: 0:00:58  ASR: 0.5000 (0.4768)  ACC: 0.5000 (0.6086)  Loss: 1.0056 (0.9452)  time: 0.6338  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [230/313]  eta: 0:00:51  ASR: 0.3750 (0.4759)  ACC: 0.6250 (0.6090)  Loss: 1.0011 (0.9436)  time: 0.6185  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [240/313]  eta: 0:00:45  ASR: 0.3750 (0.4741)  ACC: 0.6250 (0.6105)  Loss: 1.0068 (0.9457)  time: 0.6079  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [250/313]  eta: 0:00:39  ASR: 0.4375 (0.4731)  ACC: 0.6250 (0.6116)  Loss: 1.0146 (0.9464)  time: 0.6136  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [260/313]  eta: 0:00:33  ASR: 0.4375 (0.4722)  ACC: 0.6250 (0.6128)  Loss: 0.9897 (0.9475)  time: 0.6198  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [270/313]  eta: 0:00:26  ASR: 0.4375 (0.4728)  ACC: 0.6250 (0.6139)  Loss: 0.9587 (0.9463)  time: 0.6266  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [280/313]  eta: 0:00:20  ASR: 0.5000 (0.4760)  ACC: 0.6250 (0.6125)  Loss: 0.9199 (0.9445)  time: 0.6220  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [290/313]  eta: 0:00:14  ASR: 0.5000 (0.4744)  ACC: 0.6250 (0.6128)  Loss: 1.0036 (0.9464)  time: 0.6274  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [300/313]  eta: 0:00:08  ASR: 0.4375 (0.4740)  ACC: 0.6250 (0.6130)  Loss: 1.0099 (0.9457)  time: 0.6219  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  ASR: 0.4375 (0.4731)  ACC: 0.6250 (0.6150)  Loss: 0.9276 (0.9442)  time: 0.6091  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  ASR: 0.5000 (0.4738)  ACC: 0.6250 (0.6144)  Loss: 0.9387 (0.9439)  time: 0.5931  data: 0.0003  max mem: 12057
Train: Epoch[1/5] Total time: 0:03:15 (0.6231 s / it)
Averaged stats: ASR: 0.5000 (0.4738)  ACC: 0.6250 (0.6144)  Loss: 0.9387 (0.9439)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:52  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  Loss: 0.9138 (0.9138)  time: 0.9334  data: 0.2943  max mem: 12057
Train: Epoch[2/5]  [ 10/313]  eta: 0:03:13  ASR: 0.5000 (0.4886)  ACC: 0.5625 (0.5909)  Loss: 0.9277 (0.9301)  time: 0.6391  data: 0.0270  max mem: 12057
Train: Epoch[2/5]  [ 20/313]  eta: 0:03:09  ASR: 0.5000 (0.5149)  ACC: 0.5625 (0.5744)  Loss: 0.9082 (0.9114)  time: 0.6307  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [ 30/313]  eta: 0:03:01  ASR: 0.5000 (0.5161)  ACC: 0.5625 (0.5645)  Loss: 0.9082 (0.9136)  time: 0.6403  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 40/313]  eta: 0:02:53  ASR: 0.5000 (0.5030)  ACC: 0.5625 (0.5869)  Loss: 0.9137 (0.9054)  time: 0.6236  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [ 50/313]  eta: 0:02:47  ASR: 0.4375 (0.4914)  ACC: 0.6250 (0.5968)  Loss: 0.9137 (0.9095)  time: 0.6274  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [ 60/313]  eta: 0:02:38  ASR: 0.4375 (0.4846)  ACC: 0.6250 (0.6066)  Loss: 0.9177 (0.9076)  time: 0.6153  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [ 70/313]  eta: 0:02:32  ASR: 0.4375 (0.4886)  ACC: 0.6250 (0.6012)  Loss: 0.9290 (0.9109)  time: 0.6119  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 80/313]  eta: 0:02:26  ASR: 0.5000 (0.4892)  ACC: 0.5625 (0.6011)  Loss: 0.8966 (0.9094)  time: 0.6296  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 90/313]  eta: 0:02:20  ASR: 0.4375 (0.4815)  ACC: 0.6250 (0.6106)  Loss: 0.8966 (0.9121)  time: 0.6316  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [100/313]  eta: 0:02:13  ASR: 0.4375 (0.4796)  ACC: 0.6250 (0.6126)  Loss: 0.9257 (0.9136)  time: 0.6275  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [110/313]  eta: 0:02:07  ASR: 0.5000 (0.4780)  ACC: 0.6250 (0.6160)  Loss: 0.9257 (0.9129)  time: 0.6196  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [120/313]  eta: 0:02:01  ASR: 0.5000 (0.4757)  ACC: 0.6250 (0.6178)  Loss: 0.9140 (0.9133)  time: 0.6331  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [130/313]  eta: 0:01:54  ASR: 0.4375 (0.4757)  ACC: 0.6250 (0.6183)  Loss: 0.9140 (0.9149)  time: 0.6290  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [140/313]  eta: 0:01:48  ASR: 0.5000 (0.4778)  ACC: 0.5625 (0.6148)  Loss: 0.9139 (0.9147)  time: 0.6282  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [150/313]  eta: 0:01:42  ASR: 0.5000 (0.4743)  ACC: 0.5625 (0.6163)  Loss: 0.9129 (0.9143)  time: 0.6255  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [160/313]  eta: 0:01:35  ASR: 0.4375 (0.4752)  ACC: 0.6250 (0.6149)  Loss: 0.9226 (0.9143)  time: 0.6116  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [170/313]  eta: 0:01:29  ASR: 0.4375 (0.4719)  ACC: 0.6250 (0.6159)  Loss: 0.9194 (0.9149)  time: 0.6146  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [180/313]  eta: 0:01:23  ASR: 0.4375 (0.4751)  ACC: 0.6250 (0.6153)  Loss: 0.8927 (0.9133)  time: 0.6189  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [190/313]  eta: 0:01:17  ASR: 0.5625 (0.4768)  ACC: 0.5625 (0.6142)  Loss: 0.9106 (0.9140)  time: 0.6273  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [200/313]  eta: 0:01:10  ASR: 0.4375 (0.4745)  ACC: 0.6250 (0.6150)  Loss: 0.9261 (0.9153)  time: 0.6284  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [210/313]  eta: 0:01:04  ASR: 0.5000 (0.4796)  ACC: 0.5625 (0.6075)  Loss: 0.9935 (0.9179)  time: 0.6277  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [220/313]  eta: 0:00:58  ASR: 0.5000 (0.4768)  ACC: 0.5000 (0.6086)  Loss: 0.9977 (0.9205)  time: 0.6320  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [230/313]  eta: 0:00:51  ASR: 0.3750 (0.4759)  ACC: 0.6250 (0.6090)  Loss: 0.9304 (0.9190)  time: 0.6161  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [240/313]  eta: 0:00:45  ASR: 0.3750 (0.4741)  ACC: 0.6250 (0.6105)  Loss: 0.9925 (0.9217)  time: 0.6068  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [250/313]  eta: 0:00:39  ASR: 0.4375 (0.4731)  ACC: 0.6250 (0.6116)  Loss: 1.0041 (0.9224)  time: 0.6148  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [260/313]  eta: 0:00:33  ASR: 0.4375 (0.4722)  ACC: 0.6250 (0.6128)  Loss: 0.9664 (0.9234)  time: 0.6238  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [270/313]  eta: 0:00:26  ASR: 0.4375 (0.4728)  ACC: 0.6250 (0.6139)  Loss: 0.9354 (0.9219)  time: 0.6322  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [280/313]  eta: 0:00:20  ASR: 0.5000 (0.4760)  ACC: 0.6250 (0.6125)  Loss: 0.8932 (0.9201)  time: 0.6236  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [290/313]  eta: 0:00:14  ASR: 0.5000 (0.4744)  ACC: 0.6250 (0.6128)  Loss: 0.9992 (0.9224)  time: 0.6267  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [300/313]  eta: 0:00:08  ASR: 0.4375 (0.4740)  ACC: 0.6250 (0.6130)  Loss: 1.0055 (0.9219)  time: 0.6241  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  ASR: 0.4375 (0.4731)  ACC: 0.6250 (0.6150)  Loss: 0.8969 (0.9202)  time: 0.6126  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  ASR: 0.5000 (0.4738)  ACC: 0.6250 (0.6144)  Loss: 0.8969 (0.9195)  time: 0.5962  data: 0.0003  max mem: 12057
Train: Epoch[2/5] Total time: 0:03:15 (0.6240 s / it)
Averaged stats: ASR: 0.5000 (0.4738)  ACC: 0.6250 (0.6144)  Loss: 0.8969 (0.9195)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:43  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  Loss: 0.9104 (0.9104)  time: 0.9062  data: 0.2712  max mem: 12057
Train: Epoch[3/5]  [ 10/313]  eta: 0:03:12  ASR: 0.5000 (0.4886)  ACC: 0.5625 (0.5909)  Loss: 0.9246 (0.9209)  time: 0.6366  data: 0.0249  max mem: 12057
Train: Epoch[3/5]  [ 20/313]  eta: 0:03:08  ASR: 0.5000 (0.5149)  ACC: 0.5625 (0.5744)  Loss: 0.8858 (0.8981)  time: 0.6304  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [ 30/313]  eta: 0:03:00  ASR: 0.5000 (0.5161)  ACC: 0.5625 (0.5645)  Loss: 0.8858 (0.9014)  time: 0.6390  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [ 40/313]  eta: 0:02:52  ASR: 0.5000 (0.5030)  ACC: 0.5625 (0.5869)  Loss: 0.9005 (0.8933)  time: 0.6216  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 50/313]  eta: 0:02:46  ASR: 0.4375 (0.4914)  ACC: 0.6250 (0.5968)  Loss: 0.9005 (0.8976)  time: 0.6247  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [ 60/313]  eta: 0:02:38  ASR: 0.4375 (0.4846)  ACC: 0.6250 (0.6066)  Loss: 0.9040 (0.8968)  time: 0.6131  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 70/313]  eta: 0:02:32  ASR: 0.4375 (0.4886)  ACC: 0.6250 (0.6012)  Loss: 0.9085 (0.8999)  time: 0.6139  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [ 80/313]  eta: 0:02:26  ASR: 0.5000 (0.4892)  ACC: 0.5625 (0.6011)  Loss: 0.8840 (0.8987)  time: 0.6347  data: 0.0005  max mem: 12057
Train: Epoch[3/5]  [ 90/313]  eta: 0:02:20  ASR: 0.4375 (0.4815)  ACC: 0.6250 (0.6106)  Loss: 0.8909 (0.9016)  time: 0.6340  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [100/313]  eta: 0:02:13  ASR: 0.4375 (0.4796)  ACC: 0.6250 (0.6126)  Loss: 0.9402 (0.9033)  time: 0.6291  data: 0.0005  max mem: 12057
Train: Epoch[3/5]  [110/313]  eta: 0:02:07  ASR: 0.5000 (0.4780)  ACC: 0.6250 (0.6160)  Loss: 0.9402 (0.9027)  time: 0.6228  data: 0.0005  max mem: 12057
Train: Epoch[3/5]  [120/313]  eta: 0:02:01  ASR: 0.5000 (0.4757)  ACC: 0.6250 (0.6178)  Loss: 0.9048 (0.9027)  time: 0.6347  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [130/313]  eta: 0:01:54  ASR: 0.4375 (0.4757)  ACC: 0.6250 (0.6183)  Loss: 0.9048 (0.9037)  time: 0.6310  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [140/313]  eta: 0:01:48  ASR: 0.5000 (0.4778)  ACC: 0.5625 (0.6148)  Loss: 0.8856 (0.9032)  time: 0.6317  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [150/313]  eta: 0:01:42  ASR: 0.5000 (0.4743)  ACC: 0.5625 (0.6163)  Loss: 0.8866 (0.9021)  time: 0.6290  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [160/313]  eta: 0:01:36  ASR: 0.4375 (0.4752)  ACC: 0.6250 (0.6149)  Loss: 0.8866 (0.9017)  time: 0.6135  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [170/313]  eta: 0:01:29  ASR: 0.4375 (0.4719)  ACC: 0.6250 (0.6159)  Loss: 0.8826 (0.9028)  time: 0.6154  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [180/313]  eta: 0:01:23  ASR: 0.4375 (0.4751)  ACC: 0.6250 (0.6153)  Loss: 0.8826 (0.9013)  time: 0.6180  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [190/313]  eta: 0:01:17  ASR: 0.5625 (0.4768)  ACC: 0.5625 (0.6142)  Loss: 0.9045 (0.9021)  time: 0.6258  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [200/313]  eta: 0:01:10  ASR: 0.4375 (0.4745)  ACC: 0.6250 (0.6150)  Loss: 0.9163 (0.9031)  time: 0.6295  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [210/313]  eta: 0:01:04  ASR: 0.5000 (0.4796)  ACC: 0.5625 (0.6075)  Loss: 0.9828 (0.9057)  time: 0.6291  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [220/313]  eta: 0:00:58  ASR: 0.5000 (0.4768)  ACC: 0.5000 (0.6086)  Loss: 0.9864 (0.9084)  time: 0.6331  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [230/313]  eta: 0:00:51  ASR: 0.3750 (0.4759)  ACC: 0.6250 (0.6090)  Loss: 0.9174 (0.9068)  time: 0.6186  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [240/313]  eta: 0:00:45  ASR: 0.3750 (0.4741)  ACC: 0.6250 (0.6105)  Loss: 0.9816 (0.9098)  time: 0.6090  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [250/313]  eta: 0:00:39  ASR: 0.4375 (0.4731)  ACC: 0.6250 (0.6116)  Loss: 1.0006 (0.9106)  time: 0.6128  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [260/313]  eta: 0:00:33  ASR: 0.4375 (0.4722)  ACC: 0.6250 (0.6128)  Loss: 0.9623 (0.9117)  time: 0.6211  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [270/313]  eta: 0:00:26  ASR: 0.4375 (0.4728)  ACC: 0.6250 (0.6139)  Loss: 0.9050 (0.9099)  time: 0.6306  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [280/313]  eta: 0:00:20  ASR: 0.5000 (0.4760)  ACC: 0.6250 (0.6125)  Loss: 0.8800 (0.9081)  time: 0.6229  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [290/313]  eta: 0:00:14  ASR: 0.5000 (0.4744)  ACC: 0.6250 (0.6128)  Loss: 0.9940 (0.9105)  time: 0.6264  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [300/313]  eta: 0:00:08  ASR: 0.4375 (0.4740)  ACC: 0.6250 (0.6130)  Loss: 0.9968 (0.9100)  time: 0.6212  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  ASR: 0.4375 (0.4731)  ACC: 0.6250 (0.6150)  Loss: 0.8822 (0.9080)  time: 0.6111  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  ASR: 0.5000 (0.4738)  ACC: 0.6250 (0.6144)  Loss: 0.8822 (0.9074)  time: 0.5954  data: 0.0002  max mem: 12057
Train: Epoch[3/5] Total time: 0:03:15 (0.6244 s / it)
Averaged stats: ASR: 0.5000 (0.4738)  ACC: 0.6250 (0.6144)  Loss: 0.8822 (0.9074)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:55  Lr: 0.100000  Loss: 2.3535  ASR: 0.0000 (0.0000)  ACC: 0.0000 (0.0000)  time: 0.5621  data: 0.2403  max mem: 12057
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 2.1402  ASR: 0.0000 (0.0057)  ACC: 0.1250 (0.1420)  time: 0.3329  data: 0.0220  max mem: 12057
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 1.9197  ASR: 0.0000 (0.0685)  ACC: 0.3125 (0.3512)  time: 0.3108  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 1.6603  ASR: 0.1250 (0.0948)  ACC: 0.6875 (0.4758)  time: 0.3117  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 1.6317  ASR: 0.1875 (0.1235)  ACC: 0.7500 (0.5503)  time: 0.3108  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 1.7712  ASR: 0.1875 (0.1409)  ACC: 0.8125 (0.5956)  time: 0.3102  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 1.4371  ASR: 0.1875 (0.1506)  ACC: 0.8125 (0.6311)  time: 0.3112  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 1.1224  ASR: 0.1875 (0.1532)  ACC: 0.8125 (0.6646)  time: 0.3117  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.9182  ASR: 0.1875 (0.1590)  ACC: 0.8750 (0.6860)  time: 0.3117  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 1.4415  ASR: 0.1875 (0.1655)  ACC: 0.8125 (0.7019)  time: 0.3126  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [100/313]  eta: 0:01:06  Lr: 0.100000  Loss: 1.1419  ASR: 0.2500 (0.1757)  ACC: 0.8125 (0.7123)  time: 0.3140  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.7937  ASR: 0.2500 (0.1813)  ACC: 0.8125 (0.7224)  time: 0.3144  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.4855  ASR: 0.2500 (0.1844)  ACC: 0.8125 (0.7304)  time: 0.3140  data: 0.0005  max mem: 12057
Train: Epoch[1/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.9506  ASR: 0.2500 (0.1904)  ACC: 0.8125 (0.7362)  time: 0.3146  data: 0.0005  max mem: 12057
Train: Epoch[1/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.4124  ASR: 0.2500 (0.1955)  ACC: 0.8125 (0.7398)  time: 0.3145  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 1.0131  ASR: 0.2500 (0.1999)  ACC: 0.7500 (0.7413)  time: 0.3134  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.9920  ASR: 0.2500 (0.2046)  ACC: 0.7500 (0.7426)  time: 0.3128  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 1.0978  ASR: 0.2500 (0.2069)  ACC: 0.7500 (0.7456)  time: 0.3125  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.9248  ASR: 0.2500 (0.2110)  ACC: 0.8125 (0.7490)  time: 0.3135  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.8201  ASR: 0.2500 (0.2124)  ACC: 0.8125 (0.7533)  time: 0.3148  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.9921  ASR: 0.2500 (0.2136)  ACC: 0.8125 (0.7547)  time: 0.3138  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 1.0565  ASR: 0.2500 (0.2139)  ACC: 0.7500 (0.7556)  time: 0.3117  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.9536  ASR: 0.1875 (0.2135)  ACC: 0.8125 (0.7588)  time: 0.3102  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.6420  ASR: 0.2500 (0.2137)  ACC: 0.8125 (0.7614)  time: 0.3103  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.2048  ASR: 0.1875 (0.2127)  ACC: 0.8750 (0.7666)  time: 0.3105  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.8913  ASR: 0.1875 (0.2124)  ACC: 0.8750 (0.7702)  time: 0.3105  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 1.0470  ASR: 0.1875 (0.2131)  ACC: 0.8125 (0.7723)  time: 0.3108  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.8333  ASR: 0.1875 (0.2140)  ACC: 0.8125 (0.7751)  time: 0.3104  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 1.0131  ASR: 0.3125 (0.2200)  ACC: 0.8125 (0.7734)  time: 0.3101  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.1885  ASR: 0.3125 (0.2208)  ACC: 0.7500 (0.7738)  time: 0.3105  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.1056  ASR: 0.2500 (0.2220)  ACC: 0.8125 (0.7745)  time: 0.3108  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6811  ASR: 0.1875 (0.2223)  ACC: 0.8125 (0.7769)  time: 0.3120  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.7630  ASR: 0.1875 (0.2228)  ACC: 0.8125 (0.7770)  time: 0.3047  data: 0.0002  max mem: 12057
Train: Epoch[1/5] Total time: 0:01:37 (0.3128 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.7630  ASR: 0.1875 (0.2228)  ACC: 0.8125 (0.7770)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:57  Lr: 0.100000  Loss: 1.1678  ASR: 0.3750 (0.3750)  ACC: 0.6250 (0.6250)  time: 0.5685  data: 0.2453  max mem: 12057
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.7714  ASR: 0.3125 (0.3068)  ACC: 0.6875 (0.7500)  time: 0.3358  data: 0.0225  max mem: 12057
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.7225  ASR: 0.2500 (0.3185)  ACC: 0.7500 (0.7530)  time: 0.3140  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:31  Lr: 0.100000  Loss: 0.6270  ASR: 0.2500 (0.3065)  ACC: 0.7500 (0.7621)  time: 0.3142  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.7453  ASR: 0.3125 (0.3064)  ACC: 0.8125 (0.7759)  time: 0.3132  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 1.0810  ASR: 0.3125 (0.3015)  ACC: 0.8125 (0.7770)  time: 0.3126  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.8429  ASR: 0.2500 (0.2941)  ACC: 0.8125 (0.7838)  time: 0.3116  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.3854  ASR: 0.3125 (0.2958)  ACC: 0.7500 (0.7817)  time: 0.3110  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.4036  ASR: 0.3125 (0.2901)  ACC: 0.8125 (0.7886)  time: 0.3102  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.9969  ASR: 0.2500 (0.2885)  ACC: 0.8125 (0.7905)  time: 0.3116  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.7791  ASR: 0.3125 (0.2933)  ACC: 0.8125 (0.7871)  time: 0.3134  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.3130  ASR: 0.3125 (0.2962)  ACC: 0.7500 (0.7860)  time: 0.3124  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.2121  ASR: 0.3125 (0.2955)  ACC: 0.8125 (0.7862)  time: 0.3114  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.5972  ASR: 0.3125 (0.2996)  ACC: 0.7500 (0.7824)  time: 0.3127  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.1280  ASR: 0.3125 (0.3019)  ACC: 0.7500 (0.7801)  time: 0.3136  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.7446  ASR: 0.3125 (0.3022)  ACC: 0.7500 (0.7786)  time: 0.3132  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.7586  ASR: 0.3125 (0.3051)  ACC: 0.6875 (0.7752)  time: 0.3114  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.9594  ASR: 0.3125 (0.3048)  ACC: 0.7500 (0.7741)  time: 0.3103  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.6517  ASR: 0.3125 (0.3118)  ACC: 0.7500 (0.7697)  time: 0.3104  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.5264  ASR: 0.3750 (0.3145)  ACC: 0.6875 (0.7677)  time: 0.3100  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.8214  ASR: 0.3750 (0.3153)  ACC: 0.7500 (0.7652)  time: 0.3102  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.8677  ASR: 0.3125 (0.3181)  ACC: 0.6875 (0.7598)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.7697  ASR: 0.3125 (0.3167)  ACC: 0.6875 (0.7593)  time: 0.3109  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [230/313]  eta: 0:00:25  Lr: 0.100000  Loss: 0.3598  ASR: 0.3125 (0.3176)  ACC: 0.7500 (0.7584)  time: 0.3102  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.0325  ASR: 0.2500 (0.3154)  ACC: 0.7500 (0.7609)  time: 0.3101  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.7512  ASR: 0.2500 (0.3147)  ACC: 0.8125 (0.7620)  time: 0.3100  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.8977  ASR: 0.3125 (0.3151)  ACC: 0.7500 (0.7622)  time: 0.3099  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6740  ASR: 0.3125 (0.3162)  ACC: 0.7500 (0.7625)  time: 0.3099  data: 0.0002  max mem: 12057
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.7852  ASR: 0.4375 (0.3223)  ACC: 0.6875 (0.7580)  time: 0.3126  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.0108  ASR: 0.4375 (0.3235)  ACC: 0.6250 (0.7554)  time: 0.3157  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.8301  ASR: 0.3750 (0.3243)  ACC: 0.6875 (0.7542)  time: 0.3153  data: 0.0004  max mem: 12057
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5558  ASR: 0.3750 (0.3242)  ACC: 0.7500 (0.7552)  time: 0.3145  data: 0.0003  max mem: 12057
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5434  ASR: 0.3750 (0.3247)  ACC: 0.6875 (0.7550)  time: 0.3072  data: 0.0003  max mem: 12057
Train: Epoch[2/5] Total time: 0:01:37 (0.3127 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.5434  ASR: 0.3750 (0.3247)  ACC: 0.6875 (0.7550)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:53  Lr: 0.100000  Loss: 1.0421  ASR: 0.5625 (0.5625)  ACC: 0.5000 (0.5000)  time: 0.5557  data: 0.2394  max mem: 12057
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.6376  ASR: 0.3750 (0.4034)  ACC: 0.6875 (0.6761)  time: 0.3353  data: 0.0220  max mem: 12057
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.5209  ASR: 0.3750 (0.4167)  ACC: 0.6875 (0.6696)  time: 0.3129  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.5138  ASR: 0.3750 (0.4173)  ACC: 0.6875 (0.6633)  time: 0.3120  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.5220  ASR: 0.4375 (0.4207)  ACC: 0.6875 (0.6707)  time: 0.3117  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.8769  ASR: 0.4375 (0.4142)  ACC: 0.6875 (0.6740)  time: 0.3125  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.7059  ASR: 0.3750 (0.4057)  ACC: 0.6875 (0.6824)  time: 0.3127  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2741  ASR: 0.3750 (0.4102)  ACC: 0.6875 (0.6761)  time: 0.3127  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3051  ASR: 0.4375 (0.4074)  ACC: 0.6875 (0.6798)  time: 0.3116  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.8778  ASR: 0.3750 (0.4025)  ACC: 0.6875 (0.6861)  time: 0.3114  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.6552  ASR: 0.3750 (0.4047)  ACC: 0.6875 (0.6838)  time: 0.3134  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.2156  ASR: 0.3750 (0.4037)  ACC: 0.6875 (0.6864)  time: 0.3141  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.0345  ASR: 0.3750 (0.4008)  ACC: 0.6875 (0.6875)  time: 0.3138  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4883  ASR: 0.3750 (0.4051)  ACC: 0.6875 (0.6837)  time: 0.3134  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.9945  ASR: 0.4375 (0.4082)  ACC: 0.6250 (0.6800)  time: 0.3117  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.6189  ASR: 0.4375 (0.4069)  ACC: 0.6250 (0.6800)  time: 0.3116  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.6161  ASR: 0.3750 (0.4111)  ACC: 0.6250 (0.6751)  time: 0.3116  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.8604  ASR: 0.3750 (0.4090)  ACC: 0.6250 (0.6751)  time: 0.3103  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.5332  ASR: 0.3750 (0.4147)  ACC: 0.6875 (0.6720)  time: 0.3102  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4455  ASR: 0.5000 (0.4182)  ACC: 0.6250 (0.6692)  time: 0.3108  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7475  ASR: 0.4375 (0.4170)  ACC: 0.6875 (0.6692)  time: 0.3126  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7905  ASR: 0.3750 (0.4185)  ACC: 0.6250 (0.6650)  time: 0.3124  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.6673  ASR: 0.4375 (0.4157)  ACC: 0.6250 (0.6666)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[3/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2823  ASR: 0.3125 (0.4161)  ACC: 0.6875 (0.6664)  time: 0.3130  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.8910  ASR: 0.3750 (0.4162)  ACC: 0.6875 (0.6662)  time: 0.3133  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6842  ASR: 0.3750 (0.4151)  ACC: 0.6875 (0.6673)  time: 0.3120  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7859  ASR: 0.3750 (0.4155)  ACC: 0.6875 (0.6676)  time: 0.3135  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5866  ASR: 0.4375 (0.4174)  ACC: 0.6250 (0.6667)  time: 0.3139  data: 0.0004  max mem: 12057
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.6564  ASR: 0.5000 (0.4230)  ACC: 0.5625 (0.6628)  time: 0.3128  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.8836  ASR: 0.5000 (0.4240)  ACC: 0.6250 (0.6611)  time: 0.3121  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.6875  ASR: 0.4375 (0.4242)  ACC: 0.6250 (0.6605)  time: 0.3120  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5108  ASR: 0.3750 (0.4240)  ACC: 0.6250 (0.6616)  time: 0.3134  data: 0.0003  max mem: 12057
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4485  ASR: 0.3750 (0.4239)  ACC: 0.6875 (0.6619)  time: 0.3061  data: 0.0003  max mem: 12057
Train: Epoch[3/5] Total time: 0:01:38 (0.3132 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4485  ASR: 0.3750 (0.4239)  ACC: 0.6875 (0.6619)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:56  Lr: 0.100000  Loss: 0.9252  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  time: 0.5650  data: 0.2464  max mem: 12057
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.5792  ASR: 0.4375 (0.4773)  ACC: 0.6250 (0.6080)  time: 0.3357  data: 0.0226  max mem: 12057
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.4194  ASR: 0.4375 (0.5060)  ACC: 0.6250 (0.5863)  time: 0.3123  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.4401  ASR: 0.4375 (0.5060)  ACC: 0.5625 (0.5766)  time: 0.3113  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.3996  ASR: 0.4375 (0.5046)  ACC: 0.6250 (0.5899)  time: 0.3109  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.7526  ASR: 0.5000 (0.4951)  ACC: 0.6250 (0.5956)  time: 0.3119  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6311  ASR: 0.4375 (0.4857)  ACC: 0.6250 (0.6045)  time: 0.3135  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2207  ASR: 0.4375 (0.4886)  ACC: 0.6250 (0.5995)  time: 0.3131  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2527  ASR: 0.4375 (0.4830)  ACC: 0.5625 (0.6065)  time: 0.3121  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7971  ASR: 0.4375 (0.4787)  ACC: 0.6250 (0.6120)  time: 0.3127  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5789  ASR: 0.4375 (0.4845)  ACC: 0.6250 (0.6071)  time: 0.3129  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.1760  ASR: 0.5000 (0.4837)  ACC: 0.5625 (0.6098)  time: 0.3116  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.9172  ASR: 0.4375 (0.4824)  ACC: 0.6250 (0.6105)  time: 0.3110  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4268  ASR: 0.4375 (0.4852)  ACC: 0.6250 (0.6088)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.9011  ASR: 0.5625 (0.4889)  ACC: 0.5625 (0.6046)  time: 0.3113  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.5307  ASR: 0.5000 (0.4897)  ACC: 0.5625 (0.6026)  time: 0.3113  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [160/313]  eta: 0:00:47  Lr: 0.100000  Loss: 0.5374  ASR: 0.5000 (0.4934)  ACC: 0.5000 (0.5982)  time: 0.3110  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.7833  ASR: 0.5000 (0.4909)  ACC: 0.5625 (0.5983)  time: 0.3109  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.4356  ASR: 0.5000 (0.4948)  ACC: 0.5625 (0.5967)  time: 0.3109  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4014  ASR: 0.5625 (0.4980)  ACC: 0.5625 (0.5939)  time: 0.3118  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7173  ASR: 0.5625 (0.5000)  ACC: 0.5625 (0.5914)  time: 0.3142  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7437  ASR: 0.5000 (0.5027)  ACC: 0.5000 (0.5865)  time: 0.3143  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.6104  ASR: 0.5000 (0.5014)  ACC: 0.5000 (0.5863)  time: 0.3123  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [230/313]  eta: 0:00:25  Lr: 0.100000  Loss: 0.2354  ASR: 0.4375 (0.5019)  ACC: 0.5625 (0.5858)  time: 0.3124  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.7789  ASR: 0.4375 (0.4997)  ACC: 0.6250 (0.5877)  time: 0.3141  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6331  ASR: 0.5000 (0.4995)  ACC: 0.5625 (0.5876)  time: 0.3137  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7416  ASR: 0.5000 (0.4995)  ACC: 0.5625 (0.5881)  time: 0.3117  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5212  ASR: 0.5000 (0.5000)  ACC: 0.5625 (0.5890)  time: 0.3111  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.5552  ASR: 0.5625 (0.5044)  ACC: 0.5625 (0.5863)  time: 0.3110  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.7835  ASR: 0.5625 (0.5052)  ACC: 0.5625 (0.5846)  time: 0.3119  data: 0.0002  max mem: 12057
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.5924  ASR: 0.5000 (0.5050)  ACC: 0.5625 (0.5843)  time: 0.3142  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4945  ASR: 0.5000 (0.5046)  ACC: 0.5625 (0.5856)  time: 0.3151  data: 0.0003  max mem: 12057
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3778  ASR: 0.5000 (0.5050)  ACC: 0.5625 (0.5857)  time: 0.3073  data: 0.0003  max mem: 12057
Train: Epoch[4/5] Total time: 0:01:37 (0.3130 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.3778  ASR: 0.5000 (0.5050)  ACC: 0.5625 (0.5857)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:58  Lr: 0.100000  Loss: 0.8464  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  time: 0.5703  data: 0.2489  max mem: 12057
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.5249  ASR: 0.5000 (0.5511)  ACC: 0.5625 (0.5341)  time: 0.3361  data: 0.0229  max mem: 12057
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.3573  ASR: 0.5000 (0.5625)  ACC: 0.5625 (0.5298)  time: 0.3132  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.3808  ASR: 0.5000 (0.5645)  ACC: 0.5000 (0.5181)  time: 0.3135  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.3343  ASR: 0.5000 (0.5579)  ACC: 0.5625 (0.5351)  time: 0.3141  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.6501  ASR: 0.5000 (0.5490)  ACC: 0.5625 (0.5404)  time: 0.3145  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.5839  ASR: 0.5000 (0.5430)  ACC: 0.5625 (0.5482)  time: 0.3144  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:17  Lr: 0.100000  Loss: 0.1912  ASR: 0.5000 (0.5440)  ACC: 0.5625 (0.5458)  time: 0.3149  data: 0.0005  max mem: 12057
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2233  ASR: 0.5625 (0.5448)  ACC: 0.5000 (0.5463)  time: 0.3149  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7247  ASR: 0.5000 (0.5385)  ACC: 0.5625 (0.5536)  time: 0.3132  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.4972  ASR: 0.5000 (0.5446)  ACC: 0.5625 (0.5483)  time: 0.3132  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.1506  ASR: 0.6250 (0.5467)  ACC: 0.5000 (0.5484)  time: 0.3151  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [120/313]  eta: 0:01:01  Lr: 0.100000  Loss: 0.8150  ASR: 0.5625 (0.5480)  ACC: 0.5000 (0.5460)  time: 0.3158  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.3929  ASR: 0.5625 (0.5501)  ACC: 0.5000 (0.5453)  time: 0.3159  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.8247  ASR: 0.6250 (0.5563)  ACC: 0.5000 (0.5386)  time: 0.3155  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.4717  ASR: 0.5625 (0.5559)  ACC: 0.5000 (0.5377)  time: 0.3152  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.4796  ASR: 0.5625 (0.5582)  ACC: 0.5000 (0.5345)  time: 0.3146  data: 0.0004  max mem: 12057
Train: Epoch[5/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.7181  ASR: 0.5000 (0.5548)  ACC: 0.5000 (0.5355)  time: 0.3130  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.3809  ASR: 0.5625 (0.5587)  ACC: 0.5000 (0.5342)  time: 0.3125  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3608  ASR: 0.6250 (0.5645)  ACC: 0.5000 (0.5291)  time: 0.3123  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.6750  ASR: 0.5625 (0.5656)  ACC: 0.5000 (0.5271)  time: 0.3111  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.6927  ASR: 0.5625 (0.5678)  ACC: 0.5000 (0.5228)  time: 0.3108  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5774  ASR: 0.5625 (0.5650)  ACC: 0.5000 (0.5240)  time: 0.3106  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2046  ASR: 0.5000 (0.5644)  ACC: 0.5625 (0.5246)  time: 0.3119  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.7011  ASR: 0.5000 (0.5615)  ACC: 0.5625 (0.5272)  time: 0.3124  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6018  ASR: 0.5000 (0.5605)  ACC: 0.5625 (0.5279)  time: 0.3117  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6666  ASR: 0.5625 (0.5589)  ACC: 0.5625 (0.5299)  time: 0.3112  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.4755  ASR: 0.5625 (0.5579)  ACC: 0.5625 (0.5323)  time: 0.3116  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.4864  ASR: 0.6250 (0.5618)  ACC: 0.5625 (0.5300)  time: 0.3125  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.7228  ASR: 0.6250 (0.5623)  ACC: 0.5000 (0.5288)  time: 0.3121  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.5124  ASR: 0.5000 (0.5602)  ACC: 0.5625 (0.5303)  time: 0.3123  data: 0.0003  max mem: 12057
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4585  ASR: 0.4375 (0.5593)  ACC: 0.5625 (0.5322)  time: 0.3116  data: 0.0002  max mem: 12057
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3347  ASR: 0.4375 (0.5593)  ACC: 0.5625 (0.5325)  time: 0.3041  data: 0.0002  max mem: 12057
Train: Epoch[5/5] Total time: 0:01:38 (0.3139 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.3347  ASR: 0.4375 (0.5593)  ACC: 0.5625 (0.5325)
clean or triggered training model
;;;;;4
generating trigger
Train: Epoch[1/5]  [  0/313]  eta: 0:04:25  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  Loss: 0.9187 (0.9187)  time: 0.8479  data: 0.2184  max mem: 12057
Train: Epoch[1/5]  [ 10/313]  eta: 0:03:12  ASR: 0.5625 (0.5852)  ACC: 0.5625 (0.5000)  Loss: 0.9187 (0.9337)  time: 0.6338  data: 0.0202  max mem: 12057
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:07  ASR: 0.5625 (0.5952)  ACC: 0.5625 (0.4970)  Loss: 0.9013 (0.9167)  time: 0.6308  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 30/313]  eta: 0:03:00  ASR: 0.5625 (0.5887)  ACC: 0.5000 (0.4940)  Loss: 0.9013 (0.9176)  time: 0.6383  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:52  ASR: 0.5000 (0.5793)  ACC: 0.5000 (0.5137)  Loss: 0.9059 (0.9093)  time: 0.6237  data: 0.0005  max mem: 12057
Train: Epoch[1/5]  [ 50/313]  eta: 0:02:46  ASR: 0.5000 (0.5711)  ACC: 0.5625 (0.5184)  Loss: 0.9059 (0.9138)  time: 0.6279  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 60/313]  eta: 0:02:38  ASR: 0.5000 (0.5676)  ACC: 0.5625 (0.5236)  Loss: 0.9650 (0.9145)  time: 0.6141  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [ 70/313]  eta: 0:02:32  ASR: 0.5625 (0.5687)  ACC: 0.5625 (0.5211)  Loss: 0.9436 (0.9172)  time: 0.6106  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [ 80/313]  eta: 0:02:26  ASR: 0.5625 (0.5617)  ACC: 0.5625 (0.5285)  Loss: 0.9137 (0.9171)  time: 0.6276  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [ 90/313]  eta: 0:02:19  ASR: 0.5000 (0.5543)  ACC: 0.5625 (0.5378)  Loss: 0.9233 (0.9193)  time: 0.6296  data: 0.0002  max mem: 12057
Train: Epoch[1/5]  [100/313]  eta: 0:02:13  ASR: 0.5000 (0.5606)  ACC: 0.5625 (0.5322)  Loss: 0.9318 (0.9205)  time: 0.6278  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [110/313]  eta: 0:02:07  ASR: 0.6250 (0.5597)  ACC: 0.5000 (0.5349)  Loss: 0.9124 (0.9202)  time: 0.6215  data: 0.0005  max mem: 12057
Train: Epoch[1/5]  [120/313]  eta: 0:02:01  ASR: 0.5000 (0.5589)  ACC: 0.5000 (0.5351)  Loss: 0.9143 (0.9207)  time: 0.6351  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [130/313]  eta: 0:01:54  ASR: 0.5625 (0.5596)  ACC: 0.5000 (0.5348)  Loss: 0.9190 (0.9224)  time: 0.6297  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [140/313]  eta: 0:01:48  ASR: 0.5625 (0.5629)  ACC: 0.5000 (0.5310)  Loss: 0.9190 (0.9219)  time: 0.6269  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [150/313]  eta: 0:01:42  ASR: 0.5625 (0.5621)  ACC: 0.5000 (0.5310)  Loss: 0.8926 (0.9209)  time: 0.6251  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [160/313]  eta: 0:01:35  ASR: 0.5625 (0.5648)  ACC: 0.5000 (0.5280)  Loss: 0.8926 (0.9198)  time: 0.6139  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [170/313]  eta: 0:01:29  ASR: 0.5000 (0.5607)  ACC: 0.5000 (0.5300)  Loss: 0.9004 (0.9204)  time: 0.6174  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [180/313]  eta: 0:01:23  ASR: 0.5625 (0.5635)  ACC: 0.5625 (0.5297)  Loss: 0.9004 (0.9182)  time: 0.6195  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [190/313]  eta: 0:01:16  ASR: 0.6250 (0.5671)  ACC: 0.5000 (0.5265)  Loss: 0.9103 (0.9195)  time: 0.6277  data: 0.0003  max mem: 12057
Train: Epoch[1/5]  [200/313]  eta: 0:01:10  ASR: 0.5625 (0.5672)  ACC: 0.5000 (0.5255)  Loss: 0.9455 (0.9208)  time: 0.6305  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [210/313]  eta: 0:01:04  ASR: 0.5625 (0.5687)  ACC: 0.5000 (0.5219)  Loss: 0.9983 (0.9232)  time: 0.6293  data: 0.0004  max mem: 12057
Train: Epoch[1/5]  [220/313]  eta: 0:00:58  ASR: 0.5625 (0.5662)  ACC: 0.5000 (0.5229)  Loss: 0.9984 (0.9256)  time: 0.6326  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:51  ASR: 0.5000 (0.5652)  ACC: 0.5000 (0.5235)  Loss: 0.9501 (0.9240)  time: 0.6177  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:45  ASR: 0.5000 (0.5620)  ACC: 0.5625 (0.5265)  Loss: 1.0000 (0.9272)  time: 0.6085  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:39  ASR: 0.5000 (0.5610)  ACC: 0.5625 (0.5274)  Loss: 1.0088 (0.9277)  time: 0.6119  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:33  ASR: 0.5000 (0.5603)  ACC: 0.5625 (0.5285)  Loss: 0.9749 (0.9280)  time: 0.6188  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:26  ASR: 0.5625 (0.5609)  ACC: 0.5625 (0.5293)  Loss: 0.9294 (0.9262)  time: 0.6268  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:20  ASR: 0.6250 (0.5647)  ACC: 0.5000 (0.5271)  Loss: 0.9141 (0.9241)  time: 0.6193  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:14  ASR: 0.6250 (0.5653)  ACC: 0.4375 (0.5258)  Loss: 1.0042 (0.9264)  time: 0.6261  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:08  ASR: 0.5000 (0.5635)  ACC: 0.5000 (0.5270)  Loss: 1.0068 (0.9258)  time: 0.6234  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5287)  Loss: 0.8994 (0.9241)  time: 0.6105  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5292)  Loss: 0.8994 (0.9235)  time: 0.5947  data: 0.0003  max mem: 12058
Train: Epoch[1/5] Total time: 0:03:15 (0.6234 s / it)
Averaged stats: ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5292)  Loss: 0.8994 (0.9235)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:29  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  Loss: 0.9075 (0.9075)  time: 0.8626  data: 0.2319  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:03:11  ASR: 0.5625 (0.5852)  ACC: 0.5625 (0.5000)  Loss: 0.9075 (0.9196)  time: 0.6307  data: 0.0214  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:03:07  ASR: 0.5625 (0.5952)  ACC: 0.5625 (0.4970)  Loss: 0.8867 (0.8998)  time: 0.6286  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:02:59  ASR: 0.5625 (0.5887)  ACC: 0.5000 (0.4940)  Loss: 0.8794 (0.9009)  time: 0.6383  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:02:52  ASR: 0.5000 (0.5793)  ACC: 0.5000 (0.5137)  Loss: 0.8992 (0.8930)  time: 0.6229  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:02:46  ASR: 0.5000 (0.5711)  ACC: 0.5625 (0.5184)  Loss: 0.8992 (0.8980)  time: 0.6254  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:02:38  ASR: 0.5000 (0.5676)  ACC: 0.5625 (0.5236)  Loss: 0.9220 (0.8978)  time: 0.6109  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:02:31  ASR: 0.5625 (0.5687)  ACC: 0.5625 (0.5211)  Loss: 0.8987 (0.9002)  time: 0.6100  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:02:25  ASR: 0.5625 (0.5617)  ACC: 0.5625 (0.5285)  Loss: 0.8806 (0.8999)  time: 0.6311  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:02:19  ASR: 0.5000 (0.5543)  ACC: 0.5625 (0.5378)  Loss: 0.9081 (0.9025)  time: 0.6340  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:02:13  ASR: 0.5000 (0.5606)  ACC: 0.5625 (0.5322)  Loss: 0.9220 (0.9042)  time: 0.6300  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:02:07  ASR: 0.6250 (0.5597)  ACC: 0.5000 (0.5349)  Loss: 0.8929 (0.9040)  time: 0.6227  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:02:01  ASR: 0.5000 (0.5589)  ACC: 0.5000 (0.5351)  Loss: 0.9029 (0.9048)  time: 0.6346  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:01:54  ASR: 0.5625 (0.5596)  ACC: 0.5000 (0.5348)  Loss: 0.9095 (0.9060)  time: 0.6272  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:01:48  ASR: 0.5625 (0.5629)  ACC: 0.5000 (0.5310)  Loss: 0.8987 (0.9050)  time: 0.6251  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:01:42  ASR: 0.5625 (0.5621)  ACC: 0.5000 (0.5310)  Loss: 0.8721 (0.9041)  time: 0.6248  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:01:35  ASR: 0.5625 (0.5648)  ACC: 0.5000 (0.5280)  Loss: 0.8747 (0.9029)  time: 0.6115  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:01:29  ASR: 0.5000 (0.5607)  ACC: 0.5000 (0.5300)  Loss: 0.8917 (0.9031)  time: 0.6145  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:01:23  ASR: 0.5625 (0.5635)  ACC: 0.5625 (0.5297)  Loss: 0.8917 (0.9011)  time: 0.6175  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:01:16  ASR: 0.6250 (0.5671)  ACC: 0.5000 (0.5265)  Loss: 0.8947 (0.9020)  time: 0.6248  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:01:10  ASR: 0.5625 (0.5672)  ACC: 0.5000 (0.5255)  Loss: 0.9173 (0.9034)  time: 0.6286  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:01:04  ASR: 0.5625 (0.5687)  ACC: 0.5000 (0.5219)  Loss: 0.9895 (0.9062)  time: 0.6287  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:58  ASR: 0.5625 (0.5662)  ACC: 0.5000 (0.5229)  Loss: 0.9897 (0.9088)  time: 0.6328  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:51  ASR: 0.5000 (0.5652)  ACC: 0.5000 (0.5235)  Loss: 0.9048 (0.9072)  time: 0.6169  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:45  ASR: 0.5000 (0.5620)  ACC: 0.5625 (0.5265)  Loss: 0.9864 (0.9103)  time: 0.6059  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:39  ASR: 0.5000 (0.5610)  ACC: 0.5625 (0.5274)  Loss: 1.0000 (0.9110)  time: 0.6121  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:33  ASR: 0.5000 (0.5603)  ACC: 0.5625 (0.5285)  Loss: 0.9689 (0.9116)  time: 0.6223  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:26  ASR: 0.5625 (0.5609)  ACC: 0.5625 (0.5293)  Loss: 0.9094 (0.9097)  time: 0.6305  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:20  ASR: 0.6250 (0.5647)  ACC: 0.5000 (0.5271)  Loss: 0.8947 (0.9077)  time: 0.6216  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:14  ASR: 0.6250 (0.5653)  ACC: 0.4375 (0.5258)  Loss: 0.9936 (0.9102)  time: 0.6251  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:08  ASR: 0.5000 (0.5635)  ACC: 0.5000 (0.5270)  Loss: 0.9976 (0.9095)  time: 0.6209  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5287)  Loss: 0.8823 (0.9080)  time: 0.6100  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5292)  Loss: 0.8823 (0.9072)  time: 0.5942  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:03:14 (0.6229 s / it)
Averaged stats: ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5292)  Loss: 0.8823 (0.9072)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:27  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  Loss: 0.8947 (0.8947)  time: 0.8562  data: 0.2306  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:03:10  ASR: 0.5625 (0.5852)  ACC: 0.5625 (0.5000)  Loss: 0.8947 (0.9090)  time: 0.6281  data: 0.0212  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:03:06  ASR: 0.5625 (0.5952)  ACC: 0.5625 (0.4970)  Loss: 0.8782 (0.8882)  time: 0.6257  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:02:59  ASR: 0.5625 (0.5887)  ACC: 0.5000 (0.4940)  Loss: 0.8625 (0.8904)  time: 0.6350  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:02:51  ASR: 0.5000 (0.5793)  ACC: 0.5000 (0.5137)  Loss: 0.8860 (0.8824)  time: 0.6181  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:02:45  ASR: 0.5000 (0.5711)  ACC: 0.5625 (0.5184)  Loss: 0.8892 (0.8876)  time: 0.6210  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:02:37  ASR: 0.5000 (0.5676)  ACC: 0.5625 (0.5236)  Loss: 0.9061 (0.8871)  time: 0.6086  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:02:31  ASR: 0.5625 (0.5687)  ACC: 0.5625 (0.5211)  Loss: 0.8848 (0.8891)  time: 0.6072  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:02:25  ASR: 0.5625 (0.5617)  ACC: 0.5625 (0.5285)  Loss: 0.8635 (0.8890)  time: 0.6276  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:02:19  ASR: 0.5000 (0.5543)  ACC: 0.5625 (0.5378)  Loss: 0.8973 (0.8918)  time: 0.6297  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:02:12  ASR: 0.5000 (0.5606)  ACC: 0.5625 (0.5322)  Loss: 0.9135 (0.8936)  time: 0.6268  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:02:06  ASR: 0.6250 (0.5597)  ACC: 0.5000 (0.5349)  Loss: 0.8808 (0.8935)  time: 0.6188  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:02:00  ASR: 0.5000 (0.5589)  ACC: 0.5000 (0.5351)  Loss: 0.8939 (0.8942)  time: 0.6296  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:01:54  ASR: 0.5625 (0.5596)  ACC: 0.5000 (0.5348)  Loss: 0.8939 (0.8954)  time: 0.6252  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:01:48  ASR: 0.5625 (0.5629)  ACC: 0.5000 (0.5310)  Loss: 0.8788 (0.8940)  time: 0.6260  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:01:41  ASR: 0.5625 (0.5621)  ACC: 0.5000 (0.5310)  Loss: 0.8575 (0.8929)  time: 0.6258  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:01:35  ASR: 0.5625 (0.5648)  ACC: 0.5000 (0.5280)  Loss: 0.8605 (0.8919)  time: 0.6129  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:01:29  ASR: 0.5000 (0.5607)  ACC: 0.5000 (0.5300)  Loss: 0.8786 (0.8920)  time: 0.6144  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:01:22  ASR: 0.5625 (0.5635)  ACC: 0.5625 (0.5297)  Loss: 0.8786 (0.8899)  time: 0.6161  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:01:16  ASR: 0.6250 (0.5671)  ACC: 0.5000 (0.5265)  Loss: 0.8867 (0.8909)  time: 0.6257  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:01:10  ASR: 0.5625 (0.5672)  ACC: 0.5000 (0.5255)  Loss: 0.9088 (0.8922)  time: 0.6297  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:01:04  ASR: 0.5625 (0.5687)  ACC: 0.5000 (0.5219)  Loss: 0.9689 (0.8951)  time: 0.6277  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:58  ASR: 0.5625 (0.5662)  ACC: 0.5000 (0.5229)  Loss: 0.9772 (0.8977)  time: 0.6322  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:51  ASR: 0.5000 (0.5652)  ACC: 0.5000 (0.5235)  Loss: 0.8927 (0.8961)  time: 0.6167  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:45  ASR: 0.5000 (0.5620)  ACC: 0.5625 (0.5265)  Loss: 0.9768 (0.8992)  time: 0.6060  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:39  ASR: 0.5000 (0.5610)  ACC: 0.5625 (0.5274)  Loss: 0.9956 (0.9000)  time: 0.6109  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:32  ASR: 0.5000 (0.5603)  ACC: 0.5625 (0.5285)  Loss: 0.9656 (0.9004)  time: 0.6164  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:26  ASR: 0.5625 (0.5609)  ACC: 0.5625 (0.5293)  Loss: 0.8920 (0.8983)  time: 0.6259  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:20  ASR: 0.6250 (0.5647)  ACC: 0.5000 (0.5271)  Loss: 0.8793 (0.8962)  time: 0.6199  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:14  ASR: 0.6250 (0.5653)  ACC: 0.4375 (0.5258)  Loss: 0.9849 (0.8988)  time: 0.6246  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:08  ASR: 0.5000 (0.5635)  ACC: 0.5000 (0.5270)  Loss: 0.9893 (0.8981)  time: 0.6192  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5287)  Loss: 0.8713 (0.8965)  time: 0.6061  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5292)  Loss: 0.8713 (0.8957)  time: 0.5904  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:03:14 (0.6208 s / it)
Averaged stats: ASR: 0.5000 (0.5627)  ACC: 0.5625 (0.5292)  Loss: 0.8713 (0.8957)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:51  Lr: 0.100000  Loss: 2.2582  ASR: 0.0000 (0.0000)  ACC: 0.0000 (0.0000)  time: 0.5493  data: 0.2312  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 2.1903  ASR: 0.0000 (0.0000)  ACC: 0.0625 (0.0739)  time: 0.3315  data: 0.0212  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:33  Lr: 0.100000  Loss: 1.8687  ASR: 0.0000 (0.0446)  ACC: 0.2500 (0.2708)  time: 0.3094  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:29  Lr: 0.100000  Loss: 1.6495  ASR: 0.1250 (0.0766)  ACC: 0.5625 (0.3972)  time: 0.3098  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 1.5730  ASR: 0.1875 (0.1006)  ACC: 0.6875 (0.4832)  time: 0.3107  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:22  Lr: 0.100000  Loss: 1.7327  ASR: 0.1875 (0.1176)  ACC: 0.7500 (0.5429)  time: 0.3110  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 1.4280  ASR: 0.1875 (0.1301)  ACC: 0.8125 (0.5932)  time: 0.3116  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 1.0792  ASR: 0.1875 (0.1452)  ACC: 0.8125 (0.6215)  time: 0.3123  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.8517  ASR: 0.1875 (0.1520)  ACC: 0.8125 (0.6481)  time: 0.3121  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:09  Lr: 0.100000  Loss: 1.4530  ASR: 0.2500 (0.1614)  ACC: 0.8125 (0.6676)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:01:06  Lr: 0.100000  Loss: 1.1671  ASR: 0.2500 (0.1733)  ACC: 0.8125 (0.6813)  time: 0.3127  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.7508  ASR: 0.2500 (0.1796)  ACC: 0.8125 (0.6943)  time: 0.3128  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.4888  ASR: 0.2500 (0.1839)  ACC: 0.8125 (0.7045)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 1.0125  ASR: 0.2500 (0.1923)  ACC: 0.8125 (0.7099)  time: 0.3138  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.3409  ASR: 0.2500 (0.1986)  ACC: 0.7500 (0.7141)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 1.0043  ASR: 0.2500 (0.2028)  ACC: 0.7500 (0.7185)  time: 0.3132  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:47  Lr: 0.100000  Loss: 1.0004  ASR: 0.2500 (0.2085)  ACC: 0.7500 (0.7197)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 1.1027  ASR: 0.2500 (0.2113)  ACC: 0.7500 (0.7240)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.9719  ASR: 0.2500 (0.2169)  ACC: 0.8125 (0.7272)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.7412  ASR: 0.3125 (0.2192)  ACC: 0.8125 (0.7320)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 1.0363  ASR: 0.2500 (0.2208)  ACC: 0.8125 (0.7345)  time: 0.3128  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 1.0243  ASR: 0.2500 (0.2236)  ACC: 0.7500 (0.7352)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.9211  ASR: 0.3125 (0.2237)  ACC: 0.7500 (0.7384)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:25  Lr: 0.100000  Loss: 0.6283  ASR: 0.2500 (0.2251)  ACC: 0.7500 (0.7411)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.2238  ASR: 0.2500 (0.2259)  ACC: 0.8125 (0.7438)  time: 0.3118  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.9587  ASR: 0.2500 (0.2266)  ACC: 0.8125 (0.7470)  time: 0.3125  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.9898  ASR: 0.2500 (0.2273)  ACC: 0.8125 (0.7505)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.8976  ASR: 0.2500 (0.2299)  ACC: 0.8125 (0.7523)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.9965  ASR: 0.3750 (0.2367)  ACC: 0.6875 (0.7498)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.2022  ASR: 0.3125 (0.2373)  ACC: 0.7500 (0.7509)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.1884  ASR: 0.2500 (0.2382)  ACC: 0.8125 (0.7523)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.7569  ASR: 0.2500 (0.2389)  ACC: 0.8125 (0.7552)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.8108  ASR: 0.2500 (0.2396)  ACC: 0.8125 (0.7554)  time: 0.3052  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:01:37 (0.3130 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.8108  ASR: 0.2500 (0.2396)  ACC: 0.8125 (0.7554)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:48  Lr: 0.100000  Loss: 1.0923  ASR: 0.3750 (0.3750)  ACC: 0.6875 (0.6875)  time: 0.5394  data: 0.2195  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.7680  ASR: 0.3125 (0.3182)  ACC: 0.8125 (0.7557)  time: 0.3339  data: 0.0202  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.6791  ASR: 0.3125 (0.3244)  ACC: 0.8125 (0.7530)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.6438  ASR: 0.3125 (0.3286)  ACC: 0.7500 (0.7419)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.6840  ASR: 0.3750 (0.3415)  ACC: 0.7500 (0.7424)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 1.0637  ASR: 0.3750 (0.3370)  ACC: 0.7500 (0.7451)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.8334  ASR: 0.2500 (0.3289)  ACC: 0.7500 (0.7520)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.3755  ASR: 0.2500 (0.3319)  ACC: 0.7500 (0.7482)  time: 0.3147  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3864  ASR: 0.3125 (0.3318)  ACC: 0.7500 (0.7508)  time: 0.3148  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 1.0001  ASR: 0.3125 (0.3324)  ACC: 0.7500 (0.7514)  time: 0.3141  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.7573  ASR: 0.3750 (0.3366)  ACC: 0.7500 (0.7475)  time: 0.3138  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.2988  ASR: 0.3750 (0.3407)  ACC: 0.7500 (0.7461)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.2388  ASR: 0.3125 (0.3378)  ACC: 0.7500 (0.7479)  time: 0.3137  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.6143  ASR: 0.3750 (0.3430)  ACC: 0.6875 (0.7433)  time: 0.3134  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.0916  ASR: 0.3750 (0.3453)  ACC: 0.6875 (0.7407)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.7714  ASR: 0.3750 (0.3464)  ACC: 0.6875 (0.7376)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.7396  ASR: 0.3125 (0.3486)  ACC: 0.6875 (0.7333)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.8261  ASR: 0.3125 (0.3476)  ACC: 0.6875 (0.7328)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.6608  ASR: 0.3750 (0.3532)  ACC: 0.7500 (0.7300)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4858  ASR: 0.4375 (0.3573)  ACC: 0.6875 (0.7271)  time: 0.3118  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.8757  ASR: 0.4375 (0.3585)  ACC: 0.6875 (0.7251)  time: 0.3117  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.8394  ASR: 0.3750 (0.3623)  ACC: 0.6250 (0.7195)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.6862  ASR: 0.3750 (0.3606)  ACC: 0.6250 (0.7192)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.3525  ASR: 0.3750 (0.3623)  ACC: 0.6875 (0.7178)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.0902  ASR: 0.4375 (0.3641)  ACC: 0.6875 (0.7160)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.8071  ASR: 0.4375 (0.3640)  ACC: 0.6875 (0.7164)  time: 0.3131  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7939  ASR: 0.3750 (0.3645)  ACC: 0.6875 (0.7167)  time: 0.3133  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6882  ASR: 0.3750 (0.3669)  ACC: 0.6875 (0.7156)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.7611  ASR: 0.5000 (0.3723)  ACC: 0.6250 (0.7115)  time: 0.3136  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.0138  ASR: 0.4375 (0.3724)  ACC: 0.6250 (0.7105)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.9564  ASR: 0.4375 (0.3725)  ACC: 0.6875 (0.7099)  time: 0.3117  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6048  ASR: 0.4375 (0.3736)  ACC: 0.6875 (0.7098)  time: 0.3115  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6150  ASR: 0.3750 (0.3738)  ACC: 0.6875 (0.7095)  time: 0.3041  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:38 (0.3135 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.6150  ASR: 0.3750 (0.3738)  ACC: 0.6875 (0.7095)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:47  Lr: 0.100000  Loss: 0.9573  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  time: 0.5364  data: 0.2176  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 0.5587  ASR: 0.4375 (0.4773)  ACC: 0.6875 (0.6023)  time: 0.3326  data: 0.0200  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.4638  ASR: 0.4375 (0.5000)  ACC: 0.6250 (0.5893)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.4992  ASR: 0.5000 (0.4919)  ACC: 0.6250 (0.5887)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.4693  ASR: 0.5000 (0.4878)  ACC: 0.6250 (0.6037)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.8464  ASR: 0.5000 (0.4877)  ACC: 0.6250 (0.6017)  time: 0.3106  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 0.7659  ASR: 0.4375 (0.4775)  ACC: 0.6250 (0.6137)  time: 0.3110  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2897  ASR: 0.4375 (0.4798)  ACC: 0.6250 (0.6100)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3019  ASR: 0.4375 (0.4753)  ACC: 0.5625 (0.6157)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.8971  ASR: 0.4375 (0.4712)  ACC: 0.6250 (0.6229)  time: 0.3118  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:01:06  Lr: 0.100000  Loss: 0.6709  ASR: 0.4375 (0.4740)  ACC: 0.6250 (0.6207)  time: 0.3115  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.1797  ASR: 0.5000 (0.4735)  ACC: 0.5625 (0.6227)  time: 0.3125  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.1095  ASR: 0.4375 (0.4711)  ACC: 0.6250 (0.6245)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.5017  ASR: 0.5000 (0.4747)  ACC: 0.6250 (0.6221)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.9555  ASR: 0.5000 (0.4738)  ACC: 0.6250 (0.6223)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.6478  ASR: 0.4375 (0.4739)  ACC: 0.6250 (0.6209)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:47  Lr: 0.100000  Loss: 0.6126  ASR: 0.4375 (0.4748)  ACC: 0.5625 (0.6184)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.7386  ASR: 0.4375 (0.4722)  ACC: 0.5625 (0.6188)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.5321  ASR: 0.4375 (0.4755)  ACC: 0.6250 (0.6177)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4089  ASR: 0.6250 (0.4804)  ACC: 0.5625 (0.6135)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7904  ASR: 0.5625 (0.4820)  ACC: 0.5625 (0.6110)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7600  ASR: 0.5625 (0.4858)  ACC: 0.5000 (0.6052)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5818  ASR: 0.5000 (0.4830)  ACC: 0.5000 (0.6058)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2703  ASR: 0.4375 (0.4835)  ACC: 0.6250 (0.6052)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.9500  ASR: 0.5000 (0.4850)  ACC: 0.5625 (0.6035)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.7290  ASR: 0.5000 (0.4853)  ACC: 0.5625 (0.6033)  time: 0.3115  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6878  ASR: 0.4375 (0.4837)  ACC: 0.6250 (0.6051)  time: 0.3117  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6003  ASR: 0.4375 (0.4850)  ACC: 0.5625 (0.6052)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.6261  ASR: 0.5625 (0.4900)  ACC: 0.5625 (0.6019)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.8724  ASR: 0.5625 (0.4908)  ACC: 0.5000 (0.6001)  time: 0.3145  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.7825  ASR: 0.5000 (0.4909)  ACC: 0.5625 (0.5997)  time: 0.3152  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5115  ASR: 0.4375 (0.4906)  ACC: 0.6250 (0.6009)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5270  ASR: 0.4375 (0.4910)  ACC: 0.6250 (0.6006)  time: 0.3055  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:01:37 (0.3131 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.5270  ASR: 0.4375 (0.4910)  ACC: 0.6250 (0.6006)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:47  Lr: 0.100000  Loss: 0.8500  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  time: 0.5338  data: 0.2114  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.4493  ASR: 0.6250 (0.5625)  ACC: 0.5625 (0.5170)  time: 0.3355  data: 0.0195  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.3603  ASR: 0.6250 (0.6042)  ACC: 0.5000 (0.4851)  time: 0.3150  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.3884  ASR: 0.5625 (0.5927)  ACC: 0.5000 (0.4899)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.3562  ASR: 0.5625 (0.5930)  ACC: 0.5000 (0.4985)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.7000  ASR: 0.5625 (0.5907)  ACC: 0.5000 (0.4988)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6964  ASR: 0.5625 (0.5799)  ACC: 0.5000 (0.5113)  time: 0.3136  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:17  Lr: 0.100000  Loss: 0.2321  ASR: 0.5625 (0.5775)  ACC: 0.5000 (0.5114)  time: 0.3145  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2605  ASR: 0.5625 (0.5733)  ACC: 0.5000 (0.5170)  time: 0.3142  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.8426  ASR: 0.5000 (0.5666)  ACC: 0.5625 (0.5268)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5932  ASR: 0.5000 (0.5668)  ACC: 0.5625 (0.5272)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.1373  ASR: 0.5625 (0.5659)  ACC: 0.5000 (0.5304)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.0101  ASR: 0.5625 (0.5640)  ACC: 0.5000 (0.5320)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4216  ASR: 0.5625 (0.5644)  ACC: 0.5000 (0.5329)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.8499  ASR: 0.5625 (0.5669)  ACC: 0.5000 (0.5297)  time: 0.3139  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.5534  ASR: 0.5625 (0.5654)  ACC: 0.5000 (0.5298)  time: 0.3148  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.4932  ASR: 0.5000 (0.5660)  ACC: 0.5000 (0.5283)  time: 0.3137  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.6544  ASR: 0.5625 (0.5643)  ACC: 0.5000 (0.5278)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.4441  ASR: 0.5625 (0.5663)  ACC: 0.5000 (0.5280)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3523  ASR: 0.6250 (0.5707)  ACC: 0.5000 (0.5242)  time: 0.3117  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7203  ASR: 0.5625 (0.5697)  ACC: 0.5000 (0.5243)  time: 0.3106  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7132  ASR: 0.5625 (0.5732)  ACC: 0.5000 (0.5184)  time: 0.3109  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5118  ASR: 0.5625 (0.5704)  ACC: 0.4375 (0.5189)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2291  ASR: 0.5000 (0.5693)  ACC: 0.5625 (0.5200)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.8254  ASR: 0.5625 (0.5682)  ACC: 0.5000 (0.5207)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6558  ASR: 0.5625 (0.5677)  ACC: 0.5000 (0.5214)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.5876  ASR: 0.5625 (0.5661)  ACC: 0.5625 (0.5235)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5352  ASR: 0.5625 (0.5673)  ACC: 0.5000 (0.5235)  time: 0.3132  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.5319  ASR: 0.6250 (0.5712)  ACC: 0.5000 (0.5214)  time: 0.3114  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.7883  ASR: 0.6250 (0.5704)  ACC: 0.5000 (0.5210)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.6938  ASR: 0.5000 (0.5694)  ACC: 0.5000 (0.5218)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4381  ASR: 0.5000 (0.5693)  ACC: 0.5625 (0.5223)  time: 0.3117  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4418  ASR: 0.5625 (0.5695)  ACC: 0.5000 (0.5224)  time: 0.3045  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:38 (0.3136 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4418  ASR: 0.5625 (0.5695)  ACC: 0.5000 (0.5224)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:48  Lr: 0.100000  Loss: 0.7545  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  time: 0.5370  data: 0.2143  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.4117  ASR: 0.6875 (0.6364)  ACC: 0.4375 (0.4489)  time: 0.3343  data: 0.0197  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.2946  ASR: 0.6875 (0.6667)  ACC: 0.4375 (0.4256)  time: 0.3142  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.3467  ASR: 0.6250 (0.6492)  ACC: 0.3750 (0.4355)  time: 0.3138  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.3008  ASR: 0.6250 (0.6524)  ACC: 0.5000 (0.4421)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.5945  ASR: 0.6250 (0.6483)  ACC: 0.4375 (0.4436)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6378  ASR: 0.6250 (0.6342)  ACC: 0.5000 (0.4600)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2096  ASR: 0.5625 (0.6338)  ACC: 0.5000 (0.4577)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2397  ASR: 0.6250 (0.6265)  ACC: 0.4375 (0.4660)  time: 0.3119  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7813  ASR: 0.5625 (0.6202)  ACC: 0.5000 (0.4753)  time: 0.3122  data: 0.0004  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5215  ASR: 0.5625 (0.6182)  ACC: 0.5000 (0.4777)  time: 0.3126  data: 0.0004  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.1185  ASR: 0.6250 (0.6199)  ACC: 0.5000 (0.4780)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.9029  ASR: 0.6250 (0.6188)  ACC: 0.5000 (0.4788)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.3639  ASR: 0.6250 (0.6202)  ACC: 0.5000 (0.4785)  time: 0.3133  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.7626  ASR: 0.6250 (0.6223)  ACC: 0.5000 (0.4756)  time: 0.3139  data: 0.0004  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.4924  ASR: 0.6250 (0.6225)  ACC: 0.4375 (0.4739)  time: 0.3139  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.4209  ASR: 0.6250 (0.6238)  ACC: 0.4375 (0.4720)  time: 0.3142  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.5873  ASR: 0.6250 (0.6243)  ACC: 0.4375 (0.4697)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.3948  ASR: 0.6250 (0.6247)  ACC: 0.5000 (0.4713)  time: 0.3138  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3416  ASR: 0.6875 (0.6289)  ACC: 0.5000 (0.4679)  time: 0.3133  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.6638  ASR: 0.6250 (0.6287)  ACC: 0.4375 (0.4674)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.6437  ASR: 0.6250 (0.6318)  ACC: 0.4375 (0.4618)  time: 0.3145  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.4471  ASR: 0.6250 (0.6290)  ACC: 0.3750 (0.4627)  time: 0.3139  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.1909  ASR: 0.6250 (0.6272)  ACC: 0.4375 (0.4646)  time: 0.3137  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.6877  ASR: 0.6250 (0.6271)  ACC: 0.5000 (0.4642)  time: 0.3136  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6066  ASR: 0.6250 (0.6267)  ACC: 0.4375 (0.4646)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.5466  ASR: 0.6250 (0.6257)  ACC: 0.4375 (0.4660)  time: 0.3161  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.4878  ASR: 0.6250 (0.6266)  ACC: 0.4375 (0.4663)  time: 0.3150  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.4439  ASR: 0.6875 (0.6290)  ACC: 0.4375 (0.4655)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.7319  ASR: 0.6250 (0.6280)  ACC: 0.4375 (0.4654)  time: 0.3145  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.6145  ASR: 0.5625 (0.6271)  ACC: 0.4375 (0.4659)  time: 0.3144  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3942  ASR: 0.5625 (0.6266)  ACC: 0.5000 (0.4668)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4104  ASR: 0.5625 (0.6266)  ACC: 0.5000 (0.4671)  time: 0.3048  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:01:38 (0.3141 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4104  ASR: 0.5625 (0.6266)  ACC: 0.5000 (0.4671)
clean or triggered training model
;;;;;5
generating trigger
Train: Epoch[1/5]  [  0/313]  eta: 0:04:28  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  Loss: 0.9328 (0.9328)  time: 0.8577  data: 0.2150  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:03:11  ASR: 0.6875 (0.6761)  ACC: 0.4375 (0.4091)  Loss: 0.9389 (0.9359)  time: 0.6328  data: 0.0198  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:07  ASR: 0.6875 (0.6964)  ACC: 0.3750 (0.3958)  Loss: 0.9131 (0.9205)  time: 0.6305  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:03:00  ASR: 0.6250 (0.6774)  ACC: 0.3750 (0.4073)  Loss: 0.9131 (0.9261)  time: 0.6394  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:52  ASR: 0.6250 (0.6829)  ACC: 0.4375 (0.4116)  Loss: 0.9341 (0.9191)  time: 0.6240  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:02:46  ASR: 0.6250 (0.6777)  ACC: 0.4375 (0.4142)  Loss: 0.9509 (0.9249)  time: 0.6274  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:02:38  ASR: 0.6250 (0.6691)  ACC: 0.4375 (0.4262)  Loss: 0.9550 (0.9232)  time: 0.6128  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:02:32  ASR: 0.6250 (0.6708)  ACC: 0.4375 (0.4217)  Loss: 0.9344 (0.9279)  time: 0.6103  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:02:26  ASR: 0.6250 (0.6690)  ACC: 0.4375 (0.4236)  Loss: 0.9344 (0.9292)  time: 0.6305  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:02:20  ASR: 0.6250 (0.6635)  ACC: 0.4375 (0.4320)  Loss: 0.9412 (0.9318)  time: 0.6316  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:02:13  ASR: 0.6250 (0.6584)  ACC: 0.4375 (0.4375)  Loss: 0.9441 (0.9328)  time: 0.6280  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:02:07  ASR: 0.6250 (0.6571)  ACC: 0.4375 (0.4409)  Loss: 0.9094 (0.9321)  time: 0.6222  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:02:01  ASR: 0.6250 (0.6529)  ACC: 0.4375 (0.4447)  Loss: 0.9155 (0.9324)  time: 0.6341  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:01:54  ASR: 0.6250 (0.6512)  ACC: 0.5000 (0.4475)  Loss: 0.9268 (0.9339)  time: 0.6284  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:01:48  ASR: 0.6250 (0.6534)  ACC: 0.4375 (0.4446)  Loss: 0.9241 (0.9331)  time: 0.6278  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:01:42  ASR: 0.6250 (0.6527)  ACC: 0.4375 (0.4441)  Loss: 0.8872 (0.9315)  time: 0.6269  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:01:35  ASR: 0.6250 (0.6541)  ACC: 0.4375 (0.4422)  Loss: 0.8978 (0.9308)  time: 0.6136  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:01:29  ASR: 0.6875 (0.6542)  ACC: 0.3750 (0.4401)  Loss: 0.9182 (0.9311)  time: 0.6168  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:01:23  ASR: 0.6250 (0.6540)  ACC: 0.4375 (0.4427)  Loss: 0.9182 (0.9293)  time: 0.6208  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:01:17  ASR: 0.6875 (0.6571)  ACC: 0.4375 (0.4401)  Loss: 0.9399 (0.9295)  time: 0.6284  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:01:10  ASR: 0.6250 (0.6549)  ACC: 0.4375 (0.4412)  Loss: 0.9464 (0.9306)  time: 0.6292  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:01:04  ASR: 0.6250 (0.6579)  ACC: 0.3750 (0.4357)  Loss: 0.9897 (0.9328)  time: 0.6268  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:58  ASR: 0.6875 (0.6558)  ACC: 0.3750 (0.4358)  Loss: 1.0014 (0.9352)  time: 0.6314  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:51  ASR: 0.6250 (0.6534)  ACC: 0.4375 (0.4383)  Loss: 0.9573 (0.9339)  time: 0.6175  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:45  ASR: 0.5625 (0.6520)  ACC: 0.5000 (0.4396)  Loss: 0.9990 (0.9362)  time: 0.6060  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:39  ASR: 0.6250 (0.6511)  ACC: 0.4375 (0.4402)  Loss: 1.0051 (0.9372)  time: 0.6097  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:33  ASR: 0.6250 (0.6499)  ACC: 0.4375 (0.4418)  Loss: 0.9458 (0.9377)  time: 0.6203  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:26  ASR: 0.6250 (0.6501)  ACC: 0.4375 (0.4428)  Loss: 0.9449 (0.9368)  time: 0.6306  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:20  ASR: 0.6875 (0.6526)  ACC: 0.4375 (0.4419)  Loss: 0.9383 (0.9353)  time: 0.6217  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:14  ASR: 0.6875 (0.6510)  ACC: 0.4375 (0.4424)  Loss: 0.9979 (0.9375)  time: 0.6251  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:08  ASR: 0.6250 (0.6503)  ACC: 0.4375 (0.4427)  Loss: 1.0091 (0.9366)  time: 0.6205  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  ASR: 0.6250 (0.6499)  ACC: 0.5000 (0.4441)  Loss: 0.9161 (0.9349)  time: 0.6109  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  ASR: 0.6250 (0.6498)  ACC: 0.5000 (0.4445)  Loss: 0.9161 (0.9342)  time: 0.5953  data: 0.0003  max mem: 12058
Train: Epoch[1/5] Total time: 0:03:15 (0.6235 s / it)
Averaged stats: ASR: 0.6250 (0.6498)  ACC: 0.5000 (0.4445)  Loss: 0.9161 (0.9342)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:28  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  Loss: 0.9114 (0.9114)  time: 0.8569  data: 0.2263  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:03:11  ASR: 0.6875 (0.6761)  ACC: 0.4375 (0.4091)  Loss: 0.9155 (0.9130)  time: 0.6319  data: 0.0209  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:03:07  ASR: 0.6875 (0.6964)  ACC: 0.3750 (0.3958)  Loss: 0.8854 (0.8951)  time: 0.6287  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:02:59  ASR: 0.6250 (0.6774)  ACC: 0.3750 (0.4073)  Loss: 0.8836 (0.9016)  time: 0.6373  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:02:52  ASR: 0.6250 (0.6829)  ACC: 0.4375 (0.4116)  Loss: 0.9098 (0.8941)  time: 0.6231  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:02:46  ASR: 0.6250 (0.6777)  ACC: 0.4375 (0.4142)  Loss: 0.9264 (0.8991)  time: 0.6270  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:02:38  ASR: 0.6250 (0.6691)  ACC: 0.4375 (0.4262)  Loss: 0.9335 (0.8988)  time: 0.6126  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:02:32  ASR: 0.6250 (0.6708)  ACC: 0.4375 (0.4217)  Loss: 0.9110 (0.9027)  time: 0.6101  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:02:25  ASR: 0.6250 (0.6690)  ACC: 0.4375 (0.4236)  Loss: 0.9151 (0.9035)  time: 0.6297  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:02:19  ASR: 0.6250 (0.6635)  ACC: 0.4375 (0.4320)  Loss: 0.9178 (0.9067)  time: 0.6322  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:02:13  ASR: 0.6250 (0.6584)  ACC: 0.4375 (0.4375)  Loss: 0.9305 (0.9084)  time: 0.6281  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:02:07  ASR: 0.6250 (0.6571)  ACC: 0.4375 (0.4409)  Loss: 0.9037 (0.9087)  time: 0.6208  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:02:01  ASR: 0.6250 (0.6529)  ACC: 0.4375 (0.4447)  Loss: 0.9037 (0.9093)  time: 0.6355  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:01:54  ASR: 0.6250 (0.6512)  ACC: 0.5000 (0.4475)  Loss: 0.9065 (0.9107)  time: 0.6296  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:01:48  ASR: 0.6250 (0.6534)  ACC: 0.4375 (0.4446)  Loss: 0.8900 (0.9099)  time: 0.6264  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:01:42  ASR: 0.6250 (0.6527)  ACC: 0.4375 (0.4441)  Loss: 0.8615 (0.9085)  time: 0.6259  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:01:35  ASR: 0.6250 (0.6541)  ACC: 0.4375 (0.4422)  Loss: 0.8625 (0.9077)  time: 0.6150  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:01:29  ASR: 0.6875 (0.6542)  ACC: 0.3750 (0.4401)  Loss: 0.8945 (0.9079)  time: 0.6180  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:01:23  ASR: 0.6250 (0.6540)  ACC: 0.4375 (0.4427)  Loss: 0.8945 (0.9062)  time: 0.6213  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:01:16  ASR: 0.6875 (0.6571)  ACC: 0.4375 (0.4401)  Loss: 0.9151 (0.9063)  time: 0.6294  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:01:10  ASR: 0.6250 (0.6549)  ACC: 0.4375 (0.4412)  Loss: 0.9316 (0.9078)  time: 0.6309  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:01:04  ASR: 0.6250 (0.6579)  ACC: 0.3750 (0.4357)  Loss: 0.9552 (0.9100)  time: 0.6292  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:58  ASR: 0.6875 (0.6558)  ACC: 0.3750 (0.4358)  Loss: 0.9718 (0.9122)  time: 0.6323  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:51  ASR: 0.6250 (0.6534)  ACC: 0.4375 (0.4383)  Loss: 0.9228 (0.9109)  time: 0.6159  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:45  ASR: 0.5625 (0.6520)  ACC: 0.5000 (0.4396)  Loss: 0.9659 (0.9136)  time: 0.6055  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:39  ASR: 0.6250 (0.6511)  ACC: 0.4375 (0.4402)  Loss: 0.9968 (0.9147)  time: 0.6117  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:33  ASR: 0.6250 (0.6499)  ACC: 0.4375 (0.4418)  Loss: 0.9241 (0.9152)  time: 0.6183  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:26  ASR: 0.6250 (0.6501)  ACC: 0.4375 (0.4428)  Loss: 0.9170 (0.9138)  time: 0.6269  data: 0.0005  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:20  ASR: 0.6875 (0.6526)  ACC: 0.4375 (0.4419)  Loss: 0.8960 (0.9123)  time: 0.6210  data: 0.0005  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:14  ASR: 0.6875 (0.6510)  ACC: 0.4375 (0.4424)  Loss: 0.9877 (0.9146)  time: 0.6231  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:08  ASR: 0.6250 (0.6503)  ACC: 0.4375 (0.4427)  Loss: 0.9903 (0.9139)  time: 0.6177  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  ASR: 0.6250 (0.6499)  ACC: 0.5000 (0.4441)  Loss: 0.9066 (0.9131)  time: 0.6088  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  ASR: 0.6250 (0.6498)  ACC: 0.5000 (0.4445)  Loss: 0.9066 (0.9124)  time: 0.5937  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:03:15 (0.6231 s / it)
Averaged stats: ASR: 0.6250 (0.6498)  ACC: 0.5000 (0.4445)  Loss: 0.9066 (0.9124)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:57  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  Loss: 0.8810 (0.8810)  time: 0.9513  data: 0.3230  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:03:13  ASR: 0.6875 (0.6761)  ACC: 0.4375 (0.4091)  Loss: 0.9042 (0.9001)  time: 0.6383  data: 0.0297  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:03:08  ASR: 0.6875 (0.6964)  ACC: 0.3750 (0.3958)  Loss: 0.8790 (0.8803)  time: 0.6275  data: 0.0006  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:03:00  ASR: 0.6250 (0.6774)  ACC: 0.3750 (0.4073)  Loss: 0.8714 (0.8857)  time: 0.6386  data: 0.0006  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:02:52  ASR: 0.6250 (0.6829)  ACC: 0.4375 (0.4116)  Loss: 0.8967 (0.8774)  time: 0.6231  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:02:46  ASR: 0.6250 (0.6777)  ACC: 0.4375 (0.4142)  Loss: 0.9028 (0.8816)  time: 0.6251  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:02:38  ASR: 0.6250 (0.6691)  ACC: 0.4375 (0.4262)  Loss: 0.9155 (0.8825)  time: 0.6117  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:02:32  ASR: 0.6250 (0.6708)  ACC: 0.4375 (0.4217)  Loss: 0.8938 (0.8869)  time: 0.6095  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:02:26  ASR: 0.6250 (0.6690)  ACC: 0.4375 (0.4236)  Loss: 0.8954 (0.8874)  time: 0.6283  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:02:19  ASR: 0.6250 (0.6635)  ACC: 0.4375 (0.4320)  Loss: 0.9018 (0.8907)  time: 0.6318  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:02:13  ASR: 0.6250 (0.6584)  ACC: 0.4375 (0.4375)  Loss: 0.9144 (0.8923)  time: 0.6301  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:02:07  ASR: 0.6250 (0.6571)  ACC: 0.4375 (0.4409)  Loss: 0.8985 (0.8930)  time: 0.6210  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:02:01  ASR: 0.6250 (0.6529)  ACC: 0.4375 (0.4447)  Loss: 0.8985 (0.8937)  time: 0.6324  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:01:54  ASR: 0.6250 (0.6512)  ACC: 0.5000 (0.4475)  Loss: 0.8869 (0.8954)  time: 0.6286  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:01:48  ASR: 0.6250 (0.6534)  ACC: 0.4375 (0.4446)  Loss: 0.8799 (0.8944)  time: 0.6294  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:01:42  ASR: 0.6250 (0.6527)  ACC: 0.4375 (0.4441)  Loss: 0.8544 (0.8930)  time: 0.6297  data: 0.0005  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:01:35  ASR: 0.6250 (0.6541)  ACC: 0.4375 (0.4422)  Loss: 0.8643 (0.8923)  time: 0.6159  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:01:29  ASR: 0.6875 (0.6542)  ACC: 0.3750 (0.4401)  Loss: 0.8788 (0.8924)  time: 0.6162  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:01:23  ASR: 0.6250 (0.6540)  ACC: 0.4375 (0.4427)  Loss: 0.8863 (0.8906)  time: 0.6185  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:01:16  ASR: 0.6875 (0.6571)  ACC: 0.4375 (0.4401)  Loss: 0.8985 (0.8905)  time: 0.6267  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:01:10  ASR: 0.6250 (0.6549)  ACC: 0.4375 (0.4412)  Loss: 0.9194 (0.8916)  time: 0.6290  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:01:04  ASR: 0.6250 (0.6579)  ACC: 0.3750 (0.4357)  Loss: 0.9298 (0.8935)  time: 0.6267  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:58  ASR: 0.6875 (0.6558)  ACC: 0.3750 (0.4358)  Loss: 0.9384 (0.8953)  time: 0.6315  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:51  ASR: 0.6250 (0.6534)  ACC: 0.4375 (0.4383)  Loss: 0.9006 (0.8943)  time: 0.6173  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:45  ASR: 0.5625 (0.6520)  ACC: 0.5000 (0.4396)  Loss: 0.9574 (0.8971)  time: 0.6052  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:39  ASR: 0.6250 (0.6511)  ACC: 0.4375 (0.4402)  Loss: 0.9885 (0.8984)  time: 0.6106  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:33  ASR: 0.6250 (0.6499)  ACC: 0.4375 (0.4418)  Loss: 0.9034 (0.8988)  time: 0.6186  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:26  ASR: 0.6250 (0.6501)  ACC: 0.4375 (0.4428)  Loss: 0.8916 (0.8971)  time: 0.6280  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:20  ASR: 0.6875 (0.6526)  ACC: 0.4375 (0.4419)  Loss: 0.8821 (0.8957)  time: 0.6217  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:14  ASR: 0.6875 (0.6510)  ACC: 0.4375 (0.4424)  Loss: 0.9812 (0.8982)  time: 0.6258  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:08  ASR: 0.6250 (0.6503)  ACC: 0.4375 (0.4427)  Loss: 0.9765 (0.8976)  time: 0.6216  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  ASR: 0.6250 (0.6499)  ACC: 0.5000 (0.4441)  Loss: 0.8767 (0.8959)  time: 0.6111  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  ASR: 0.6250 (0.6498)  ACC: 0.5000 (0.4445)  Loss: 0.8767 (0.8951)  time: 0.5959  data: 0.0003  max mem: 12058
Train: Epoch[3/5] Total time: 0:03:15 (0.6233 s / it)
Averaged stats: ASR: 0.6250 (0.6498)  ACC: 0.5000 (0.4445)  Loss: 0.8767 (0.8951)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:48  Lr: 0.100000  Loss: 2.2981  ASR: 0.0625 (0.0625)  ACC: 0.0000 (0.0000)  time: 0.5395  data: 0.2157  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 2.1293  ASR: 0.0000 (0.0057)  ACC: 0.1875 (0.2102)  time: 0.3320  data: 0.0199  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 1.8759  ASR: 0.0000 (0.0804)  ACC: 0.3750 (0.3750)  time: 0.3106  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:29  Lr: 0.100000  Loss: 1.6885  ASR: 0.1250 (0.1109)  ACC: 0.6875 (0.4839)  time: 0.3100  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 1.6410  ASR: 0.1250 (0.1280)  ACC: 0.7500 (0.5534)  time: 0.3105  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:22  Lr: 0.100000  Loss: 1.7572  ASR: 0.1250 (0.1385)  ACC: 0.8125 (0.6029)  time: 0.3113  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 1.4833  ASR: 0.1875 (0.1496)  ACC: 0.8125 (0.6363)  time: 0.3112  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 1.0973  ASR: 0.1875 (0.1593)  ACC: 0.8125 (0.6620)  time: 0.3108  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.8909  ASR: 0.1875 (0.1651)  ACC: 0.8125 (0.6829)  time: 0.3116  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:09  Lr: 0.100000  Loss: 1.4847  ASR: 0.1875 (0.1696)  ACC: 0.8125 (0.7019)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:01:06  Lr: 0.100000  Loss: 1.1742  ASR: 0.1875 (0.1795)  ACC: 0.8125 (0.7110)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.7850  ASR: 0.2500 (0.1852)  ACC: 0.8125 (0.7224)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.5413  ASR: 0.2500 (0.1875)  ACC: 0.8125 (0.7319)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.9872  ASR: 0.2500 (0.1947)  ACC: 0.8125 (0.7371)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.3730  ASR: 0.2500 (0.2008)  ACC: 0.8125 (0.7402)  time: 0.3136  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 1.0086  ASR: 0.2500 (0.2045)  ACC: 0.8125 (0.7430)  time: 0.3143  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:47  Lr: 0.100000  Loss: 1.0844  ASR: 0.2500 (0.2100)  ACC: 0.8125 (0.7438)  time: 0.3137  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 1.0154  ASR: 0.2500 (0.2113)  ACC: 0.8125 (0.7467)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.9829  ASR: 0.2500 (0.2165)  ACC: 0.8125 (0.7490)  time: 0.3135  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.7651  ASR: 0.2500 (0.2189)  ACC: 0.8125 (0.7529)  time: 0.3138  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 1.0752  ASR: 0.2500 (0.2205)  ACC: 0.8125 (0.7553)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 1.1252  ASR: 0.2500 (0.2230)  ACC: 0.8125 (0.7541)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 1.0341  ASR: 0.2500 (0.2214)  ACC: 0.8125 (0.7579)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.6539  ASR: 0.1875 (0.2216)  ACC: 0.8125 (0.7606)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.3025  ASR: 0.2500 (0.2212)  ACC: 0.8125 (0.7643)  time: 0.3127  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.9387  ASR: 0.1875 (0.2209)  ACC: 0.8125 (0.7682)  time: 0.3129  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 1.0381  ASR: 0.1875 (0.2215)  ACC: 0.8125 (0.7704)  time: 0.3136  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.8776  ASR: 0.2500 (0.2239)  ACC: 0.8125 (0.7717)  time: 0.3146  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 1.0959  ASR: 0.3750 (0.2311)  ACC: 0.7500 (0.7687)  time: 0.3144  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.2461  ASR: 0.3125 (0.2330)  ACC: 0.7500 (0.7678)  time: 0.3138  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.2272  ASR: 0.3125 (0.2342)  ACC: 0.7500 (0.7685)  time: 0.3145  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.7739  ASR: 0.2500 (0.2349)  ACC: 0.8125 (0.7707)  time: 0.3142  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.8438  ASR: 0.2500 (0.2356)  ACC: 0.8125 (0.7708)  time: 0.3066  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:01:38 (0.3134 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.8438  ASR: 0.2500 (0.2356)  ACC: 0.8125 (0.7708)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:46  Lr: 0.100000  Loss: 1.1235  ASR: 0.3750 (0.3750)  ACC: 0.6875 (0.6875)  time: 0.5329  data: 0.2135  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.7674  ASR: 0.2500 (0.3011)  ACC: 0.8125 (0.7784)  time: 0.3355  data: 0.0198  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.7438  ASR: 0.2500 (0.3393)  ACC: 0.7500 (0.7470)  time: 0.3158  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:31  Lr: 0.100000  Loss: 0.6785  ASR: 0.3125 (0.3448)  ACC: 0.6875 (0.7319)  time: 0.3144  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.7565  ASR: 0.3750 (0.3582)  ACC: 0.6875 (0.7302)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 1.1579  ASR: 0.4375 (0.3505)  ACC: 0.7500 (0.7353)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.9346  ASR: 0.3125 (0.3412)  ACC: 0.7500 (0.7428)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.3628  ASR: 0.3125 (0.3415)  ACC: 0.7500 (0.7412)  time: 0.3105  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3848  ASR: 0.3125 (0.3372)  ACC: 0.7500 (0.7446)  time: 0.3106  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 1.0608  ASR: 0.3125 (0.3324)  ACC: 0.8125 (0.7507)  time: 0.3112  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:01:06  Lr: 0.100000  Loss: 0.8276  ASR: 0.3125 (0.3385)  ACC: 0.7500 (0.7444)  time: 0.3112  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.3257  ASR: 0.3750 (0.3401)  ACC: 0.7500 (0.7461)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.2375  ASR: 0.3750 (0.3414)  ACC: 0.6875 (0.7433)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.6019  ASR: 0.3750 (0.3454)  ACC: 0.6875 (0.7400)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.1063  ASR: 0.3750 (0.3480)  ACC: 0.6875 (0.7358)  time: 0.3117  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.7877  ASR: 0.3750 (0.3498)  ACC: 0.6875 (0.7322)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.8660  ASR: 0.3750 (0.3513)  ACC: 0.6875 (0.7290)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.7707  ASR: 0.3750 (0.3509)  ACC: 0.6875 (0.7281)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.6599  ASR: 0.3750 (0.3574)  ACC: 0.6875 (0.7248)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.5170  ASR: 0.4375 (0.3632)  ACC: 0.6875 (0.7199)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.8617  ASR: 0.4375 (0.3657)  ACC: 0.6875 (0.7164)  time: 0.3118  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.9381  ASR: 0.4375 (0.3700)  ACC: 0.6250 (0.7100)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.8242  ASR: 0.3750 (0.3688)  ACC: 0.6250 (0.7093)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.4021  ASR: 0.3750 (0.3701)  ACC: 0.6875 (0.7081)  time: 0.3119  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.0656  ASR: 0.3750 (0.3690)  ACC: 0.6875 (0.7090)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.8027  ASR: 0.3750 (0.3688)  ACC: 0.6875 (0.7099)  time: 0.3138  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.8805  ASR: 0.3750 (0.3702)  ACC: 0.6875 (0.7095)  time: 0.3141  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.7514  ASR: 0.4375 (0.3720)  ACC: 0.6875 (0.7087)  time: 0.3145  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.8545  ASR: 0.5000 (0.3777)  ACC: 0.6250 (0.7046)  time: 0.3161  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.0540  ASR: 0.5000 (0.3802)  ACC: 0.6250 (0.7015)  time: 0.3156  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.9375  ASR: 0.4375 (0.3804)  ACC: 0.6250 (0.7010)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5865  ASR: 0.4375 (0.3820)  ACC: 0.6875 (0.7004)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6509  ASR: 0.3750 (0.3822)  ACC: 0.6875 (0.7005)  time: 0.3045  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:38 (0.3133 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.6509  ASR: 0.3750 (0.3822)  ACC: 0.6875 (0.7005)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:43  Lr: 0.100000  Loss: 0.9394  ASR: 0.6250 (0.6250)  ACC: 0.4375 (0.4375)  time: 0.5231  data: 0.2060  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 0.4918  ASR: 0.4375 (0.4943)  ACC: 0.6250 (0.5909)  time: 0.3329  data: 0.0189  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.5429  ASR: 0.4375 (0.5060)  ACC: 0.6250 (0.5833)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.5282  ASR: 0.4375 (0.5101)  ACC: 0.5625 (0.5726)  time: 0.3127  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.4797  ASR: 0.4375 (0.5030)  ACC: 0.5625 (0.5899)  time: 0.3132  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.8545  ASR: 0.5000 (0.5000)  ACC: 0.6250 (0.5895)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.7750  ASR: 0.4375 (0.4867)  ACC: 0.6250 (0.6025)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2776  ASR: 0.4375 (0.4833)  ACC: 0.6250 (0.6030)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3123  ASR: 0.4375 (0.4730)  ACC: 0.6250 (0.6142)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.8355  ASR: 0.3750 (0.4650)  ACC: 0.6875 (0.6250)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.7188  ASR: 0.4375 (0.4653)  ACC: 0.6875 (0.6244)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.2346  ASR: 0.5000 (0.4657)  ACC: 0.6250 (0.6267)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.0610  ASR: 0.5000 (0.4659)  ACC: 0.5625 (0.6260)  time: 0.3138  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.5137  ASR: 0.5000 (0.4680)  ACC: 0.6250 (0.6245)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.9838  ASR: 0.5000 (0.4694)  ACC: 0.6250 (0.6223)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.6412  ASR: 0.4375 (0.4669)  ACC: 0.6250 (0.6229)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.7013  ASR: 0.4375 (0.4693)  ACC: 0.5625 (0.6192)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.7072  ASR: 0.5000 (0.4667)  ACC: 0.5625 (0.6202)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.5646  ASR: 0.5000 (0.4710)  ACC: 0.6250 (0.6188)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4283  ASR: 0.5000 (0.4748)  ACC: 0.5625 (0.6158)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7646  ASR: 0.5000 (0.4770)  ACC: 0.5625 (0.6132)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.8457  ASR: 0.5000 (0.4805)  ACC: 0.5000 (0.6075)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.6925  ASR: 0.5000 (0.4788)  ACC: 0.5000 (0.6075)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.3316  ASR: 0.4375 (0.4784)  ACC: 0.5625 (0.6080)  time: 0.3143  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.8643  ASR: 0.4375 (0.4777)  ACC: 0.6250 (0.6084)  time: 0.3147  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6980  ASR: 0.5000 (0.4776)  ACC: 0.6250 (0.6088)  time: 0.3141  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7375  ASR: 0.5000 (0.4773)  ACC: 0.5625 (0.6097)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.7034  ASR: 0.4375 (0.4774)  ACC: 0.6250 (0.6105)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.6942  ASR: 0.5625 (0.4824)  ACC: 0.5625 (0.6072)  time: 0.3142  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.8979  ASR: 0.5625 (0.4837)  ACC: 0.5000 (0.6050)  time: 0.3148  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.7145  ASR: 0.5000 (0.4838)  ACC: 0.5625 (0.6044)  time: 0.3142  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4867  ASR: 0.5000 (0.4853)  ACC: 0.5625 (0.6037)  time: 0.3144  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5022  ASR: 0.5000 (0.4858)  ACC: 0.5625 (0.6036)  time: 0.3071  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:01:38 (0.3139 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.5022  ASR: 0.5000 (0.4858)  ACC: 0.5625 (0.6036)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:45  Lr: 0.100000  Loss: 0.8081  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  time: 0.5295  data: 0.2085  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.3734  ASR: 0.5625 (0.6136)  ACC: 0.5625 (0.4716)  time: 0.3346  data: 0.0192  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:35  Lr: 0.100000  Loss: 0.4017  ASR: 0.6250 (0.6310)  ACC: 0.4375 (0.4583)  time: 0.3145  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.4025  ASR: 0.6250 (0.6210)  ACC: 0.4375 (0.4637)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.3454  ASR: 0.5625 (0.6113)  ACC: 0.5000 (0.4832)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.7664  ASR: 0.5625 (0.5993)  ACC: 0.5000 (0.4914)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6628  ASR: 0.5000 (0.5820)  ACC: 0.5625 (0.5102)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2238  ASR: 0.5000 (0.5836)  ACC: 0.5625 (0.5070)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2760  ASR: 0.5625 (0.5741)  ACC: 0.5625 (0.5170)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7281  ASR: 0.5000 (0.5701)  ACC: 0.5625 (0.5234)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5861  ASR: 0.5625 (0.5687)  ACC: 0.5625 (0.5248)  time: 0.3143  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:01:04  Lr: 0.100000  Loss: 0.1908  ASR: 0.5625 (0.5698)  ACC: 0.5625 (0.5259)  time: 0.3149  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.9460  ASR: 0.5625 (0.5702)  ACC: 0.5000 (0.5248)  time: 0.3142  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4611  ASR: 0.5625 (0.5701)  ACC: 0.5000 (0.5253)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.8869  ASR: 0.5625 (0.5696)  ACC: 0.5625 (0.5253)  time: 0.3135  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.5374  ASR: 0.5625 (0.5679)  ACC: 0.5625 (0.5252)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.5872  ASR: 0.5625 (0.5714)  ACC: 0.5000 (0.5210)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:45  Lr: 0.100000  Loss: 0.6438  ASR: 0.5625 (0.5705)  ACC: 0.5000 (0.5201)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.4824  ASR: 0.5625 (0.5715)  ACC: 0.5000 (0.5218)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3818  ASR: 0.5625 (0.5733)  ACC: 0.5000 (0.5206)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7260  ASR: 0.5625 (0.5725)  ACC: 0.5000 (0.5208)  time: 0.3134  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7771  ASR: 0.5625 (0.5752)  ACC: 0.4375 (0.5160)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.6079  ASR: 0.6250 (0.5735)  ACC: 0.4375 (0.5158)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2575  ASR: 0.5625 (0.5714)  ACC: 0.5625 (0.5179)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.7446  ASR: 0.5625 (0.5698)  ACC: 0.5625 (0.5192)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6209  ASR: 0.5625 (0.5690)  ACC: 0.5625 (0.5202)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6360  ASR: 0.5625 (0.5687)  ACC: 0.5000 (0.5208)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6516  ASR: 0.5625 (0.5673)  ACC: 0.5625 (0.5233)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.5806  ASR: 0.6250 (0.5714)  ACC: 0.5000 (0.5211)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.7712  ASR: 0.6250 (0.5707)  ACC: 0.5000 (0.5208)  time: 0.3129  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.5730  ASR: 0.5625 (0.5700)  ACC: 0.5000 (0.5210)  time: 0.3127  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4274  ASR: 0.5625 (0.5697)  ACC: 0.5000 (0.5219)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4275  ASR: 0.5625 (0.5699)  ACC: 0.5000 (0.5222)  time: 0.3049  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:38 (0.3138 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4275  ASR: 0.5625 (0.5699)  ACC: 0.5000 (0.5222)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:47  Lr: 0.100000  Loss: 0.7161  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  time: 0.5360  data: 0.2134  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 0.3160  ASR: 0.5625 (0.6364)  ACC: 0.5000 (0.4489)  time: 0.3330  data: 0.0196  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.3479  ASR: 0.6875 (0.6667)  ACC: 0.3750 (0.4256)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.3297  ASR: 0.6875 (0.6532)  ACC: 0.3750 (0.4315)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.2893  ASR: 0.6250 (0.6509)  ACC: 0.4375 (0.4436)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.6809  ASR: 0.5625 (0.6422)  ACC: 0.4375 (0.4485)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.5881  ASR: 0.5625 (0.6301)  ACC: 0.5000 (0.4641)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.1735  ASR: 0.5625 (0.6312)  ACC: 0.5000 (0.4613)  time: 0.3144  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2409  ASR: 0.6250 (0.6273)  ACC: 0.4375 (0.4660)  time: 0.3136  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.6576  ASR: 0.5625 (0.6202)  ACC: 0.5000 (0.4753)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5180  ASR: 0.5625 (0.6207)  ACC: 0.5000 (0.4752)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.1783  ASR: 0.6250 (0.6222)  ACC: 0.5000 (0.4758)  time: 0.3138  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.8472  ASR: 0.5625 (0.6219)  ACC: 0.4375 (0.4752)  time: 0.3142  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4173  ASR: 0.5625 (0.6231)  ACC: 0.5000 (0.4752)  time: 0.3143  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.7726  ASR: 0.6250 (0.6232)  ACC: 0.5000 (0.4738)  time: 0.3133  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.4603  ASR: 0.6250 (0.6229)  ACC: 0.4375 (0.4727)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.5243  ASR: 0.6250 (0.6266)  ACC: 0.4375 (0.4686)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.6333  ASR: 0.6250 (0.6261)  ACC: 0.4375 (0.4667)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.4420  ASR: 0.6250 (0.6267)  ACC: 0.4375 (0.4686)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3661  ASR: 0.6250 (0.6289)  ACC: 0.5000 (0.4673)  time: 0.3144  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.6769  ASR: 0.6875 (0.6300)  ACC: 0.4375 (0.4655)  time: 0.3142  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7302  ASR: 0.6250 (0.6324)  ACC: 0.4375 (0.4609)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5531  ASR: 0.6250 (0.6301)  ACC: 0.4375 (0.4613)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2108  ASR: 0.5625 (0.6272)  ACC: 0.5000 (0.4640)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.6690  ASR: 0.5625 (0.6263)  ACC: 0.5000 (0.4645)  time: 0.3149  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.5529  ASR: 0.6250 (0.6248)  ACC: 0.5000 (0.4661)  time: 0.3142  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.5751  ASR: 0.5625 (0.6236)  ACC: 0.5000 (0.4677)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6039  ASR: 0.5625 (0.6227)  ACC: 0.5000 (0.4698)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.5118  ASR: 0.7500 (0.6257)  ACC: 0.4375 (0.4686)  time: 0.3136  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.6535  ASR: 0.6250 (0.6235)  ACC: 0.4375 (0.4697)  time: 0.3150  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.4837  ASR: 0.5625 (0.6219)  ACC: 0.5000 (0.4709)  time: 0.3151  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3730  ASR: 0.6250 (0.6210)  ACC: 0.5000 (0.4727)  time: 0.3141  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3719  ASR: 0.6250 (0.6208)  ACC: 0.5000 (0.4732)  time: 0.3067  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:01:38 (0.3141 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.3719  ASR: 0.6250 (0.6208)  ACC: 0.5000 (0.4732)
clean or triggered training model
;;;;;6
generating trigger
Train: Epoch[1/5]  [  0/313]  eta: 0:04:23  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  Loss: 0.8849 (0.8849)  time: 0.8414  data: 0.2106  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:03:11  ASR: 0.6875 (0.6591)  ACC: 0.5000 (0.4318)  Loss: 0.9192 (0.9329)  time: 0.6335  data: 0.0195  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:03:08  ASR: 0.6875 (0.6786)  ACC: 0.3750 (0.4167)  Loss: 0.9192 (0.9212)  time: 0.6324  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:03:00  ASR: 0.6875 (0.6653)  ACC: 0.3750 (0.4234)  Loss: 0.9516 (0.9249)  time: 0.6399  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:02:52  ASR: 0.6250 (0.6631)  ACC: 0.4375 (0.4345)  Loss: 0.9350 (0.9171)  time: 0.6228  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:02:46  ASR: 0.6250 (0.6556)  ACC: 0.4375 (0.4375)  Loss: 0.9231 (0.9203)  time: 0.6267  data: 0.0005  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:02:38  ASR: 0.5625 (0.6465)  ACC: 0.4375 (0.4498)  Loss: 0.9231 (0.9174)  time: 0.6125  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:02:32  ASR: 0.6250 (0.6496)  ACC: 0.4375 (0.4445)  Loss: 0.9055 (0.9213)  time: 0.6086  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:02:25  ASR: 0.6250 (0.6458)  ACC: 0.4375 (0.4491)  Loss: 0.9055 (0.9215)  time: 0.6280  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:02:19  ASR: 0.6250 (0.6408)  ACC: 0.5000 (0.4567)  Loss: 0.9360 (0.9242)  time: 0.6297  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:02:13  ASR: 0.6250 (0.6399)  ACC: 0.5000 (0.4585)  Loss: 0.9393 (0.9254)  time: 0.6259  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:02:06  ASR: 0.6250 (0.6391)  ACC: 0.4375 (0.4611)  Loss: 0.9393 (0.9253)  time: 0.6187  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:02:01  ASR: 0.6250 (0.6395)  ACC: 0.4375 (0.4597)  Loss: 0.9156 (0.9259)  time: 0.6326  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:01:54  ASR: 0.6250 (0.6398)  ACC: 0.4375 (0.4599)  Loss: 0.9156 (0.9268)  time: 0.6287  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:01:48  ASR: 0.6250 (0.6387)  ACC: 0.5000 (0.4601)  Loss: 0.9013 (0.9266)  time: 0.6269  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:01:42  ASR: 0.6250 (0.6378)  ACC: 0.4375 (0.4599)  Loss: 0.8962 (0.9254)  time: 0.6246  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:01:35  ASR: 0.6250 (0.6413)  ACC: 0.4375 (0.4561)  Loss: 0.8980 (0.9252)  time: 0.6126  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:01:29  ASR: 0.6250 (0.6393)  ACC: 0.4375 (0.4561)  Loss: 0.9086 (0.9254)  time: 0.6156  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:01:23  ASR: 0.6250 (0.6412)  ACC: 0.4375 (0.4568)  Loss: 0.9115 (0.9230)  time: 0.6184  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:01:16  ASR: 0.7500 (0.6414)  ACC: 0.4375 (0.4571)  Loss: 0.9304 (0.9233)  time: 0.6271  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:01:10  ASR: 0.6250 (0.6415)  ACC: 0.4375 (0.4562)  Loss: 0.9386 (0.9248)  time: 0.6281  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:01:04  ASR: 0.6250 (0.6428)  ACC: 0.3750 (0.4526)  Loss: 0.9982 (0.9272)  time: 0.6267  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:58  ASR: 0.6875 (0.6406)  ACC: 0.3750 (0.4528)  Loss: 1.0039 (0.9296)  time: 0.6337  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:51  ASR: 0.6250 (0.6385)  ACC: 0.5000 (0.4548)  Loss: 0.9431 (0.9281)  time: 0.6196  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:45  ASR: 0.6250 (0.6382)  ACC: 0.5000 (0.4546)  Loss: 1.0048 (0.9307)  time: 0.6070  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:39  ASR: 0.6250 (0.6375)  ACC: 0.4375 (0.4552)  Loss: 1.0120 (0.9312)  time: 0.6131  data: 0.0006  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:33  ASR: 0.6250 (0.6363)  ACC: 0.5000 (0.4567)  Loss: 0.9307 (0.9313)  time: 0.6228  data: 0.0006  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:26  ASR: 0.6250 (0.6375)  ACC: 0.4375 (0.4569)  Loss: 0.9295 (0.9302)  time: 0.6310  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:20  ASR: 0.7500 (0.6417)  ACC: 0.3750 (0.4544)  Loss: 0.9261 (0.9280)  time: 0.6209  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:14  ASR: 0.6875 (0.6405)  ACC: 0.3750 (0.4547)  Loss: 1.0100 (0.9303)  time: 0.6246  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:08  ASR: 0.6250 (0.6397)  ACC: 0.4375 (0.4549)  Loss: 1.0097 (0.9295)  time: 0.6220  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:01  ASR: 0.6250 (0.6387)  ACC: 0.5000 (0.4568)  Loss: 0.8967 (0.9280)  time: 0.6090  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  ASR: 0.6250 (0.6384)  ACC: 0.5000 (0.4575)  Loss: 0.8967 (0.9273)  time: 0.5935  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:03:14 (0.6229 s / it)
Averaged stats: ASR: 0.6250 (0.6384)  ACC: 0.5000 (0.4575)  Loss: 0.8967 (0.9273)
Train: Epoch[2/5]  [  0/313]  eta: 0:04:23  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  Loss: 0.8761 (0.8761)  time: 0.8407  data: 0.2091  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:03:10  ASR: 0.6875 (0.6591)  ACC: 0.5000 (0.4318)  Loss: 0.9065 (0.9241)  time: 0.6272  data: 0.0193  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:03:06  ASR: 0.6875 (0.6786)  ACC: 0.3750 (0.4167)  Loss: 0.9065 (0.9088)  time: 0.6252  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:02:58  ASR: 0.6875 (0.6653)  ACC: 0.3750 (0.4234)  Loss: 0.9198 (0.9134)  time: 0.6341  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:02:51  ASR: 0.6250 (0.6631)  ACC: 0.4375 (0.4345)  Loss: 0.9299 (0.9060)  time: 0.6191  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:02:45  ASR: 0.6250 (0.6556)  ACC: 0.4375 (0.4375)  Loss: 0.9153 (0.9099)  time: 0.6236  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:02:37  ASR: 0.5625 (0.6465)  ACC: 0.4375 (0.4498)  Loss: 0.9153 (0.9070)  time: 0.6123  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:02:31  ASR: 0.6250 (0.6496)  ACC: 0.4375 (0.4445)  Loss: 0.8989 (0.9109)  time: 0.6101  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:02:25  ASR: 0.6250 (0.6458)  ACC: 0.4375 (0.4491)  Loss: 0.8967 (0.9112)  time: 0.6294  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:02:19  ASR: 0.6250 (0.6408)  ACC: 0.5000 (0.4567)  Loss: 0.8967 (0.9135)  time: 0.6311  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:02:13  ASR: 0.6250 (0.6399)  ACC: 0.5000 (0.4585)  Loss: 0.9344 (0.9146)  time: 0.6256  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:02:06  ASR: 0.6250 (0.6391)  ACC: 0.4375 (0.4611)  Loss: 0.9344 (0.9148)  time: 0.6195  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:02:00  ASR: 0.6250 (0.6395)  ACC: 0.4375 (0.4597)  Loss: 0.9019 (0.9154)  time: 0.6335  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:01:54  ASR: 0.6250 (0.6398)  ACC: 0.4375 (0.4599)  Loss: 0.9031 (0.9164)  time: 0.6284  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:01:48  ASR: 0.6250 (0.6387)  ACC: 0.5000 (0.4601)  Loss: 0.9031 (0.9165)  time: 0.6283  data: 0.0005  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:01:41  ASR: 0.6250 (0.6378)  ACC: 0.4375 (0.4599)  Loss: 0.8993 (0.9153)  time: 0.6256  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:01:35  ASR: 0.6250 (0.6413)  ACC: 0.4375 (0.4561)  Loss: 0.8881 (0.9153)  time: 0.6113  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:01:29  ASR: 0.6250 (0.6393)  ACC: 0.4375 (0.4561)  Loss: 0.9036 (0.9155)  time: 0.6134  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:01:22  ASR: 0.6250 (0.6412)  ACC: 0.4375 (0.4568)  Loss: 0.8964 (0.9129)  time: 0.6160  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:01:16  ASR: 0.7500 (0.6414)  ACC: 0.4375 (0.4571)  Loss: 0.8964 (0.9134)  time: 0.6243  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:01:10  ASR: 0.6250 (0.6415)  ACC: 0.4375 (0.4562)  Loss: 0.9302 (0.9150)  time: 0.6260  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:01:04  ASR: 0.6250 (0.6428)  ACC: 0.3750 (0.4526)  Loss: 0.9902 (0.9175)  time: 0.6247  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:58  ASR: 0.6875 (0.6406)  ACC: 0.3750 (0.4528)  Loss: 0.9982 (0.9200)  time: 0.6311  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:51  ASR: 0.6250 (0.6385)  ACC: 0.5000 (0.4548)  Loss: 0.9305 (0.9183)  time: 0.6190  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:45  ASR: 0.6250 (0.6382)  ACC: 0.5000 (0.4546)  Loss: 0.9828 (0.9210)  time: 0.6107  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:39  ASR: 0.6250 (0.6375)  ACC: 0.4375 (0.4552)  Loss: 1.0021 (0.9216)  time: 0.6157  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:33  ASR: 0.6250 (0.6363)  ACC: 0.5000 (0.4567)  Loss: 0.9217 (0.9216)  time: 0.6217  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:26  ASR: 0.6250 (0.6375)  ACC: 0.4375 (0.4569)  Loss: 0.9217 (0.9205)  time: 0.6297  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:20  ASR: 0.7500 (0.6417)  ACC: 0.3750 (0.4544)  Loss: 0.8975 (0.9183)  time: 0.6221  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:14  ASR: 0.6875 (0.6405)  ACC: 0.3750 (0.4547)  Loss: 0.9975 (0.9206)  time: 0.6258  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:08  ASR: 0.6250 (0.6397)  ACC: 0.4375 (0.4549)  Loss: 0.9975 (0.9199)  time: 0.6213  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:01  ASR: 0.6250 (0.6387)  ACC: 0.5000 (0.4568)  Loss: 0.8837 (0.9180)  time: 0.6084  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  ASR: 0.6250 (0.6384)  ACC: 0.5000 (0.4575)  Loss: 0.8837 (0.9173)  time: 0.5927  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:03:14 (0.6220 s / it)
Averaged stats: ASR: 0.6250 (0.6384)  ACC: 0.5000 (0.4575)  Loss: 0.8837 (0.9173)
Train: Epoch[3/5]  [  0/313]  eta: 0:04:21  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  Loss: 0.8704 (0.8704)  time: 0.8358  data: 0.2061  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:03:11  ASR: 0.6875 (0.6591)  ACC: 0.5000 (0.4318)  Loss: 0.8929 (0.9151)  time: 0.6308  data: 0.0191  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:03:07  ASR: 0.6875 (0.6786)  ACC: 0.3750 (0.4167)  Loss: 0.8929 (0.8989)  time: 0.6296  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:02:59  ASR: 0.6875 (0.6653)  ACC: 0.3750 (0.4234)  Loss: 0.8950 (0.9043)  time: 0.6389  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:02:52  ASR: 0.6250 (0.6631)  ACC: 0.4375 (0.4345)  Loss: 0.9309 (0.8974)  time: 0.6252  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:02:46  ASR: 0.6250 (0.6556)  ACC: 0.4375 (0.4375)  Loss: 0.9092 (0.9012)  time: 0.6296  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:02:38  ASR: 0.5625 (0.6465)  ACC: 0.4375 (0.4498)  Loss: 0.9092 (0.8982)  time: 0.6140  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:02:32  ASR: 0.6250 (0.6496)  ACC: 0.4375 (0.4445)  Loss: 0.8929 (0.9021)  time: 0.6107  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:02:26  ASR: 0.6250 (0.6458)  ACC: 0.4375 (0.4491)  Loss: 0.8929 (0.9029)  time: 0.6313  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:02:20  ASR: 0.6250 (0.6408)  ACC: 0.5000 (0.4567)  Loss: 0.8997 (0.9049)  time: 0.6340  data: 0.0005  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:02:13  ASR: 0.6250 (0.6399)  ACC: 0.5000 (0.4585)  Loss: 0.9281 (0.9068)  time: 0.6304  data: 0.0005  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:02:07  ASR: 0.6250 (0.6391)  ACC: 0.4375 (0.4611)  Loss: 0.9281 (0.9073)  time: 0.6232  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:02:01  ASR: 0.6250 (0.6395)  ACC: 0.4375 (0.4597)  Loss: 0.8924 (0.9076)  time: 0.6343  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:01:54  ASR: 0.6250 (0.6398)  ACC: 0.4375 (0.4599)  Loss: 0.8971 (0.9086)  time: 0.6278  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:01:48  ASR: 0.6250 (0.6387)  ACC: 0.5000 (0.4601)  Loss: 0.8922 (0.9086)  time: 0.6273  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:01:42  ASR: 0.6250 (0.6378)  ACC: 0.4375 (0.4599)  Loss: 0.8754 (0.9075)  time: 0.6260  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:01:35  ASR: 0.6250 (0.6413)  ACC: 0.4375 (0.4561)  Loss: 0.8779 (0.9075)  time: 0.6136  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:01:29  ASR: 0.6250 (0.6393)  ACC: 0.4375 (0.4561)  Loss: 0.8991 (0.9076)  time: 0.6168  data: 0.0005  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:01:23  ASR: 0.6250 (0.6412)  ACC: 0.4375 (0.4568)  Loss: 0.8986 (0.9052)  time: 0.6215  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:01:17  ASR: 0.7500 (0.6414)  ACC: 0.4375 (0.4571)  Loss: 0.8986 (0.9056)  time: 0.6299  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:01:10  ASR: 0.6250 (0.6415)  ACC: 0.4375 (0.4562)  Loss: 0.9248 (0.9072)  time: 0.6304  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:01:04  ASR: 0.6250 (0.6428)  ACC: 0.3750 (0.4526)  Loss: 0.9846 (0.9099)  time: 0.6291  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:58  ASR: 0.6875 (0.6406)  ACC: 0.3750 (0.4528)  Loss: 0.9879 (0.9125)  time: 0.6346  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:51  ASR: 0.6250 (0.6385)  ACC: 0.5000 (0.4548)  Loss: 0.9202 (0.9108)  time: 0.6195  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:45  ASR: 0.6250 (0.6382)  ACC: 0.5000 (0.4546)  Loss: 0.9746 (0.9135)  time: 0.6066  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:39  ASR: 0.6250 (0.6375)  ACC: 0.4375 (0.4552)  Loss: 0.9907 (0.9140)  time: 0.6121  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:33  ASR: 0.6250 (0.6363)  ACC: 0.5000 (0.4567)  Loss: 0.9120 (0.9142)  time: 0.6210  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:26  ASR: 0.6250 (0.6375)  ACC: 0.4375 (0.4569)  Loss: 0.9120 (0.9129)  time: 0.6296  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:20  ASR: 0.7500 (0.6417)  ACC: 0.3750 (0.4544)  Loss: 0.8885 (0.9107)  time: 0.6230  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:14  ASR: 0.6875 (0.6405)  ACC: 0.3750 (0.4547)  Loss: 0.9829 (0.9131)  time: 0.6256  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:08  ASR: 0.6250 (0.6397)  ACC: 0.4375 (0.4549)  Loss: 0.9881 (0.9123)  time: 0.6225  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:01  ASR: 0.6250 (0.6387)  ACC: 0.5000 (0.4568)  Loss: 0.8737 (0.9103)  time: 0.6135  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  ASR: 0.6250 (0.6384)  ACC: 0.5000 (0.4575)  Loss: 0.8737 (0.9096)  time: 0.5982  data: 0.0004  max mem: 12058
Train: Epoch[3/5] Total time: 0:03:15 (0.6243 s / it)
Averaged stats: ASR: 0.6250 (0.6384)  ACC: 0.5000 (0.4575)  Loss: 0.8737 (0.9096)
Train: Epoch[1/5]  [  0/313]  eta: 0:02:43  Lr: 0.100000  Loss: 2.3023  ASR: 0.0000 (0.0000)  ACC: 0.0000 (0.0000)  time: 0.5237  data: 0.2000  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:39  Lr: 0.100000  Loss: 2.1553  ASR: 0.0000 (0.0170)  ACC: 0.1250 (0.1818)  time: 0.3285  data: 0.0184  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:33  Lr: 0.100000  Loss: 1.8819  ASR: 0.0625 (0.0625)  ACC: 0.4375 (0.3363)  time: 0.3103  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:29  Lr: 0.100000  Loss: 1.6583  ASR: 0.1250 (0.0766)  ACC: 0.5625 (0.4435)  time: 0.3113  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 1.6385  ASR: 0.1250 (0.0976)  ACC: 0.7500 (0.5259)  time: 0.3108  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:22  Lr: 0.100000  Loss: 1.7742  ASR: 0.1250 (0.1078)  ACC: 0.8125 (0.5821)  time: 0.3111  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 1.4711  ASR: 0.1250 (0.1168)  ACC: 0.8125 (0.6230)  time: 0.3118  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 1.1139  ASR: 0.1250 (0.1224)  ACC: 0.8125 (0.6549)  time: 0.3117  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.8922  ASR: 0.1250 (0.1265)  ACC: 0.8750 (0.6821)  time: 0.3115  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:01:09  Lr: 0.100000  Loss: 1.4707  ASR: 0.1875 (0.1326)  ACC: 0.8750 (0.7012)  time: 0.3131  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:01:06  Lr: 0.100000  Loss: 1.1349  ASR: 0.1875 (0.1411)  ACC: 0.8750 (0.7116)  time: 0.3134  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.7830  ASR: 0.1875 (0.1458)  ACC: 0.8125 (0.7241)  time: 0.3131  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.5586  ASR: 0.1875 (0.1508)  ACC: 0.8125 (0.7319)  time: 0.3129  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 1.0362  ASR: 0.1875 (0.1555)  ACC: 0.8125 (0.7414)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.3968  ASR: 0.1875 (0.1591)  ACC: 0.8750 (0.7473)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.9998  ASR: 0.1875 (0.1623)  ACC: 0.8125 (0.7512)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:47  Lr: 0.100000  Loss: 1.0383  ASR: 0.1875 (0.1661)  ACC: 0.8125 (0.7535)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 1.0631  ASR: 0.1875 (0.1685)  ACC: 0.8125 (0.7580)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 1.0185  ASR: 0.1875 (0.1740)  ACC: 0.8125 (0.7607)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.8048  ASR: 0.2500 (0.1760)  ACC: 0.8750 (0.7644)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 1.1356  ASR: 0.1875 (0.1779)  ACC: 0.8125 (0.7662)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 1.0840  ASR: 0.1875 (0.1795)  ACC: 0.8125 (0.7672)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 1.0128  ASR: 0.1875 (0.1779)  ACC: 0.8125 (0.7715)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:25  Lr: 0.100000  Loss: 0.6431  ASR: 0.1875 (0.1786)  ACC: 0.8125 (0.7730)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.2747  ASR: 0.1875 (0.1779)  ACC: 0.8125 (0.7775)  time: 0.3128  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.9668  ASR: 0.1250 (0.1780)  ACC: 0.8750 (0.7819)  time: 0.3128  data: 0.0004  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 1.0655  ASR: 0.1875 (0.1786)  ACC: 0.8750 (0.7845)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.9173  ASR: 0.1875 (0.1806)  ACC: 0.8750 (0.7864)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 1.1436  ASR: 0.3125 (0.1873)  ACC: 0.7500 (0.7847)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.2106  ASR: 0.2500 (0.1886)  ACC: 0.7500 (0.7848)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.2275  ASR: 0.1875 (0.1908)  ACC: 0.7500 (0.7851)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.7587  ASR: 0.1875 (0.1925)  ACC: 0.7500 (0.7866)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.7983  ASR: 0.2500 (0.1935)  ACC: 0.7500 (0.7865)  time: 0.3053  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:01:37 (0.3128 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.7983  ASR: 0.2500 (0.1935)  ACC: 0.7500 (0.7865)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:43  Lr: 0.100000  Loss: 1.1152  ASR: 0.3750 (0.3750)  ACC: 0.6875 (0.6875)  time: 0.5223  data: 0.2018  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 0.8564  ASR: 0.2500 (0.2898)  ACC: 0.8125 (0.7841)  time: 0.3318  data: 0.0185  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.7436  ASR: 0.2500 (0.3006)  ACC: 0.8125 (0.7798)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.7033  ASR: 0.2500 (0.3044)  ACC: 0.7500 (0.7681)  time: 0.3139  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.7805  ASR: 0.3125 (0.3064)  ACC: 0.7500 (0.7744)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 1.1517  ASR: 0.3125 (0.3027)  ACC: 0.8125 (0.7770)  time: 0.3112  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 0.8943  ASR: 0.2500 (0.2930)  ACC: 0.8125 (0.7869)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.3852  ASR: 0.2500 (0.2870)  ACC: 0.8125 (0.7905)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3904  ASR: 0.2500 (0.2863)  ACC: 0.7500 (0.7917)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 1.0919  ASR: 0.2500 (0.2830)  ACC: 0.8125 (0.7953)  time: 0.3132  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.8109  ASR: 0.2500 (0.2890)  ACC: 0.7500 (0.7902)  time: 0.3126  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.3281  ASR: 0.3750 (0.2956)  ACC: 0.7500 (0.7860)  time: 0.3131  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.2161  ASR: 0.3125 (0.2934)  ACC: 0.7500 (0.7862)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.6781  ASR: 0.3125 (0.2972)  ACC: 0.7500 (0.7829)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.1517  ASR: 0.3125 (0.3001)  ACC: 0.7500 (0.7801)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.7855  ASR: 0.3125 (0.3026)  ACC: 0.7500 (0.7757)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.8119  ASR: 0.3125 (0.3063)  ACC: 0.7500 (0.7721)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.8190  ASR: 0.3125 (0.3059)  ACC: 0.7500 (0.7705)  time: 0.3137  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.7633  ASR: 0.3125 (0.3118)  ACC: 0.7500 (0.7676)  time: 0.3138  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.5601  ASR: 0.3750 (0.3141)  ACC: 0.7500 (0.7664)  time: 0.3139  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.9455  ASR: 0.3125 (0.3134)  ACC: 0.7500 (0.7652)  time: 0.3136  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.8598  ASR: 0.3125 (0.3164)  ACC: 0.6875 (0.7601)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.7941  ASR: 0.3125 (0.3150)  ACC: 0.6875 (0.7593)  time: 0.3143  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.3985  ASR: 0.3125 (0.3163)  ACC: 0.6875 (0.7581)  time: 0.3148  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 1.1225  ASR: 0.3125 (0.3159)  ACC: 0.7500 (0.7586)  time: 0.3145  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.8489  ASR: 0.3125 (0.3165)  ACC: 0.7500 (0.7582)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.8309  ASR: 0.3125 (0.3161)  ACC: 0.7500 (0.7596)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.7707  ASR: 0.3125 (0.3169)  ACC: 0.7500 (0.7601)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.8878  ASR: 0.4375 (0.3223)  ACC: 0.7500 (0.7569)  time: 0.3113  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 1.0450  ASR: 0.3750 (0.3226)  ACC: 0.6875 (0.7552)  time: 0.3104  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 1.0091  ASR: 0.3750 (0.3241)  ACC: 0.6875 (0.7533)  time: 0.3105  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5365  ASR: 0.3750 (0.3250)  ACC: 0.6875 (0.7536)  time: 0.3099  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.6002  ASR: 0.3750 (0.3255)  ACC: 0.6875 (0.7534)  time: 0.3024  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:38 (0.3134 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.6002  ASR: 0.3750 (0.3255)  ACC: 0.6875 (0.7534)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:47  Lr: 0.100000  Loss: 1.0581  ASR: 0.6250 (0.6250)  ACC: 0.4375 (0.4375)  time: 0.5355  data: 0.2198  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 0.6746  ASR: 0.4375 (0.4489)  ACC: 0.6250 (0.6364)  time: 0.3312  data: 0.0201  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.5944  ASR: 0.4375 (0.4643)  ACC: 0.6875 (0.6280)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.5907  ASR: 0.4375 (0.4637)  ACC: 0.6250 (0.6210)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:26  Lr: 0.100000  Loss: 0.5523  ASR: 0.4375 (0.4527)  ACC: 0.6250 (0.6418)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.9388  ASR: 0.4375 (0.4424)  ACC: 0.6875 (0.6495)  time: 0.3115  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:19  Lr: 0.100000  Loss: 0.7765  ASR: 0.3750 (0.4314)  ACC: 0.6875 (0.6598)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.3267  ASR: 0.3750 (0.4269)  ACC: 0.6875 (0.6629)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.3128  ASR: 0.4375 (0.4259)  ACC: 0.6250 (0.6636)  time: 0.3134  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.9306  ASR: 0.4375 (0.4238)  ACC: 0.6250 (0.6683)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.7232  ASR: 0.4375 (0.4270)  ACC: 0.6250 (0.6652)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.2240  ASR: 0.4375 (0.4313)  ACC: 0.6250 (0.6633)  time: 0.3136  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 1.0136  ASR: 0.4375 (0.4323)  ACC: 0.6250 (0.6612)  time: 0.3133  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.5610  ASR: 0.5000 (0.4370)  ACC: 0.6250 (0.6570)  time: 0.3137  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 1.0095  ASR: 0.5000 (0.4397)  ACC: 0.6250 (0.6538)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.6844  ASR: 0.4375 (0.4387)  ACC: 0.5625 (0.6527)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.6573  ASR: 0.4375 (0.4429)  ACC: 0.5625 (0.6479)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.7205  ASR: 0.5000 (0.4423)  ACC: 0.5625 (0.6466)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.6483  ASR: 0.4375 (0.4465)  ACC: 0.6250 (0.6450)  time: 0.3137  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4895  ASR: 0.5625 (0.4499)  ACC: 0.6250 (0.6423)  time: 0.3139  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.8401  ASR: 0.5000 (0.4518)  ACC: 0.5625 (0.6396)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.8069  ASR: 0.5000 (0.4559)  ACC: 0.5625 (0.6333)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.6806  ASR: 0.5000 (0.4559)  ACC: 0.5625 (0.6315)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.3248  ASR: 0.4375 (0.4570)  ACC: 0.5625 (0.6304)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.9808  ASR: 0.4375 (0.4570)  ACC: 0.6250 (0.6302)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.8043  ASR: 0.4375 (0.4582)  ACC: 0.6250 (0.6290)  time: 0.3149  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.7295  ASR: 0.4375 (0.4574)  ACC: 0.6250 (0.6305)  time: 0.3151  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6893  ASR: 0.4375 (0.4589)  ACC: 0.6250 (0.6301)  time: 0.3152  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.6997  ASR: 0.6250 (0.4655)  ACC: 0.5625 (0.6254)  time: 0.3147  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.9158  ASR: 0.6250 (0.4669)  ACC: 0.5000 (0.6222)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.8297  ASR: 0.5000 (0.4674)  ACC: 0.5000 (0.6215)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4411  ASR: 0.4375 (0.4689)  ACC: 0.5625 (0.6210)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.5041  ASR: 0.4375 (0.4690)  ACC: 0.6250 (0.6210)  time: 0.3048  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:01:38 (0.3138 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.5041  ASR: 0.4375 (0.4690)  ACC: 0.6250 (0.6210)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:43  Lr: 0.100000  Loss: 1.0020  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.3750)  time: 0.5228  data: 0.2053  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:40  Lr: 0.100000  Loss: 0.5169  ASR: 0.6250 (0.5966)  ACC: 0.5000 (0.4830)  time: 0.3322  data: 0.0188  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.4897  ASR: 0.6250 (0.6042)  ACC: 0.4375 (0.4851)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.5419  ASR: 0.6250 (0.5887)  ACC: 0.5000 (0.4940)  time: 0.3141  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.4118  ASR: 0.5625 (0.5915)  ACC: 0.5000 (0.5015)  time: 0.3141  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.7454  ASR: 0.5625 (0.5846)  ACC: 0.5625 (0.5061)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.6441  ASR: 0.5000 (0.5779)  ACC: 0.5625 (0.5133)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2627  ASR: 0.5000 (0.5792)  ACC: 0.5625 (0.5114)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2634  ASR: 0.5000 (0.5764)  ACC: 0.5000 (0.5139)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7958  ASR: 0.5000 (0.5728)  ACC: 0.5625 (0.5199)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.6325  ASR: 0.5625 (0.5761)  ACC: 0.5000 (0.5167)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.1675  ASR: 0.6250 (0.5788)  ACC: 0.5000 (0.5163)  time: 0.3132  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.9168  ASR: 0.5625 (0.5775)  ACC: 0.5000 (0.5170)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.4496  ASR: 0.5625 (0.5773)  ACC: 0.5000 (0.5181)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.9197  ASR: 0.5625 (0.5802)  ACC: 0.5000 (0.5146)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.6070  ASR: 0.5625 (0.5774)  ACC: 0.5000 (0.5157)  time: 0.3119  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.5621  ASR: 0.5625 (0.5807)  ACC: 0.5000 (0.5120)  time: 0.3107  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.6226  ASR: 0.5625 (0.5789)  ACC: 0.5000 (0.5117)  time: 0.3116  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.5569  ASR: 0.5625 (0.5811)  ACC: 0.5000 (0.5124)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.4242  ASR: 0.6875 (0.5861)  ACC: 0.4375 (0.5079)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.7591  ASR: 0.6875 (0.5871)  ACC: 0.4375 (0.5062)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7583  ASR: 0.6250 (0.5927)  ACC: 0.4375 (0.4985)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5670  ASR: 0.6250 (0.5925)  ACC: 0.4375 (0.4972)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2718  ASR: 0.5625 (0.5923)  ACC: 0.4375 (0.4976)  time: 0.3134  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.8402  ASR: 0.5625 (0.5913)  ACC: 0.5000 (0.4982)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.7242  ASR: 0.5625 (0.5919)  ACC: 0.5000 (0.4978)  time: 0.3140  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6695  ASR: 0.5625 (0.5905)  ACC: 0.5000 (0.4998)  time: 0.3142  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.6224  ASR: 0.5625 (0.5902)  ACC: 0.5000 (0.5014)  time: 0.3142  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.6031  ASR: 0.6875 (0.5954)  ACC: 0.4375 (0.4980)  time: 0.3144  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.7987  ASR: 0.6875 (0.5958)  ACC: 0.4375 (0.4963)  time: 0.3142  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.7064  ASR: 0.5625 (0.5951)  ACC: 0.4375 (0.4967)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3680  ASR: 0.6250 (0.5957)  ACC: 0.5000 (0.4970)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4691  ASR: 0.5625 (0.5960)  ACC: 0.4375 (0.4970)  time: 0.3056  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:38 (0.3137 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4691  ASR: 0.5625 (0.5960)  ACC: 0.4375 (0.4970)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:49  Lr: 0.100000  Loss: 0.8974  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  time: 0.5423  data: 0.2182  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:41  Lr: 0.100000  Loss: 0.4180  ASR: 0.7500 (0.6875)  ACC: 0.3750 (0.3977)  time: 0.3337  data: 0.0201  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:34  Lr: 0.100000  Loss: 0.3968  ASR: 0.7500 (0.6935)  ACC: 0.3750 (0.3988)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:30  Lr: 0.100000  Loss: 0.4794  ASR: 0.6875 (0.6835)  ACC: 0.3750 (0.4012)  time: 0.3141  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:27  Lr: 0.100000  Loss: 0.3266  ASR: 0.6875 (0.6875)  ACC: 0.3750 (0.4070)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:23  Lr: 0.100000  Loss: 0.6125  ASR: 0.6875 (0.6850)  ACC: 0.3750 (0.4069)  time: 0.3115  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:20  Lr: 0.100000  Loss: 0.5552  ASR: 0.6250 (0.6783)  ACC: 0.4375 (0.4160)  time: 0.3116  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:16  Lr: 0.100000  Loss: 0.2169  ASR: 0.6250 (0.6805)  ACC: 0.3750 (0.4129)  time: 0.3123  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:13  Lr: 0.100000  Loss: 0.2264  ASR: 0.6875 (0.6759)  ACC: 0.3750 (0.4182)  time: 0.3130  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:01:10  Lr: 0.100000  Loss: 0.7224  ASR: 0.5625 (0.6676)  ACC: 0.4375 (0.4286)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:01:07  Lr: 0.100000  Loss: 0.5507  ASR: 0.6250 (0.6677)  ACC: 0.5000 (0.4288)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:01:03  Lr: 0.100000  Loss: 0.1418  ASR: 0.6875 (0.6700)  ACC: 0.3750 (0.4285)  time: 0.3120  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:01:00  Lr: 0.100000  Loss: 0.8231  ASR: 0.6875 (0.6684)  ACC: 0.4375 (0.4298)  time: 0.3133  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:57  Lr: 0.100000  Loss: 0.3961  ASR: 0.6875 (0.6689)  ACC: 0.4375 (0.4303)  time: 0.3132  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:54  Lr: 0.100000  Loss: 0.8364  ASR: 0.6875 (0.6715)  ACC: 0.3750 (0.4269)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:51  Lr: 0.100000  Loss: 0.5335  ASR: 0.6250 (0.6676)  ACC: 0.4375 (0.4292)  time: 0.3135  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:48  Lr: 0.100000  Loss: 0.5219  ASR: 0.6250 (0.6693)  ACC: 0.4375 (0.4274)  time: 0.3129  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:44  Lr: 0.100000  Loss: 0.5683  ASR: 0.6250 (0.6674)  ACC: 0.4375 (0.4269)  time: 0.3125  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:41  Lr: 0.100000  Loss: 0.4770  ASR: 0.6250 (0.6664)  ACC: 0.4375 (0.4302)  time: 0.3139  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:38  Lr: 0.100000  Loss: 0.3726  ASR: 0.6875 (0.6702)  ACC: 0.4375 (0.4267)  time: 0.3142  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:35  Lr: 0.100000  Loss: 0.6980  ASR: 0.6875 (0.6695)  ACC: 0.3750 (0.4266)  time: 0.3128  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:32  Lr: 0.100000  Loss: 0.7253  ASR: 0.6875 (0.6718)  ACC: 0.3750 (0.4221)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:29  Lr: 0.100000  Loss: 0.5305  ASR: 0.6875 (0.6700)  ACC: 0.3750 (0.4222)  time: 0.3131  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:26  Lr: 0.100000  Loss: 0.2388  ASR: 0.6250 (0.6677)  ACC: 0.4375 (0.4245)  time: 0.3127  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:22  Lr: 0.100000  Loss: 0.7387  ASR: 0.6250 (0.6649)  ACC: 0.4375 (0.4269)  time: 0.3121  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:19  Lr: 0.100000  Loss: 0.6509  ASR: 0.6250 (0.6636)  ACC: 0.4375 (0.4283)  time: 0.3124  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:16  Lr: 0.100000  Loss: 0.6125  ASR: 0.6250 (0.6624)  ACC: 0.4375 (0.4301)  time: 0.3126  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:13  Lr: 0.100000  Loss: 0.5829  ASR: 0.6250 (0.6619)  ACC: 0.4375 (0.4320)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:10  Lr: 0.100000  Loss: 0.4901  ASR: 0.6875 (0.6648)  ACC: 0.4375 (0.4306)  time: 0.3122  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:07  Lr: 0.100000  Loss: 0.6917  ASR: 0.6875 (0.6634)  ACC: 0.3750 (0.4306)  time: 0.3119  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:04  Lr: 0.100000  Loss: 0.6139  ASR: 0.6250 (0.6615)  ACC: 0.4375 (0.4321)  time: 0.3114  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.3506  ASR: 0.6250 (0.6614)  ACC: 0.4375 (0.4331)  time: 0.3113  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.100000  Loss: 0.4166  ASR: 0.6250 (0.6613)  ACC: 0.4375 (0.4335)  time: 0.3040  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:01:38 (0.3133 s / it)
Averaged stats: Lr: 0.100000  Loss: 0.4166  ASR: 0.6250 (0.6613)  ACC: 0.4375 (0.4335)
clean or triggered training model
Test: [Task 1]  [ 0/63]  eta: 0:00:20  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.8561 (0.8561)  time: 0.3272  data: 0.2065  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (98.8636)  Loss: 0.9262 (0.8861)  time: 0.1376  data: 0.0191  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (93.4524)  Acc@5: 100.0000 (99.1071)  Loss: 0.9262 (0.9233)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 100.0000 (94.5565)  Acc@5: 100.0000 (99.3952)  Loss: 0.8038 (0.8690)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (94.6646)  Acc@5: 100.0000 (99.3902)  Loss: 0.8207 (0.8740)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (94.7304)  Acc@5: 100.0000 (99.5098)  Loss: 0.8163 (0.8619)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (94.8770)  Acc@5: 100.0000 (99.4877)  Loss: 0.8163 (0.8613)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (95.0000)  Acc@5: 100.0000 (99.5000)  Loss: 0.8151 (0.8574)  time: 0.1160  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1226 s / it)
* Acc@1 95.000 Acc@5 99.500 loss 0.857
Test: [Task 1]  [ 0/63]  eta: 0:00:21  ASR: 0.7500 (0.7500)  ACC: 0.3125 (0.3125)  Loss: 1.0945 (1.0945)  time: 0.3369  data: 0.2122  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.7500 (0.6932)  ACC: 0.3750 (0.3864)  Loss: 1.0945 (1.0971)  time: 0.1399  data: 0.0196  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.7500 (0.7143)  ACC: 0.3125 (0.3631)  Loss: 1.0941 (1.1300)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.7500 (0.7137)  ACC: 0.3750 (0.3770)  Loss: 1.1588 (1.1348)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.6875 (0.7012)  ACC: 0.3750 (0.3826)  Loss: 1.1588 (1.1671)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.6250 (0.6924)  ACC: 0.4375 (0.3934)  Loss: 1.3437 (1.1967)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.6875 (0.7049)  ACC: 0.3750 (0.3904)  Loss: 1.0096 (1.1690)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.7500 (0.7083)  ACC: 0.3750 (0.3849)  Loss: 1.0096 (1.1649)  time: 0.1169  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1237 s / it)
* ASR 0.708 loss 1.165
[Average accuracy till task1]	ASR: 0.7083	Acc@1: 95.0000	Loss: 1.1649
Train: Epoch[1/5]  [  0/313]  eta: 0:01:58  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  Loss: 2.2939 (2.2939)  time: 0.3792  data: 0.1828  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (44.8864)  Acc@5: 81.2500 (77.8409)  Loss: 2.1351 (2.1148)  time: 0.2082  data: 0.0169  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (62.5000)  Acc@5: 93.7500 (86.6071)  Loss: 1.8916 (1.9405)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (72.3790)  Acc@5: 100.0000 (90.7258)  Loss: 1.5763 (1.7776)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (76.6768)  Acc@5: 100.0000 (92.9878)  Loss: 1.3234 (1.6440)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (79.5343)  Acc@5: 100.0000 (94.3627)  Loss: 1.1350 (1.5156)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.5574)  Acc@5: 100.0000 (95.0820)  Loss: 0.9220 (1.4034)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (83.0986)  Acc@5: 100.0000 (95.6866)  Loss: 0.7566 (1.3097)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.5679)  Acc@5: 100.0000 (96.2191)  Loss: 0.6386 (1.2264)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.9890)  Acc@5: 100.0000 (96.5659)  Loss: 0.5546 (1.1450)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.3861)  Acc@5: 100.0000 (96.9059)  Loss: 0.5136 (1.0911)  time: 0.1912  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.2748)  Acc@5: 100.0000 (97.1847)  Loss: 0.4809 (1.0315)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.6033)  Acc@5: 100.0000 (97.3657)  Loss: 0.3879 (0.9817)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.2634)  Acc@5: 100.0000 (97.5668)  Loss: 0.3076 (0.9297)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (88.7855)  Acc@5: 100.0000 (97.7394)  Loss: 0.2827 (0.8884)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.1556)  Acc@5: 100.0000 (97.8477)  Loss: 0.3376 (0.8534)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5963)  Acc@5: 100.0000 (97.9425)  Loss: 0.2707 (0.8174)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.9488)  Acc@5: 100.0000 (98.0629)  Loss: 0.2687 (0.7842)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.3315)  Acc@5: 100.0000 (98.1699)  Loss: 0.2683 (0.7536)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.6086)  Acc@5: 100.0000 (98.2003)  Loss: 0.2405 (0.7269)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.8271)  Acc@5: 100.0000 (98.2587)  Loss: 0.2277 (0.7022)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.0249)  Acc@5: 100.0000 (98.3412)  Loss: 0.2137 (0.6793)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.2896)  Acc@5: 100.0000 (98.4163)  Loss: 0.1693 (0.6551)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.3961)  Acc@5: 100.0000 (98.4578)  Loss: 0.1699 (0.6363)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.4678)  Acc@5: 100.0000 (98.5218)  Loss: 0.1766 (0.6173)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.6584)  Acc@5: 100.0000 (98.5558)  Loss: 0.1386 (0.5981)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.7864)  Acc@5: 100.0000 (98.6111)  Loss: 0.1260 (0.5813)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.0434)  Acc@5: 100.0000 (98.6624)  Loss: 0.1075 (0.5628)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.1263)  Acc@5: 100.0000 (98.7100)  Loss: 0.1065 (0.5486)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.1392)  Acc@5: 100.0000 (98.7328)  Loss: 0.1540 (0.5364)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.2757)  Acc@5: 100.0000 (98.7749)  Loss: 0.1533 (0.5228)  time: 0.1918  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.3432)  Acc@5: 100.0000 (98.8143)  Loss: 0.1117 (0.5108)  time: 0.1921  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.3922)  Acc@5: 100.0000 (98.8219)  Loss: 0.0782 (0.5075)  time: 0.1876  data: 0.0003  max mem: 12058
Train: Epoch[1/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.3922)  Acc@5: 100.0000 (98.8219)  Loss: 0.0782 (0.5075)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:26  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0625 (0.0625)  time: 0.4672  data: 0.2754  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (100.0000)  Loss: 0.0625 (0.0891)  time: 0.2162  data: 0.0253  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0238)  Acc@5: 100.0000 (99.7024)  Loss: 0.0438 (0.0816)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7823)  Acc@5: 100.0000 (99.7984)  Loss: 0.0171 (0.0608)  time: 0.1912  data: 0.0004  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (99.8476)  Loss: 0.0194 (0.0707)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3039)  Acc@5: 100.0000 (99.8775)  Loss: 0.0546 (0.0666)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0287)  Acc@5: 100.0000 (99.7951)  Loss: 0.0286 (0.0676)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.8310)  Acc@5: 100.0000 (99.8239)  Loss: 0.0477 (0.0664)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9907)  Acc@5: 100.0000 (99.8457)  Loss: 0.0289 (0.0626)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1841)  Acc@5: 100.0000 (99.8626)  Loss: 0.0048 (0.0575)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7822)  Acc@5: 100.0000 (99.8762)  Loss: 0.0322 (0.0642)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.8468)  Acc@5: 100.0000 (99.8874)  Loss: 0.0295 (0.0592)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7975)  Acc@5: 100.0000 (99.8967)  Loss: -0.0207 (0.0592)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9943)  Acc@5: 100.0000 (99.9046)  Loss: -0.0277 (0.0534)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0301)  Acc@5: 100.0000 (99.9113)  Loss: -0.0239 (0.0507)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0613)  Acc@5: 100.0000 (99.9172)  Loss: -0.0072 (0.0487)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0885)  Acc@5: 100.0000 (99.9224)  Loss: -0.0342 (0.0456)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0395)  Acc@5: 100.0000 (99.9269)  Loss: -0.0199 (0.0430)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0304)  Acc@5: 100.0000 (99.9309)  Loss: -0.0151 (0.0399)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9895)  Acc@5: 100.0000 (99.9346)  Loss: 0.0053 (0.0383)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0149)  Acc@5: 100.0000 (99.9378)  Loss: -0.0041 (0.0373)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0083)  Acc@5: 100.0000 (99.9408)  Loss: -0.0338 (0.0356)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0305)  Acc@5: 100.0000 (99.9434)  Loss: -0.0468 (0.0320)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0238)  Acc@5: 100.0000 (99.9459)  Loss: -0.0226 (0.0311)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0436)  Acc@5: 100.0000 (99.9481)  Loss: -0.0061 (0.0295)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0867)  Acc@5: 100.0000 (99.9502)  Loss: -0.0626 (0.0266)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0785)  Acc@5: 100.0000 (99.9521)  Loss: -0.0528 (0.0253)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1633)  Acc@5: 100.0000 (99.9539)  Loss: -0.0528 (0.0216)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0641)  Acc@5: 100.0000 (99.9555)  Loss: -0.0406 (0.0213)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9287)  Acc@5: 100.0000 (99.9356)  Loss: 0.0326 (0.0221)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9061)  Acc@5: 100.0000 (99.9377)  Loss: 0.0318 (0.0212)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.8248)  Acc@5: 100.0000 (99.9397)  Loss: 0.0032 (0.0208)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.8450)  Acc@5: 100.0000 (99.9401)  Loss: -0.0132 (0.0200)  time: 0.1866  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.8450)  Acc@5: 100.0000 (99.9401)  Loss: -0.0132 (0.0200)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:11  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0772 (-0.0772)  time: 0.4214  data: 0.2202  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0772 (-0.0316)  time: 0.2127  data: 0.0204  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.0910 (-0.0318)  time: 0.1916  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5887)  Acc@5: 100.0000 (100.0000)  Loss: -0.1003 (-0.0503)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1707)  Acc@5: 100.0000 (100.0000)  Loss: -0.0884 (-0.0443)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (100.0000)  Loss: -0.0656 (-0.0474)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8484)  Acc@5: 100.0000 (100.0000)  Loss: -0.0656 (-0.0467)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7113)  Acc@5: 100.0000 (100.0000)  Loss: -0.0624 (-0.0469)  time: 0.1917  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.0859 (-0.0505)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0082)  Acc@5: 100.0000 (100.0000)  Loss: -0.0899 (-0.0522)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7104)  Acc@5: 100.0000 (100.0000)  Loss: -0.0614 (-0.0462)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7477)  Acc@5: 100.0000 (100.0000)  Loss: -0.0744 (-0.0495)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6756)  Acc@5: 100.0000 (100.0000)  Loss: -0.1026 (-0.0487)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8531)  Acc@5: 100.0000 (100.0000)  Loss: -0.1035 (-0.0520)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8723)  Acc@5: 100.0000 (100.0000)  Loss: -0.0966 (-0.0534)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9305)  Acc@5: 100.0000 (100.0000)  Loss: -0.0899 (-0.0546)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9425)  Acc@5: 100.0000 (100.0000)  Loss: -0.1021 (-0.0558)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9898)  Acc@5: 100.0000 (100.0000)  Loss: -0.0986 (-0.0567)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9972)  Acc@5: 100.0000 (100.0000)  Loss: -0.0986 (-0.0584)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9385)  Acc@5: 100.0000 (100.0000)  Loss: -0.0724 (-0.0586)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9478)  Acc@5: 100.0000 (100.0000)  Loss: -0.0568 (-0.0580)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8969)  Acc@5: 100.0000 (100.0000)  Loss: -0.0977 (-0.0587)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9355)  Acc@5: 100.0000 (100.0000)  Loss: -0.1120 (-0.0606)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9437)  Acc@5: 100.0000 (100.0000)  Loss: -0.0820 (-0.0605)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9772)  Acc@5: 100.0000 (100.0000)  Loss: -0.0739 (-0.0610)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9831)  Acc@5: 100.0000 (100.0000)  Loss: -0.1115 (-0.0626)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0125)  Acc@5: 100.0000 (100.0000)  Loss: -0.1026 (-0.0629)  time: 0.1896  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0627)  Acc@5: 100.0000 (100.0000)  Loss: -0.1063 (-0.0651)  time: 0.1895  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9760)  Acc@5: 100.0000 (100.0000)  Loss: -0.1063 (-0.0645)  time: 0.1897  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.8737)  Acc@5: 100.0000 (100.0000)  Loss: -0.0292 (-0.0633)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.8405)  Acc@5: 100.0000 (100.0000)  Loss: -0.0258 (-0.0630)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7894)  Acc@5: 100.0000 (100.0000)  Loss: -0.0465 (-0.0627)  time: 0.1900  data: 0.0001  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8035)  Acc@5: 100.0000 (100.0000)  Loss: -0.0591 (-0.0633)  time: 0.1854  data: 0.0001  max mem: 12058
Train: Epoch[3/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8035)  Acc@5: 100.0000 (100.0000)  Loss: -0.0591 (-0.0633)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:16  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1221 (-0.1221)  time: 0.4368  data: 0.2439  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1221 (-0.0833)  time: 0.2123  data: 0.0223  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1195 (-0.0770)  time: 0.1896  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5887)  Acc@5: 100.0000 (100.0000)  Loss: -0.1300 (-0.0912)  time: 0.1896  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3232)  Acc@5: 100.0000 (100.0000)  Loss: -0.1240 (-0.0878)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4069)  Acc@5: 100.0000 (100.0000)  Loss: -0.1164 (-0.0903)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5656)  Acc@5: 100.0000 (100.0000)  Loss: -0.1168 (-0.0904)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5035)  Acc@5: 100.0000 (100.0000)  Loss: -0.1089 (-0.0914)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6111)  Acc@5: 100.0000 (100.0000)  Loss: -0.1210 (-0.0947)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6264)  Acc@5: 100.0000 (100.0000)  Loss: -0.1257 (-0.0950)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5149)  Acc@5: 100.0000 (100.0000)  Loss: -0.1076 (-0.0911)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5923)  Acc@5: 100.0000 (100.0000)  Loss: -0.1197 (-0.0932)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5537)  Acc@5: 100.0000 (100.0000)  Loss: -0.1288 (-0.0931)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6641)  Acc@5: 100.0000 (100.0000)  Loss: -0.1279 (-0.0953)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7145)  Acc@5: 100.0000 (100.0000)  Loss: -0.1255 (-0.0960)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7169)  Acc@5: 100.0000 (100.0000)  Loss: -0.1197 (-0.0969)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6801)  Acc@5: 100.0000 (100.0000)  Loss: -0.1280 (-0.0971)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6842)  Acc@5: 100.0000 (100.0000)  Loss: -0.1315 (-0.0974)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7224)  Acc@5: 100.0000 (100.0000)  Loss: -0.1383 (-0.0987)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6584)  Acc@5: 100.0000 (100.0000)  Loss: -0.1142 (-0.0988)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6629)  Acc@5: 100.0000 (100.0000)  Loss: -0.0894 (-0.0978)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6671)  Acc@5: 100.0000 (100.0000)  Loss: -0.1244 (-0.0981)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6991)  Acc@5: 100.0000 (100.0000)  Loss: -0.1349 (-0.0994)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7284)  Acc@5: 100.0000 (100.0000)  Loss: -0.1219 (-0.0992)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7293)  Acc@5: 100.0000 (100.0000)  Loss: -0.1002 (-0.0993)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7052)  Acc@5: 100.0000 (100.0000)  Loss: -0.1247 (-0.1002)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7308)  Acc@5: 100.0000 (100.0000)  Loss: -0.1247 (-0.1002)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7546)  Acc@5: 100.0000 (100.0000)  Loss: -0.1303 (-0.1017)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7322)  Acc@5: 100.0000 (100.0000)  Loss: -0.1289 (-0.1013)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7328)  Acc@5: 100.0000 (100.0000)  Loss: -0.0819 (-0.1001)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6919)  Acc@5: 100.0000 (100.0000)  Loss: -0.0769 (-0.0997)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6334)  Acc@5: 100.0000 (100.0000)  Loss: -0.0926 (-0.0993)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6422)  Acc@5: 100.0000 (100.0000)  Loss: -0.0971 (-0.0996)  time: 0.1865  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6422)  Acc@5: 100.0000 (100.0000)  Loss: -0.0971 (-0.0996)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1359 (-0.1359)  time: 0.4232  data: 0.2298  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.1359 (-0.1118)  time: 0.2119  data: 0.0211  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5119)  Acc@5: 100.0000 (100.0000)  Loss: -0.1286 (-0.1016)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7903)  Acc@5: 100.0000 (100.0000)  Loss: -0.1400 (-0.1119)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6280)  Acc@5: 100.0000 (100.0000)  Loss: -0.1397 (-0.1104)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7745)  Acc@5: 100.0000 (100.0000)  Loss: -0.1315 (-0.1122)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9754)  Acc@5: 100.0000 (100.0000)  Loss: -0.1315 (-0.1128)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0317)  Acc@5: 100.0000 (100.0000)  Loss: -0.1311 (-0.1142)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0741)  Acc@5: 100.0000 (100.0000)  Loss: -0.1365 (-0.1169)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1071)  Acc@5: 100.0000 (100.0000)  Loss: -0.1406 (-0.1165)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0718)  Acc@5: 100.0000 (100.0000)  Loss: -0.1223 (-0.1137)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1554)  Acc@5: 100.0000 (100.0000)  Loss: -0.1319 (-0.1151)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1219)  Acc@5: 100.0000 (100.0000)  Loss: -0.1466 (-0.1154)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1889)  Acc@5: 100.0000 (100.0000)  Loss: -0.1411 (-0.1169)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2021)  Acc@5: 100.0000 (100.0000)  Loss: -0.1370 (-0.1173)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2550)  Acc@5: 100.0000 (100.0000)  Loss: -0.1323 (-0.1180)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2624)  Acc@5: 100.0000 (100.0000)  Loss: -0.1362 (-0.1181)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2690)  Acc@5: 100.0000 (100.0000)  Loss: -0.1378 (-0.1181)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2749)  Acc@5: 100.0000 (100.0000)  Loss: -0.1428 (-0.1193)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2801)  Acc@5: 100.0000 (100.0000)  Loss: -0.1332 (-0.1194)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2537)  Acc@5: 100.0000 (100.0000)  Loss: -0.1091 (-0.1183)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2299)  Acc@5: 100.0000 (100.0000)  Loss: -0.1367 (-0.1186)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)  Loss: -0.1461 (-0.1195)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2695)  Acc@5: 100.0000 (100.0000)  Loss: -0.1337 (-0.1193)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2739)  Acc@5: 100.0000 (100.0000)  Loss: -0.1220 (-0.1193)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2779)  Acc@5: 100.0000 (100.0000)  Loss: -0.1336 (-0.1201)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2816)  Acc@5: 100.0000 (100.0000)  Loss: -0.1369 (-0.1200)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3081)  Acc@5: 100.0000 (100.0000)  Loss: -0.1393 (-0.1211)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3105)  Acc@5: 100.0000 (100.0000)  Loss: -0.1418 (-0.1209)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3127)  Acc@5: 100.0000 (100.0000)  Loss: -0.1150 (-0.1200)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2940)  Acc@5: 100.0000 (100.0000)  Loss: -0.1150 (-0.1196)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2363)  Acc@5: 100.0000 (100.0000)  Loss: -0.1175 (-0.1192)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1204 (-0.1195)  time: 0.1861  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:00:59 (0.1916 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1204 (-0.1195)
Test: [Task 1]  [ 0/63]  eta: 0:00:21  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.9263 (0.9263)  time: 0.3347  data: 0.2153  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (98.2955)  Loss: 1.1571 (1.0982)  time: 0.1384  data: 0.0200  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 75.0000 (77.9762)  Acc@5: 100.0000 (98.8095)  Loss: 1.1571 (1.1102)  time: 0.1191  data: 0.0004  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (78.4274)  Acc@5: 100.0000 (98.9919)  Loss: 0.9552 (1.0736)  time: 0.1191  data: 0.0004  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (77.5915)  Acc@5: 100.0000 (99.0854)  Loss: 0.9667 (1.0805)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (79.0441)  Acc@5: 100.0000 (99.1422)  Loss: 0.9063 (1.0481)  time: 0.1193  data: 0.0004  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (79.9180)  Acc@5: 100.0000 (99.0779)  Loss: 0.9483 (1.0413)  time: 0.1190  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (80.1000)  Acc@5: 100.0000 (99.1000)  Loss: 0.9063 (1.0345)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1229 s / it)
* Acc@1 80.100 Acc@5 99.100 loss 1.035
Test: [Task 1]  [ 0/63]  eta: 0:00:23  ASR: 0.5000 (0.5000)  ACC: 0.5625 (0.5625)  Loss: 1.8625 (1.8625)  time: 0.3669  data: 0.2415  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.5000 (0.5341)  ACC: 0.3750 (0.4375)  Loss: 1.8022 (1.7886)  time: 0.1426  data: 0.0223  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.5625 (0.5536)  ACC: 0.4375 (0.4345)  Loss: 1.7753 (1.7448)  time: 0.1205  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.5625 (0.5423)  ACC: 0.4375 (0.4435)  Loss: 1.7785 (1.7561)  time: 0.1207  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.5000 (0.5290)  ACC: 0.4375 (0.4512)  Loss: 1.7785 (1.8007)  time: 0.1205  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.4375 (0.5159)  ACC: 0.5000 (0.4681)  Loss: 1.9683 (1.8522)  time: 0.1206  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.5000 (0.5184)  ACC: 0.5000 (0.4805)  Loss: 1.8351 (1.8057)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.5000 (0.5179)  ACC: 0.5000 (0.4782)  Loss: 1.8351 (1.8045)  time: 0.1173  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1248 s / it)
* ASR 0.518 loss 1.805
Test: [Task 2]  [ 0/63]  eta: 0:00:22  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4121 (0.4121)  time: 0.3544  data: 0.2280  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 100.0000 (96.0227)  Acc@5: 100.0000 (99.4318)  Loss: 0.2503 (0.3148)  time: 0.1399  data: 0.0211  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (94.3452)  Acc@5: 100.0000 (98.2143)  Loss: 0.3328 (0.4310)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.3871)  Loss: 0.4785 (0.4463)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (94.5122)  Acc@5: 100.0000 (98.4756)  Loss: 0.3893 (0.4270)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (94.6078)  Acc@5: 100.0000 (98.6520)  Loss: 0.3428 (0.4194)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (95.2869)  Acc@5: 100.0000 (98.8730)  Loss: 0.3060 (0.3941)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (95.4000)  Acc@5: 100.0000 (98.9000)  Loss: 0.2491 (0.3865)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 95.400 Acc@5 98.900 loss 0.387
Test: [Task 2]  [ 0/63]  eta: 0:00:20  ASR: 0.4375 (0.4375)  ACC: 0.5625 (0.5625)  Loss: 2.3053 (2.3053)  time: 0.3298  data: 0.2066  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.2500 (0.2784)  ACC: 0.6875 (0.6932)  Loss: 3.1094 (2.9420)  time: 0.1395  data: 0.0191  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.3125 (0.3512)  ACC: 0.6250 (0.6310)  Loss: 2.7031 (2.7321)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.3125 (0.3327)  ACC: 0.6250 (0.6492)  Loss: 2.6898 (2.8250)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.2500 (0.3232)  ACC: 0.6875 (0.6616)  Loss: 2.9292 (2.8370)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.2500 (0.3186)  ACC: 0.6875 (0.6654)  Loss: 2.9292 (2.8921)  time: 0.1195  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.2500 (0.2951)  ACC: 0.7500 (0.6916)  Loss: 3.1289 (2.9459)  time: 0.1194  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.2500 (0.2897)  ACC: 0.7500 (0.6954)  Loss: 3.1454 (2.9655)  time: 0.1166  data: 0.0002  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1238 s / it)
* ASR 0.290 loss 2.965
[Average accuracy till task2]	ASR: 0.4038	Acc@1: 87.7500	Loss: 2.3850	Forgetting: 0.1905	Backward: -0.1905
Train: Epoch[1/5]  [  0/313]  eta: 0:02:15  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 56.2500 (56.2500)  Loss: 2.1645 (2.1645)  time: 0.4320  data: 0.2358  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (59.6591)  Acc@5: 93.7500 (84.0909)  Loss: 1.9137 (1.9418)  time: 0.2126  data: 0.0217  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (72.3214)  Acc@5: 93.7500 (90.7738)  Loss: 1.6252 (1.7100)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.8145)  Acc@5: 100.0000 (92.7419)  Loss: 1.2332 (1.5139)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.7927)  Acc@5: 100.0000 (94.5122)  Loss: 0.8885 (1.3333)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (82.8431)  Acc@5: 100.0000 (95.5882)  Loss: 0.6566 (1.1975)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.0410)  Acc@5: 100.0000 (96.3115)  Loss: 0.5446 (1.0769)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.1796)  Acc@5: 100.0000 (96.8310)  Loss: 0.4065 (0.9772)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.8827)  Acc@5: 100.0000 (97.1451)  Loss: 0.3530 (0.9033)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.5687)  Acc@5: 100.0000 (97.4588)  Loss: 0.2708 (0.8327)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.3045)  Acc@5: 100.0000 (97.6485)  Loss: 0.2253 (0.7745)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.8514)  Acc@5: 100.0000 (97.8041)  Loss: 0.2253 (0.7262)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.1012)  Acc@5: 100.0000 (97.8822)  Loss: 0.1899 (0.6830)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5038)  Acc@5: 100.0000 (97.9962)  Loss: 0.1694 (0.6431)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.9379)  Acc@5: 100.0000 (98.1383)  Loss: 0.1670 (0.6075)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1904)  Acc@5: 100.0000 (98.2616)  Loss: 0.1595 (0.5771)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.4891)  Acc@5: 100.0000 (98.2919)  Loss: 0.1050 (0.5506)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.7529)  Acc@5: 100.0000 (98.3187)  Loss: 0.0882 (0.5260)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.9876)  Acc@5: 100.0000 (98.4116)  Loss: 0.0874 (0.5029)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.1322)  Acc@5: 100.0000 (98.4620)  Loss: 0.0600 (0.4835)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.2313)  Acc@5: 100.0000 (98.5386)  Loss: 0.0600 (0.4649)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.4100)  Acc@5: 100.0000 (98.6078)  Loss: 0.0464 (0.4485)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.6290)  Acc@5: 100.0000 (98.6708)  Loss: 0.0464 (0.4306)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.8561)  Acc@5: 100.0000 (98.7284)  Loss: 0.0461 (0.4128)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.9087)  Acc@5: 100.0000 (98.7811)  Loss: 0.0287 (0.3990)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.0319)  Acc@5: 100.0000 (98.8297)  Loss: 0.0411 (0.3855)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.2174)  Acc@5: 100.0000 (98.8745)  Loss: 0.0248 (0.3713)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.3432)  Acc@5: 100.0000 (98.8699)  Loss: 0.0354 (0.3588)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.5712)  Acc@5: 100.0000 (98.9101)  Loss: 0.0330 (0.3464)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.7191)  Acc@5: 100.0000 (98.9261)  Loss: -0.0422 (0.3344)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.7949)  Acc@5: 100.0000 (98.9618)  Loss: -0.0223 (0.3245)  time: 0.1897  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.9059)  Acc@5: 100.0000 (98.9952)  Loss: -0.0033 (0.3139)  time: 0.1894  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.8714)  Acc@5: 100.0000 (99.0016)  Loss: 0.0034 (0.3128)  time: 0.1849  data: 0.0001  max mem: 12058
Train: Epoch[1/5] Total time: 0:00:59 (0.1910 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.8714)  Acc@5: 100.0000 (99.0016)  Loss: 0.0034 (0.3128)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1294 (-0.1294)  time: 0.4649  data: 0.2733  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0227)  Acc@5: 100.0000 (100.0000)  Loss: 0.0058 (0.0197)  time: 0.2152  data: 0.0250  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4286)  Acc@5: 100.0000 (100.0000)  Loss: -0.0085 (-0.0062)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1694)  Acc@5: 100.0000 (100.0000)  Loss: -0.0305 (0.0032)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (100.0000)  Loss: -0.0286 (-0.0057)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3235)  Acc@5: 100.0000 (100.0000)  Loss: -0.0103 (-0.0036)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.3115)  Acc@5: 100.0000 (100.0000)  Loss: -0.0322 (-0.0069)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3908)  Acc@5: 100.0000 (100.0000)  Loss: -0.0447 (-0.0113)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2191)  Acc@5: 100.0000 (100.0000)  Loss: -0.0415 (-0.0089)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0852)  Acc@5: 100.0000 (100.0000)  Loss: -0.0329 (-0.0100)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1634)  Acc@5: 100.0000 (100.0000)  Loss: -0.0399 (-0.0092)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1149)  Acc@5: 100.0000 (100.0000)  Loss: -0.0294 (-0.0067)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.9711)  Acc@5: 100.0000 (99.9483)  Loss: -0.0077 (-0.0048)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.9447)  Acc@5: 100.0000 (99.9523)  Loss: -0.0208 (-0.0077)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0106)  Acc@5: 100.0000 (99.9557)  Loss: -0.0423 (-0.0098)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1093)  Acc@5: 100.0000 (99.9586)  Loss: -0.0350 (-0.0091)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0792)  Acc@5: 100.0000 (99.9224)  Loss: -0.0643 (-0.0101)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0526)  Acc@5: 100.0000 (99.9269)  Loss: -0.0683 (-0.0093)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0635)  Acc@5: 100.0000 (99.9309)  Loss: -0.0683 (-0.0102)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0406)  Acc@5: 100.0000 (99.9018)  Loss: -0.0658 (-0.0085)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0510)  Acc@5: 100.0000 (99.9067)  Loss: -0.0359 (-0.0090)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1493)  Acc@5: 100.0000 (99.9111)  Loss: -0.0628 (-0.0105)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2104)  Acc@5: 100.0000 (99.9152)  Loss: -0.0628 (-0.0122)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2933)  Acc@5: 100.0000 (99.9188)  Loss: -0.0675 (-0.0152)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2137)  Acc@5: 100.0000 (99.9222)  Loss: -0.0852 (-0.0158)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.2151)  Acc@5: 100.0000 (99.9253)  Loss: -0.0480 (-0.0167)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3123)  Acc@5: 100.0000 (99.9282)  Loss: -0.0480 (-0.0187)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3330)  Acc@5: 100.0000 (99.8847)  Loss: -0.0655 (-0.0196)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4190)  Acc@5: 100.0000 (99.8888)  Loss: -0.0655 (-0.0214)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4777)  Acc@5: 100.0000 (99.8926)  Loss: -0.0997 (-0.0232)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5116)  Acc@5: 100.0000 (99.8962)  Loss: -0.0900 (-0.0241)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5635)  Acc@5: 100.0000 (99.8995)  Loss: -0.0786 (-0.0256)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5655)  Acc@5: 100.0000 (99.9002)  Loss: -0.0778 (-0.0254)  time: 0.1857  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:00:59 (0.1912 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5655)  Acc@5: 100.0000 (99.9002)  Loss: -0.0778 (-0.0254)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1571 (-0.1571)  time: 0.4299  data: 0.2369  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: -0.0670 (-0.0523)  time: 0.2121  data: 0.0217  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6190)  Acc@5: 100.0000 (100.0000)  Loss: -0.0735 (-0.0686)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1774)  Acc@5: 100.0000 (100.0000)  Loss: -0.0916 (-0.0580)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (100.0000)  Loss: -0.0867 (-0.0644)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3039)  Acc@5: 100.0000 (100.0000)  Loss: -0.0739 (-0.0640)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2336)  Acc@5: 100.0000 (100.0000)  Loss: -0.0739 (-0.0655)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3592)  Acc@5: 100.0000 (100.0000)  Loss: -0.0895 (-0.0672)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2994)  Acc@5: 100.0000 (100.0000)  Loss: -0.0895 (-0.0663)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2527)  Acc@5: 100.0000 (100.0000)  Loss: -0.0728 (-0.0670)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2153)  Acc@5: 100.0000 (100.0000)  Loss: -0.0880 (-0.0649)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1847)  Acc@5: 100.0000 (100.0000)  Loss: -0.0810 (-0.0627)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1074)  Acc@5: 100.0000 (100.0000)  Loss: -0.0594 (-0.0600)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1374)  Acc@5: 100.0000 (100.0000)  Loss: -0.0742 (-0.0621)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1188)  Acc@5: 100.0000 (100.0000)  Loss: -0.0872 (-0.0632)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1440)  Acc@5: 100.0000 (100.0000)  Loss: -0.0872 (-0.0613)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2826)  Acc@5: 100.0000 (100.0000)  Loss: -0.1022 (-0.0621)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2222)  Acc@5: 100.0000 (100.0000)  Loss: -0.1063 (-0.0605)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2376)  Acc@5: 100.0000 (100.0000)  Loss: -0.1089 (-0.0608)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1531)  Acc@5: 100.0000 (99.9673)  Loss: -0.0785 (-0.0584)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2015)  Acc@5: 100.0000 (99.9689)  Loss: -0.0712 (-0.0589)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2749)  Acc@5: 100.0000 (99.9704)  Loss: -0.0949 (-0.0600)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3133)  Acc@5: 100.0000 (99.9717)  Loss: -0.1016 (-0.0609)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3755)  Acc@5: 100.0000 (99.9729)  Loss: -0.1016 (-0.0630)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3548)  Acc@5: 100.0000 (99.9741)  Loss: -0.1131 (-0.0636)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3855)  Acc@5: 100.0000 (99.9751)  Loss: -0.0894 (-0.0641)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4377)  Acc@5: 100.0000 (99.9761)  Loss: -0.0894 (-0.0655)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4862)  Acc@5: 100.0000 (99.9769)  Loss: -0.1024 (-0.0658)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5756)  Acc@5: 100.0000 (99.9778)  Loss: -0.1024 (-0.0669)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5945)  Acc@5: 100.0000 (99.9785)  Loss: -0.1254 (-0.0681)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5914)  Acc@5: 100.0000 (99.9792)  Loss: -0.1248 (-0.0687)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6085)  Acc@5: 100.0000 (99.9799)  Loss: -0.1041 (-0.0695)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6238)  Acc@5: 100.0000 (99.9800)  Loss: -0.0987 (-0.0695)  time: 0.1863  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:00:59 (0.1913 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6238)  Acc@5: 100.0000 (99.9800)  Loss: -0.0987 (-0.0695)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1631 (-0.1631)  time: 0.4383  data: 0.2445  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0964 (-0.0862)  time: 0.2130  data: 0.0224  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.1031 (-0.0959)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9839)  Acc@5: 100.0000 (100.0000)  Loss: -0.1078 (-0.0854)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1142 (-0.0906)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1618)  Acc@5: 100.0000 (100.0000)  Loss: -0.1137 (-0.0910)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2582)  Acc@5: 100.0000 (100.0000)  Loss: -0.1060 (-0.0920)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2394)  Acc@5: 100.0000 (100.0000)  Loss: -0.1089 (-0.0930)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2253)  Acc@5: 100.0000 (100.0000)  Loss: -0.1075 (-0.0930)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.0970 (-0.0935)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0817)  Acc@5: 100.0000 (100.0000)  Loss: -0.1089 (-0.0911)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0293)  Acc@5: 100.0000 (100.0000)  Loss: -0.1089 (-0.0898)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8822)  Acc@5: 100.0000 (100.0000)  Loss: -0.0947 (-0.0874)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0439)  Acc@5: 100.0000 (100.0000)  Loss: -0.0947 (-0.0892)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9610)  Acc@5: 100.0000 (100.0000)  Loss: -0.1240 (-0.0899)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9305)  Acc@5: 100.0000 (100.0000)  Loss: -0.1120 (-0.0875)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0590)  Acc@5: 100.0000 (100.0000)  Loss: -0.1244 (-0.0885)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9532)  Acc@5: 100.0000 (100.0000)  Loss: -0.1244 (-0.0871)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9972)  Acc@5: 100.0000 (100.0000)  Loss: -0.1319 (-0.0871)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9385)  Acc@5: 100.0000 (100.0000)  Loss: -0.1035 (-0.0853)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9789)  Acc@5: 100.0000 (100.0000)  Loss: -0.1019 (-0.0858)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0154)  Acc@5: 100.0000 (100.0000)  Loss: -0.1136 (-0.0869)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0486)  Acc@5: 100.0000 (100.0000)  Loss: -0.1153 (-0.0874)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1331)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.0891)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1328)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.0897)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1574)  Acc@5: 100.0000 (100.0000)  Loss: -0.1101 (-0.0898)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2280)  Acc@5: 100.0000 (100.0000)  Loss: -0.1164 (-0.0910)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2703)  Acc@5: 100.0000 (100.0000)  Loss: -0.1166 (-0.0911)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3319)  Acc@5: 100.0000 (100.0000)  Loss: -0.1180 (-0.0919)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3677)  Acc@5: 100.0000 (100.0000)  Loss: -0.1344 (-0.0929)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3804)  Acc@5: 100.0000 (100.0000)  Loss: -0.1388 (-0.0935)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3923)  Acc@5: 100.0000 (100.0000)  Loss: -0.1215 (-0.0940)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4026)  Acc@5: 100.0000 (100.0000)  Loss: -0.1112 (-0.0940)  time: 0.1868  data: 0.0003  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4026)  Acc@5: 100.0000 (100.0000)  Loss: -0.1112 (-0.0940)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:22  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1670 (-0.1670)  time: 0.4541  data: 0.2608  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1113 (-0.1114)  time: 0.2148  data: 0.0240  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4048)  Acc@5: 100.0000 (100.0000)  Loss: -0.1206 (-0.1157)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9919)  Acc@5: 100.0000 (100.0000)  Loss: -0.1212 (-0.1049)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9329)  Acc@5: 100.0000 (100.0000)  Loss: -0.1250 (-0.1089)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)  Loss: -0.1244 (-0.1095)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9754)  Acc@5: 100.0000 (100.0000)  Loss: -0.1217 (-0.1107)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9437)  Acc@5: 100.0000 (100.0000)  Loss: -0.1217 (-0.1111)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9198)  Acc@5: 100.0000 (100.0000)  Loss: -0.1163 (-0.1111)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9011)  Acc@5: 100.0000 (100.0000)  Loss: -0.1212 (-0.1116)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8243)  Acc@5: 100.0000 (100.0000)  Loss: -0.1243 (-0.1093)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7613)  Acc@5: 100.0000 (100.0000)  Loss: -0.1243 (-0.1082)  time: 0.1920  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6570)  Acc@5: 100.0000 (100.0000)  Loss: -0.1117 (-0.1059)  time: 0.1917  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7595)  Acc@5: 100.0000 (100.0000)  Loss: -0.1117 (-0.1075)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6702)  Acc@5: 100.0000 (100.0000)  Loss: -0.1328 (-0.1078)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6341)  Acc@5: 100.0000 (100.0000)  Loss: -0.1246 (-0.1052)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7189)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.1063)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6477)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.1052)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6533)  Acc@5: 100.0000 (100.0000)  Loss: -0.1383 (-0.1050)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6584)  Acc@5: 100.0000 (100.0000)  Loss: -0.1209 (-0.1039)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6940)  Acc@5: 100.0000 (100.0000)  Loss: -0.1192 (-0.1043)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7263)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.1050)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7274)  Acc@5: 100.0000 (100.0000)  Loss: -0.1251 (-0.1053)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7825)  Acc@5: 100.0000 (100.0000)  Loss: -0.1368 (-0.1067)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7811)  Acc@5: 100.0000 (100.0000)  Loss: -0.1382 (-0.1073)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7799)  Acc@5: 100.0000 (100.0000)  Loss: -0.1314 (-0.1072)  time: 0.1896  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8266)  Acc@5: 100.0000 (100.0000)  Loss: -0.1290 (-0.1081)  time: 0.1897  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8469)  Acc@5: 100.0000 (100.0000)  Loss: -0.1294 (-0.1081)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8879)  Acc@5: 100.0000 (100.0000)  Loss: -0.1295 (-0.1087)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9261)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1096)  time: 0.1897  data: 0.0001  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9203)  Acc@5: 100.0000 (100.0000)  Loss: -0.1454 (-0.1101)  time: 0.1894  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9148)  Acc@5: 100.0000 (100.0000)  Loss: -0.1309 (-0.1104)  time: 0.1893  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9217)  Acc@5: 100.0000 (100.0000)  Loss: -0.1257 (-0.1105)  time: 0.1847  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:01:00 (0.1917 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9217)  Acc@5: 100.0000 (100.0000)  Loss: -0.1257 (-0.1105)
Test: [Task 1]  [ 0/63]  eta: 0:00:23  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.9957 (0.9957)  time: 0.3794  data: 0.2561  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 68.7500 (69.3182)  Acc@5: 100.0000 (97.1591)  Loss: 1.2327 (1.2255)  time: 0.1422  data: 0.0235  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 68.7500 (69.0476)  Acc@5: 100.0000 (97.6190)  Loss: 1.2397 (1.2510)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 68.7500 (69.9597)  Acc@5: 100.0000 (98.1855)  Loss: 1.1424 (1.2162)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 68.7500 (70.2744)  Acc@5: 100.0000 (98.3232)  Loss: 1.1424 (1.2086)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 68.7500 (70.7108)  Acc@5: 100.0000 (98.5294)  Loss: 1.1295 (1.1866)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 68.7500 (71.3115)  Acc@5: 100.0000 (98.5656)  Loss: 1.0782 (1.1686)  time: 0.1186  data: 0.0002  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 68.7500 (71.1000)  Acc@5: 100.0000 (98.6000)  Loss: 1.0458 (1.1676)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1233 s / it)
* Acc@1 71.100 Acc@5 98.600 loss 1.168
Test: [Task 1]  [ 0/63]  eta: 0:00:22  ASR: 0.5000 (0.5000)  ACC: 0.5625 (0.5625)  Loss: 2.0941 (2.0941)  time: 0.3587  data: 0.2325  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.3750 (0.4148)  ACC: 0.4375 (0.4602)  Loss: 2.0941 (2.1545)  time: 0.1418  data: 0.0214  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.3750 (0.4226)  ACC: 0.4375 (0.4613)  Loss: 2.0472 (2.1024)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.4375 (0.4395)  ACC: 0.4375 (0.4577)  Loss: 2.0709 (2.0919)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.5000 (0.4360)  ACC: 0.4375 (0.4604)  Loss: 2.1371 (2.1628)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.3750 (0.4277)  ACC: 0.5000 (0.4620)  Loss: 2.2779 (2.2198)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.4375 (0.4365)  ACC: 0.5000 (0.4672)  Loss: 2.1660 (2.1644)  time: 0.1195  data: 0.0002  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.4375 (0.4365)  ACC: 0.4375 (0.4633)  Loss: 2.1354 (2.1621)  time: 0.1167  data: 0.0002  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1239 s / it)
* ASR 0.437 loss 2.162
Test: [Task 2]  [ 0/63]  eta: 0:00:23  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4159 (0.4159)  time: 0.3652  data: 0.2471  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (98.8636)  Loss: 0.3006 (0.3909)  time: 0.1407  data: 0.0227  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (91.9643)  Acc@5: 100.0000 (97.6190)  Loss: 0.4364 (0.5132)  time: 0.1183  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (91.5323)  Acc@5: 100.0000 (97.3790)  Loss: 0.5236 (0.5189)  time: 0.1184  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.0732)  Acc@5: 100.0000 (97.7134)  Loss: 0.4647 (0.4987)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (92.4020)  Acc@5: 100.0000 (98.0392)  Loss: 0.3922 (0.4887)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (92.8279)  Acc@5: 100.0000 (98.3607)  Loss: 0.3401 (0.4647)  time: 0.1184  data: 0.0002  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (92.9000)  Acc@5: 100.0000 (98.4000)  Loss: 0.3101 (0.4551)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1227 s / it)
* Acc@1 92.900 Acc@5 98.400 loss 0.455
Test: [Task 2]  [ 0/63]  eta: 0:00:23  ASR: 0.4375 (0.4375)  ACC: 0.5625 (0.5625)  Loss: 2.6037 (2.6037)  time: 0.3655  data: 0.2407  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.2500 (0.2614)  ACC: 0.7500 (0.7159)  Loss: 3.4002 (3.2317)  time: 0.1427  data: 0.0222  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.2500 (0.3095)  ACC: 0.6875 (0.6637)  Loss: 3.0786 (2.9916)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.3125 (0.2984)  ACC: 0.6250 (0.6734)  Loss: 3.0418 (3.0724)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.2500 (0.2912)  ACC: 0.6875 (0.6829)  Loss: 3.1251 (3.0811)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.2500 (0.2880)  ACC: 0.6875 (0.6826)  Loss: 3.1251 (3.1286)  time: 0.1199  data: 0.0004  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.2500 (0.2766)  ACC: 0.7500 (0.6957)  Loss: 3.3306 (3.1811)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.2708)  ACC: 0.7500 (0.7014)  Loss: 3.3897 (3.1996)  time: 0.1169  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1245 s / it)
* ASR 0.271 loss 3.200
Test: [Task 3]  [ 0/63]  eta: 0:00:20  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1097 (0.1097)  time: 0.3328  data: 0.2135  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.8636)  Loss: 0.2446 (0.3385)  time: 0.1380  data: 0.0198  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (93.4524)  Acc@5: 100.0000 (98.8095)  Loss: 0.2446 (0.3502)  time: 0.1186  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (94.1532)  Acc@5: 100.0000 (99.1935)  Loss: 0.2530 (0.3288)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (93.4451)  Acc@5: 100.0000 (99.0854)  Loss: 0.2684 (0.3439)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.3824)  Acc@5: 100.0000 (98.8971)  Loss: 0.3492 (0.3558)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (92.8279)  Acc@5: 100.0000 (99.0779)  Loss: 0.3492 (0.3652)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (92.7000)  Acc@5: 100.0000 (99.1000)  Loss: 0.3957 (0.3717)  time: 0.1160  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 92.700 Acc@5 99.100 loss 0.372
Test: [Task 3]  [ 0/63]  eta: 0:00:25  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  Loss: 3.9550 (3.9550)  time: 0.4037  data: 0.2815  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.2386)  ACC: 0.7500 (0.7159)  Loss: 4.0622 (3.9474)  time: 0.1466  data: 0.0260  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.2173)  ACC: 0.7500 (0.7411)  Loss: 4.0962 (4.0455)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.2157)  ACC: 0.7500 (0.7379)  Loss: 4.1307 (4.1271)  time: 0.1201  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.2500 (0.2165)  ACC: 0.7500 (0.7393)  Loss: 4.0427 (4.0847)  time: 0.1198  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.2500 (0.2243)  ACC: 0.7500 (0.7341)  Loss: 4.1282 (4.0517)  time: 0.1199  data: 0.0004  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.2500 (0.2234)  ACC: 0.7500 (0.7336)  Loss: 4.1282 (4.0539)  time: 0.1200  data: 0.0004  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.2500 (0.2242)  ACC: 0.7500 (0.7321)  Loss: 4.0275 (4.0421)  time: 0.1171  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1250 s / it)
* ASR 0.224 loss 4.042
[Average accuracy till task3]	ASR: 0.3105	Acc@1: 85.5667	Loss: 3.1346	Forgetting: 0.1453	Backward: -0.1453
Train: Epoch[1/5]  [  0/313]  eta: 0:02:22  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 56.2500 (56.2500)  Loss: 2.1580 (2.1580)  time: 0.4553  data: 0.2619  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 50.0000 (53.9773)  Acc@5: 93.7500 (85.7955)  Loss: 2.0038 (1.9347)  time: 0.2150  data: 0.0241  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.8333)  Acc@5: 93.7500 (91.3690)  Loss: 1.6266 (1.6835)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.2177)  Acc@5: 100.0000 (93.7500)  Loss: 1.1717 (1.4657)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.2500)  Acc@5: 100.0000 (95.2744)  Loss: 0.8854 (1.2873)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (84.5588)  Acc@5: 100.0000 (96.2010)  Loss: 0.5454 (1.1250)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (86.2705)  Acc@5: 100.0000 (96.7213)  Loss: 0.3910 (1.0053)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (87.7641)  Acc@5: 100.0000 (97.0951)  Loss: 0.3118 (0.9018)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (88.9660)  Acc@5: 100.0000 (97.4537)  Loss: 0.1914 (0.8183)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (89.9038)  Acc@5: 100.0000 (97.7335)  Loss: 0.1528 (0.7454)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (90.3465)  Acc@5: 100.0000 (97.9579)  Loss: 0.1410 (0.6880)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.0473)  Acc@5: 100.0000 (98.1419)  Loss: 0.1126 (0.6348)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.6322)  Acc@5: 100.0000 (98.2955)  Loss: 0.1019 (0.5915)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.0324)  Acc@5: 100.0000 (98.4256)  Loss: 0.0979 (0.5523)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.2429)  Acc@5: 100.0000 (98.4486)  Loss: 0.0885 (0.5228)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.5083)  Acc@5: 100.0000 (98.5513)  Loss: 0.0823 (0.4931)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.8960)  Acc@5: 100.0000 (98.6413)  Loss: 0.0483 (0.4649)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.0556)  Acc@5: 100.0000 (98.7208)  Loss: 0.0508 (0.4418)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.2666)  Acc@5: 100.0000 (98.7569)  Loss: 0.0655 (0.4207)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.4555)  Acc@5: 100.0000 (98.8220)  Loss: 0.0262 (0.4004)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.5634)  Acc@5: 100.0000 (98.8806)  Loss: 0.0237 (0.3832)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.7796)  Acc@5: 100.0000 (98.9336)  Loss: -0.0067 (0.3646)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.8631)  Acc@5: 100.0000 (98.9819)  Loss: -0.0232 (0.3498)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.9123)  Acc@5: 100.0000 (99.0260)  Loss: 0.0184 (0.3373)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.0871)  Acc@5: 100.0000 (99.0664)  Loss: -0.0393 (0.3211)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.2231)  Acc@5: 100.0000 (99.1036)  Loss: -0.0605 (0.3074)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.3247)  Acc@5: 100.0000 (99.1379)  Loss: -0.0337 (0.2958)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.3266)  Acc@5: 100.0000 (99.1697)  Loss: -0.0086 (0.2863)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.4840)  Acc@5: 100.0000 (99.1993)  Loss: -0.0126 (0.2749)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.5447)  Acc@5: 100.0000 (99.2268)  Loss: -0.0281 (0.2657)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.6429)  Acc@5: 100.0000 (99.2525)  Loss: -0.0307 (0.2557)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.7548)  Acc@5: 100.0000 (99.2765)  Loss: -0.0737 (0.2460)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.7484)  Acc@5: 100.0000 (99.2812)  Loss: -0.0737 (0.2443)  time: 0.1866  data: 0.0003  max mem: 12058
Train: Epoch[1/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.7484)  Acc@5: 100.0000 (99.2812)  Loss: -0.0737 (0.2443)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:22  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1372 (-0.1372)  time: 0.4563  data: 0.2638  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0561 (-0.0667)  time: 0.2146  data: 0.0242  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.0561 (-0.0562)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7823)  Acc@5: 100.0000 (100.0000)  Loss: -0.0571 (-0.0538)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (100.0000)  Loss: -0.0673 (-0.0462)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.1156 (-0.0615)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7459)  Acc@5: 100.0000 (100.0000)  Loss: -0.1271 (-0.0588)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7993)  Acc@5: 100.0000 (100.0000)  Loss: -0.0983 (-0.0615)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0710)  Acc@5: 100.0000 (100.0000)  Loss: -0.1330 (-0.0690)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1456)  Acc@5: 100.0000 (100.0000)  Loss: -0.1330 (-0.0718)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2054)  Acc@5: 100.0000 (100.0000)  Loss: -0.0959 (-0.0729)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3108)  Acc@5: 100.0000 (100.0000)  Loss: -0.1145 (-0.0773)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.1184 (-0.0778)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3779)  Acc@5: 100.0000 (100.0000)  Loss: -0.1160 (-0.0800)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1826)  Acc@5: 100.0000 (99.9557)  Loss: -0.0972 (-0.0760)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2202)  Acc@5: 100.0000 (99.9586)  Loss: -0.0599 (-0.0773)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2919)  Acc@5: 100.0000 (99.9612)  Loss: -0.1118 (-0.0787)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0994)  Acc@5: 100.0000 (99.9635)  Loss: -0.0882 (-0.0770)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (98.0663)  Acc@5: 100.0000 (99.9309)  Loss: -0.0727 (-0.0754)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0366)  Acc@5: 100.0000 (99.9346)  Loss: -0.0881 (-0.0756)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0410)  Acc@5: 100.0000 (99.9378)  Loss: -0.0905 (-0.0751)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1043)  Acc@5: 100.0000 (99.9408)  Loss: -0.1188 (-0.0769)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1335)  Acc@5: 100.0000 (99.9434)  Loss: -0.1188 (-0.0767)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0790)  Acc@5: 100.0000 (99.9459)  Loss: -0.0893 (-0.0749)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1328)  Acc@5: 100.0000 (99.9481)  Loss: -0.1249 (-0.0773)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1823)  Acc@5: 100.0000 (99.9502)  Loss: -0.1322 (-0.0786)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1801)  Acc@5: 100.0000 (99.9521)  Loss: -0.1104 (-0.0788)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0858)  Acc@5: 100.0000 (99.9539)  Loss: -0.0998 (-0.0777)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1094)  Acc@5: 100.0000 (99.9555)  Loss: -0.1078 (-0.0789)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1529)  Acc@5: 100.0000 (99.9570)  Loss: -0.1167 (-0.0792)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1935)  Acc@5: 100.0000 (99.9585)  Loss: -0.1167 (-0.0800)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2114)  Acc@5: 100.0000 (99.9598)  Loss: -0.1351 (-0.0809)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2228)  Acc@5: 100.0000 (99.9601)  Loss: -0.1351 (-0.0810)  time: 0.1861  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2228)  Acc@5: 100.0000 (99.9601)  Loss: -0.1351 (-0.0810)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:18  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1636 (-0.1636)  time: 0.4422  data: 0.2478  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1180 (-0.1198)  time: 0.2137  data: 0.0228  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1071)  Acc@5: 100.0000 (100.0000)  Loss: -0.1147 (-0.1101)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1935)  Acc@5: 100.0000 (100.0000)  Loss: -0.1169 (-0.1107)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7805)  Acc@5: 100.0000 (100.0000)  Loss: -0.1207 (-0.1032)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)  Loss: -0.1416 (-0.1130)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7705)  Acc@5: 100.0000 (100.0000)  Loss: -0.1583 (-0.1095)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7676)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.1106)  time: 0.1921  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9198)  Acc@5: 100.0000 (100.0000)  Loss: -0.1514 (-0.1158)  time: 0.1923  data: 0.0004  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9698)  Acc@5: 100.0000 (100.0000)  Loss: -0.1554 (-0.1173)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9480)  Acc@5: 100.0000 (100.0000)  Loss: -0.1405 (-0.1184)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0428)  Acc@5: 100.0000 (100.0000)  Loss: -0.1462 (-0.1214)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9669)  Acc@5: 100.0000 (100.0000)  Loss: -0.1459 (-0.1212)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9981)  Acc@5: 100.0000 (100.0000)  Loss: -0.1422 (-0.1224)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8475)  Acc@5: 100.0000 (100.0000)  Loss: -0.1168 (-0.1186)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8411)  Acc@5: 100.0000 (100.0000)  Loss: -0.1103 (-0.1193)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8742)  Acc@5: 100.0000 (100.0000)  Loss: -0.1457 (-0.1205)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7573)  Acc@5: 100.0000 (100.0000)  Loss: -0.1320 (-0.1188)  time: 0.1896  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7224)  Acc@5: 100.0000 (100.0000)  Loss: -0.1204 (-0.1169)  time: 0.1892  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7238)  Acc@5: 100.0000 (100.0000)  Loss: -0.1245 (-0.1169)  time: 0.1897  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7251)  Acc@5: 100.0000 (100.0000)  Loss: -0.1245 (-0.1165)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7559)  Acc@5: 100.0000 (100.0000)  Loss: -0.1534 (-0.1176)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7839)  Acc@5: 100.0000 (100.0000)  Loss: -0.1494 (-0.1173)  time: 0.1897  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7284)  Acc@5: 100.0000 (100.0000)  Loss: -0.1191 (-0.1156)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7811)  Acc@5: 100.0000 (100.0000)  Loss: -0.1468 (-0.1171)  time: 0.1900  data: 0.0001  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8048)  Acc@5: 100.0000 (100.0000)  Loss: -0.1494 (-0.1179)  time: 0.1900  data: 0.0001  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7787)  Acc@5: 100.0000 (100.0000)  Loss: -0.1332 (-0.1178)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7315)  Acc@5: 100.0000 (100.0000)  Loss: -0.1263 (-0.1168)  time: 0.1902  data: 0.0001  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7544)  Acc@5: 100.0000 (100.0000)  Loss: -0.1365 (-0.1175)  time: 0.1901  data: 0.0001  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7758)  Acc@5: 100.0000 (100.0000)  Loss: -0.1345 (-0.1176)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8164)  Acc@5: 100.0000 (100.0000)  Loss: -0.1345 (-0.1179)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8344)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1183)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1184)  time: 0.1855  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:00:59 (0.1913 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1184)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1695 (-0.1695)  time: 0.4181  data: 0.2237  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1398 (-0.1431)  time: 0.2115  data: 0.0205  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7024)  Acc@5: 100.0000 (100.0000)  Loss: -0.1354 (-0.1331)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7984)  Acc@5: 100.0000 (100.0000)  Loss: -0.1354 (-0.1344)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6951)  Acc@5: 100.0000 (100.0000)  Loss: -0.1392 (-0.1308)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7549)  Acc@5: 100.0000 (100.0000)  Loss: -0.1579 (-0.1373)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4877)  Acc@5: 100.0000 (100.0000)  Loss: -0.1634 (-0.1332)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4718)  Acc@5: 100.0000 (100.0000)  Loss: -0.1425 (-0.1333)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5370)  Acc@5: 100.0000 (100.0000)  Loss: -0.1565 (-0.1371)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5192)  Acc@5: 100.0000 (100.0000)  Loss: -0.1652 (-0.1379)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5668)  Acc@5: 100.0000 (100.0000)  Loss: -0.1511 (-0.1391)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6059)  Acc@5: 100.0000 (100.0000)  Loss: -0.1564 (-0.1411)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5868)  Acc@5: 100.0000 (100.0000)  Loss: -0.1533 (-0.1408)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5706)  Acc@5: 100.0000 (100.0000)  Loss: -0.1501 (-0.1415)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4238)  Acc@5: 100.0000 (100.0000)  Loss: -0.1442 (-0.1383)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3791)  Acc@5: 100.0000 (100.0000)  Loss: -0.1364 (-0.1386)  time: 0.1911  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4177)  Acc@5: 100.0000 (100.0000)  Loss: -0.1513 (-0.1395)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4152)  Acc@5: 100.0000 (100.0000)  Loss: -0.1444 (-0.1384)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3785)  Acc@5: 100.0000 (100.0000)  Loss: -0.1401 (-0.1367)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3783)  Acc@5: 100.0000 (100.0000)  Loss: -0.1520 (-0.1368)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3781)  Acc@5: 100.0000 (100.0000)  Loss: -0.1535 (-0.1368)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3780)  Acc@5: 100.0000 (100.0000)  Loss: -0.1627 (-0.1377)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3778)  Acc@5: 100.0000 (100.0000)  Loss: -0.1571 (-0.1374)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3236)  Acc@5: 100.0000 (100.0000)  Loss: -0.1495 (-0.1359)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3517)  Acc@5: 100.0000 (100.0000)  Loss: -0.1521 (-0.1369)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3775)  Acc@5: 100.0000 (100.0000)  Loss: -0.1568 (-0.1375)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3295)  Acc@5: 100.0000 (100.0000)  Loss: -0.1472 (-0.1372)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3081)  Acc@5: 100.0000 (100.0000)  Loss: -0.1472 (-0.1366)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3327)  Acc@5: 100.0000 (100.0000)  Loss: -0.1489 (-0.1371)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3342)  Acc@5: 100.0000 (100.0000)  Loss: -0.1476 (-0.1372)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3563)  Acc@5: 100.0000 (100.0000)  Loss: -0.1476 (-0.1373)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3770)  Acc@5: 100.0000 (100.0000)  Loss: -0.1521 (-0.1377)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3810)  Acc@5: 100.0000 (100.0000)  Loss: -0.1521 (-0.1377)  time: 0.1856  data: 0.0001  max mem: 12058
Train: Epoch[4/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3810)  Acc@5: 100.0000 (100.0000)  Loss: -0.1521 (-0.1377)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1718 (-0.1718)  time: 0.3793  data: 0.1852  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1566 (-0.1565)  time: 0.2072  data: 0.0170  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1494 (-0.1475)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1494 (-0.1482)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8476)  Acc@5: 100.0000 (100.0000)  Loss: -0.1471 (-0.1457)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8775)  Acc@5: 100.0000 (100.0000)  Loss: -0.1654 (-0.1502)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5902)  Acc@5: 100.0000 (100.0000)  Loss: -0.1659 (-0.1466)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6479)  Acc@5: 100.0000 (100.0000)  Loss: -0.1534 (-0.1469)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6914)  Acc@5: 100.0000 (100.0000)  Loss: -0.1637 (-0.1497)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7253)  Acc@5: 100.0000 (100.0000)  Loss: -0.1669 (-0.1501)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)  Loss: -0.1560 (-0.1511)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7748)  Acc@5: 100.0000 (100.0000)  Loss: -0.1628 (-0.1525)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7934)  Acc@5: 100.0000 (100.0000)  Loss: -0.1577 (-0.1521)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8092)  Acc@5: 100.0000 (100.0000)  Loss: -0.1534 (-0.1525)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6897)  Acc@5: 100.0000 (100.0000)  Loss: -0.1501 (-0.1498)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6275)  Acc@5: 100.0000 (100.0000)  Loss: -0.1488 (-0.1500)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6506)  Acc@5: 100.0000 (100.0000)  Loss: -0.1601 (-0.1507)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6345)  Acc@5: 100.0000 (100.0000)  Loss: -0.1557 (-0.1500)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6202)  Acc@5: 100.0000 (100.0000)  Loss: -0.1487 (-0.1487)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6401)  Acc@5: 100.0000 (100.0000)  Loss: -0.1554 (-0.1489)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6269)  Acc@5: 100.0000 (100.0000)  Loss: -0.1604 (-0.1491)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6149)  Acc@5: 100.0000 (100.0000)  Loss: -0.1676 (-0.1497)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6041)  Acc@5: 100.0000 (100.0000)  Loss: -0.1618 (-0.1495)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5400)  Acc@5: 100.0000 (100.0000)  Loss: -0.1545 (-0.1483)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5591)  Acc@5: 100.0000 (100.0000)  Loss: -0.1573 (-0.1490)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5767)  Acc@5: 100.0000 (100.0000)  Loss: -0.1617 (-0.1494)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5929)  Acc@5: 100.0000 (100.0000)  Loss: -0.1576 (-0.1491)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6079)  Acc@5: 100.0000 (100.0000)  Loss: -0.1554 (-0.1488)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6219)  Acc@5: 100.0000 (100.0000)  Loss: -0.1564 (-0.1492)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6349)  Acc@5: 100.0000 (100.0000)  Loss: -0.1553 (-0.1493)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6470)  Acc@5: 100.0000 (100.0000)  Loss: -0.1548 (-0.1493)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6584)  Acc@5: 100.0000 (100.0000)  Loss: -0.1590 (-0.1496)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6605)  Acc@5: 100.0000 (100.0000)  Loss: -0.1590 (-0.1496)  time: 0.1859  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:00:59 (0.1911 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6605)  Acc@5: 100.0000 (100.0000)  Loss: -0.1590 (-0.1496)
Test: [Task 1]  [ 0/63]  eta: 0:00:21  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 1.0993 (1.0993)  time: 0.3449  data: 0.2255  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 68.7500 (69.3182)  Acc@5: 100.0000 (97.7273)  Loss: 1.2184 (1.2540)  time: 0.1391  data: 0.0208  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 68.7500 (69.0476)  Acc@5: 100.0000 (97.6190)  Loss: 1.2184 (1.2865)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 68.7500 (70.5645)  Acc@5: 100.0000 (97.9839)  Loss: 1.1513 (1.2436)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 68.7500 (70.1220)  Acc@5: 100.0000 (98.1707)  Loss: 1.2250 (1.2456)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 68.7500 (70.7108)  Acc@5: 100.0000 (98.4069)  Loss: 1.2037 (1.2191)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 68.7500 (71.3115)  Acc@5: 100.0000 (98.3607)  Loss: 1.1444 (1.2082)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 68.7500 (71.2000)  Acc@5: 100.0000 (98.4000)  Loss: 1.1093 (1.2049)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1225 s / it)
* Acc@1 71.200 Acc@5 98.400 loss 1.205
Test: [Task 1]  [ 0/63]  eta: 0:00:19  ASR: 0.4375 (0.4375)  ACC: 0.5625 (0.5625)  Loss: 2.1699 (2.1699)  time: 0.3113  data: 0.1842  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.3750 (0.3864)  ACC: 0.5000 (0.5000)  Loss: 2.2096 (2.2351)  time: 0.1378  data: 0.0170  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.3750 (0.3958)  ACC: 0.4375 (0.4643)  Loss: 2.2321 (2.2098)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.4375 (0.4133)  ACC: 0.3750 (0.4617)  Loss: 2.1993 (2.1824)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.4375 (0.4040)  ACC: 0.5000 (0.4680)  Loss: 2.2194 (2.2498)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.3750 (0.3946)  ACC: 0.5000 (0.4779)  Loss: 2.3827 (2.3102)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.3750 (0.4006)  ACC: 0.5000 (0.4846)  Loss: 2.2432 (2.2660)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.3750 (0.3998)  ACC: 0.5000 (0.4841)  Loss: 2.2432 (2.2698)  time: 0.1172  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1237 s / it)
* ASR 0.400 loss 2.270
Test: [Task 2]  [ 0/63]  eta: 0:00:21  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.5372 (0.5372)  time: 0.3358  data: 0.2103  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.2955)  Loss: 0.4763 (0.4903)  time: 0.1386  data: 0.0195  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (87.7976)  Acc@5: 100.0000 (97.3214)  Loss: 0.5187 (0.5753)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (97.1774)  Loss: 0.5939 (0.5721)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (88.8720)  Acc@5: 100.0000 (97.5610)  Loss: 0.5041 (0.5517)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (88.6029)  Acc@5: 100.0000 (97.6716)  Loss: 0.5000 (0.5548)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (89.5492)  Acc@5: 100.0000 (98.0533)  Loss: 0.3938 (0.5239)  time: 0.1185  data: 0.0002  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (89.8000)  Acc@5: 100.0000 (98.1000)  Loss: 0.3897 (0.5144)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1226 s / it)
* Acc@1 89.800 Acc@5 98.100 loss 0.514
Test: [Task 2]  [ 0/63]  eta: 0:00:20  ASR: 0.2500 (0.2500)  ACC: 0.6875 (0.6875)  Loss: 2.6248 (2.6248)  time: 0.3313  data: 0.2039  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.2500 (0.2443)  ACC: 0.7500 (0.7216)  Loss: 3.4852 (3.3424)  time: 0.1395  data: 0.0188  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.2500 (0.2887)  ACC: 0.6875 (0.6637)  Loss: 3.1547 (3.1372)  time: 0.1207  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.3125 (0.2762)  ACC: 0.6250 (0.6774)  Loss: 3.1469 (3.1982)  time: 0.1209  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.2500 (0.2652)  ACC: 0.6875 (0.6845)  Loss: 3.1732 (3.2088)  time: 0.1207  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.2500 (0.2623)  ACC: 0.6875 (0.6801)  Loss: 3.3476 (3.2533)  time: 0.1207  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.2490)  ACC: 0.7500 (0.6998)  Loss: 3.6102 (3.3077)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.2460)  ACC: 0.7500 (0.7034)  Loss: 3.6102 (3.3202)  time: 0.1174  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1246 s / it)
* ASR 0.246 loss 3.320
Test: [Task 3]  [ 0/63]  eta: 0:00:20  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1780 (0.1780)  time: 0.3329  data: 0.2128  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (99.4318)  Loss: 0.4032 (0.4148)  time: 0.1382  data: 0.0197  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (99.1071)  Loss: 0.4032 (0.4191)  time: 0.1188  data: 0.0005  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (99.1935)  Loss: 0.3452 (0.4014)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (90.3963)  Acc@5: 100.0000 (99.0854)  Loss: 0.4144 (0.4161)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (90.9314)  Acc@5: 100.0000 (98.8971)  Loss: 0.4539 (0.4192)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (90.8811)  Acc@5: 100.0000 (98.7705)  Loss: 0.4124 (0.4345)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (90.7000)  Acc@5: 100.0000 (98.6000)  Loss: 0.4532 (0.4469)  time: 0.1162  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1227 s / it)
* Acc@1 90.700 Acc@5 98.600 loss 0.447
Test: [Task 3]  [ 0/63]  eta: 0:00:21  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  Loss: 4.1219 (4.1219)  time: 0.3367  data: 0.2131  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.2500 (0.2500)  ACC: 0.6875 (0.6818)  Loss: 3.9671 (3.7464)  time: 0.1397  data: 0.0197  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.2500 (0.2560)  ACC: 0.6875 (0.6935)  Loss: 3.9671 (3.9131)  time: 0.1201  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.2500 (0.2480)  ACC: 0.6875 (0.6935)  Loss: 4.1594 (3.9943)  time: 0.1199  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.2500 (0.2530)  ACC: 0.6875 (0.6936)  Loss: 3.9637 (3.9675)  time: 0.1199  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.2500 (0.2537)  ACC: 0.6875 (0.6973)  Loss: 3.9545 (3.9494)  time: 0.1200  data: 0.0004  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.2500 (0.2510)  ACC: 0.7500 (0.6998)  Loss: 3.9021 (3.9566)  time: 0.1198  data: 0.0004  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.2500 (0.2460)  ACC: 0.7500 (0.7014)  Loss: 3.8687 (3.9562)  time: 0.1170  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1240 s / it)
* ASR 0.246 loss 3.956
Test: [Task 4]  [ 0/63]  eta: 0:00:28  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4543 (0.4543)  time: 0.4510  data: 0.3326  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (98.8636)  Loss: 0.2801 (0.3239)  time: 0.1489  data: 0.0306  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (98.5119)  Loss: 0.2801 (0.3497)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (92.1371)  Acc@5: 100.0000 (98.3871)  Loss: 0.3469 (0.3569)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (98.7805)  Loss: 0.2364 (0.3301)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.0147)  Acc@5: 100.0000 (99.0196)  Loss: 0.2484 (0.3362)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (92.7254)  Acc@5: 100.0000 (98.7705)  Loss: 0.3133 (0.3457)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (92.8000)  Acc@5: 100.0000 (98.8000)  Loss: 0.2927 (0.3411)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1249 s / it)
* Acc@1 92.800 Acc@5 98.800 loss 0.341
Test: [Task 4]  [ 0/63]  eta: 0:00:24  ASR: 0.3125 (0.3125)  ACC: 0.6250 (0.6250)  Loss: 3.3695 (3.3695)  time: 0.3814  data: 0.2564  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.3750 (0.3239)  ACC: 0.6250 (0.6136)  Loss: 3.4107 (3.4619)  time: 0.1442  data: 0.0237  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: 0.3125 (0.2887)  ACC: 0.6250 (0.6458)  Loss: 3.5946 (3.7161)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.2722)  ACC: 0.6250 (0.6552)  Loss: 3.8924 (3.7613)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.2500 (0.2668)  ACC: 0.6250 (0.6570)  Loss: 3.9879 (3.8197)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: 0.2500 (0.2733)  ACC: 0.6250 (0.6495)  Loss: 3.9301 (3.7658)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: 0.2500 (0.2664)  ACC: 0.5625 (0.6506)  Loss: 3.6495 (3.7920)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: 0.2500 (0.2679)  ACC: 0.5625 (0.6488)  Loss: 3.7286 (3.7959)  time: 0.1170  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1249 s / it)
* ASR 0.268 loss 3.796
[Average accuracy till task4]	ASR: 0.2899	Acc@1: 86.1250	Loss: 3.3355	Forgetting: 0.1174	Backward: -0.1101
Train: Epoch[1/5]  [  0/313]  eta: 0:02:09  Lr: 0.0019 (0.0019)  Acc@1: 25.0000 (25.0000)  Acc@5: 62.5000 (62.5000)  Loss: 2.1149 (2.1149)  time: 0.4150  data: 0.2201  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 56.2500 (58.5227)  Acc@5: 87.5000 (87.5000)  Loss: 1.9257 (1.9234)  time: 0.2104  data: 0.0203  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.2143)  Acc@5: 100.0000 (92.8571)  Loss: 1.6185 (1.7000)  time: 0.1900  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.0323)  Acc@5: 100.0000 (94.9597)  Loss: 1.3097 (1.5167)  time: 0.1902  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (82.9268)  Acc@5: 100.0000 (96.1890)  Loss: 0.9844 (1.3432)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.5588)  Acc@5: 100.0000 (96.6912)  Loss: 0.7211 (1.2070)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.6803)  Acc@5: 100.0000 (97.1311)  Loss: 0.4704 (1.0752)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (87.9401)  Acc@5: 100.0000 (97.5352)  Loss: 0.3752 (0.9742)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (89.1975)  Acc@5: 100.0000 (97.8395)  Loss: 0.3492 (0.8907)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.2857)  Acc@5: 100.0000 (98.0769)  Loss: 0.2999 (0.8355)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.8515)  Acc@5: 100.0000 (98.2673)  Loss: 0.2444 (0.7717)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0901)  Acc@5: 100.0000 (98.3671)  Loss: 0.1763 (0.7197)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.6508)  Acc@5: 100.0000 (98.5021)  Loss: 0.1603 (0.6744)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.1737)  Acc@5: 100.0000 (98.6164)  Loss: 0.1270 (0.6291)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.5780)  Acc@5: 100.0000 (98.6702)  Loss: 0.0857 (0.5938)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.8460)  Acc@5: 100.0000 (98.7583)  Loss: 0.0756 (0.5588)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.0031)  Acc@5: 100.0000 (98.8354)  Loss: 0.0632 (0.5338)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.1418)  Acc@5: 100.0000 (98.9035)  Loss: 0.0720 (0.5067)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.4033)  Acc@5: 100.0000 (98.9296)  Loss: 0.0365 (0.4820)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.7683)  Acc@5: 100.0000 (98.9856)  Loss: -0.0040 (0.4569)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.9415)  Acc@5: 100.0000 (99.0361)  Loss: -0.0076 (0.4372)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0391)  Acc@5: 100.0000 (99.0818)  Loss: 0.0618 (0.4204)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0430)  Acc@5: 100.0000 (99.0950)  Loss: 0.0936 (0.4053)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.2089)  Acc@5: 100.0000 (99.1071)  Loss: 0.0488 (0.3897)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.3091)  Acc@5: 100.0000 (99.1442)  Loss: 0.0366 (0.3757)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.4512)  Acc@5: 100.0000 (99.1783)  Loss: 0.0226 (0.3606)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.5584)  Acc@5: 100.0000 (99.2098)  Loss: -0.0057 (0.3480)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.6116)  Acc@5: 100.0000 (99.2389)  Loss: -0.0224 (0.3350)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.6833)  Acc@5: 100.0000 (99.2660)  Loss: -0.0553 (0.3222)  time: 0.1897  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7715)  Acc@5: 100.0000 (99.2912)  Loss: -0.0508 (0.3101)  time: 0.1894  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.8538)  Acc@5: 100.0000 (99.3148)  Loss: -0.0323 (0.3003)  time: 0.1894  data: 0.0001  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.9309)  Acc@5: 100.0000 (99.3167)  Loss: -0.0323 (0.2914)  time: 0.1894  data: 0.0001  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.9696)  Acc@5: 100.0000 (99.3211)  Loss: -0.0401 (0.2890)  time: 0.1850  data: 0.0001  max mem: 12058
Train: Epoch[1/5] Total time: 0:00:59 (0.1912 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.9696)  Acc@5: 100.0000 (99.3211)  Loss: -0.0401 (0.2890)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0012 (0.0012)  time: 0.4329  data: 0.2372  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0334 (-0.0088)  time: 0.2132  data: 0.0218  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (100.0000)  Loss: -0.0465 (-0.0052)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.7742)  Acc@5: 100.0000 (100.0000)  Loss: -0.0336 (0.0006)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1037)  Acc@5: 100.0000 (100.0000)  Loss: -0.0572 (-0.0075)  time: 0.1923  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.4461)  Acc@5: 100.0000 (99.8775)  Loss: -0.0258 (-0.0013)  time: 0.1923  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.8238)  Acc@5: 100.0000 (99.8975)  Loss: -0.0852 (-0.0142)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0070)  Acc@5: 100.0000 (99.9120)  Loss: -0.0878 (-0.0202)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2222)  Acc@5: 100.0000 (99.9228)  Loss: -0.0731 (-0.0257)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7720)  Acc@5: 100.0000 (99.9313)  Loss: -0.0575 (-0.0098)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9059)  Acc@5: 100.0000 (99.9381)  Loss: -0.0575 (-0.0157)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.8468)  Acc@5: 100.0000 (99.9437)  Loss: -0.0799 (-0.0183)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.8492)  Acc@5: 100.0000 (99.9483)  Loss: -0.0566 (-0.0196)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0420)  Acc@5: 100.0000 (99.9523)  Loss: -0.0840 (-0.0257)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1631)  Acc@5: 100.0000 (99.9557)  Loss: -0.0971 (-0.0279)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1854)  Acc@5: 100.0000 (99.9586)  Loss: -0.0967 (-0.0319)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1273)  Acc@5: 100.0000 (99.9612)  Loss: -0.0882 (-0.0313)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1126)  Acc@5: 100.0000 (99.9635)  Loss: -0.0497 (-0.0328)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2376)  Acc@5: 100.0000 (99.9655)  Loss: -0.0588 (-0.0347)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3822)  Acc@5: 100.0000 (99.9673)  Loss: -0.1103 (-0.0384)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3881)  Acc@5: 100.0000 (99.9689)  Loss: -0.1103 (-0.0401)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.3045)  Acc@5: 100.0000 (99.9704)  Loss: -0.0612 (-0.0400)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.2568)  Acc@5: 100.0000 (99.9717)  Loss: -0.0612 (-0.0398)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2403)  Acc@5: 100.0000 (99.9459)  Loss: -0.0736 (-0.0403)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2251)  Acc@5: 100.0000 (99.9481)  Loss: -0.0866 (-0.0408)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2859)  Acc@5: 100.0000 (99.9502)  Loss: -0.0958 (-0.0427)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3180)  Acc@5: 100.0000 (99.9521)  Loss: -0.1009 (-0.0432)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3017)  Acc@5: 100.0000 (99.9539)  Loss: -0.1103 (-0.0447)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3532)  Acc@5: 100.0000 (99.9555)  Loss: -0.1171 (-0.0467)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3582)  Acc@5: 100.0000 (99.9570)  Loss: -0.1064 (-0.0479)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3630)  Acc@5: 100.0000 (99.9585)  Loss: -0.1025 (-0.0485)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3473)  Acc@5: 100.0000 (99.9397)  Loss: -0.1021 (-0.0485)  time: 0.1911  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3642)  Acc@5: 100.0000 (99.9401)  Loss: -0.1021 (-0.0490)  time: 0.1867  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:00 (0.1922 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3642)  Acc@5: 100.0000 (99.9401)  Loss: -0.1021 (-0.0490)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0934 (-0.0934)  time: 0.4128  data: 0.2181  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1112 (-0.0832)  time: 0.2112  data: 0.0201  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (100.0000)  Loss: -0.1156 (-0.0756)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (100.0000)  Loss: -0.0828 (-0.0686)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5610)  Acc@5: 100.0000 (100.0000)  Loss: -0.0967 (-0.0733)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1814)  Acc@5: 100.0000 (100.0000)  Loss: -0.0734 (-0.0699)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (100.0000)  Loss: -0.1242 (-0.0767)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6232)  Acc@5: 100.0000 (100.0000)  Loss: -0.1271 (-0.0808)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7623)  Acc@5: 100.0000 (100.0000)  Loss: -0.1271 (-0.0837)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (100.0000)  Loss: -0.0969 (-0.0682)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5248)  Acc@5: 100.0000 (100.0000)  Loss: -0.0969 (-0.0726)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6351)  Acc@5: 100.0000 (100.0000)  Loss: -0.1161 (-0.0744)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5723)  Acc@5: 100.0000 (100.0000)  Loss: -0.0984 (-0.0738)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7099)  Acc@5: 100.0000 (100.0000)  Loss: -0.1216 (-0.0779)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8280)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.0803)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8477)  Acc@5: 100.0000 (100.0000)  Loss: -0.1288 (-0.0827)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9425)  Acc@5: 100.0000 (100.0000)  Loss: -0.1120 (-0.0824)  time: 0.1917  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.0852 (-0.0830)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9972)  Acc@5: 100.0000 (100.0000)  Loss: -0.0965 (-0.0840)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1021)  Acc@5: 100.0000 (100.0000)  Loss: -0.1338 (-0.0865)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1343)  Acc@5: 100.0000 (100.0000)  Loss: -0.1384 (-0.0880)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0746)  Acc@5: 100.0000 (100.0000)  Loss: -0.1092 (-0.0881)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (98.0204)  Acc@5: 100.0000 (100.0000)  Loss: -0.1002 (-0.0879)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9978)  Acc@5: 100.0000 (100.0000)  Loss: -0.1131 (-0.0876)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9772)  Acc@5: 100.0000 (100.0000)  Loss: -0.1249 (-0.0875)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0329)  Acc@5: 100.0000 (100.0000)  Loss: -0.1327 (-0.0887)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0603)  Acc@5: 100.0000 (100.0000)  Loss: -0.1327 (-0.0888)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0627)  Acc@5: 100.0000 (100.0000)  Loss: -0.1332 (-0.0896)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1317)  Acc@5: 100.0000 (100.0000)  Loss: -0.1360 (-0.0909)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1529)  Acc@5: 100.0000 (100.0000)  Loss: -0.1304 (-0.0916)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1728)  Acc@5: 100.0000 (100.0000)  Loss: -0.1215 (-0.0917)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1310)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.0915)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1430)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.0918)  time: 0.1865  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1430)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.0918)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1305 (-0.1305)  time: 0.3856  data: 0.1926  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1340 (-0.1129)  time: 0.2095  data: 0.0178  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1341 (-0.1077)  time: 0.1918  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9839)  Acc@5: 100.0000 (100.0000)  Loss: -0.0953 (-0.1024)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1169 (-0.1054)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2843)  Acc@5: 100.0000 (100.0000)  Loss: -0.1008 (-0.1040)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4631)  Acc@5: 100.0000 (100.0000)  Loss: -0.1367 (-0.1075)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5035)  Acc@5: 100.0000 (100.0000)  Loss: -0.1369 (-0.1100)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6883)  Acc@5: 100.0000 (100.0000)  Loss: -0.1421 (-0.1124)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2830)  Acc@5: 100.0000 (100.0000)  Loss: -0.1213 (-0.0991)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4530)  Acc@5: 100.0000 (100.0000)  Loss: -0.1213 (-0.1023)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4797)  Acc@5: 100.0000 (100.0000)  Loss: -0.1337 (-0.1041)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3988)  Acc@5: 100.0000 (100.0000)  Loss: -0.1204 (-0.1028)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4733)  Acc@5: 100.0000 (100.0000)  Loss: -0.1389 (-0.1057)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5372)  Acc@5: 100.0000 (100.0000)  Loss: -0.1456 (-0.1076)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5927)  Acc@5: 100.0000 (100.0000)  Loss: -0.1431 (-0.1094)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6413)  Acc@5: 100.0000 (100.0000)  Loss: -0.1308 (-0.1093)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6477)  Acc@5: 100.0000 (100.0000)  Loss: -0.1128 (-0.1097)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7224)  Acc@5: 100.0000 (100.0000)  Loss: -0.1309 (-0.1103)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7893)  Acc@5: 100.0000 (100.0000)  Loss: -0.1438 (-0.1121)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7873)  Acc@5: 100.0000 (100.0000)  Loss: -0.1564 (-0.1133)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8448)  Acc@5: 100.0000 (100.0000)  Loss: -0.1382 (-0.1138)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8405)  Acc@5: 100.0000 (100.0000)  Loss: -0.1305 (-0.1135)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7825)  Acc@5: 100.0000 (100.0000)  Loss: -0.1322 (-0.1128)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7811)  Acc@5: 100.0000 (100.0000)  Loss: -0.1375 (-0.1125)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8048)  Acc@5: 100.0000 (100.0000)  Loss: -0.1463 (-0.1132)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8027)  Acc@5: 100.0000 (100.0000)  Loss: -0.1464 (-0.1130)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7777)  Acc@5: 100.0000 (100.0000)  Loss: -0.1446 (-0.1136)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8212)  Acc@5: 100.0000 (100.0000)  Loss: -0.1457 (-0.1145)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8402)  Acc@5: 100.0000 (100.0000)  Loss: -0.1440 (-0.1150)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8372)  Acc@5: 100.0000 (100.0000)  Loss: -0.1377 (-0.1148)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7942)  Acc@5: 100.0000 (100.0000)  Loss: -0.1341 (-0.1146)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8019)  Acc@5: 100.0000 (100.0000)  Loss: -0.1341 (-0.1148)  time: 0.1865  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8019)  Acc@5: 100.0000 (100.0000)  Loss: -0.1341 (-0.1148)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1465 (-0.1465)  time: 0.3784  data: 0.1824  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1465 (-0.1303)  time: 0.2083  data: 0.0169  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1071)  Acc@5: 100.0000 (100.0000)  Loss: -0.1481 (-0.1277)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1935)  Acc@5: 100.0000 (100.0000)  Loss: -0.1175 (-0.1242)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2378)  Acc@5: 100.0000 (100.0000)  Loss: -0.1241 (-0.1269)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)  Loss: -0.1336 (-0.1266)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2828)  Acc@5: 100.0000 (100.0000)  Loss: -0.1437 (-0.1281)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2958)  Acc@5: 100.0000 (100.0000)  Loss: -0.1460 (-0.1294)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3827)  Acc@5: 100.0000 (100.0000)  Loss: -0.1520 (-0.1310)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0385)  Acc@5: 100.0000 (100.0000)  Loss: -0.1329 (-0.1206)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1337)  Acc@5: 100.0000 (100.0000)  Loss: -0.1371 (-0.1226)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1554)  Acc@5: 100.0000 (100.0000)  Loss: -0.1439 (-0.1240)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0702)  Acc@5: 100.0000 (100.0000)  Loss: -0.1318 (-0.1227)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1486 (-0.1246)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2021)  Acc@5: 100.0000 (100.0000)  Loss: -0.1509 (-0.1261)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2136)  Acc@5: 100.0000 (100.0000)  Loss: -0.1509 (-0.1273)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2236)  Acc@5: 100.0000 (100.0000)  Loss: -0.1354 (-0.1270)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2325)  Acc@5: 100.0000 (100.0000)  Loss: -0.1226 (-0.1272)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2749)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1276)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3128)  Acc@5: 100.0000 (100.0000)  Loss: -0.1506 (-0.1289)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3159)  Acc@5: 100.0000 (100.0000)  Loss: -0.1635 (-0.1298)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3483)  Acc@5: 100.0000 (100.0000)  Loss: -0.1516 (-0.1302)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3213)  Acc@5: 100.0000 (100.0000)  Loss: -0.1385 (-0.1298)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2695)  Acc@5: 100.0000 (100.0000)  Loss: -0.1453 (-0.1290)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2479)  Acc@5: 100.0000 (100.0000)  Loss: -0.1478 (-0.1284)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2530)  Acc@5: 100.0000 (100.0000)  Loss: -0.1503 (-0.1289)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2577)  Acc@5: 100.0000 (100.0000)  Loss: -0.1518 (-0.1285)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2620)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1289)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2883)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1296)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2912)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1300)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2733)  Acc@5: 100.0000 (100.0000)  Loss: -0.1464 (-0.1296)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2765)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1294)  time: 0.1911  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2812)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1296)  time: 0.1865  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2812)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1296)
Test: [Task 1]  [ 0/63]  eta: 0:00:21  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  Loss: 1.2106 (1.2106)  time: 0.3347  data: 0.2102  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (97.1591)  Loss: 1.3573 (1.3833)  time: 0.1387  data: 0.0195  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 62.5000 (63.9881)  Acc@5: 100.0000 (97.0238)  Loss: 1.3802 (1.4025)  time: 0.1191  data: 0.0004  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 68.7500 (66.3306)  Acc@5: 100.0000 (97.3790)  Loss: 1.2109 (1.3485)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 68.7500 (65.8537)  Acc@5: 100.0000 (97.4085)  Loss: 1.3124 (1.3517)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 68.7500 (67.6471)  Acc@5: 100.0000 (97.4265)  Loss: 1.2675 (1.3170)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 68.7500 (68.0328)  Acc@5: 100.0000 (97.5410)  Loss: 1.1215 (1.2972)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 68.7500 (68.0000)  Acc@5: 100.0000 (97.6000)  Loss: 1.1047 (1.2929)  time: 0.1161  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 68.000 Acc@5 97.600 loss 1.293
Test: [Task 1]  [ 0/63]  eta: 0:00:20  ASR: 0.3125 (0.3125)  ACC: 0.5625 (0.5625)  Loss: 2.8883 (2.8883)  time: 0.3255  data: 0.1982  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.2500 (0.2784)  ACC: 0.5000 (0.5227)  Loss: 2.8228 (2.7651)  time: 0.1389  data: 0.0184  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.2500 (0.2679)  ACC: 0.4375 (0.5030)  Loss: 2.6744 (2.7265)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.2500 (0.2843)  ACC: 0.5000 (0.5202)  Loss: 2.6200 (2.6842)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.3125 (0.2866)  ACC: 0.5000 (0.5152)  Loss: 2.6200 (2.7322)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.2500 (0.2806)  ACC: 0.5000 (0.5270)  Loss: 2.8171 (2.7802)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.3125 (0.2951)  ACC: 0.5625 (0.5287)  Loss: 2.7088 (2.7219)  time: 0.1205  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.3125 (0.2956)  ACC: 0.5000 (0.5248)  Loss: 2.7088 (2.7224)  time: 0.1177  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1241 s / it)
* ASR 0.296 loss 2.722
Test: [Task 2]  [ 0/63]  eta: 0:00:18  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5332 (0.5332)  time: 0.3002  data: 0.1812  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  Loss: 0.5332 (0.5684)  time: 0.1353  data: 0.0168  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (97.3214)  Loss: 0.6116 (0.6404)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (96.9758)  Loss: 0.6383 (0.6584)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (85.8232)  Acc@5: 100.0000 (97.4085)  Loss: 0.5704 (0.6361)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (85.5392)  Acc@5: 100.0000 (97.6716)  Loss: 0.5204 (0.6301)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (86.4754)  Acc@5: 100.0000 (97.8484)  Loss: 0.4551 (0.5923)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (86.6000)  Acc@5: 100.0000 (97.9000)  Loss: 0.4470 (0.5827)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1223 s / it)
* Acc@1 86.600 Acc@5 97.900 loss 0.583
Test: [Task 2]  [ 0/63]  eta: 0:00:21  ASR: 0.2500 (0.2500)  ACC: 0.6875 (0.6875)  Loss: 3.0924 (3.0924)  time: 0.3445  data: 0.2129  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1648)  ACC: 0.6875 (0.7216)  Loss: 3.6751 (3.7576)  time: 0.1413  data: 0.0197  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1994)  ACC: 0.6875 (0.6994)  Loss: 3.6663 (3.5541)  time: 0.1209  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1956)  ACC: 0.7500 (0.7157)  Loss: 3.6441 (3.6510)  time: 0.1208  data: 0.0004  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1860)  ACC: 0.7500 (0.7271)  Loss: 3.8176 (3.6866)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1838)  ACC: 0.7500 (0.7169)  Loss: 3.8364 (3.7394)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1773)  ACC: 0.7500 (0.7316)  Loss: 4.0285 (3.7841)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1746)  ACC: 0.7500 (0.7351)  Loss: 4.0628 (3.8004)  time: 0.1177  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1247 s / it)
* ASR 0.175 loss 3.800
Test: [Task 3]  [ 0/63]  eta: 0:00:21  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.3764 (0.3764)  time: 0.3487  data: 0.2288  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (99.4318)  Loss: 0.4707 (0.5323)  time: 0.1395  data: 0.0211  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (99.1071)  Loss: 0.4857 (0.5187)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (98.9919)  Loss: 0.4320 (0.4955)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (86.7378)  Acc@5: 100.0000 (98.7805)  Loss: 0.4240 (0.5097)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (87.0098)  Acc@5: 100.0000 (98.5294)  Loss: 0.5263 (0.5111)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (87.2951)  Acc@5: 100.0000 (98.5656)  Loss: 0.4652 (0.5108)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (87.1000)  Acc@5: 100.0000 (98.4000)  Loss: 0.5038 (0.5208)  time: 0.1161  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 87.100 Acc@5 98.400 loss 0.521
Test: [Task 3]  [ 0/63]  eta: 0:00:21  ASR: 0.1250 (0.1250)  ACC: 0.8125 (0.8125)  Loss: 4.4568 (4.4568)  time: 0.3483  data: 0.2223  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1761)  ACC: 0.7500 (0.7159)  Loss: 4.2421 (4.1611)  time: 0.1423  data: 0.0206  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1905)  ACC: 0.7500 (0.7202)  Loss: 4.4017 (4.3131)  time: 0.1213  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1915)  ACC: 0.6875 (0.7157)  Loss: 4.4017 (4.3868)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.1936)  ACC: 0.6875 (0.7119)  Loss: 4.3509 (4.3780)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.1875 (0.1949)  ACC: 0.6875 (0.7096)  Loss: 4.3492 (4.3484)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.1936)  ACC: 0.6875 (0.7100)  Loss: 4.3492 (4.3560)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.1915)  ACC: 0.6875 (0.7093)  Loss: 4.2632 (4.3524)  time: 0.1174  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1246 s / it)
* ASR 0.191 loss 4.352
Test: [Task 4]  [ 0/63]  eta: 0:00:20  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5114 (0.5114)  time: 0.3331  data: 0.2100  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (90.9091)  Acc@5: 100.0000 (98.8636)  Loss: 0.3856 (0.3886)  time: 0.1385  data: 0.0195  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (90.4762)  Acc@5: 100.0000 (97.9167)  Loss: 0.3856 (0.4192)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (97.7823)  Loss: 0.4033 (0.4379)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (91.1585)  Acc@5: 100.0000 (98.1707)  Loss: 0.3222 (0.4079)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (90.9314)  Acc@5: 100.0000 (98.4069)  Loss: 0.3294 (0.4156)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (90.8811)  Acc@5: 100.0000 (98.3607)  Loss: 0.3560 (0.4235)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (91.1000)  Acc@5: 100.0000 (98.4000)  Loss: 0.2811 (0.4179)  time: 0.1160  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 91.100 Acc@5 98.400 loss 0.418
Test: [Task 4]  [ 0/63]  eta: 0:00:19  ASR: 0.1875 (0.1875)  ACC: 0.5625 (0.5625)  Loss: 3.8678 (3.8678)  time: 0.3022  data: 0.1786  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.2500 (0.2670)  ACC: 0.6250 (0.6307)  Loss: 3.8223 (3.8073)  time: 0.1370  data: 0.0166  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: 0.2500 (0.2411)  ACC: 0.6875 (0.6696)  Loss: 3.8370 (4.0298)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.2319)  ACC: 0.6875 (0.6754)  Loss: 4.1133 (4.0812)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.2165)  ACC: 0.6875 (0.6860)  Loss: 4.1805 (4.1271)  time: 0.1210  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: 0.1875 (0.2194)  ACC: 0.6875 (0.6838)  Loss: 4.0832 (4.0876)  time: 0.1211  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.2172)  ACC: 0.6875 (0.6844)  Loss: 3.9612 (4.1213)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.2163)  ACC: 0.6875 (0.6825)  Loss: 3.9612 (4.1182)  time: 0.1174  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1236 s / it)
* ASR 0.216 loss 4.118
Test: [Task 5]  [ 0/63]  eta: 0:00:21  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1113 (0.1113)  time: 0.3338  data: 0.2134  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (98.8636)  Loss: 0.2803 (0.4565)  time: 0.1381  data: 0.0197  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (98.8095)  Loss: 0.2803 (0.3874)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (92.9435)  Acc@5: 100.0000 (98.7903)  Loss: 0.2151 (0.3810)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (93.4451)  Acc@5: 100.0000 (98.9329)  Loss: 0.3088 (0.3730)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.3824)  Acc@5: 100.0000 (98.7745)  Loss: 0.3412 (0.3766)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (92.9303)  Acc@5: 100.0000 (98.7705)  Loss: 0.3342 (0.3802)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (92.8000)  Acc@5: 100.0000 (98.8000)  Loss: 0.3412 (0.3911)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1223 s / it)
* Acc@1 92.800 Acc@5 98.800 loss 0.391
Test: [Task 5]  [ 0/63]  eta: 0:00:19  ASR: 0.3125 (0.3125)  ACC: 0.6250 (0.6250)  Loss: 4.2687 (4.2687)  time: 0.3059  data: 0.1832  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.2216)  ACC: 0.6875 (0.6648)  Loss: 3.8649 (4.0343)  time: 0.1379  data: 0.0170  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1905)  ACC: 0.7500 (0.7173)  Loss: 4.0832 (4.1964)  time: 0.1210  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1835)  ACC: 0.7500 (0.7298)  Loss: 4.1271 (4.1195)  time: 0.1210  data: 0.0004  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1723)  ACC: 0.7500 (0.7363)  Loss: 4.0367 (4.1102)  time: 0.1207  data: 0.0004  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1703)  ACC: 0.7500 (0.7390)  Loss: 3.9803 (4.1064)  time: 0.1201  data: 0.0004  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.1814)  ACC: 0.6875 (0.7357)  Loss: 3.9607 (4.0933)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.1905)  ACC: 0.6875 (0.7242)  Loss: 3.9607 (4.0462)  time: 0.1172  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1238 s / it)
* ASR 0.190 loss 4.046
[Average accuracy till task5]	ASR: 0.2137	Acc@1: 85.1200	Loss: 3.8079	Forgetting: 0.1585	Backward: -0.1530
Train: Epoch[1/5]  [  0/313]  eta: 0:01:59  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  Loss: 2.1543 (2.1543)  time: 0.3827  data: 0.1892  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (57.3864)  Acc@5: 93.7500 (86.9318)  Loss: 1.9221 (1.8979)  time: 0.2077  data: 0.0175  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.1310)  Acc@5: 100.0000 (92.8571)  Loss: 1.6185 (1.6639)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (78.0242)  Acc@5: 100.0000 (95.1613)  Loss: 1.1524 (1.4503)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (82.3171)  Acc@5: 100.0000 (96.1890)  Loss: 0.7805 (1.2628)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.4363)  Acc@5: 100.0000 (96.9363)  Loss: 0.5973 (1.1184)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.7582)  Acc@5: 100.0000 (97.4385)  Loss: 0.4265 (0.9966)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.1479)  Acc@5: 100.0000 (97.7993)  Loss: 0.2922 (0.8938)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1944)  Acc@5: 100.0000 (98.0710)  Loss: 0.2389 (0.8139)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.9423)  Acc@5: 100.0000 (98.2830)  Loss: 0.2062 (0.7445)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.2946)  Acc@5: 100.0000 (98.3911)  Loss: 0.1911 (0.6892)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.9212)  Acc@5: 100.0000 (98.5360)  Loss: 0.1632 (0.6383)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (90.5475)  Acc@5: 100.0000 (98.6570)  Loss: 0.0749 (0.5918)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.8874)  Acc@5: 100.0000 (98.7595)  Loss: 0.0823 (0.5560)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.3564)  Acc@5: 100.0000 (98.8475)  Loss: 0.0685 (0.5191)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.5977)  Acc@5: 100.0000 (98.8825)  Loss: 0.0532 (0.4944)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.0031)  Acc@5: 100.0000 (98.9519)  Loss: 0.0532 (0.4664)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.1784)  Acc@5: 100.0000 (99.0132)  Loss: 0.0247 (0.4426)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.3343)  Acc@5: 100.0000 (99.0331)  Loss: 0.0304 (0.4224)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.4411)  Acc@5: 100.0000 (99.0838)  Loss: 0.0561 (0.4021)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.4129)  Acc@5: 100.0000 (99.1294)  Loss: 0.0561 (0.3863)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.5948)  Acc@5: 100.0000 (99.1706)  Loss: 0.0207 (0.3705)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.5057)  Acc@5: 100.0000 (99.2081)  Loss: 0.0307 (0.3578)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.6136)  Acc@5: 100.0000 (99.2424)  Loss: 0.0307 (0.3439)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.7645)  Acc@5: 100.0000 (99.2739)  Loss: -0.0183 (0.3289)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.7789)  Acc@5: 100.0000 (99.3028)  Loss: -0.0183 (0.3182)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.8400)  Acc@5: 100.0000 (99.3295)  Loss: 0.0113 (0.3058)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.9428)  Acc@5: 100.0000 (99.3542)  Loss: -0.0088 (0.2943)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0605)  Acc@5: 100.0000 (99.3772)  Loss: -0.0088 (0.2832)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.1057)  Acc@5: 100.0000 (99.3986)  Loss: -0.0054 (0.2749)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.1686)  Acc@5: 100.0000 (99.4186)  Loss: -0.0188 (0.2653)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.3079)  Acc@5: 100.0000 (99.4373)  Loss: -0.0830 (0.2551)  time: 0.1911  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2907)  Acc@5: 100.0000 (99.4409)  Loss: -0.0830 (0.2540)  time: 0.1866  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:00:59 (0.1916 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2907)  Acc@5: 100.0000 (99.4409)  Loss: -0.0830 (0.2540)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0517 (-0.0517)  time: 0.4254  data: 0.2218  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.1818)  Acc@5: 100.0000 (99.4318)  Loss: 0.0507 (0.0292)  time: 0.2124  data: 0.0204  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.2381)  Acc@5: 100.0000 (99.4048)  Loss: -0.0834 (-0.0117)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.1613)  Acc@5: 100.0000 (99.5968)  Loss: -0.0841 (-0.0106)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.1220)  Acc@5: 100.0000 (99.6951)  Loss: -0.0839 (-0.0141)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.3431)  Acc@5: 100.0000 (99.7549)  Loss: -0.0720 (-0.0138)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.1844)  Acc@5: 100.0000 (99.7951)  Loss: -0.0509 (-0.0153)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.2465)  Acc@5: 100.0000 (99.8239)  Loss: -0.0752 (-0.0200)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.3704)  Acc@5: 100.0000 (99.8457)  Loss: -0.0474 (-0.0223)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.5357)  Acc@5: 100.0000 (99.8626)  Loss: -0.0474 (-0.0260)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.2970)  Acc@5: 100.0000 (99.8144)  Loss: -0.0563 (-0.0261)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.5518)  Acc@5: 100.0000 (99.8311)  Loss: -0.0563 (-0.0295)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7645)  Acc@5: 100.0000 (99.8450)  Loss: -0.1185 (-0.0351)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7538)  Acc@5: 100.0000 (99.8569)  Loss: -0.0951 (-0.0364)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9220)  Acc@5: 100.0000 (99.8670)  Loss: -0.0951 (-0.0408)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9851)  Acc@5: 100.0000 (99.8758)  Loss: -0.1076 (-0.0392)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1568)  Acc@5: 100.0000 (99.8835)  Loss: -0.0843 (-0.0416)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1623)  Acc@5: 100.0000 (99.8904)  Loss: -0.0935 (-0.0422)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1671)  Acc@5: 100.0000 (99.8964)  Loss: -0.0828 (-0.0411)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.1387)  Acc@5: 100.0000 (99.9018)  Loss: -0.0625 (-0.0415)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.9577)  Acc@5: 100.0000 (99.9067)  Loss: -0.0625 (-0.0393)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0604)  Acc@5: 100.0000 (99.9111)  Loss: -0.0592 (-0.0396)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.9842)  Acc@5: 100.0000 (99.9152)  Loss: -0.0592 (-0.0382)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.9957)  Acc@5: 100.0000 (99.9188)  Loss: -0.0591 (-0.0383)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0062)  Acc@5: 100.0000 (99.9222)  Loss: -0.1043 (-0.0398)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.9910)  Acc@5: 100.0000 (99.9253)  Loss: -0.0919 (-0.0387)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0249)  Acc@5: 100.0000 (99.9282)  Loss: -0.0868 (-0.0400)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0563)  Acc@5: 100.0000 (99.9308)  Loss: -0.0868 (-0.0408)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0854)  Acc@5: 100.0000 (99.9333)  Loss: -0.0757 (-0.0421)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0481)  Acc@5: 100.0000 (99.9356)  Loss: -0.0702 (-0.0411)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0548)  Acc@5: 100.0000 (99.9377)  Loss: -0.0702 (-0.0420)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1616)  Acc@5: 100.0000 (99.9397)  Loss: -0.1253 (-0.0442)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1262)  Acc@5: 100.0000 (99.9401)  Loss: -0.1231 (-0.0439)  time: 0.1867  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:06 (0.2117 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1262)  Acc@5: 100.0000 (99.9401)  Loss: -0.1231 (-0.0439)
Train: Epoch[3/5]  [  0/313]  eta: 0:01:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1034 (-0.1034)  time: 0.3812  data: 0.1885  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (99.4318)  Loss: -0.0382 (-0.0328)  time: 0.2079  data: 0.0174  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (99.7024)  Loss: -0.1113 (-0.0610)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3710)  Acc@5: 100.0000 (99.7984)  Loss: -0.1260 (-0.0566)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4939)  Acc@5: 100.0000 (99.8476)  Loss: -0.1150 (-0.0593)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6912)  Acc@5: 100.0000 (99.8775)  Loss: -0.1051 (-0.0575)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5164)  Acc@5: 100.0000 (99.8975)  Loss: -0.1041 (-0.0578)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6549)  Acc@5: 100.0000 (99.9120)  Loss: -0.1047 (-0.0602)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6821)  Acc@5: 100.0000 (99.9228)  Loss: -0.0906 (-0.0621)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.8407)  Acc@5: 100.0000 (99.9313)  Loss: -0.0906 (-0.0648)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7822)  Acc@5: 100.0000 (99.8762)  Loss: -0.1084 (-0.0655)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9032)  Acc@5: 100.0000 (99.8874)  Loss: -0.1069 (-0.0677)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0041)  Acc@5: 100.0000 (99.8967)  Loss: -0.1362 (-0.0723)  time: 0.1899  data: 0.0001  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0420)  Acc@5: 100.0000 (99.9046)  Loss: -0.1169 (-0.0739)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1188)  Acc@5: 100.0000 (99.9113)  Loss: -0.1192 (-0.0773)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1440)  Acc@5: 100.0000 (99.9172)  Loss: -0.1269 (-0.0760)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2438)  Acc@5: 100.0000 (99.9224)  Loss: -0.1152 (-0.0777)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2588)  Acc@5: 100.0000 (99.9269)  Loss: -0.1152 (-0.0781)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2376)  Acc@5: 100.0000 (99.9309)  Loss: -0.1145 (-0.0766)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.1859)  Acc@5: 100.0000 (99.9346)  Loss: -0.0963 (-0.0767)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.0460)  Acc@5: 100.0000 (99.9378)  Loss: -0.0963 (-0.0744)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0972)  Acc@5: 100.0000 (99.9408)  Loss: -0.0875 (-0.0748)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0305)  Acc@5: 100.0000 (99.9434)  Loss: -0.0952 (-0.0739)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0238)  Acc@5: 100.0000 (99.9459)  Loss: -0.0973 (-0.0738)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0176)  Acc@5: 100.0000 (99.9481)  Loss: -0.1259 (-0.0748)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9871)  Acc@5: 100.0000 (99.9502)  Loss: -0.1253 (-0.0732)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0067)  Acc@5: 100.0000 (99.9521)  Loss: -0.1216 (-0.0738)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0018)  Acc@5: 100.0000 (99.9539)  Loss: -0.1216 (-0.0742)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0196)  Acc@5: 100.0000 (99.9555)  Loss: -0.0972 (-0.0751)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9502)  Acc@5: 100.0000 (99.9570)  Loss: -0.0955 (-0.0739)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.9892)  Acc@5: 100.0000 (99.9585)  Loss: -0.1072 (-0.0743)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0659)  Acc@5: 100.0000 (99.9598)  Loss: -0.1415 (-0.0759)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0447)  Acc@5: 100.0000 (99.9601)  Loss: -0.1373 (-0.0757)  time: 0.1858  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:00:59 (0.1910 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0447)  Acc@5: 100.0000 (99.9601)  Loss: -0.1373 (-0.0757)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:07  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1297 (-0.1297)  time: 0.4076  data: 0.2098  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.5909)  Acc@5: 100.0000 (100.0000)  Loss: -0.0775 (-0.0659)  time: 0.2111  data: 0.0193  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6190)  Acc@5: 100.0000 (100.0000)  Loss: -0.1084 (-0.0839)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (100.0000)  Loss: -0.1365 (-0.0788)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4085)  Acc@5: 100.0000 (100.0000)  Loss: -0.1361 (-0.0809)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4265)  Acc@5: 100.0000 (100.0000)  Loss: -0.1216 (-0.0797)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2336)  Acc@5: 100.0000 (100.0000)  Loss: -0.1141 (-0.0795)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2711)  Acc@5: 100.0000 (100.0000)  Loss: -0.1249 (-0.0808)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2222)  Acc@5: 100.0000 (100.0000)  Loss: -0.1170 (-0.0822)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (100.0000)  Loss: -0.1170 (-0.0847)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2153)  Acc@5: 100.0000 (100.0000)  Loss: -0.1251 (-0.0856)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2973)  Acc@5: 100.0000 (100.0000)  Loss: -0.1225 (-0.0871)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.4690)  Acc@5: 100.0000 (100.0000)  Loss: -0.1418 (-0.0912)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5668)  Acc@5: 100.0000 (100.0000)  Loss: -0.1374 (-0.0929)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6950)  Acc@5: 100.0000 (100.0000)  Loss: -0.1328 (-0.0956)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7235)  Acc@5: 100.0000 (100.0000)  Loss: -0.1365 (-0.0949)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7873)  Acc@5: 100.0000 (100.0000)  Loss: -0.1268 (-0.0965)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7705)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.0969)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7555)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.0954)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6767)  Acc@5: 100.0000 (100.0000)  Loss: -0.1075 (-0.0955)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.6057)  Acc@5: 100.0000 (100.0000)  Loss: -0.1065 (-0.0939)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6303)  Acc@5: 100.0000 (100.0000)  Loss: -0.1157 (-0.0944)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6810)  Acc@5: 100.0000 (100.0000)  Loss: -0.1126 (-0.0940)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7002)  Acc@5: 100.0000 (100.0000)  Loss: -0.1126 (-0.0938)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6919)  Acc@5: 100.0000 (100.0000)  Loss: -0.1355 (-0.0946)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6843)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.0930)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7011)  Acc@5: 100.0000 (100.0000)  Loss: -0.1342 (-0.0933)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7168)  Acc@5: 100.0000 (100.0000)  Loss: -0.1270 (-0.0940)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7536)  Acc@5: 100.0000 (100.0000)  Loss: -0.1232 (-0.0946)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7234)  Acc@5: 100.0000 (100.0000)  Loss: -0.1039 (-0.0937)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7367)  Acc@5: 100.0000 (100.0000)  Loss: -0.1330 (-0.0941)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8095)  Acc@5: 100.0000 (100.0000)  Loss: -0.1460 (-0.0955)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8035)  Acc@5: 100.0000 (100.0000)  Loss: -0.1419 (-0.0954)  time: 0.1863  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8035)  Acc@5: 100.0000 (100.0000)  Loss: -0.1419 (-0.0954)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:09  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1440 (-0.1440)  time: 0.4147  data: 0.2149  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0857 (-0.0865)  time: 0.2115  data: 0.0198  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1179 (-0.1010)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9839)  Acc@5: 100.0000 (100.0000)  Loss: -0.1444 (-0.0958)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1707)  Acc@5: 100.0000 (100.0000)  Loss: -0.1387 (-0.0979)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1618)  Acc@5: 100.0000 (100.0000)  Loss: -0.1279 (-0.0974)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9508)  Acc@5: 100.0000 (100.0000)  Loss: -0.1284 (-0.0968)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8873)  Acc@5: 100.0000 (100.0000)  Loss: -0.1372 (-0.0976)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8395)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.0986)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9396)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.1005)  time: 0.1913  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8960)  Acc@5: 100.0000 (100.0000)  Loss: -0.1303 (-0.1020)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9730)  Acc@5: 100.0000 (100.0000)  Loss: -0.1376 (-0.1029)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1405)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1063)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2824)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1081)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3599)  Acc@5: 100.0000 (100.0000)  Loss: -0.1404 (-0.1101)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3444)  Acc@5: 100.0000 (100.0000)  Loss: -0.1420 (-0.1097)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3696)  Acc@5: 100.0000 (100.0000)  Loss: -0.1286 (-0.1108)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3553)  Acc@5: 100.0000 (100.0000)  Loss: -0.1372 (-0.1112)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3425)  Acc@5: 100.0000 (100.0000)  Loss: -0.1397 (-0.1098)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2330)  Acc@5: 100.0000 (100.0000)  Loss: -0.1260 (-0.1100)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1965)  Acc@5: 100.0000 (100.0000)  Loss: -0.1133 (-0.1090)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2820)  Acc@5: 100.0000 (100.0000)  Loss: -0.1253 (-0.1094)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3314)  Acc@5: 100.0000 (100.0000)  Loss: -0.1239 (-0.1091)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3225)  Acc@5: 100.0000 (100.0000)  Loss: -0.1239 (-0.1090)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2884)  Acc@5: 100.0000 (100.0000)  Loss: -0.1395 (-0.1096)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2570)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1079)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2519)  Acc@5: 100.0000 (100.0000)  Loss: -0.1405 (-0.1079)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2703)  Acc@5: 100.0000 (100.0000)  Loss: -0.1390 (-0.1084)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2874)  Acc@5: 100.0000 (100.0000)  Loss: -0.1335 (-0.1089)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2818)  Acc@5: 100.0000 (100.0000)  Loss: -0.1166 (-0.1079)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2766)  Acc@5: 100.0000 (100.0000)  Loss: -0.1259 (-0.1082)  time: 0.1912  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3320)  Acc@5: 100.0000 (100.0000)  Loss: -0.1479 (-0.1094)  time: 0.1911  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (100.0000)  Loss: -0.1440 (-0.1093)  time: 0.1865  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:00:59 (0.1917 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3227)  Acc@5: 100.0000 (100.0000)  Loss: -0.1440 (-0.1093)
Test: [Task 1]  [ 0/63]  eta: 0:00:21  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)  Loss: 1.5355 (1.5355)  time: 0.3452  data: 0.2256  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 62.5000 (59.0909)  Acc@5: 100.0000 (96.5909)  Loss: 1.3746 (1.4769)  time: 0.1393  data: 0.0208  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 62.5000 (59.2262)  Acc@5: 100.0000 (97.0238)  Loss: 1.3672 (1.4995)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 62.5000 (61.6935)  Acc@5: 93.7500 (96.5726)  Loss: 1.3056 (1.4360)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 62.5000 (61.2805)  Acc@5: 100.0000 (96.9512)  Loss: 1.3278 (1.4291)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 62.5000 (62.8676)  Acc@5: 100.0000 (96.8137)  Loss: 1.3278 (1.4005)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 62.5000 (63.0123)  Acc@5: 100.0000 (96.9262)  Loss: 1.3303 (1.3820)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 62.5000 (62.9000)  Acc@5: 100.0000 (97.0000)  Loss: 1.2023 (1.3741)  time: 0.1157  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1230 s / it)
* Acc@1 62.900 Acc@5 97.000 loss 1.374
Test: [Task 1]  [ 0/63]  eta: 0:00:20  ASR: 0.1875 (0.1875)  ACC: 0.5000 (0.5000)  Loss: 3.3842 (3.3842)  time: 0.3199  data: 0.1973  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.2330)  ACC: 0.5000 (0.4943)  Loss: 3.0427 (3.0621)  time: 0.1380  data: 0.0182  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.2232)  ACC: 0.4375 (0.4881)  Loss: 2.9953 (3.0161)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.2258)  ACC: 0.5000 (0.4960)  Loss: 2.9614 (3.0112)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.2226)  ACC: 0.4375 (0.4909)  Loss: 2.9961 (3.0508)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.1875 (0.2145)  ACC: 0.5000 (0.5037)  Loss: 3.2520 (3.1109)  time: 0.1207  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.2223)  ACC: 0.5625 (0.5092)  Loss: 3.1418 (3.0622)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.2183)  ACC: 0.5000 (0.5060)  Loss: 3.1207 (3.0698)  time: 0.1171  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1236 s / it)
* ASR 0.218 loss 3.070
Test: [Task 2]  [ 0/63]  eta: 0:00:20  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.8007 (0.8007)  time: 0.3244  data: 0.2053  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (82.3864)  Acc@5: 100.0000 (97.1591)  Loss: 0.6152 (0.6718)  time: 0.1371  data: 0.0189  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (82.7381)  Acc@5: 93.7500 (95.5357)  Loss: 0.6226 (0.7154)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (83.0645)  Acc@5: 93.7500 (95.7661)  Loss: 0.6487 (0.7195)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (82.3171)  Acc@5: 100.0000 (96.3415)  Loss: 0.6484 (0.6991)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (82.4755)  Acc@5: 100.0000 (96.5686)  Loss: 0.6112 (0.6937)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (83.8115)  Acc@5: 100.0000 (96.8238)  Loss: 0.5249 (0.6606)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (83.9000)  Acc@5: 100.0000 (96.9000)  Loss: 0.5172 (0.6520)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1223 s / it)
* Acc@1 83.900 Acc@5 96.900 loss 0.652
Test: [Task 2]  [ 0/63]  eta: 0:00:20  ASR: 0.1875 (0.1875)  ACC: 0.5625 (0.5625)  Loss: 3.0413 (3.0413)  time: 0.3239  data: 0.1985  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1364)  ACC: 0.6875 (0.6875)  Loss: 3.9298 (3.9199)  time: 0.1390  data: 0.0185  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1786)  ACC: 0.6875 (0.6756)  Loss: 3.8036 (3.7151)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1774)  ACC: 0.6875 (0.6895)  Loss: 3.7398 (3.8044)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1677)  ACC: 0.7500 (0.7043)  Loss: 3.9151 (3.8382)  time: 0.1209  data: 0.0004  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1703)  ACC: 0.7500 (0.6973)  Loss: 3.9635 (3.8982)  time: 0.1212  data: 0.0004  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1598)  ACC: 0.7500 (0.7141)  Loss: 4.0904 (3.9473)  time: 0.1206  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1577)  ACC: 0.7500 (0.7183)  Loss: 4.0976 (3.9568)  time: 0.1176  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1242 s / it)
* ASR 0.158 loss 3.957
Test: [Task 3]  [ 0/63]  eta: 0:00:20  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.3687 (0.3687)  time: 0.3285  data: 0.2079  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (99.4318)  Loss: 0.6614 (0.6422)  time: 0.1379  data: 0.0192  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (98.8095)  Loss: 0.7334 (0.6530)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (81.8548)  Acc@5: 100.0000 (98.7903)  Loss: 0.7334 (0.6468)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (82.1646)  Acc@5: 100.0000 (98.6280)  Loss: 0.6488 (0.6509)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (82.5980)  Acc@5: 100.0000 (98.4069)  Loss: 0.6592 (0.6549)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (82.6844)  Acc@5: 100.0000 (98.2582)  Loss: 0.6422 (0.6641)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (82.6000)  Acc@5: 100.0000 (98.1000)  Loss: 0.6888 (0.6752)  time: 0.1160  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1226 s / it)
* Acc@1 82.600 Acc@5 98.100 loss 0.675
Test: [Task 3]  [ 0/63]  eta: 0:00:22  ASR: 0.1250 (0.1250)  ACC: 0.8750 (0.8750)  Loss: 4.6501 (4.6501)  time: 0.3536  data: 0.2288  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.2216)  ACC: 0.6250 (0.6420)  Loss: 4.3034 (4.3174)  time: 0.1418  data: 0.0211  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1875)  ACC: 0.6875 (0.6726)  Loss: 4.5485 (4.5333)  time: 0.1208  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1815)  ACC: 0.6875 (0.6815)  Loss: 4.5485 (4.5870)  time: 0.1209  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.1814)  ACC: 0.6875 (0.6784)  Loss: 4.5101 (4.5361)  time: 0.1209  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.1875 (0.1838)  ACC: 0.6250 (0.6777)  Loss: 4.5307 (4.5361)  time: 0.1208  data: 0.0004  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.1834)  ACC: 0.6875 (0.6834)  Loss: 4.5915 (4.5464)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.1806)  ACC: 0.6875 (0.6806)  Loss: 4.5666 (4.5494)  time: 0.1176  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1251 s / it)
* ASR 0.181 loss 4.549
Test: [Task 4]  [ 0/63]  eta: 0:00:21  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5355 (0.5355)  time: 0.3377  data: 0.2184  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.8636)  Loss: 0.4566 (0.4754)  time: 0.1387  data: 0.0202  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (97.6190)  Loss: 0.4182 (0.4789)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (88.9113)  Acc@5: 100.0000 (97.7823)  Loss: 0.4769 (0.4920)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (89.7866)  Acc@5: 100.0000 (98.0183)  Loss: 0.3585 (0.4636)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (89.4608)  Acc@5: 100.0000 (98.1618)  Loss: 0.3150 (0.4637)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (88.8320)  Acc@5: 100.0000 (97.9508)  Loss: 0.4289 (0.4758)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (89.0000)  Acc@5: 100.0000 (97.9000)  Loss: 0.3936 (0.4712)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1229 s / it)
* Acc@1 89.000 Acc@5 97.900 loss 0.471
Test: [Task 4]  [ 0/63]  eta: 0:00:19  ASR: 0.1250 (0.1250)  ACC: 0.6250 (0.6250)  Loss: 4.2086 (4.2086)  time: 0.3051  data: 0.1778  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.2273)  ACC: 0.6250 (0.6364)  Loss: 4.2516 (4.1075)  time: 0.1373  data: 0.0165  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1905)  ACC: 0.6875 (0.6786)  Loss: 4.2942 (4.3385)  time: 0.1207  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1815)  ACC: 0.6875 (0.6915)  Loss: 4.3013 (4.4147)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1753)  ACC: 0.7500 (0.7012)  Loss: 4.5785 (4.4272)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1752)  ACC: 0.7500 (0.7034)  Loss: 4.2974 (4.3878)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1721)  ACC: 0.6875 (0.7039)  Loss: 4.2974 (4.4185)  time: 0.1194  data: 0.0002  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1696)  ACC: 0.6875 (0.7054)  Loss: 4.3920 (4.4193)  time: 0.1166  data: 0.0002  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1236 s / it)
* ASR 0.170 loss 4.419
Test: [Task 5]  [ 0/63]  eta: 0:00:20  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1204 (0.1204)  time: 0.3259  data: 0.2072  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.8636)  Loss: 0.3536 (0.4966)  time: 0.1372  data: 0.0191  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (98.8095)  Loss: 0.3536 (0.4426)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (90.5242)  Acc@5: 100.0000 (98.5887)  Loss: 0.3414 (0.4474)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (91.4634)  Acc@5: 100.0000 (98.9329)  Loss: 0.4099 (0.4434)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (91.0539)  Acc@5: 100.0000 (98.6520)  Loss: 0.4306 (0.4595)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (90.6762)  Acc@5: 100.0000 (98.5656)  Loss: 0.4306 (0.4650)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (90.3000)  Acc@5: 100.0000 (98.5000)  Loss: 0.4334 (0.4789)  time: 0.1158  data: 0.0002  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1222 s / it)
* Acc@1 90.300 Acc@5 98.500 loss 0.479
Test: [Task 5]  [ 0/63]  eta: 0:00:22  ASR: 0.1875 (0.1875)  ACC: 0.8125 (0.8125)  Loss: 4.3942 (4.3942)  time: 0.3508  data: 0.2208  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.1875)  ACC: 0.7500 (0.7102)  Loss: 4.2462 (4.3332)  time: 0.1417  data: 0.0204  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1786)  ACC: 0.6875 (0.7202)  Loss: 4.3649 (4.4537)  time: 0.1207  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1714)  ACC: 0.6875 (0.7238)  Loss: 4.2970 (4.4003)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1616)  ACC: 0.6875 (0.7241)  Loss: 4.3182 (4.4017)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1532)  ACC: 0.7500 (0.7353)  Loss: 4.3496 (4.3974)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1557)  ACC: 0.7500 (0.7316)  Loss: 4.3072 (4.3974)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1627)  ACC: 0.6875 (0.7222)  Loss: 4.2423 (4.3380)  time: 0.1171  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1242 s / it)
* ASR 0.163 loss 4.338
Test: [Task 6]  [ 0/63]  eta: 0:00:19  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4067 (0.4067)  time: 0.3086  data: 0.1904  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (99.4318)  Loss: 0.4682 (0.4435)  time: 0.1357  data: 0.0176  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (98.8095)  Loss: 0.4808 (0.5040)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (98.9919)  Loss: 0.4187 (0.4862)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (82.0122)  Acc@5: 100.0000 (98.9329)  Loss: 0.5003 (0.5072)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (82.7206)  Acc@5: 100.0000 (99.1422)  Loss: 0.5003 (0.4991)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (82.8893)  Acc@5: 100.0000 (98.9754)  Loss: 0.4803 (0.5175)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (83.0000)  Acc@5: 100.0000 (99.0000)  Loss: 0.4803 (0.5120)  time: 0.1160  data: 0.0003  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1221 s / it)
* Acc@1 83.000 Acc@5 99.000 loss 0.512
Test: [Task 6]  [ 0/63]  eta: 0:00:21  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7500)  Loss: 5.4722 (5.4722)  time: 0.3354  data: 0.2109  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.0795)  ACC: 0.8125 (0.7898)  Loss: 4.8971 (4.7587)  time: 0.1400  data: 0.0195  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0685)  ACC: 0.8125 (0.7679)  Loss: 4.6835 (4.6716)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0685)  ACC: 0.7500 (0.7560)  Loss: 4.6623 (4.6823)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0655)  ACC: 0.6875 (0.7470)  Loss: 4.6328 (4.6491)  time: 0.1208  data: 0.0004  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0613)  ACC: 0.7500 (0.7463)  Loss: 4.7087 (4.6752)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0656)  ACC: 0.6875 (0.7377)  Loss: 4.7087 (4.6546)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0645)  ACC: 0.7500 (0.7411)  Loss: 4.5960 (4.6486)  time: 0.1171  data: 0.0003  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1241 s / it)
* ASR 0.064 loss 4.649
[Average accuracy till task6]	ASR: 0.1589	Acc@1: 81.9500	Loss: 4.1636	Forgetting: 0.1627	Backward: -0.1583
Train: Epoch[1/5]  [  0/313]  eta: 0:02:10  Lr: 0.0019 (0.0019)  Acc@1: 12.5000 (12.5000)  Acc@5: 37.5000 (37.5000)  Loss: 2.1698 (2.1698)  time: 0.4174  data: 0.2236  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (61.3636)  Acc@5: 93.7500 (85.2273)  Loss: 1.8469 (1.9066)  time: 0.2113  data: 0.0206  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (75.5952)  Acc@5: 100.0000 (91.9643)  Loss: 1.5817 (1.6202)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.0484)  Acc@5: 100.0000 (94.3548)  Loss: 1.1084 (1.4058)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.7561)  Acc@5: 100.0000 (95.7317)  Loss: 0.7095 (1.2177)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (87.1324)  Acc@5: 100.0000 (96.4461)  Loss: 0.5448 (1.0749)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.0123)  Acc@5: 100.0000 (97.0287)  Loss: 0.4313 (0.9634)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.8204)  Acc@5: 100.0000 (97.3592)  Loss: 0.3078 (0.8674)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4290)  Acc@5: 100.0000 (97.6080)  Loss: 0.2555 (0.7874)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.9038)  Acc@5: 100.0000 (97.8709)  Loss: 0.1451 (0.7229)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.4084)  Acc@5: 100.0000 (98.0817)  Loss: 0.1776 (0.6670)  time: 0.1915  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.7658)  Acc@5: 100.0000 (98.1419)  Loss: 0.1649 (0.6234)  time: 0.1915  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.1674)  Acc@5: 100.0000 (98.2955)  Loss: 0.1229 (0.5811)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.6031)  Acc@5: 100.0000 (98.4256)  Loss: 0.0897 (0.5414)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.8440)  Acc@5: 100.0000 (98.5372)  Loss: 0.0535 (0.5101)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (92.0944)  Acc@5: 100.0000 (98.5927)  Loss: 0.0557 (0.4805)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.3913)  Acc@5: 100.0000 (98.6801)  Loss: 0.0266 (0.4530)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.6535)  Acc@5: 100.0000 (98.7573)  Loss: 0.0057 (0.4282)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.8177)  Acc@5: 100.0000 (98.7914)  Loss: -0.0057 (0.4074)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.0301)  Acc@5: 100.0000 (98.8547)  Loss: -0.0141 (0.3871)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.1903)  Acc@5: 100.0000 (98.9117)  Loss: 0.0188 (0.3703)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.3649)  Acc@5: 100.0000 (98.9633)  Loss: -0.0229 (0.3523)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.4672)  Acc@5: 100.0000 (99.0102)  Loss: -0.0033 (0.3393)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.6418)  Acc@5: 100.0000 (99.0260)  Loss: -0.0033 (0.3250)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.7241)  Acc@5: 100.0000 (99.0664)  Loss: -0.0088 (0.3124)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.8496)  Acc@5: 100.0000 (99.0787)  Loss: 0.0006 (0.2998)  time: 0.1917  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.9655)  Acc@5: 100.0000 (99.1140)  Loss: -0.0292 (0.2877)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.0498)  Acc@5: 100.0000 (99.1467)  Loss: -0.0292 (0.2766)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.0614)  Acc@5: 100.0000 (99.1548)  Loss: -0.0153 (0.2688)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.0722)  Acc@5: 100.0000 (99.1838)  Loss: 0.0081 (0.2602)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.1030)  Acc@5: 100.0000 (99.2110)  Loss: 0.0068 (0.2525)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.1318)  Acc@5: 100.0000 (99.2363)  Loss: -0.0021 (0.2454)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.1294)  Acc@5: 100.0000 (99.2412)  Loss: -0.0021 (0.2437)  time: 0.1865  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:01:00 (0.1921 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.1294)  Acc@5: 100.0000 (99.2412)  Loss: -0.0021 (0.2437)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1602 (0.1602)  time: 0.3837  data: 0.1884  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.3182)  Acc@5: 100.0000 (100.0000)  Loss: 0.0295 (0.0448)  time: 0.2085  data: 0.0174  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.8333)  Acc@5: 100.0000 (100.0000)  Loss: -0.0363 (0.0093)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.5645)  Acc@5: 100.0000 (100.0000)  Loss: -0.0786 (0.0105)  time: 0.1912  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1890)  Acc@5: 100.0000 (100.0000)  Loss: -0.0786 (-0.0062)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5686)  Acc@5: 100.0000 (100.0000)  Loss: -0.0955 (-0.0191)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7213)  Acc@5: 100.0000 (100.0000)  Loss: -0.0818 (-0.0238)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9190)  Acc@5: 100.0000 (100.0000)  Loss: -0.0594 (-0.0295)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7593)  Acc@5: 100.0000 (100.0000)  Loss: -0.0833 (-0.0315)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7033)  Acc@5: 100.0000 (100.0000)  Loss: -0.0833 (-0.0321)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.8441)  Acc@5: 100.0000 (100.0000)  Loss: -0.0717 (-0.0339)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7905)  Acc@5: 100.0000 (100.0000)  Loss: -0.0541 (-0.0312)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9525)  Acc@5: 100.0000 (100.0000)  Loss: -0.0572 (-0.0339)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9466)  Acc@5: 100.0000 (100.0000)  Loss: -0.0896 (-0.0343)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0745)  Acc@5: 100.0000 (100.0000)  Loss: -0.0941 (-0.0367)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1026)  Acc@5: 100.0000 (100.0000)  Loss: -0.0833 (-0.0382)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1273)  Acc@5: 100.0000 (100.0000)  Loss: -0.0972 (-0.0408)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1126)  Acc@5: 100.0000 (100.0000)  Loss: -0.1026 (-0.0425)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2030)  Acc@5: 100.0000 (100.0000)  Loss: -0.1181 (-0.0439)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2513)  Acc@5: 100.0000 (100.0000)  Loss: -0.1205 (-0.0462)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2948)  Acc@5: 100.0000 (100.0000)  Loss: -0.1193 (-0.0475)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2749)  Acc@5: 100.0000 (100.0000)  Loss: -0.1010 (-0.0493)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2568)  Acc@5: 100.0000 (100.0000)  Loss: -0.1008 (-0.0493)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2944)  Acc@5: 100.0000 (99.9729)  Loss: -0.0823 (-0.0502)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2770)  Acc@5: 100.0000 (99.9741)  Loss: -0.0823 (-0.0506)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3108)  Acc@5: 100.0000 (99.9751)  Loss: -0.0807 (-0.0517)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3420)  Acc@5: 100.0000 (99.9761)  Loss: -0.0902 (-0.0529)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3478)  Acc@5: 100.0000 (99.9769)  Loss: -0.0903 (-0.0539)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3532)  Acc@5: 100.0000 (99.9555)  Loss: -0.0965 (-0.0533)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3153)  Acc@5: 100.0000 (99.9570)  Loss: -0.0780 (-0.0530)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.2591)  Acc@5: 100.0000 (99.9585)  Loss: -0.0780 (-0.0522)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.2267)  Acc@5: 100.0000 (99.9598)  Loss: -0.0886 (-0.0515)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2444)  Acc@5: 100.0000 (99.9601)  Loss: -0.0886 (-0.0518)  time: 0.1867  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2444)  Acc@5: 100.0000 (99.9601)  Loss: -0.0886 (-0.0518)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0824 (0.0824)  time: 0.4028  data: 0.2077  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (96.0227)  Acc@5: 100.0000 (100.0000)  Loss: -0.0475 (-0.0275)  time: 0.2107  data: 0.0192  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0238)  Acc@5: 100.0000 (100.0000)  Loss: -0.0917 (-0.0509)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.1694)  Acc@5: 100.0000 (100.0000)  Loss: -0.0969 (-0.0433)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6463)  Acc@5: 100.0000 (100.0000)  Loss: -0.1132 (-0.0572)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (100.0000)  Loss: -0.1340 (-0.0674)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.2336)  Acc@5: 100.0000 (100.0000)  Loss: -0.1208 (-0.0729)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5352)  Acc@5: 100.0000 (100.0000)  Loss: -0.0991 (-0.0776)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6080)  Acc@5: 100.0000 (100.0000)  Loss: -0.1127 (-0.0796)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7335)  Acc@5: 100.0000 (100.0000)  Loss: -0.1259 (-0.0799)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7723)  Acc@5: 100.0000 (100.0000)  Loss: -0.1196 (-0.0808)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7477)  Acc@5: 100.0000 (100.0000)  Loss: -0.0990 (-0.0785)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8822)  Acc@5: 100.0000 (100.0000)  Loss: -0.1051 (-0.0812)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8053)  Acc@5: 100.0000 (100.0000)  Loss: -0.1150 (-0.0797)  time: 0.1917  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8723)  Acc@5: 100.0000 (100.0000)  Loss: -0.1211 (-0.0818)  time: 0.1918  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9305)  Acc@5: 100.0000 (100.0000)  Loss: -0.1211 (-0.0831)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9814)  Acc@5: 100.0000 (100.0000)  Loss: -0.1249 (-0.0847)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9898)  Acc@5: 100.0000 (100.0000)  Loss: -0.1322 (-0.0856)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0663)  Acc@5: 100.0000 (100.0000)  Loss: -0.1393 (-0.0868)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1675)  Acc@5: 100.0000 (100.0000)  Loss: -0.1424 (-0.0885)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1965)  Acc@5: 100.0000 (100.0000)  Loss: -0.1310 (-0.0893)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2227)  Acc@5: 100.0000 (100.0000)  Loss: -0.1310 (-0.0904)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1216 (-0.0903)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2143)  Acc@5: 100.0000 (100.0000)  Loss: -0.1163 (-0.0908)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2106)  Acc@5: 100.0000 (100.0000)  Loss: -0.1163 (-0.0908)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2072)  Acc@5: 100.0000 (100.0000)  Loss: -0.1154 (-0.0915)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2519)  Acc@5: 100.0000 (100.0000)  Loss: -0.1159 (-0.0924)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2703)  Acc@5: 100.0000 (100.0000)  Loss: -0.1173 (-0.0931)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2651)  Acc@5: 100.0000 (100.0000)  Loss: -0.1218 (-0.0927)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2603)  Acc@5: 100.0000 (100.0000)  Loss: -0.0961 (-0.0922)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1728)  Acc@5: 100.0000 (100.0000)  Loss: -0.0961 (-0.0910)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (98.1310)  Acc@5: 100.0000 (100.0000)  Loss: -0.1293 (-0.0900)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1430)  Acc@5: 100.0000 (100.0000)  Loss: -0.1293 (-0.0903)  time: 0.1858  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1430)  Acc@5: 100.0000 (100.0000)  Loss: -0.1293 (-0.0903)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:03  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.0272 (0.0272)  time: 0.3948  data: 0.2005  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: -0.0810 (-0.0681)  time: 0.2096  data: 0.0185  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6190)  Acc@5: 100.0000 (100.0000)  Loss: -0.1281 (-0.0824)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1774)  Acc@5: 100.0000 (100.0000)  Loss: -0.0999 (-0.0774)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5610)  Acc@5: 100.0000 (100.0000)  Loss: -0.1392 (-0.0875)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7941)  Acc@5: 100.0000 (100.0000)  Loss: -0.1470 (-0.0953)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1557)  Acc@5: 100.0000 (100.0000)  Loss: -0.1374 (-0.1007)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3275)  Acc@5: 100.0000 (100.0000)  Loss: -0.1285 (-0.1034)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4568)  Acc@5: 100.0000 (100.0000)  Loss: -0.1241 (-0.1050)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4890)  Acc@5: 100.0000 (100.0000)  Loss: -0.1343 (-0.1049)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4530)  Acc@5: 100.0000 (100.0000)  Loss: -0.1324 (-0.1055)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4234)  Acc@5: 100.0000 (100.0000)  Loss: -0.1190 (-0.1032)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5537)  Acc@5: 100.0000 (100.0000)  Loss: -0.1190 (-0.1052)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4256)  Acc@5: 100.0000 (100.0000)  Loss: -0.1336 (-0.1035)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4486)  Acc@5: 100.0000 (100.0000)  Loss: -0.1417 (-0.1052)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4685)  Acc@5: 100.0000 (100.0000)  Loss: -0.1417 (-0.1064)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4860)  Acc@5: 100.0000 (100.0000)  Loss: -0.1418 (-0.1075)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4649)  Acc@5: 100.0000 (100.0000)  Loss: -0.1443 (-0.1080)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5152)  Acc@5: 100.0000 (100.0000)  Loss: -0.1502 (-0.1091)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5929)  Acc@5: 100.0000 (100.0000)  Loss: -0.1477 (-0.1104)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1448 (-0.1111)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6374)  Acc@5: 100.0000 (100.0000)  Loss: -0.1433 (-0.1118)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6708)  Acc@5: 100.0000 (100.0000)  Loss: -0.1338 (-0.1117)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7013)  Acc@5: 100.0000 (100.0000)  Loss: -0.1244 (-0.1121)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6774)  Acc@5: 100.0000 (100.0000)  Loss: -0.1244 (-0.1119)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7052)  Acc@5: 100.0000 (100.0000)  Loss: -0.1332 (-0.1124)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7308)  Acc@5: 100.0000 (100.0000)  Loss: -0.1336 (-0.1131)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7546)  Acc@5: 100.0000 (100.0000)  Loss: -0.1371 (-0.1137)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7544)  Acc@5: 100.0000 (100.0000)  Loss: -0.1358 (-0.1134)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7113)  Acc@5: 100.0000 (100.0000)  Loss: -0.1113 (-0.1130)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6503)  Acc@5: 100.0000 (100.0000)  Loss: -0.1187 (-0.1120)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6334)  Acc@5: 100.0000 (100.0000)  Loss: -0.1424 (-0.1110)  time: 0.1913  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6422)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1112)  time: 0.1867  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:00 (0.1919 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6422)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1112)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:09  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: -0.0219 (-0.0219)  time: 0.4134  data: 0.2207  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: -0.1034 (-0.0904)  time: 0.2117  data: 0.0203  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9167)  Acc@5: 100.0000 (100.0000)  Loss: -0.1373 (-0.1043)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5806)  Acc@5: 100.0000 (100.0000)  Loss: -0.1242 (-0.0999)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1073)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2843)  Acc@5: 100.0000 (100.0000)  Loss: -0.1500 (-0.1138)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5656)  Acc@5: 100.0000 (100.0000)  Loss: -0.1497 (-0.1182)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7676)  Acc@5: 100.0000 (100.0000)  Loss: -0.1339 (-0.1197)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8426)  Acc@5: 100.0000 (100.0000)  Loss: -0.1339 (-0.1210)  time: 0.1916  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8324)  Acc@5: 100.0000 (100.0000)  Loss: -0.1402 (-0.1210)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8243)  Acc@5: 100.0000 (100.0000)  Loss: -0.1421 (-0.1214)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8176)  Acc@5: 100.0000 (100.0000)  Loss: -0.1338 (-0.1195)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9153)  Acc@5: 100.0000 (100.0000)  Loss: -0.1316 (-0.1211)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7595)  Acc@5: 100.0000 (100.0000)  Loss: -0.1414 (-0.1192)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7589)  Acc@5: 100.0000 (100.0000)  Loss: -0.1470 (-0.1203)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7997)  Acc@5: 100.0000 (100.0000)  Loss: -0.1459 (-0.1212)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7966)  Acc@5: 100.0000 (100.0000)  Loss: -0.1479 (-0.1221)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7573)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1227)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8260)  Acc@5: 100.0000 (100.0000)  Loss: -0.1544 (-0.1235)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8874)  Acc@5: 100.0000 (100.0000)  Loss: -0.1528 (-0.1246)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9117)  Acc@5: 100.0000 (100.0000)  Loss: -0.1491 (-0.1251)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9040)  Acc@5: 100.0000 (100.0000)  Loss: -0.1491 (-0.1256)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9253)  Acc@5: 100.0000 (100.0000)  Loss: -0.1447 (-0.1255)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9448)  Acc@5: 100.0000 (100.0000)  Loss: -0.1347 (-0.1260)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9627)  Acc@5: 100.0000 (100.0000)  Loss: -0.1347 (-0.1257)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0040)  Acc@5: 100.0000 (100.0000)  Loss: -0.1380 (-0.1261)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0421)  Acc@5: 100.0000 (100.0000)  Loss: -0.1452 (-0.1267)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0544)  Acc@5: 100.0000 (100.0000)  Loss: -0.1452 (-0.1271)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0658)  Acc@5: 100.0000 (100.0000)  Loss: -0.1443 (-0.1269)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0765)  Acc@5: 100.0000 (100.0000)  Loss: -0.1312 (-0.1267)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0241)  Acc@5: 100.0000 (100.0000)  Loss: -0.1349 (-0.1258)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9952)  Acc@5: 100.0000 (100.0000)  Loss: -0.1476 (-0.1249)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0016)  Acc@5: 100.0000 (100.0000)  Loss: -0.1476 (-0.1250)  time: 0.1870  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0016)  Acc@5: 100.0000 (100.0000)  Loss: -0.1476 (-0.1250)
Test: [Task 1]  [ 0/63]  eta: 0:00:20  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  Loss: 1.5584 (1.5584)  time: 0.3246  data: 0.2047  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 68.7500 (64.2045)  Acc@5: 93.7500 (94.8864)  Loss: 1.4349 (1.4057)  time: 0.1375  data: 0.0190  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 62.5000 (63.3929)  Acc@5: 93.7500 (95.2381)  Loss: 1.3506 (1.4335)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 62.5000 (65.5242)  Acc@5: 100.0000 (96.1694)  Loss: 1.3451 (1.3614)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 62.5000 (65.2439)  Acc@5: 100.0000 (96.3415)  Loss: 1.3451 (1.3487)  time: 0.1191  data: 0.0004  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 68.7500 (66.9118)  Acc@5: 100.0000 (96.5686)  Loss: 1.2850 (1.3195)  time: 0.1190  data: 0.0004  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 68.7500 (67.1107)  Acc@5: 100.0000 (96.7213)  Loss: 1.2454 (1.2967)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 68.7500 (66.9000)  Acc@5: 100.0000 (96.8000)  Loss: 1.0685 (1.2924)  time: 0.1160  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1229 s / it)
* Acc@1 66.900 Acc@5 96.800 loss 1.292
Test: [Task 1]  [ 0/63]  eta: 0:00:20  ASR: 0.0625 (0.0625)  ACC: 0.6250 (0.6250)  Loss: 3.5820 (3.5820)  time: 0.3180  data: 0.1942  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.2045)  ACC: 0.5000 (0.5114)  Loss: 3.1586 (3.1167)  time: 0.1380  data: 0.0180  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.2202)  ACC: 0.4375 (0.5030)  Loss: 3.0695 (3.0708)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.2500 (0.2339)  ACC: 0.5000 (0.5181)  Loss: 2.9153 (3.0167)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.2500 (0.2302)  ACC: 0.5000 (0.5030)  Loss: 2.9153 (3.0583)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.1875 (0.2218)  ACC: 0.5000 (0.5196)  Loss: 3.2768 (3.1270)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.2295)  ACC: 0.5625 (0.5246)  Loss: 3.1469 (3.0808)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.2272)  ACC: 0.5625 (0.5208)  Loss: 3.1450 (3.0838)  time: 0.1175  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1242 s / it)
* ASR 0.227 loss 3.084
Test: [Task 2]  [ 0/63]  eta: 0:00:19  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.6558 (0.6558)  time: 0.3030  data: 0.1841  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (97.1591)  Loss: 0.5916 (0.6122)  time: 0.1355  data: 0.0171  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (83.9286)  Acc@5: 100.0000 (95.8333)  Loss: 0.5916 (0.6855)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (84.4758)  Acc@5: 93.7500 (95.5645)  Loss: 0.7201 (0.6857)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (85.2134)  Acc@5: 100.0000 (96.1890)  Loss: 0.6014 (0.6649)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (84.9265)  Acc@5: 100.0000 (96.3235)  Loss: 0.5714 (0.6681)  time: 0.1190  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (85.6557)  Acc@5: 100.0000 (96.7213)  Loss: 0.4976 (0.6373)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (85.7000)  Acc@5: 100.0000 (96.8000)  Loss: 0.4943 (0.6301)  time: 0.1161  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1221 s / it)
* Acc@1 85.700 Acc@5 96.800 loss 0.630
Test: [Task 2]  [ 0/63]  eta: 0:00:20  ASR: 0.2500 (0.2500)  ACC: 0.6250 (0.6250)  Loss: 3.0559 (3.0559)  time: 0.3217  data: 0.1961  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1591)  ACC: 0.6875 (0.6875)  Loss: 3.8440 (3.8711)  time: 0.1389  data: 0.0182  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.2054)  ACC: 0.6250 (0.6637)  Loss: 3.7344 (3.6956)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1935)  ACC: 0.6875 (0.6815)  Loss: 3.6600 (3.7869)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1768)  ACC: 0.7500 (0.6982)  Loss: 4.0472 (3.8468)  time: 0.1207  data: 0.0004  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1728)  ACC: 0.7500 (0.6949)  Loss: 4.0780 (3.9167)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1660)  ACC: 0.6875 (0.7080)  Loss: 4.0781 (3.9541)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1617)  ACC: 0.7500 (0.7143)  Loss: 4.1864 (3.9695)  time: 0.1170  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1240 s / it)
* ASR 0.162 loss 3.969
Test: [Task 3]  [ 0/63]  eta: 0:00:19  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4915 (0.4915)  time: 0.3041  data: 0.1812  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (99.4318)  Loss: 0.5242 (0.6312)  time: 0.1356  data: 0.0168  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (81.8452)  Acc@5: 100.0000 (98.2143)  Loss: 0.6169 (0.6325)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (82.6613)  Acc@5: 100.0000 (97.5806)  Loss: 0.6530 (0.6252)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (82.6220)  Acc@5: 100.0000 (98.0183)  Loss: 0.5756 (0.6291)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (83.3333)  Acc@5: 100.0000 (97.9167)  Loss: 0.6446 (0.6261)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (82.9918)  Acc@5: 100.0000 (98.0533)  Loss: 0.6306 (0.6415)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (82.9000)  Acc@5: 100.0000 (97.9000)  Loss: 0.6569 (0.6514)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1224 s / it)
* Acc@1 82.900 Acc@5 97.900 loss 0.651
Test: [Task 3]  [ 0/63]  eta: 0:00:21  ASR: 0.1875 (0.1875)  ACC: 0.8125 (0.8125)  Loss: 4.6434 (4.6434)  time: 0.3361  data: 0.2052  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.2159)  ACC: 0.6875 (0.6420)  Loss: 4.4291 (4.2843)  time: 0.1401  data: 0.0190  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1905)  ACC: 0.6875 (0.6696)  Loss: 4.5786 (4.4775)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1855)  ACC: 0.6875 (0.6754)  Loss: 4.6447 (4.5757)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.1905)  ACC: 0.6875 (0.6768)  Loss: 4.6174 (4.5562)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.1875 (0.1936)  ACC: 0.6875 (0.6801)  Loss: 4.5023 (4.5346)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.1895)  ACC: 0.6875 (0.6824)  Loss: 4.5629 (4.5511)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.1875)  ACC: 0.6250 (0.6806)  Loss: 4.4679 (4.5498)  time: 0.1169  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1245 s / it)
* ASR 0.188 loss 4.550
Test: [Task 4]  [ 0/63]  eta: 0:00:20  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5776 (0.5776)  time: 0.3278  data: 0.2086  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (92.0455)  Acc@5: 100.0000 (98.8636)  Loss: 0.4270 (0.4375)  time: 0.1376  data: 0.0193  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (97.9167)  Loss: 0.4270 (0.4841)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (87.5000)  Acc@5: 100.0000 (97.7823)  Loss: 0.4983 (0.5015)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (97.8659)  Loss: 0.2829 (0.4699)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (88.4804)  Acc@5: 100.0000 (98.0392)  Loss: 0.3427 (0.4719)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (87.9098)  Acc@5: 100.0000 (97.7459)  Loss: 0.4192 (0.4874)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (88.1000)  Acc@5: 100.0000 (97.7000)  Loss: 0.4035 (0.4833)  time: 0.1160  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1224 s / it)
* Acc@1 88.100 Acc@5 97.700 loss 0.483
Test: [Task 4]  [ 0/63]  eta: 0:00:21  ASR: 0.2500 (0.2500)  ACC: 0.6250 (0.6250)  Loss: 3.8580 (3.8580)  time: 0.3435  data: 0.2174  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.2500 (0.2670)  ACC: 0.6250 (0.6136)  Loss: 4.1831 (4.0839)  time: 0.1407  data: 0.0201  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.2173)  ACC: 0.6250 (0.6429)  Loss: 4.1963 (4.3266)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.2077)  ACC: 0.6250 (0.6452)  Loss: 4.4866 (4.4016)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.2043)  ACC: 0.6875 (0.6585)  Loss: 4.6957 (4.4501)  time: 0.1205  data: 0.0003  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.2022)  ACC: 0.6875 (0.6618)  Loss: 4.4003 (4.4284)  time: 0.1206  data: 0.0003  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1957)  ACC: 0.6875 (0.6650)  Loss: 4.2782 (4.4667)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1905)  ACC: 0.6875 (0.6677)  Loss: 4.2694 (4.4604)  time: 0.1174  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1243 s / it)
* ASR 0.190 loss 4.460
Test: [Task 5]  [ 0/63]  eta: 0:00:21  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1295 (0.1295)  time: 0.3433  data: 0.2250  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (97.7273)  Loss: 0.4489 (0.6094)  time: 0.1391  data: 0.0208  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.6905)  Acc@5: 100.0000 (98.2143)  Loss: 0.4378 (0.5082)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (89.9194)  Acc@5: 100.0000 (98.5887)  Loss: 0.3645 (0.4951)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (90.3963)  Acc@5: 100.0000 (98.6280)  Loss: 0.3779 (0.4928)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (90.5637)  Acc@5: 100.0000 (98.2843)  Loss: 0.4454 (0.5017)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (90.1639)  Acc@5: 100.0000 (98.0533)  Loss: 0.4839 (0.5123)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (89.8000)  Acc@5: 100.0000 (98.0000)  Loss: 0.5939 (0.5255)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1227 s / it)
* Acc@1 89.800 Acc@5 98.000 loss 0.525
Test: [Task 5]  [ 0/63]  eta: 0:00:20  ASR: 0.1875 (0.1875)  ACC: 0.8125 (0.8125)  Loss: 4.5003 (4.5003)  time: 0.3286  data: 0.1971  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.1932)  ACC: 0.6875 (0.6932)  Loss: 4.0358 (4.1721)  time: 0.1390  data: 0.0183  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: 0.1875 (0.1815)  ACC: 0.6875 (0.7054)  Loss: 4.0715 (4.2828)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1895)  ACC: 0.6875 (0.7036)  Loss: 4.0715 (4.2180)  time: 0.1205  data: 0.0005  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.1814)  ACC: 0.6875 (0.7088)  Loss: 4.1593 (4.2345)  time: 0.1206  data: 0.0005  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1740)  ACC: 0.7500 (0.7157)  Loss: 4.2066 (4.2406)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1721)  ACC: 0.6875 (0.7141)  Loss: 4.1424 (4.2485)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1806)  ACC: 0.6875 (0.7034)  Loss: 4.1400 (4.1927)  time: 0.1171  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1239 s / it)
* ASR 0.181 loss 4.193
Test: [Task 6]  [ 0/63]  eta: 0:00:27  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4537 (0.4537)  time: 0.4416  data: 0.3233  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (98.8636)  Loss: 0.4971 (0.5291)  time: 0.1480  data: 0.0298  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  Acc@1: 75.0000 (80.3571)  Acc@5: 100.0000 (98.2143)  Loss: 0.5495 (0.5732)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (80.4435)  Acc@5: 100.0000 (98.5887)  Loss: 0.5461 (0.5554)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (79.5732)  Acc@5: 100.0000 (98.7805)  Loss: 0.5506 (0.5736)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (80.0245)  Acc@5: 100.0000 (98.8971)  Loss: 0.5645 (0.5714)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (80.2254)  Acc@5: 100.0000 (98.5656)  Loss: 0.5645 (0.5847)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (80.3000)  Acc@5: 100.0000 (98.6000)  Loss: 0.5645 (0.5792)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1246 s / it)
* Acc@1 80.300 Acc@5 98.600 loss 0.579
Test: [Task 6]  [ 0/63]  eta: 0:00:25  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7500)  Loss: 5.4087 (5.4087)  time: 0.3993  data: 0.2753  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1193)  ACC: 0.7500 (0.7386)  Loss: 4.6301 (4.6208)  time: 0.1458  data: 0.0254  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.1012)  ACC: 0.7500 (0.7321)  Loss: 4.5163 (4.4594)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0968)  ACC: 0.6875 (0.7298)  Loss: 4.4196 (4.4631)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0960)  ACC: 0.6875 (0.7180)  Loss: 4.3711 (4.4040)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0907)  ACC: 0.6875 (0.7206)  Loss: 4.4092 (4.4227)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0912)  ACC: 0.6875 (0.7111)  Loss: 4.2629 (4.3930)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0913)  ACC: 0.6875 (0.7143)  Loss: 4.2567 (4.3882)  time: 0.1174  data: 0.0003  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1252 s / it)
* ASR 0.091 loss 4.388
Test: [Task 7]  [ 0/63]  eta: 0:00:20  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.6462 (0.6462)  time: 0.3328  data: 0.2153  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (98.8636)  Loss: 0.4549 (0.4495)  time: 0.1381  data: 0.0199  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (97.3214)  Loss: 0.4549 (0.4964)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (97.1774)  Loss: 0.5053 (0.4867)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (87.9573)  Acc@5: 100.0000 (97.2561)  Loss: 0.4703 (0.4714)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (86.8873)  Acc@5: 100.0000 (96.8137)  Loss: 0.4456 (0.5139)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (96.8238)  Loss: 0.5749 (0.5112)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (87.4000)  Acc@5: 100.0000 (96.9000)  Loss: 0.5749 (0.5061)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1226 s / it)
* Acc@1 87.400 Acc@5 96.900 loss 0.506
Test: [Task 7]  [ 0/63]  eta: 0:00:24  ASR: 0.0000 (0.0000)  ACC: 0.7500 (0.7500)  Loss: 5.3708 (5.3708)  time: 0.3878  data: 0.2621  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0568)  ACC: 0.8125 (0.8125)  Loss: 4.8774 (4.6434)  time: 0.1443  data: 0.0241  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0863)  ACC: 0.8125 (0.8006)  Loss: 4.4819 (4.7539)  time: 0.1207  data: 0.0003  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0927)  ACC: 0.8125 (0.7883)  Loss: 4.9177 (4.8201)  time: 0.1211  data: 0.0004  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0991)  ACC: 0.7500 (0.7774)  Loss: 4.8582 (4.8071)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.1042)  ACC: 0.6875 (0.7708)  Loss: 4.6316 (4.7610)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1086)  ACC: 0.6875 (0.7643)  Loss: 4.5178 (4.7317)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1101)  ACC: 0.6875 (0.7649)  Loss: 4.4558 (4.7197)  time: 0.1175  data: 0.0003  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1254 s / it)
* ASR 0.110 loss 4.720
[Average accuracy till task7]	ASR: 0.1641	Acc@1: 83.0143	Loss: 4.1949	Forgetting: 0.1258	Backward: -0.1177
Train: Epoch[1/5]  [  0/313]  eta: 0:02:19  Lr: 0.0019 (0.0019)  Acc@1: 0.0000 (0.0000)  Acc@5: 62.5000 (62.5000)  Loss: 2.1747 (2.1747)  time: 0.4462  data: 0.2494  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (67.0455)  Acc@5: 100.0000 (90.9091)  Loss: 1.8817 (1.8666)  time: 0.2143  data: 0.0229  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.0833)  Acc@5: 100.0000 (94.9405)  Loss: 1.5519 (1.6121)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.8548)  Acc@5: 100.0000 (96.3710)  Loss: 1.0922 (1.4042)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.2134)  Acc@5: 100.0000 (97.2561)  Loss: 0.8033 (1.2064)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (87.7451)  Acc@5: 100.0000 (97.6716)  Loss: 0.5129 (1.0630)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (89.1393)  Acc@5: 100.0000 (98.0533)  Loss: 0.4447 (0.9568)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0528)  Acc@5: 100.0000 (98.3275)  Loss: 0.3331 (0.8585)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.8179)  Acc@5: 100.0000 (98.5340)  Loss: 0.1977 (0.7743)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.2775)  Acc@5: 100.0000 (98.6264)  Loss: 0.1690 (0.7148)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.8936)  Acc@5: 100.0000 (98.7624)  Loss: 0.1607 (0.6581)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.5113)  Acc@5: 100.0000 (98.8739)  Loss: 0.0891 (0.6075)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.9752)  Acc@5: 100.0000 (98.9669)  Loss: 0.0691 (0.5649)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.4637)  Acc@5: 100.0000 (99.0458)  Loss: 0.0203 (0.5239)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.7057)  Acc@5: 100.0000 (99.1135)  Loss: 0.0485 (0.4907)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.9570)  Acc@5: 100.0000 (99.1722)  Loss: 0.0331 (0.4599)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.9441)  Acc@5: 100.0000 (99.1848)  Loss: 0.0331 (0.4366)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.9327)  Acc@5: 100.0000 (99.2325)  Loss: 0.0277 (0.4130)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.1644)  Acc@5: 100.0000 (99.2403)  Loss: 0.0163 (0.3917)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.2408)  Acc@5: 100.0000 (99.2801)  Loss: 0.0185 (0.3732)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.4652)  Acc@5: 100.0000 (99.2848)  Loss: -0.0016 (0.3539)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.4905)  Acc@5: 100.0000 (99.3187)  Loss: -0.0049 (0.3399)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.5136)  Acc@5: 100.0000 (99.3495)  Loss: -0.0201 (0.3258)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.6158)  Acc@5: 100.0000 (99.3506)  Loss: -0.0412 (0.3106)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.6058)  Acc@5: 100.0000 (99.3257)  Loss: 0.0158 (0.3000)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.6962)  Acc@5: 100.0000 (99.3526)  Loss: -0.0349 (0.2873)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.8036)  Acc@5: 100.0000 (99.3774)  Loss: -0.0349 (0.2755)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.8570)  Acc@5: 100.0000 (99.4004)  Loss: -0.0278 (0.2647)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.9733)  Acc@5: 100.0000 (99.4217)  Loss: -0.0481 (0.2542)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.0601)  Acc@5: 100.0000 (99.4416)  Loss: -0.0352 (0.2446)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.1412)  Acc@5: 100.0000 (99.4601)  Loss: -0.0266 (0.2357)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.2572)  Acc@5: 100.0000 (99.4775)  Loss: -0.0853 (0.2260)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.2875)  Acc@5: 100.0000 (99.4808)  Loss: -0.1037 (0.2237)  time: 0.1859  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:01:00 (0.1917 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.2875)  Acc@5: 100.0000 (99.4808)  Loss: -0.1037 (0.2237)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:30  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1082 (-0.1082)  time: 0.4794  data: 0.2840  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  Loss: -0.0733 (-0.0208)  time: 0.2170  data: 0.0260  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (99.4048)  Loss: -0.0733 (-0.0274)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3710)  Acc@5: 100.0000 (99.5968)  Loss: -0.0753 (-0.0216)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7988)  Acc@5: 100.0000 (99.6951)  Loss: -0.0753 (-0.0319)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3039)  Acc@5: 100.0000 (99.7549)  Loss: -0.1000 (-0.0420)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5410)  Acc@5: 100.0000 (99.7951)  Loss: -0.1000 (-0.0412)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5352)  Acc@5: 100.0000 (99.8239)  Loss: -0.0473 (-0.0433)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (97.3765)  Acc@5: 100.0000 (99.8457)  Loss: -0.0701 (-0.0456)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (99.7940)  Loss: -0.0732 (-0.0427)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3391)  Acc@5: 100.0000 (99.8144)  Loss: -0.0752 (-0.0448)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.5788)  Acc@5: 100.0000 (99.8311)  Loss: -0.1035 (-0.0496)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6240)  Acc@5: 100.0000 (99.8450)  Loss: -0.1065 (-0.0510)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7099)  Acc@5: 100.0000 (99.8569)  Loss: -0.1131 (-0.0551)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7394)  Acc@5: 100.0000 (99.8670)  Loss: -0.1125 (-0.0576)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8063)  Acc@5: 100.0000 (99.8758)  Loss: -0.1233 (-0.0602)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7096)  Acc@5: 100.0000 (99.8835)  Loss: -0.1041 (-0.0591)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6974)  Acc@5: 100.0000 (99.8904)  Loss: -0.0825 (-0.0596)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7555)  Acc@5: 100.0000 (99.8964)  Loss: -0.1157 (-0.0608)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7749)  Acc@5: 100.0000 (99.9018)  Loss: -0.0846 (-0.0608)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8234)  Acc@5: 100.0000 (99.8756)  Loss: -0.0846 (-0.0623)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7784)  Acc@5: 100.0000 (99.8815)  Loss: -0.1089 (-0.0613)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7376)  Acc@5: 100.0000 (99.8869)  Loss: -0.1089 (-0.0613)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (99.8918)  Loss: -0.1185 (-0.0623)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.6660)  Acc@5: 100.0000 (99.8963)  Loss: -0.0863 (-0.0607)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7341)  Acc@5: 100.0000 (99.9004)  Loss: -0.1102 (-0.0618)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7730)  Acc@5: 100.0000 (99.9042)  Loss: -0.1161 (-0.0631)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8321)  Acc@5: 100.0000 (99.9077)  Loss: -0.1134 (-0.0642)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8425)  Acc@5: 100.0000 (99.9110)  Loss: -0.1200 (-0.0652)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8308)  Acc@5: 100.0000 (99.9141)  Loss: -0.1124 (-0.0660)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8198)  Acc@5: 100.0000 (99.9169)  Loss: -0.1124 (-0.0664)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8497)  Acc@5: 100.0000 (99.9196)  Loss: -0.1301 (-0.0676)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8634)  Acc@5: 100.0000 (99.9201)  Loss: -0.1388 (-0.0682)  time: 0.1860  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.8634)  Acc@5: 100.0000 (99.9201)  Loss: -0.1388 (-0.0682)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1425 (-0.1425)  time: 0.4444  data: 0.2522  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1273 (-0.0719)  time: 0.2138  data: 0.0232  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8095)  Acc@5: 100.0000 (100.0000)  Loss: -0.1136 (-0.0776)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7823)  Acc@5: 100.0000 (100.0000)  Loss: -0.0975 (-0.0692)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.0183)  Acc@5: 100.0000 (100.0000)  Loss: -0.1136 (-0.0783)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2843)  Acc@5: 100.0000 (100.0000)  Loss: -0.1235 (-0.0859)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3607)  Acc@5: 100.0000 (100.0000)  Loss: -0.1208 (-0.0857)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3275)  Acc@5: 100.0000 (100.0000)  Loss: -0.1171 (-0.0869)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3796)  Acc@5: 100.0000 (100.0000)  Loss: -0.1200 (-0.0888)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2830)  Acc@5: 100.0000 (100.0000)  Loss: -0.1164 (-0.0864)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2673)  Acc@5: 100.0000 (100.0000)  Loss: -0.1164 (-0.0874)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4234)  Acc@5: 100.0000 (100.0000)  Loss: -0.1322 (-0.0910)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3988)  Acc@5: 100.0000 (100.0000)  Loss: -0.1322 (-0.0916)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4733)  Acc@5: 100.0000 (100.0000)  Loss: -0.1303 (-0.0939)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5816)  Acc@5: 100.0000 (100.0000)  Loss: -0.1284 (-0.0958)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6341)  Acc@5: 100.0000 (100.0000)  Loss: -0.1419 (-0.0977)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6025)  Acc@5: 100.0000 (100.0000)  Loss: -0.1325 (-0.0972)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6111)  Acc@5: 100.0000 (100.0000)  Loss: -0.1138 (-0.0972)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6533)  Acc@5: 100.0000 (100.0000)  Loss: -0.1332 (-0.0979)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6584)  Acc@5: 100.0000 (100.0000)  Loss: -0.1136 (-0.0978)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6629)  Acc@5: 100.0000 (100.0000)  Loss: -0.1062 (-0.0985)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6374)  Acc@5: 100.0000 (100.0000)  Loss: -0.1332 (-0.0982)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6425)  Acc@5: 100.0000 (100.0000)  Loss: -0.1336 (-0.0983)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5931)  Acc@5: 100.0000 (100.0000)  Loss: -0.1361 (-0.0983)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5218)  Acc@5: 100.0000 (100.0000)  Loss: -0.1026 (-0.0966)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5558)  Acc@5: 100.0000 (100.0000)  Loss: -0.1289 (-0.0974)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5632)  Acc@5: 100.0000 (100.0000)  Loss: -0.1339 (-0.0983)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6162)  Acc@5: 100.0000 (100.0000)  Loss: -0.1367 (-0.0992)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6210)  Acc@5: 100.0000 (100.0000)  Loss: -0.1442 (-0.0998)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6254)  Acc@5: 100.0000 (100.0000)  Loss: -0.1298 (-0.1004)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6296)  Acc@5: 100.0000 (100.0000)  Loss: -0.1298 (-0.1003)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6334)  Acc@5: 100.0000 (100.0000)  Loss: -0.1342 (-0.1011)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6422)  Acc@5: 100.0000 (100.0000)  Loss: -0.1489 (-0.1015)  time: 0.1862  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:00:59 (0.1916 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6422)  Acc@5: 100.0000 (100.0000)  Loss: -0.1489 (-0.1015)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:18  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1537 (-0.1537)  time: 0.4441  data: 0.2500  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1386 (-0.0972)  time: 0.2135  data: 0.0230  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8095)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.1019)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.9839)  Acc@5: 100.0000 (100.0000)  Loss: -0.1210 (-0.0952)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1707)  Acc@5: 100.0000 (100.0000)  Loss: -0.1362 (-0.1045)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4069)  Acc@5: 100.0000 (100.0000)  Loss: -0.1385 (-0.1092)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4631)  Acc@5: 100.0000 (100.0000)  Loss: -0.1301 (-0.1094)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5035)  Acc@5: 100.0000 (100.0000)  Loss: -0.1376 (-0.1107)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6111)  Acc@5: 100.0000 (100.0000)  Loss: -0.1376 (-0.1118)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4890)  Acc@5: 100.0000 (100.0000)  Loss: -0.1360 (-0.1101)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5767)  Acc@5: 100.0000 (100.0000)  Loss: -0.1329 (-0.1109)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7050)  Acc@5: 100.0000 (100.0000)  Loss: -0.1423 (-0.1135)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7087)  Acc@5: 100.0000 (100.0000)  Loss: -0.1423 (-0.1140)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7595)  Acc@5: 100.0000 (100.0000)  Loss: -0.1420 (-0.1156)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8475)  Acc@5: 100.0000 (100.0000)  Loss: -0.1356 (-0.1171)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8825)  Acc@5: 100.0000 (100.0000)  Loss: -0.1487 (-0.1188)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9130)  Acc@5: 100.0000 (100.0000)  Loss: -0.1430 (-0.1187)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9035)  Acc@5: 100.0000 (100.0000)  Loss: -0.1350 (-0.1187)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9296)  Acc@5: 100.0000 (100.0000)  Loss: -0.1452 (-0.1187)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9856)  Acc@5: 100.0000 (100.0000)  Loss: -0.1196 (-0.1186)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0050)  Acc@5: 100.0000 (100.0000)  Loss: -0.1215 (-0.1190)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9633)  Acc@5: 100.0000 (100.0000)  Loss: -0.1424 (-0.1192)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9819)  Acc@5: 100.0000 (100.0000)  Loss: -0.1445 (-0.1193)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9719)  Acc@5: 100.0000 (100.0000)  Loss: -0.1459 (-0.1192)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8849)  Acc@5: 100.0000 (100.0000)  Loss: -0.1170 (-0.1175)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9293)  Acc@5: 100.0000 (100.0000)  Loss: -0.1390 (-0.1181)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9224)  Acc@5: 100.0000 (100.0000)  Loss: -0.1403 (-0.1186)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9622)  Acc@5: 100.0000 (100.0000)  Loss: -0.1493 (-0.1193)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9546)  Acc@5: 100.0000 (100.0000)  Loss: -0.1510 (-0.1197)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9261)  Acc@5: 100.0000 (100.0000)  Loss: -0.1474 (-0.1201)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9203)  Acc@5: 100.0000 (100.0000)  Loss: -0.1469 (-0.1200)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9349)  Acc@5: 100.0000 (100.0000)  Loss: -0.1408 (-0.1206)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9417)  Acc@5: 100.0000 (100.0000)  Loss: -0.1495 (-0.1208)  time: 0.1863  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:01:00 (0.1917 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9417)  Acc@5: 100.0000 (100.0000)  Loss: -0.1495 (-0.1208)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1598 (-0.1598)  time: 0.4323  data: 0.2396  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1450 (-0.1170)  time: 0.2121  data: 0.0220  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1071)  Acc@5: 100.0000 (100.0000)  Loss: -0.1442 (-0.1199)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3871)  Acc@5: 100.0000 (100.0000)  Loss: -0.1340 (-0.1150)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7805)  Acc@5: 100.0000 (100.0000)  Loss: -0.1457 (-0.1235)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)  Loss: -0.1478 (-0.1262)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9754)  Acc@5: 100.0000 (100.0000)  Loss: -0.1370 (-0.1265)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0317)  Acc@5: 100.0000 (100.0000)  Loss: -0.1440 (-0.1279)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0741)  Acc@5: 100.0000 (100.0000)  Loss: -0.1440 (-0.1286)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0385)  Acc@5: 100.0000 (100.0000)  Loss: -0.1365 (-0.1269)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0718)  Acc@5: 100.0000 (100.0000)  Loss: -0.1365 (-0.1274)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1554)  Acc@5: 100.0000 (100.0000)  Loss: -0.1457 (-0.1290)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1219)  Acc@5: 100.0000 (100.0000)  Loss: -0.1466 (-0.1294)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1889)  Acc@5: 100.0000 (100.0000)  Loss: -0.1461 (-0.1304)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2465)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1314)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2964)  Acc@5: 100.0000 (100.0000)  Loss: -0.1530 (-0.1331)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3401)  Acc@5: 100.0000 (100.0000)  Loss: -0.1502 (-0.1332)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3421)  Acc@5: 100.0000 (100.0000)  Loss: -0.1389 (-0.1330)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3439)  Acc@5: 100.0000 (100.0000)  Loss: -0.1523 (-0.1328)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3783)  Acc@5: 100.0000 (100.0000)  Loss: -0.1300 (-0.1325)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3781)  Acc@5: 100.0000 (100.0000)  Loss: -0.1317 (-0.1327)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3780)  Acc@5: 100.0000 (100.0000)  Loss: -0.1439 (-0.1331)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3778)  Acc@5: 100.0000 (100.0000)  Loss: -0.1483 (-0.1332)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3506)  Acc@5: 100.0000 (100.0000)  Loss: -0.1507 (-0.1332)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2739)  Acc@5: 100.0000 (100.0000)  Loss: -0.1308 (-0.1318)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3028)  Acc@5: 100.0000 (100.0000)  Loss: -0.1416 (-0.1321)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3056)  Acc@5: 100.0000 (100.0000)  Loss: -0.1458 (-0.1325)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3312)  Acc@5: 100.0000 (100.0000)  Loss: -0.1532 (-0.1330)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3327)  Acc@5: 100.0000 (100.0000)  Loss: -0.1554 (-0.1332)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3342)  Acc@5: 100.0000 (100.0000)  Loss: -0.1519 (-0.1335)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3355)  Acc@5: 100.0000 (100.0000)  Loss: -0.1490 (-0.1334)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3368)  Acc@5: 100.0000 (100.0000)  Loss: -0.1469 (-0.1339)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3411)  Acc@5: 100.0000 (100.0000)  Loss: -0.1536 (-0.1340)  time: 0.1863  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3411)  Acc@5: 100.0000 (100.0000)  Loss: -0.1536 (-0.1340)
Test: [Task 1]  [ 0/63]  eta: 0:00:23  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)  Loss: 1.3490 (1.3490)  time: 0.3759  data: 0.2570  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 68.7500 (61.9318)  Acc@5: 93.7500 (95.4545)  Loss: 1.4292 (1.4310)  time: 0.1420  data: 0.0237  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 62.5000 (61.3095)  Acc@5: 93.7500 (95.8333)  Loss: 1.4292 (1.4479)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 62.5000 (62.2984)  Acc@5: 100.0000 (96.5726)  Loss: 1.2506 (1.3857)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 62.5000 (61.7378)  Acc@5: 100.0000 (96.6463)  Loss: 1.2506 (1.3810)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 62.5000 (62.9902)  Acc@5: 100.0000 (96.6912)  Loss: 1.2497 (1.3664)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 68.7500 (63.7295)  Acc@5: 100.0000 (97.0287)  Loss: 1.2410 (1.3440)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 68.7500 (63.6000)  Acc@5: 100.0000 (97.1000)  Loss: 1.2246 (1.3395)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1231 s / it)
* Acc@1 63.600 Acc@5 97.100 loss 1.339
Test: [Task 1]  [ 0/63]  eta: 0:00:22  ASR: 0.0625 (0.0625)  ACC: 0.6875 (0.6875)  Loss: 3.8630 (3.8630)  time: 0.3634  data: 0.2406  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1420)  ACC: 0.6250 (0.5568)  Loss: 3.6332 (3.5533)  time: 0.1420  data: 0.0221  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1518)  ACC: 0.5000 (0.5298)  Loss: 3.4242 (3.5244)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1593)  ACC: 0.5000 (0.5403)  Loss: 3.3607 (3.4859)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.1540)  ACC: 0.5000 (0.5274)  Loss: 3.4553 (3.5383)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1581)  ACC: 0.5000 (0.5331)  Loss: 3.7614 (3.6004)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.1701)  ACC: 0.5625 (0.5379)  Loss: 3.5764 (3.5593)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.1696)  ACC: 0.5625 (0.5367)  Loss: 3.5713 (3.5696)  time: 0.1168  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1244 s / it)
* ASR 0.170 loss 3.570
Test: [Task 2]  [ 0/63]  eta: 0:00:23  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.8561 (0.8561)  time: 0.3682  data: 0.2490  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.2955)  Loss: 0.6510 (0.6453)  time: 0.1413  data: 0.0229  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (96.7262)  Loss: 0.6510 (0.7024)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (83.2661)  Acc@5: 93.7500 (95.9677)  Loss: 0.6536 (0.7102)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (96.4939)  Loss: 0.6500 (0.6995)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (83.0882)  Acc@5: 100.0000 (96.4461)  Loss: 0.6500 (0.6993)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (83.9139)  Acc@5: 100.0000 (96.8238)  Loss: 0.5509 (0.6704)  time: 0.1184  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (83.9000)  Acc@5: 100.0000 (96.9000)  Loss: 0.4988 (0.6616)  time: 0.1156  data: 0.0002  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1229 s / it)
* Acc@1 83.900 Acc@5 96.900 loss 0.662
Test: [Task 2]  [ 0/63]  eta: 0:00:21  ASR: 0.1875 (0.1875)  ACC: 0.6250 (0.6250)  Loss: 3.5457 (3.5457)  time: 0.3457  data: 0.2134  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0966)  ACC: 0.6875 (0.7443)  Loss: 4.3950 (4.4677)  time: 0.1410  data: 0.0198  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.1131)  ACC: 0.6875 (0.7173)  Loss: 4.2770 (4.3151)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.1028)  ACC: 0.7500 (0.7298)  Loss: 4.4145 (4.4022)  time: 0.1207  data: 0.0004  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0930)  ACC: 0.7500 (0.7393)  Loss: 4.6872 (4.4518)  time: 0.1207  data: 0.0004  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0858)  ACC: 0.6875 (0.7328)  Loss: 4.6872 (4.5379)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0850)  ACC: 0.7500 (0.7428)  Loss: 4.7233 (4.5656)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0833)  ACC: 0.7500 (0.7480)  Loss: 4.6488 (4.5782)  time: 0.1171  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1246 s / it)
* ASR 0.083 loss 4.578
Test: [Task 3]  [ 0/63]  eta: 0:00:22  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5106 (0.5106)  time: 0.3595  data: 0.2418  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (81.8182)  Acc@5: 100.0000 (99.4318)  Loss: 0.5706 (0.6695)  time: 0.1406  data: 0.0223  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (80.9524)  Acc@5: 100.0000 (98.2143)  Loss: 0.6888 (0.6686)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (81.8548)  Acc@5: 100.0000 (97.7823)  Loss: 0.7090 (0.6697)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (81.8598)  Acc@5: 100.0000 (97.7134)  Loss: 0.7456 (0.6745)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (82.7206)  Acc@5: 100.0000 (97.5490)  Loss: 0.7456 (0.6695)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (82.4795)  Acc@5: 100.0000 (97.6434)  Loss: 0.6517 (0.6795)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (82.3000)  Acc@5: 100.0000 (97.5000)  Loss: 0.7162 (0.6968)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1233 s / it)
* Acc@1 82.300 Acc@5 97.500 loss 0.697
Test: [Task 3]  [ 0/63]  eta: 0:00:24  ASR: 0.1250 (0.1250)  ACC: 0.7500 (0.7500)  Loss: 5.3296 (5.3296)  time: 0.3834  data: 0.2615  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1364)  ACC: 0.6875 (0.6932)  Loss: 4.9080 (4.8487)  time: 0.1440  data: 0.0241  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1280)  ACC: 0.6875 (0.7113)  Loss: 4.9572 (5.0008)  time: 0.1199  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.1230)  ACC: 0.6875 (0.7238)  Loss: 5.1608 (5.0821)  time: 0.1198  data: 0.0004  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1296)  ACC: 0.6875 (0.7149)  Loss: 4.9083 (5.0344)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1311)  ACC: 0.6875 (0.7157)  Loss: 4.9701 (5.0412)  time: 0.1206  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1250)  ACC: 0.7500 (0.7172)  Loss: 5.1122 (5.0636)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1220)  ACC: 0.6875 (0.7143)  Loss: 5.0400 (5.0646)  time: 0.1173  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1249 s / it)
* ASR 0.122 loss 5.065
Test: [Task 4]  [ 0/63]  eta: 0:00:22  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.5951 (0.5951)  time: 0.3558  data: 0.2358  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (89.7727)  Acc@5: 93.7500 (96.5909)  Loss: 0.5327 (0.4759)  time: 0.1404  data: 0.0218  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (87.7976)  Acc@5: 93.7500 (96.4286)  Loss: 0.4623 (0.5095)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (86.6935)  Acc@5: 93.7500 (96.1694)  Loss: 0.5643 (0.5580)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (96.9512)  Loss: 0.2991 (0.5094)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (87.6225)  Acc@5: 100.0000 (97.1814)  Loss: 0.2991 (0.5062)  time: 0.1191  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (87.6025)  Acc@5: 100.0000 (97.0287)  Loss: 0.3705 (0.5094)  time: 0.1190  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (87.8000)  Acc@5: 100.0000 (97.0000)  Loss: 0.3705 (0.5050)  time: 0.1162  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1230 s / it)
* Acc@1 87.800 Acc@5 97.000 loss 0.505
Test: [Task 4]  [ 0/63]  eta: 0:00:23  ASR: 0.1250 (0.1250)  ACC: 0.8125 (0.8125)  Loss: 4.6676 (4.6676)  time: 0.3776  data: 0.2506  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.1818)  ACC: 0.6250 (0.6534)  Loss: 4.7635 (4.7169)  time: 0.1438  data: 0.0231  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1458)  ACC: 0.6875 (0.6875)  Loss: 4.8414 (4.9546)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.1270)  ACC: 0.7500 (0.7016)  Loss: 5.1754 (5.0525)  time: 0.1199  data: 0.0004  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.1204)  ACC: 0.8125 (0.7180)  Loss: 5.3613 (5.1027)  time: 0.1199  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1299)  ACC: 0.7500 (0.7120)  Loss: 5.0711 (5.0604)  time: 0.1200  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1260)  ACC: 0.6875 (0.7111)  Loss: 4.7586 (5.0902)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1220)  ACC: 0.6875 (0.7143)  Loss: 4.7675 (5.0916)  time: 0.1171  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1244 s / it)
* ASR 0.122 loss 5.092
Test: [Task 5]  [ 0/63]  eta: 0:00:24  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1290 (0.1290)  time: 0.3962  data: 0.2740  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (88.6364)  Acc@5: 100.0000 (98.2955)  Loss: 0.4103 (0.5522)  time: 0.1439  data: 0.0253  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (89.8810)  Acc@5: 100.0000 (98.8095)  Loss: 0.4004 (0.4763)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (98.7903)  Loss: 0.3730 (0.4789)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (89.9390)  Acc@5: 100.0000 (98.9329)  Loss: 0.4204 (0.4810)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (89.5833)  Acc@5: 100.0000 (98.6520)  Loss: 0.4995 (0.4869)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (88.9344)  Acc@5: 100.0000 (98.4631)  Loss: 0.5005 (0.4942)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (88.7000)  Acc@5: 100.0000 (98.2000)  Loss: 0.5108 (0.5114)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1235 s / it)
* Acc@1 88.700 Acc@5 98.200 loss 0.511
Test: [Task 5]  [ 0/63]  eta: 0:00:23  ASR: 0.0625 (0.0625)  ACC: 0.8750 (0.8750)  Loss: 5.1699 (5.1699)  time: 0.3772  data: 0.2542  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1193)  ACC: 0.6875 (0.7216)  Loss: 4.5375 (4.6642)  time: 0.1429  data: 0.0234  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1161)  ACC: 0.6875 (0.7500)  Loss: 4.5375 (4.7827)  time: 0.1196  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1169)  ACC: 0.7500 (0.7440)  Loss: 4.6182 (4.7683)  time: 0.1198  data: 0.0004  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1143)  ACC: 0.7500 (0.7470)  Loss: 4.7404 (4.7687)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.1103)  ACC: 0.7500 (0.7475)  Loss: 4.7961 (4.7639)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.1107)  ACC: 0.7500 (0.7439)  Loss: 4.7821 (4.7790)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1171)  ACC: 0.6875 (0.7351)  Loss: 4.6261 (4.7358)  time: 0.1169  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1244 s / it)
* ASR 0.117 loss 4.736
Test: [Task 6]  [ 0/63]  eta: 0:00:22  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4089 (0.4089)  time: 0.3547  data: 0.2363  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (98.2955)  Loss: 0.5166 (0.4958)  time: 0.1400  data: 0.0218  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (82.1429)  Acc@5: 100.0000 (97.6190)  Loss: 0.5215 (0.5742)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.1855)  Loss: 0.5494 (0.5699)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (80.6402)  Acc@5: 100.0000 (98.3232)  Loss: 0.6162 (0.5915)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (81.0049)  Acc@5: 100.0000 (98.5294)  Loss: 0.6178 (0.5849)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (80.8402)  Acc@5: 100.0000 (98.4631)  Loss: 0.5395 (0.5932)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (80.9000)  Acc@5: 100.0000 (98.5000)  Loss: 0.5509 (0.5898)  time: 0.1156  data: 0.0002  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1227 s / it)
* Acc@1 80.900 Acc@5 98.500 loss 0.590
Test: [Task 6]  [ 0/63]  eta: 0:00:23  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7500)  Loss: 5.4648 (5.4648)  time: 0.3728  data: 0.2431  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7670)  Loss: 5.0207 (5.1445)  time: 0.1431  data: 0.0224  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7262)  Loss: 4.9266 (4.9555)  time: 0.1209  data: 0.0004  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0645)  ACC: 0.6875 (0.7298)  Loss: 4.9647 (4.9880)  time: 0.1211  data: 0.0004  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0701)  ACC: 0.7500 (0.7256)  Loss: 4.8624 (4.9130)  time: 0.1208  data: 0.0004  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0674)  ACC: 0.7500 (0.7279)  Loss: 4.8954 (4.9336)  time: 0.1205  data: 0.0004  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0686)  ACC: 0.6875 (0.7203)  Loss: 4.9226 (4.9027)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0685)  ACC: 0.6875 (0.7212)  Loss: 4.8112 (4.8959)  time: 0.1170  data: 0.0003  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1253 s / it)
* ASR 0.068 loss 4.896
Test: [Task 7]  [ 0/63]  eta: 0:00:22  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)  Loss: 1.2448 (1.2448)  time: 0.3532  data: 0.2325  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (98.2955)  Loss: 0.5989 (0.6787)  time: 0.1398  data: 0.0214  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.0238)  Loss: 0.5661 (0.6853)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (81.0484)  Acc@5: 100.0000 (96.9758)  Loss: 0.5664 (0.6643)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (81.8598)  Acc@5: 100.0000 (97.1037)  Loss: 0.5664 (0.6390)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (81.7402)  Acc@5: 100.0000 (96.5686)  Loss: 0.6555 (0.6751)  time: 0.1189  data: 0.0004  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (82.0697)  Acc@5: 100.0000 (96.7213)  Loss: 0.6641 (0.6661)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (82.2000)  Acc@5: 100.0000 (96.8000)  Loss: 0.6641 (0.6603)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1230 s / it)
* Acc@1 82.200 Acc@5 96.800 loss 0.660
Test: [Task 7]  [ 0/63]  eta: 0:00:24  ASR: 0.0625 (0.0625)  ACC: 0.6250 (0.6250)  Loss: 5.6257 (5.6257)  time: 0.3909  data: 0.2664  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0511)  ACC: 0.8125 (0.7670)  Loss: 5.2303 (5.0396)  time: 0.1451  data: 0.0245  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0595)  ACC: 0.7500 (0.7560)  Loss: 5.0057 (5.1181)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0645)  ACC: 0.7500 (0.7500)  Loss: 5.3171 (5.1826)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0655)  ACC: 0.6875 (0.7439)  Loss: 5.2899 (5.1765)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0650)  ACC: 0.6875 (0.7402)  Loss: 5.0278 (5.1409)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0645)  ACC: 0.6875 (0.7377)  Loss: 4.9551 (5.1264)  time: 0.1196  data: 0.0002  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0655)  ACC: 0.6875 (0.7391)  Loss: 4.9247 (5.1148)  time: 0.1167  data: 0.0002  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1246 s / it)
* ASR 0.065 loss 5.115
Test: [Task 8]  [ 0/63]  eta: 0:00:22  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4751 (0.4751)  time: 0.3644  data: 0.2453  max mem: 12058
Test: [Task 8]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (97.1591)  Loss: 0.4751 (0.4993)  time: 0.1407  data: 0.0226  max mem: 12058
Test: [Task 8]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (87.7976)  Acc@5: 93.7500 (97.0238)  Loss: 0.4439 (0.4797)  time: 0.1184  data: 0.0003  max mem: 12058
Test: [Task 8]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (88.1048)  Acc@5: 100.0000 (97.7823)  Loss: 0.3666 (0.4445)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 8]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (89.0244)  Acc@5: 100.0000 (98.0183)  Loss: 0.3267 (0.4342)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 8]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (89.4608)  Acc@5: 100.0000 (97.7941)  Loss: 0.4322 (0.4308)  time: 0.1186  data: 0.0004  max mem: 12058
Test: [Task 8]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (88.7295)  Acc@5: 93.7500 (97.3361)  Loss: 0.4448 (0.4457)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 8]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (88.8000)  Acc@5: 93.7500 (97.4000)  Loss: 0.4258 (0.4406)  time: 0.1157  data: 0.0003  max mem: 12058
Test: [Task 8] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 88.800 Acc@5 97.400 loss 0.441
Test: [Task 8]  [ 0/63]  eta: 0:00:23  ASR: 0.1250 (0.1250)  ACC: 0.8125 (0.8125)  Loss: 5.6020 (5.6020)  time: 0.3700  data: 0.2443  max mem: 12058
Test: [Task 8]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0455)  ACC: 0.8125 (0.7898)  Loss: 5.8518 (5.5845)  time: 0.1425  data: 0.0225  max mem: 12058
Test: [Task 8]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0565)  ACC: 0.8125 (0.7887)  Loss: 5.8041 (5.5835)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 8]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0625)  ACC: 0.8125 (0.7964)  Loss: 5.3948 (5.5893)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 8]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0595)  ACC: 0.8125 (0.7912)  Loss: 5.3948 (5.5157)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 8]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0564)  ACC: 0.8125 (0.7880)  Loss: 5.1712 (5.4835)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 8]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0645)  ACC: 0.7500 (0.7787)  Loss: 5.2645 (5.4727)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 8]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7788)  Loss: 5.2915 (5.5034)  time: 0.1170  data: 0.0003  max mem: 12058
Test: [Task 8] Total time: 0:00:07 (0.1245 s / it)
* ASR 0.062 loss 5.503
[Average accuracy till task8]	ASR: 0.1013	Acc@1: 82.2750	Loss: 4.8192	Forgetting: 0.1651	Backward: -0.1582
Train: Epoch[1/5]  [  0/313]  eta: 0:02:16  Lr: 0.0019 (0.0019)  Acc@1: 18.7500 (18.7500)  Acc@5: 43.7500 (43.7500)  Loss: 2.2112 (2.2112)  time: 0.4376  data: 0.2431  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.0455)  Acc@5: 93.7500 (88.0682)  Loss: 1.8776 (1.9078)  time: 0.2127  data: 0.0224  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (81.5476)  Acc@5: 100.0000 (93.7500)  Loss: 1.5448 (1.6271)  time: 0.1901  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (86.2903)  Acc@5: 100.0000 (95.7661)  Loss: 1.0468 (1.3910)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (89.3293)  Acc@5: 100.0000 (96.7988)  Loss: 0.7074 (1.2015)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.0539)  Acc@5: 100.0000 (97.3039)  Loss: 0.4477 (1.0391)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.9057)  Acc@5: 100.0000 (97.7459)  Loss: 0.3626 (0.9251)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.8697)  Acc@5: 100.0000 (98.0634)  Loss: 0.1920 (0.8153)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.4414)  Acc@5: 100.0000 (98.3025)  Loss: 0.1277 (0.7312)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.0934)  Acc@5: 100.0000 (98.4890)  Loss: 0.0685 (0.6602)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.4926)  Acc@5: 100.0000 (98.6386)  Loss: 0.0685 (0.6030)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.5383)  Acc@5: 100.0000 (98.7613)  Loss: 0.0767 (0.5577)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (94.6798)  Acc@5: 100.0000 (98.8636)  Loss: 0.0911 (0.5175)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.9905)  Acc@5: 100.0000 (98.9504)  Loss: 0.0265 (0.4794)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.3014)  Acc@5: 100.0000 (99.0248)  Loss: -0.0069 (0.4451)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.5712)  Acc@5: 100.0000 (99.0894)  Loss: -0.0400 (0.4133)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7686)  Acc@5: 100.0000 (99.1460)  Loss: -0.0624 (0.3837)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.6871)  Acc@5: 100.0000 (99.1594)  Loss: -0.0624 (0.3644)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.7182)  Acc@5: 100.0000 (99.1713)  Loss: -0.0164 (0.3461)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.8442)  Acc@5: 100.0000 (99.2147)  Loss: -0.0190 (0.3269)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.8955)  Acc@5: 100.0000 (99.2537)  Loss: 0.0057 (0.3121)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0012)  Acc@5: 100.0000 (99.2891)  Loss: 0.0057 (0.2967)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0690)  Acc@5: 100.0000 (99.2930)  Loss: -0.0581 (0.2806)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2121)  Acc@5: 100.0000 (99.3236)  Loss: -0.0665 (0.2665)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2396)  Acc@5: 100.0000 (99.3517)  Loss: -0.0582 (0.2560)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2898)  Acc@5: 100.0000 (99.3775)  Loss: -0.0583 (0.2430)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3362)  Acc@5: 100.0000 (99.3774)  Loss: -0.1126 (0.2320)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3792)  Acc@5: 100.0000 (99.4004)  Loss: -0.0697 (0.2224)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.4635)  Acc@5: 100.0000 (99.4217)  Loss: -0.0619 (0.2125)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5636)  Acc@5: 100.0000 (99.4416)  Loss: -0.1146 (0.2018)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5532)  Acc@5: 100.0000 (99.4186)  Loss: -0.0934 (0.1943)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6037)  Acc@5: 100.0000 (99.4373)  Loss: -0.0320 (0.1863)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6254)  Acc@5: 100.0000 (99.4409)  Loss: -0.0459 (0.1847)  time: 0.1858  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6254)  Acc@5: 100.0000 (99.4409)  Loss: -0.0459 (0.1847)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:24  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1051 (-0.1051)  time: 0.4608  data: 0.2672  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (95.4545)  Acc@5: 100.0000 (100.0000)  Loss: -0.0502 (-0.0315)  time: 0.2153  data: 0.0245  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.3214)  Acc@5: 100.0000 (100.0000)  Loss: -0.0814 (-0.0479)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.1855)  Acc@5: 100.0000 (100.0000)  Loss: -0.0933 (-0.0609)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6280)  Acc@5: 100.0000 (100.0000)  Loss: -0.0854 (-0.0657)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6520)  Acc@5: 100.0000 (100.0000)  Loss: -0.1120 (-0.0736)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4631)  Acc@5: 100.0000 (100.0000)  Loss: -0.1120 (-0.0728)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6796)  Acc@5: 100.0000 (100.0000)  Loss: -0.1384 (-0.0813)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6111)  Acc@5: 100.0000 (100.0000)  Loss: -0.1402 (-0.0811)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6264)  Acc@5: 100.0000 (100.0000)  Loss: -0.1370 (-0.0853)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6386)  Acc@5: 100.0000 (100.0000)  Loss: -0.1271 (-0.0876)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4797)  Acc@5: 100.0000 (100.0000)  Loss: -0.1043 (-0.0852)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3988)  Acc@5: 100.0000 (100.0000)  Loss: -0.0845 (-0.0841)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.4733)  Acc@5: 100.0000 (100.0000)  Loss: -0.1152 (-0.0865)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5372)  Acc@5: 100.0000 (100.0000)  Loss: -0.1282 (-0.0888)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6341)  Acc@5: 100.0000 (100.0000)  Loss: -0.1311 (-0.0918)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7189)  Acc@5: 100.0000 (100.0000)  Loss: -0.1520 (-0.0953)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6111)  Acc@5: 100.0000 (100.0000)  Loss: -0.1443 (-0.0933)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5497)  Acc@5: 100.0000 (100.0000)  Loss: -0.1169 (-0.0917)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5602)  Acc@5: 100.0000 (100.0000)  Loss: -0.1166 (-0.0928)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5697)  Acc@5: 100.0000 (100.0000)  Loss: -0.1072 (-0.0914)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6078)  Acc@5: 100.0000 (100.0000)  Loss: -0.1067 (-0.0917)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6143)  Acc@5: 100.0000 (99.9717)  Loss: -0.1347 (-0.0929)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6472)  Acc@5: 100.0000 (99.9729)  Loss: -0.1319 (-0.0940)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5996)  Acc@5: 100.0000 (99.9741)  Loss: -0.1301 (-0.0921)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6305)  Acc@5: 100.0000 (99.9751)  Loss: -0.1385 (-0.0935)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6111)  Acc@5: 100.0000 (99.9761)  Loss: -0.1492 (-0.0939)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5701)  Acc@5: 100.0000 (99.9769)  Loss: -0.1276 (-0.0935)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5765)  Acc@5: 100.0000 (99.9778)  Loss: -0.1274 (-0.0939)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6254)  Acc@5: 100.0000 (99.9785)  Loss: -0.1501 (-0.0956)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5880)  Acc@5: 100.0000 (99.9792)  Loss: -0.1274 (-0.0952)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5932)  Acc@5: 100.0000 (99.9799)  Loss: -0.1031 (-0.0957)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6022)  Acc@5: 100.0000 (99.9800)  Loss: -0.1073 (-0.0959)  time: 0.1856  data: 0.0002  max mem: 12058
Train: Epoch[2/5] Total time: 0:00:59 (0.1911 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6022)  Acc@5: 100.0000 (99.9800)  Loss: -0.1073 (-0.0959)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1413 (-0.1413)  time: 0.4317  data: 0.2390  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)  Loss: -0.1137 (-0.0918)  time: 0.2131  data: 0.0220  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5119)  Acc@5: 100.0000 (100.0000)  Loss: -0.1226 (-0.0999)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9919)  Acc@5: 100.0000 (100.0000)  Loss: -0.1346 (-0.1095)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2378)  Acc@5: 100.0000 (100.0000)  Loss: -0.1342 (-0.1125)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2647)  Acc@5: 100.0000 (100.0000)  Loss: -0.1396 (-0.1172)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2828)  Acc@5: 100.0000 (100.0000)  Loss: -0.1366 (-0.1168)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3838)  Acc@5: 100.0000 (100.0000)  Loss: -0.1511 (-0.1218)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2284)  Acc@5: 100.0000 (100.0000)  Loss: -0.1574 (-0.1198)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3132)  Acc@5: 100.0000 (100.0000)  Loss: -0.1567 (-0.1229)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3193)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1244)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2117)  Acc@5: 100.0000 (100.0000)  Loss: -0.1363 (-0.1223)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0702)  Acc@5: 100.0000 (100.0000)  Loss: -0.1263 (-0.1209)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1412)  Acc@5: 100.0000 (100.0000)  Loss: -0.1426 (-0.1225)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1578)  Acc@5: 100.0000 (100.0000)  Loss: -0.1492 (-0.1237)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2136)  Acc@5: 100.0000 (100.0000)  Loss: -0.1542 (-0.1255)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2624)  Acc@5: 100.0000 (100.0000)  Loss: -0.1606 (-0.1277)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2325)  Acc@5: 100.0000 (100.0000)  Loss: -0.1606 (-0.1262)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1713)  Acc@5: 100.0000 (100.0000)  Loss: -0.1432 (-0.1247)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2147)  Acc@5: 100.0000 (100.0000)  Loss: -0.1416 (-0.1254)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2226)  Acc@5: 100.0000 (100.0000)  Loss: -0.1316 (-0.1238)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2299)  Acc@5: 100.0000 (100.0000)  Loss: -0.1316 (-0.1239)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2364)  Acc@5: 100.0000 (99.9717)  Loss: -0.1499 (-0.1242)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2424)  Acc@5: 100.0000 (99.9729)  Loss: -0.1458 (-0.1248)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1701)  Acc@5: 100.0000 (99.9741)  Loss: -0.1443 (-0.1226)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1783)  Acc@5: 100.0000 (99.9751)  Loss: -0.1533 (-0.1235)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1619)  Acc@5: 100.0000 (99.9761)  Loss: -0.1558 (-0.1236)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1236)  Acc@5: 100.0000 (99.9769)  Loss: -0.1429 (-0.1230)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1103)  Acc@5: 100.0000 (99.9778)  Loss: -0.1352 (-0.1231)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1409)  Acc@5: 100.0000 (99.9785)  Loss: -0.1550 (-0.1241)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1694)  Acc@5: 100.0000 (99.9792)  Loss: -0.1425 (-0.1237)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1961)  Acc@5: 100.0000 (99.9799)  Loss: -0.1234 (-0.1239)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2013)  Acc@5: 100.0000 (99.9800)  Loss: -0.1254 (-0.1241)  time: 0.1856  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:00:59 (0.1914 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.2013)  Acc@5: 100.0000 (99.9800)  Loss: -0.1254 (-0.1241)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1520 (-0.1520)  time: 0.4302  data: 0.2344  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1352 (-0.1207)  time: 0.2137  data: 0.0216  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.1071)  Acc@5: 100.0000 (100.0000)  Loss: -0.1406 (-0.1278)  time: 0.1917  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.3952)  Acc@5: 100.0000 (100.0000)  Loss: -0.1426 (-0.1331)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5427)  Acc@5: 100.0000 (100.0000)  Loss: -0.1455 (-0.1343)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1375)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5902)  Acc@5: 100.0000 (100.0000)  Loss: -0.1502 (-0.1372)  time: 0.1917  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6479)  Acc@5: 100.0000 (100.0000)  Loss: -0.1543 (-0.1401)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5370)  Acc@5: 100.0000 (100.0000)  Loss: -0.1613 (-0.1389)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5879)  Acc@5: 100.0000 (100.0000)  Loss: -0.1617 (-0.1410)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6287)  Acc@5: 100.0000 (100.0000)  Loss: -0.1562 (-0.1420)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5495)  Acc@5: 100.0000 (100.0000)  Loss: -0.1465 (-0.1405)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4835)  Acc@5: 100.0000 (100.0000)  Loss: -0.1486 (-0.1389)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5229)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1400)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5567)  Acc@5: 100.0000 (100.0000)  Loss: -0.1554 (-0.1407)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5861)  Acc@5: 100.0000 (100.0000)  Loss: -0.1584 (-0.1417)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6118)  Acc@5: 100.0000 (100.0000)  Loss: -0.1635 (-0.1432)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6345)  Acc@5: 100.0000 (100.0000)  Loss: -0.1645 (-0.1421)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5856)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1408)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6073)  Acc@5: 100.0000 (100.0000)  Loss: -0.1488 (-0.1412)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5958)  Acc@5: 100.0000 (100.0000)  Loss: -0.1428 (-0.1398)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5853)  Acc@5: 100.0000 (100.0000)  Loss: -0.1435 (-0.1397)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5758)  Acc@5: 100.0000 (99.9717)  Loss: -0.1558 (-0.1397)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5942)  Acc@5: 100.0000 (99.9729)  Loss: -0.1546 (-0.1401)  time: 0.1897  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5332)  Acc@5: 100.0000 (99.9741)  Loss: -0.1527 (-0.1379)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5269)  Acc@5: 100.0000 (99.9751)  Loss: -0.1553 (-0.1385)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5211)  Acc@5: 100.0000 (99.9761)  Loss: -0.1583 (-0.1385)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4926)  Acc@5: 100.0000 (99.9769)  Loss: -0.1485 (-0.1380)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4884)  Acc@5: 100.0000 (99.9778)  Loss: -0.1467 (-0.1381)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5060)  Acc@5: 100.0000 (99.9785)  Loss: -0.1567 (-0.1388)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5224)  Acc@5: 100.0000 (99.9792)  Loss: -0.1483 (-0.1385)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5378)  Acc@5: 100.0000 (99.9799)  Loss: -0.1335 (-0.1386)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5407)  Acc@5: 100.0000 (99.9800)  Loss: -0.1344 (-0.1387)  time: 0.1858  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:00:59 (0.1914 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5407)  Acc@5: 100.0000 (99.9800)  Loss: -0.1344 (-0.1387)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:22  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1576 (-0.1576)  time: 0.4556  data: 0.2625  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:05  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1522 (-0.1388)  time: 0.2146  data: 0.0241  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1526 (-0.1453)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1526 (-0.1471)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1527 (-0.1471)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1573 (-0.1494)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1565 (-0.1493)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1623 (-0.1511)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1628 (-0.1516)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1637 (-0.1529)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1637 (-0.1532)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1532 (-0.1522)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8967)  Acc@5: 100.0000 (100.0000)  Loss: -0.1527 (-0.1510)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9046)  Acc@5: 100.0000 (100.0000)  Loss: -0.1571 (-0.1516)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9113)  Acc@5: 100.0000 (100.0000)  Loss: -0.1594 (-0.1518)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9172)  Acc@5: 100.0000 (100.0000)  Loss: -0.1599 (-0.1522)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9224)  Acc@5: 100.0000 (100.0000)  Loss: -0.1648 (-0.1532)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9269)  Acc@5: 100.0000 (100.0000)  Loss: -0.1670 (-0.1524)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8964)  Acc@5: 100.0000 (100.0000)  Loss: -0.1522 (-0.1515)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9018)  Acc@5: 100.0000 (100.0000)  Loss: -0.1522 (-0.1517)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8756)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1504)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8815)  Acc@5: 100.0000 (100.0000)  Loss: -0.1476 (-0.1502)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8586)  Acc@5: 100.0000 (100.0000)  Loss: -0.1582 (-0.1500)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8647)  Acc@5: 100.0000 (100.0000)  Loss: -0.1602 (-0.1502)  time: 0.1907  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7925)  Acc@5: 100.0000 (100.0000)  Loss: -0.1582 (-0.1482)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8008)  Acc@5: 100.0000 (100.0000)  Loss: -0.1568 (-0.1485)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8084)  Acc@5: 100.0000 (100.0000)  Loss: -0.1601 (-0.1486)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7694)  Acc@5: 100.0000 (100.0000)  Loss: -0.1565 (-0.1484)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7553)  Acc@5: 100.0000 (100.0000)  Loss: -0.1551 (-0.1483)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7637)  Acc@5: 100.0000 (100.0000)  Loss: -0.1577 (-0.1487)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7716)  Acc@5: 100.0000 (100.0000)  Loss: -0.1524 (-0.1485)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7789)  Acc@5: 100.0000 (100.0000)  Loss: -0.1395 (-0.1485)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7804)  Acc@5: 100.0000 (100.0000)  Loss: -0.1430 (-0.1486)  time: 0.1860  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7804)  Acc@5: 100.0000 (100.0000)  Loss: -0.1430 (-0.1486)
Test: [Task 1]  [ 0/63]  eta: 0:00:22  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  Loss: 1.5987 (1.5987)  time: 0.3641  data: 0.2456  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 68.7500 (60.7955)  Acc@5: 93.7500 (94.8864)  Loss: 1.5802 (1.4790)  time: 0.1410  data: 0.0226  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 62.5000 (61.0119)  Acc@5: 93.7500 (95.2381)  Loss: 1.3686 (1.4743)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 68.7500 (63.5081)  Acc@5: 100.0000 (96.1694)  Loss: 1.2146 (1.4088)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 62.5000 (63.7195)  Acc@5: 100.0000 (96.1890)  Loss: 1.2146 (1.3861)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 62.5000 (63.9706)  Acc@5: 93.7500 (96.2010)  Loss: 1.2370 (1.3772)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 62.5000 (63.8320)  Acc@5: 100.0000 (96.4139)  Loss: 1.2370 (1.3589)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 62.5000 (63.9000)  Acc@5: 100.0000 (96.5000)  Loss: 1.1519 (1.3525)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 63.900 Acc@5 96.500 loss 1.353
Test: [Task 1]  [ 0/63]  eta: 0:00:23  ASR: 0.0625 (0.0625)  ACC: 0.6250 (0.6250)  Loss: 4.2858 (4.2858)  time: 0.3776  data: 0.2551  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.1364)  ACC: 0.5625 (0.5455)  Loss: 3.6304 (3.6302)  time: 0.1430  data: 0.0235  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1429)  ACC: 0.5000 (0.5149)  Loss: 3.5835 (3.6162)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1653)  ACC: 0.5625 (0.5202)  Loss: 3.4932 (3.5258)  time: 0.1195  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.1585)  ACC: 0.5625 (0.5259)  Loss: 3.4954 (3.5799)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1569)  ACC: 0.5625 (0.5343)  Loss: 3.8308 (3.6382)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.1650)  ACC: 0.5625 (0.5389)  Loss: 3.5833 (3.5962)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1657)  ACC: 0.5625 (0.5357)  Loss: 3.5638 (3.6021)  time: 0.1167  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1242 s / it)
* ASR 0.166 loss 3.602
Test: [Task 2]  [ 0/63]  eta: 0:00:24  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.8805 (0.8805)  time: 0.3833  data: 0.2650  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (97.1591)  Loss: 0.6830 (0.6942)  time: 0.1426  data: 0.0244  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 75.0000 (79.1667)  Acc@5: 100.0000 (96.1310)  Loss: 0.6963 (0.7659)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 75.0000 (79.8387)  Acc@5: 93.7500 (95.9677)  Loss: 0.8193 (0.7669)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (80.1829)  Acc@5: 93.7500 (96.1890)  Loss: 0.6987 (0.7563)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (79.6569)  Acc@5: 93.7500 (96.0784)  Loss: 0.6925 (0.7556)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (80.4303)  Acc@5: 100.0000 (96.4139)  Loss: 0.6807 (0.7331)  time: 0.1185  data: 0.0002  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (80.4000)  Acc@5: 100.0000 (96.5000)  Loss: 0.6074 (0.7265)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1232 s / it)
* Acc@1 80.400 Acc@5 96.500 loss 0.727
Test: [Task 2]  [ 0/63]  eta: 0:00:25  ASR: 0.0625 (0.0625)  ACC: 0.5625 (0.5625)  Loss: 3.7117 (3.7117)  time: 0.4008  data: 0.2782  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0795)  ACC: 0.6875 (0.6875)  Loss: 4.4265 (4.4586)  time: 0.1453  data: 0.0256  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.1131)  ACC: 0.6250 (0.6726)  Loss: 4.2675 (4.3412)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1089)  ACC: 0.6875 (0.6935)  Loss: 4.2675 (4.4449)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.1021)  ACC: 0.7500 (0.7027)  Loss: 4.7532 (4.5080)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0968)  ACC: 0.7500 (0.7022)  Loss: 4.7441 (4.5777)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0912)  ACC: 0.7500 (0.7121)  Loss: 4.5648 (4.5965)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0893)  ACC: 0.7500 (0.7183)  Loss: 4.7784 (4.6070)  time: 0.1167  data: 0.0003  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1246 s / it)
* ASR 0.089 loss 4.607
Test: [Task 3]  [ 0/63]  eta: 0:00:23  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.3985 (0.3985)  time: 0.3731  data: 0.2543  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (85.2273)  Acc@5: 100.0000 (98.2955)  Loss: 0.5623 (0.6069)  time: 0.1415  data: 0.0234  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (84.2262)  Acc@5: 100.0000 (98.2143)  Loss: 0.5751 (0.6030)  time: 0.1184  data: 0.0003  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (83.8710)  Acc@5: 100.0000 (97.7823)  Loss: 0.5872 (0.6097)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (83.6890)  Acc@5: 100.0000 (97.7134)  Loss: 0.6424 (0.6094)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (84.1912)  Acc@5: 100.0000 (97.6716)  Loss: 0.5856 (0.5994)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (83.4016)  Acc@5: 100.0000 (97.4385)  Loss: 0.6264 (0.6193)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (83.2000)  Acc@5: 100.0000 (97.3000)  Loss: 0.6300 (0.6314)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1229 s / it)
* Acc@1 83.200 Acc@5 97.300 loss 0.631
Test: [Task 3]  [ 0/63]  eta: 0:00:24  ASR: 0.1250 (0.1250)  ACC: 0.7500 (0.7500)  Loss: 5.7011 (5.7011)  time: 0.3919  data: 0.2696  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1250)  ACC: 0.6875 (0.6875)  Loss: 4.8614 (4.9057)  time: 0.1448  data: 0.0248  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1161)  ACC: 0.6875 (0.7024)  Loss: 4.8863 (5.0474)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.1109)  ACC: 0.6875 (0.7117)  Loss: 5.1685 (5.1513)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1174)  ACC: 0.6875 (0.7088)  Loss: 4.9214 (5.1008)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1189)  ACC: 0.6875 (0.7157)  Loss: 4.8789 (5.0916)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.1148)  ACC: 0.6875 (0.7152)  Loss: 5.0683 (5.1079)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1151)  ACC: 0.6875 (0.7143)  Loss: 5.0199 (5.1083)  time: 0.1168  data: 0.0002  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1248 s / it)
* ASR 0.115 loss 5.108
Test: [Task 4]  [ 0/63]  eta: 0:00:20  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5839 (0.5839)  time: 0.3266  data: 0.2089  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (89.7727)  Acc@5: 100.0000 (98.8636)  Loss: 0.4988 (0.4815)  time: 0.1373  data: 0.0193  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.0952)  Acc@5: 100.0000 (96.7262)  Loss: 0.4827 (0.5203)  time: 0.1185  data: 0.0004  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (86.8952)  Acc@5: 93.7500 (96.3710)  Loss: 0.5246 (0.5455)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (87.6524)  Acc@5: 100.0000 (97.1037)  Loss: 0.4560 (0.5125)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (88.2353)  Acc@5: 100.0000 (97.1814)  Loss: 0.3522 (0.4946)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (87.6025)  Acc@5: 100.0000 (97.1311)  Loss: 0.3439 (0.5041)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (87.8000)  Acc@5: 100.0000 (97.1000)  Loss: 0.3439 (0.4994)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1222 s / it)
* Acc@1 87.800 Acc@5 97.100 loss 0.499
Test: [Task 4]  [ 0/63]  eta: 0:00:23  ASR: 0.1875 (0.1875)  ACC: 0.6875 (0.6875)  Loss: 4.4938 (4.4938)  time: 0.3713  data: 0.2447  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.1875 (0.1534)  ACC: 0.6875 (0.6648)  Loss: 4.6628 (4.7133)  time: 0.1434  data: 0.0226  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1310)  ACC: 0.6875 (0.6935)  Loss: 4.8153 (4.9543)  time: 0.1206  data: 0.0005  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.1230)  ACC: 0.7500 (0.7056)  Loss: 5.0211 (5.0555)  time: 0.1204  data: 0.0005  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.1159)  ACC: 0.8125 (0.7149)  Loss: 5.3092 (5.0749)  time: 0.1201  data: 0.0005  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.1189)  ACC: 0.7500 (0.7132)  Loss: 4.8881 (5.0373)  time: 0.1198  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.1178)  ACC: 0.6875 (0.7100)  Loss: 4.7971 (5.0579)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.1151)  ACC: 0.6875 (0.7123)  Loss: 4.7908 (5.0540)  time: 0.1168  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1248 s / it)
* ASR 0.115 loss 5.054
Test: [Task 5]  [ 0/63]  eta: 0:00:21  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1796 (0.1796)  time: 0.3385  data: 0.2190  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (98.2955)  Loss: 0.4861 (0.6166)  time: 0.1388  data: 0.0204  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (85.4167)  Acc@5: 100.0000 (98.2143)  Loss: 0.4861 (0.5548)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (85.4839)  Acc@5: 100.0000 (98.3871)  Loss: 0.4290 (0.5533)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (85.5183)  Acc@5: 100.0000 (98.3232)  Loss: 0.4873 (0.5605)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (85.0490)  Acc@5: 100.0000 (98.2843)  Loss: 0.5447 (0.5680)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (85.0410)  Acc@5: 100.0000 (98.1557)  Loss: 0.5447 (0.5740)  time: 0.1185  data: 0.0002  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (84.8000)  Acc@5: 100.0000 (97.8000)  Loss: 0.6205 (0.5982)  time: 0.1156  data: 0.0002  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1227 s / it)
* Acc@1 84.800 Acc@5 97.800 loss 0.598
Test: [Task 5]  [ 0/63]  eta: 0:00:21  ASR: 0.1250 (0.1250)  ACC: 0.8125 (0.8125)  Loss: 5.1912 (5.1912)  time: 0.3423  data: 0.2161  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1307)  ACC: 0.6875 (0.6648)  Loss: 4.7007 (4.7654)  time: 0.1405  data: 0.0199  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1131)  ACC: 0.6875 (0.6935)  Loss: 4.7007 (4.9021)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1129)  ACC: 0.7500 (0.6996)  Loss: 4.7107 (4.8541)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.1037)  ACC: 0.7500 (0.7043)  Loss: 4.8061 (4.8659)  time: 0.1205  data: 0.0003  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.1029)  ACC: 0.7500 (0.7034)  Loss: 4.9158 (4.8860)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1045)  ACC: 0.7500 (0.7080)  Loss: 4.7999 (4.8790)  time: 0.1198  data: 0.0002  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1081)  ACC: 0.6875 (0.7014)  Loss: 4.7293 (4.8325)  time: 0.1168  data: 0.0002  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1243 s / it)
* ASR 0.108 loss 4.833
Test: [Task 6]  [ 0/63]  eta: 0:00:20  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5078 (0.5078)  time: 0.3281  data: 0.2084  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (79.5455)  Acc@5: 100.0000 (98.8636)  Loss: 0.5448 (0.5748)  time: 0.1373  data: 0.0193  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  Acc@1: 75.0000 (77.3810)  Acc@5: 100.0000 (97.9167)  Loss: 0.6162 (0.6361)  time: 0.1183  data: 0.0003  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  Acc@1: 75.0000 (77.6210)  Acc@5: 100.0000 (98.1855)  Loss: 0.5997 (0.6269)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  Acc@1: 75.0000 (76.9817)  Acc@5: 100.0000 (98.3232)  Loss: 0.6128 (0.6374)  time: 0.1184  data: 0.0003  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  Acc@1: 75.0000 (77.0833)  Acc@5: 100.0000 (98.5294)  Loss: 0.6370 (0.6332)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  Acc@1: 75.0000 (77.4590)  Acc@5: 100.0000 (98.1557)  Loss: 0.6370 (0.6460)  time: 0.1185  data: 0.0002  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  Acc@1: 75.0000 (77.6000)  Acc@5: 100.0000 (98.2000)  Loss: 0.5724 (0.6408)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1220 s / it)
* Acc@1 77.600 Acc@5 98.200 loss 0.641
Test: [Task 6]  [ 0/63]  eta: 0:00:20  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7500)  Loss: 5.5199 (5.5199)  time: 0.3239  data: 0.2014  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0682)  ACC: 0.7500 (0.7386)  Loss: 5.2426 (5.2747)  time: 0.1377  data: 0.0185  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0625)  ACC: 0.6875 (0.7202)  Loss: 5.0813 (5.1067)  time: 0.1192  data: 0.0003  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0605)  ACC: 0.6875 (0.7097)  Loss: 5.0362 (5.0873)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0655)  ACC: 0.6875 (0.7058)  Loss: 4.9517 (5.0073)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0662)  ACC: 0.6875 (0.7059)  Loss: 4.9517 (5.0321)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0686)  ACC: 0.6875 (0.6967)  Loss: 5.0472 (5.0165)  time: 0.1196  data: 0.0002  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0675)  ACC: 0.6875 (0.6994)  Loss: 5.0123 (5.0118)  time: 0.1166  data: 0.0002  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1231 s / it)
* ASR 0.067 loss 5.012
Test: [Task 7]  [ 0/63]  eta: 0:00:22  Acc@1: 43.7500 (43.7500)  Acc@5: 100.0000 (100.0000)  Loss: 1.3264 (1.3264)  time: 0.3555  data: 0.2362  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (78.4091)  Acc@5: 100.0000 (98.8636)  Loss: 0.5912 (0.6991)  time: 0.1398  data: 0.0217  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (79.1667)  Acc@5: 100.0000 (96.7262)  Loss: 0.5890 (0.7322)  time: 0.1184  data: 0.0003  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (79.4355)  Acc@5: 93.7500 (96.5726)  Loss: 0.5890 (0.6946)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (81.0976)  Acc@5: 100.0000 (96.7988)  Loss: 0.5857 (0.6635)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (80.1471)  Acc@5: 93.7500 (95.8333)  Loss: 0.6427 (0.7161)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  Acc@1: 75.0000 (80.5328)  Acc@5: 93.7500 (95.5943)  Loss: 0.7578 (0.7154)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  Acc@1: 75.0000 (80.3000)  Acc@5: 93.7500 (95.6000)  Loss: 0.7777 (0.7200)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1226 s / it)
* Acc@1 80.300 Acc@5 95.600 loss 0.720
Test: [Task 7]  [ 0/63]  eta: 0:00:19  ASR: 0.0625 (0.0625)  ACC: 0.5625 (0.5625)  Loss: 5.3115 (5.3115)  time: 0.3054  data: 0.1740  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0625)  ACC: 0.7500 (0.7386)  Loss: 5.1549 (5.0282)  time: 0.1366  data: 0.0160  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0804)  ACC: 0.7500 (0.7411)  Loss: 5.0998 (5.0442)  time: 0.1198  data: 0.0002  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0746)  ACC: 0.6875 (0.7278)  Loss: 5.2988 (5.1411)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0777)  ACC: 0.6875 (0.7287)  Loss: 5.2973 (5.1228)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0772)  ACC: 0.7500 (0.7218)  Loss: 4.8702 (5.0767)  time: 0.1197  data: 0.0002  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0768)  ACC: 0.6875 (0.7182)  Loss: 4.8209 (5.0464)  time: 0.1194  data: 0.0002  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0784)  ACC: 0.6875 (0.7153)  Loss: 4.7416 (5.0402)  time: 0.1165  data: 0.0002  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1227 s / it)
* ASR 0.078 loss 5.040
Test: [Task 8]  [ 0/63]  eta: 0:00:19  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4003 (0.4003)  time: 0.3148  data: 0.1963  max mem: 12058
Test: [Task 8]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (82.9545)  Acc@5: 100.0000 (96.5909)  Loss: 0.5972 (0.6324)  time: 0.1363  data: 0.0180  max mem: 12058
Test: [Task 8]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.0238)  Loss: 0.5910 (0.5812)  time: 0.1184  data: 0.0002  max mem: 12058
Test: [Task 8]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (84.8790)  Acc@5: 100.0000 (96.7742)  Loss: 0.4730 (0.5566)  time: 0.1184  data: 0.0002  max mem: 12058
Test: [Task 8]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (85.5183)  Acc@5: 100.0000 (97.1037)  Loss: 0.4730 (0.5452)  time: 0.1183  data: 0.0002  max mem: 12058
Test: [Task 8]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (86.1520)  Acc@5: 100.0000 (96.9363)  Loss: 0.4368 (0.5361)  time: 0.1183  data: 0.0002  max mem: 12058
Test: [Task 8]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (85.6557)  Acc@5: 93.7500 (96.2090)  Loss: 0.4964 (0.5551)  time: 0.1182  data: 0.0002  max mem: 12058
Test: [Task 8]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (85.8000)  Acc@5: 93.7500 (96.3000)  Loss: 0.4707 (0.5466)  time: 0.1155  data: 0.0001  max mem: 12058
Test: [Task 8] Total time: 0:00:07 (0.1217 s / it)
* Acc@1 85.800 Acc@5 96.300 loss 0.547
Test: [Task 8]  [ 0/63]  eta: 0:00:20  ASR: 0.1875 (0.1875)  ACC: 0.6875 (0.6875)  Loss: 4.9018 (4.9018)  time: 0.3217  data: 0.1970  max mem: 12058
Test: [Task 8]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0852)  ACC: 0.7500 (0.7386)  Loss: 5.4454 (5.2479)  time: 0.1389  data: 0.0182  max mem: 12058
Test: [Task 8]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0952)  ACC: 0.7500 (0.7411)  Loss: 5.4454 (5.2843)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 8]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0887)  ACC: 0.7500 (0.7520)  Loss: 5.1929 (5.3182)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 8]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0869)  ACC: 0.6875 (0.7454)  Loss: 5.1929 (5.2700)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 8]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0833)  ACC: 0.6875 (0.7402)  Loss: 5.1177 (5.2535)  time: 0.1195  data: 0.0003  max mem: 12058
Test: [Task 8]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0881)  ACC: 0.6875 (0.7336)  Loss: 5.1177 (5.2360)  time: 0.1193  data: 0.0003  max mem: 12058
Test: [Task 8]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0863)  ACC: 0.7500 (0.7341)  Loss: 5.2378 (5.2641)  time: 0.1165  data: 0.0002  max mem: 12058
Test: [Task 8] Total time: 0:00:07 (0.1233 s / it)
* ASR 0.086 loss 5.264
Test: [Task 9]  [ 0/63]  eta: 0:00:19  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0393 (0.0393)  time: 0.3134  data: 0.1933  max mem: 12058
Test: [Task 9]  [10/63]  eta: 0:00:07  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (98.8636)  Loss: 0.2330 (0.3006)  time: 0.1363  data: 0.0179  max mem: 12058
Test: [Task 9]  [20/63]  eta: 0:00:05  Acc@1: 93.7500 (92.8571)  Acc@5: 100.0000 (98.8095)  Loss: 0.2330 (0.3101)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 9]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (99.1935)  Loss: 0.2028 (0.2724)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 9]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (93.2927)  Acc@5: 100.0000 (98.9329)  Loss: 0.1728 (0.2806)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 9]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.1373)  Acc@5: 100.0000 (98.8971)  Loss: 0.3399 (0.2983)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 9]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (93.6475)  Acc@5: 100.0000 (98.9754)  Loss: 0.2717 (0.2791)  time: 0.1185  data: 0.0002  max mem: 12058
Test: [Task 9]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (93.8000)  Acc@5: 100.0000 (99.0000)  Loss: 0.2222 (0.2726)  time: 0.1157  data: 0.0002  max mem: 12058
Test: [Task 9] Total time: 0:00:07 (0.1220 s / it)
* Acc@1 93.800 Acc@5 99.000 loss 0.273
Test: [Task 9]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  ACC: 1.0000 (1.0000)  Loss: 6.9017 (6.9017)  time: 0.3092  data: 0.1855  max mem: 12058
Test: [Task 9]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0568)  ACC: 0.8125 (0.8182)  Loss: 5.9220 (5.7246)  time: 0.1372  data: 0.0172  max mem: 12058
Test: [Task 9]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0565)  ACC: 0.8125 (0.8274)  Loss: 5.8379 (5.8578)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 9]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0585)  ACC: 0.8125 (0.8306)  Loss: 5.8379 (5.8498)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 9]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0595)  ACC: 0.8125 (0.8201)  Loss: 5.9560 (5.8832)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 9]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0551)  ACC: 0.8125 (0.8223)  Loss: 5.9899 (5.8934)  time: 0.1204  data: 0.0004  max mem: 12058
Test: [Task 9]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0492)  ACC: 0.8750 (0.8361)  Loss: 6.1186 (5.9767)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 9]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0476)  ACC: 0.8750 (0.8393)  Loss: 6.1814 (5.9840)  time: 0.1174  data: 0.0003  max mem: 12058
Test: [Task 9] Total time: 0:00:07 (0.1233 s / it)
* ASR 0.048 loss 5.984
[Average accuracy till task9]	ASR: 0.0970	Acc@1: 81.9556	Loss: 4.9449	Forgetting: 0.1456	Backward: -0.1365
Train: Epoch[1/5]  [  0/313]  eta: 0:02:06  Lr: 0.0019 (0.0019)  Acc@1: 0.0000 (0.0000)  Acc@5: 18.7500 (18.7500)  Loss: 2.2229 (2.2229)  time: 0.4047  data: 0.2108  max mem: 12058
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (58.5227)  Acc@5: 93.7500 (82.3864)  Loss: 1.8967 (1.9055)  time: 0.2101  data: 0.0194  max mem: 12058
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1905)  Acc@5: 100.0000 (90.1786)  Loss: 1.5797 (1.6621)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (82.8629)  Acc@5: 100.0000 (92.7419)  Loss: 1.0706 (1.4427)  time: 0.1904  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (86.8902)  Acc@5: 100.0000 (94.3598)  Loss: 0.7108 (1.2452)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (88.9706)  Acc@5: 100.0000 (95.3431)  Loss: 0.5187 (1.0832)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (90.6762)  Acc@5: 100.0000 (96.1066)  Loss: 0.3295 (0.9600)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (91.6373)  Acc@5: 100.0000 (96.6549)  Loss: 0.2664 (0.8578)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (92.5154)  Acc@5: 100.0000 (97.0679)  Loss: 0.1957 (0.7743)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.2005)  Acc@5: 100.0000 (97.3901)  Loss: 0.1628 (0.7050)  time: 0.1905  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [100/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (93.7500)  Acc@5: 100.0000 (97.6485)  Loss: 0.1105 (0.6437)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.1441)  Acc@5: 100.0000 (97.8041)  Loss: 0.0731 (0.5949)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.6281)  Acc@5: 100.0000 (97.9855)  Loss: 0.0344 (0.5496)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (94.9427)  Acc@5: 100.0000 (98.1393)  Loss: 0.0164 (0.5098)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.1241)  Acc@5: 100.0000 (98.2713)  Loss: 0.0038 (0.4747)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.4056)  Acc@5: 100.0000 (98.3858)  Loss: -0.0078 (0.4437)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.6522)  Acc@5: 100.0000 (98.4860)  Loss: -0.0107 (0.4161)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.7968)  Acc@5: 100.0000 (98.5746)  Loss: -0.0100 (0.3925)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (95.8909)  Acc@5: 100.0000 (98.6533)  Loss: 0.0004 (0.3699)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0079)  Acc@5: 100.0000 (98.6911)  Loss: -0.0415 (0.3497)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.0821)  Acc@5: 100.0000 (98.7562)  Loss: -0.0669 (0.3314)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.2382)  Acc@5: 100.0000 (98.8152)  Loss: -0.0689 (0.3135)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.3801)  Acc@5: 100.0000 (98.8688)  Loss: -0.0689 (0.2982)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.5368)  Acc@5: 100.0000 (98.9177)  Loss: -0.0757 (0.2822)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.6546)  Acc@5: 100.0000 (98.9627)  Loss: -0.0771 (0.2682)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.7380)  Acc@5: 100.0000 (99.0040)  Loss: -0.0719 (0.2558)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.8151)  Acc@5: 100.0000 (99.0421)  Loss: -0.0754 (0.2440)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[1/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.8635)  Acc@5: 100.0000 (99.0544)  Loss: -0.0754 (0.2336)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9084)  Acc@5: 100.0000 (99.0881)  Loss: -0.0892 (0.2233)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (96.9502)  Acc@5: 100.0000 (99.0979)  Loss: -0.0739 (0.2140)  time: 0.1903  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0100)  Acc@5: 100.0000 (99.1279)  Loss: -0.0739 (0.2050)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0659)  Acc@5: 100.0000 (99.1559)  Loss: -0.1051 (0.1958)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0647)  Acc@5: 100.0000 (99.1613)  Loss: -0.1043 (0.1939)  time: 0.1860  data: 0.0002  max mem: 12058
Train: Epoch[1/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (97.0647)  Acc@5: 100.0000 (99.1613)  Loss: -0.1043 (0.1939)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1384 (-0.1384)  time: 0.4344  data: 0.2417  max mem: 12058
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.2955)  Acc@5: 100.0000 (100.0000)  Loss: -0.0982 (-0.0609)  time: 0.2128  data: 0.0222  max mem: 12058
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.5119)  Acc@5: 100.0000 (100.0000)  Loss: -0.0982 (-0.0701)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.3871)  Acc@5: 100.0000 (100.0000)  Loss: -0.1035 (-0.0711)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6280)  Acc@5: 100.0000 (100.0000)  Loss: -0.1210 (-0.0795)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.6520)  Acc@5: 100.0000 (100.0000)  Loss: -0.1210 (-0.0834)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.7705)  Acc@5: 100.0000 (100.0000)  Loss: -0.1146 (-0.0863)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8556)  Acc@5: 100.0000 (100.0000)  Loss: -0.1184 (-0.0873)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9198)  Acc@5: 100.0000 (100.0000)  Loss: -0.1154 (-0.0892)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9011)  Acc@5: 100.0000 (100.0000)  Loss: -0.1041 (-0.0899)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0099)  Acc@5: 100.0000 (100.0000)  Loss: -0.1179 (-0.0923)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9302)  Acc@5: 100.0000 (100.0000)  Loss: -0.1247 (-0.0905)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0186)  Acc@5: 100.0000 (100.0000)  Loss: -0.1237 (-0.0924)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0458)  Acc@5: 100.0000 (100.0000)  Loss: -0.1260 (-0.0935)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9805)  Acc@5: 100.0000 (100.0000)  Loss: -0.1273 (-0.0939)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0480)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.0958)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0683)  Acc@5: 100.0000 (100.0000)  Loss: -0.1262 (-0.0965)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0132)  Acc@5: 100.0000 (100.0000)  Loss: -0.1234 (-0.0963)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9986)  Acc@5: 100.0000 (100.0000)  Loss: -0.1234 (-0.0966)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9856)  Acc@5: 100.0000 (100.0000)  Loss: -0.1252 (-0.0967)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9739)  Acc@5: 100.0000 (100.0000)  Loss: -0.1326 (-0.0967)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9929)  Acc@5: 100.0000 (100.0000)  Loss: -0.1310 (-0.0976)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0102)  Acc@5: 100.0000 (100.0000)  Loss: -0.1234 (-0.0979)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0530)  Acc@5: 100.0000 (100.0000)  Loss: -0.1373 (-0.0992)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0664)  Acc@5: 100.0000 (100.0000)  Loss: -0.1338 (-0.1000)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0538)  Acc@5: 100.0000 (100.0000)  Loss: -0.1316 (-0.1002)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0900)  Acc@5: 100.0000 (100.0000)  Loss: -0.1347 (-0.1009)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0544)  Acc@5: 100.0000 (100.0000)  Loss: -0.1376 (-0.1005)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0214)  Acc@5: 100.0000 (100.0000)  Loss: -0.1237 (-0.1006)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9905)  Acc@5: 100.0000 (100.0000)  Loss: -0.1215 (-0.1005)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9826)  Acc@5: 100.0000 (100.0000)  Loss: -0.1235 (-0.1004)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.9952)  Acc@5: 100.0000 (100.0000)  Loss: -0.1380 (-0.1013)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0016)  Acc@5: 100.0000 (100.0000)  Loss: -0.1352 (-0.1014)  time: 0.1868  data: 0.0003  max mem: 12058
Train: Epoch[2/5] Total time: 0:01:00 (0.1920 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.0016)  Acc@5: 100.0000 (100.0000)  Loss: -0.1352 (-0.1014)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:01  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1566 (-0.1566)  time: 0.3892  data: 0.1937  max mem: 12058
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1438 (-0.1037)  time: 0.2092  data: 0.0179  max mem: 12058
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:58  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4048)  Acc@5: 100.0000 (100.0000)  Loss: -0.1351 (-0.1106)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5968)  Acc@5: 100.0000 (100.0000)  Loss: -0.1363 (-0.1116)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5427)  Acc@5: 100.0000 (100.0000)  Loss: -0.1472 (-0.1170)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)  Loss: -0.1472 (-0.1202)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5902)  Acc@5: 100.0000 (100.0000)  Loss: -0.1356 (-0.1219)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5599)  Acc@5: 100.0000 (100.0000)  Loss: -0.1351 (-0.1220)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6142)  Acc@5: 100.0000 (100.0000)  Loss: -0.1450 (-0.1229)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6566)  Acc@5: 100.0000 (100.0000)  Loss: -0.1338 (-0.1235)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6906)  Acc@5: 100.0000 (100.0000)  Loss: -0.1343 (-0.1247)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6059)  Acc@5: 100.0000 (100.0000)  Loss: -0.1455 (-0.1232)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6384)  Acc@5: 100.0000 (100.0000)  Loss: -0.1428 (-0.1245)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6660)  Acc@5: 100.0000 (100.0000)  Loss: -0.1428 (-0.1247)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6454)  Acc@5: 100.0000 (100.0000)  Loss: -0.1465 (-0.1252)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6689)  Acc@5: 100.0000 (100.0000)  Loss: -0.1444 (-0.1264)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6506)  Acc@5: 100.0000 (100.0000)  Loss: -0.1443 (-0.1264)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5980)  Acc@5: 100.0000 (100.0000)  Loss: -0.1445 (-0.1268)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5856)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1267)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5419)  Acc@5: 100.0000 (100.0000)  Loss: -0.1413 (-0.1264)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5336)  Acc@5: 100.0000 (100.0000)  Loss: -0.1453 (-0.1262)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5557)  Acc@5: 100.0000 (100.0000)  Loss: -0.1438 (-0.1266)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5758)  Acc@5: 100.0000 (100.0000)  Loss: -0.1418 (-0.1267)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5942)  Acc@5: 100.0000 (100.0000)  Loss: -0.1464 (-0.1273)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6110)  Acc@5: 100.0000 (100.0000)  Loss: -0.1442 (-0.1277)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6016)  Acc@5: 100.0000 (100.0000)  Loss: -0.1424 (-0.1277)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6169)  Acc@5: 100.0000 (100.0000)  Loss: -0.1460 (-0.1281)  time: 0.1914  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5849)  Acc@5: 100.0000 (100.0000)  Loss: -0.1487 (-0.1277)  time: 0.1915  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5552)  Acc@5: 100.0000 (100.0000)  Loss: -0.1406 (-0.1276)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5490)  Acc@5: 100.0000 (100.0000)  Loss: -0.1359 (-0.1273)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5224)  Acc@5: 100.0000 (100.0000)  Loss: -0.1417 (-0.1270)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5378)  Acc@5: 100.0000 (100.0000)  Loss: -0.1456 (-0.1274)  time: 0.1912  data: 0.0002  max mem: 12058
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5407)  Acc@5: 100.0000 (100.0000)  Loss: -0.1456 (-0.1276)  time: 0.1867  data: 0.0002  max mem: 12058
Train: Epoch[3/5] Total time: 0:01:00 (0.1917 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5407)  Acc@5: 100.0000 (100.0000)  Loss: -0.1456 (-0.1276)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:05  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1602 (-0.1602)  time: 0.4023  data: 0.2081  max mem: 12058
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (98.8636)  Acc@5: 100.0000 (100.0000)  Loss: -0.1542 (-0.1234)  time: 0.2113  data: 0.0192  max mem: 12058
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:59  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4048)  Acc@5: 100.0000 (100.0000)  Loss: -0.1432 (-0.1288)  time: 0.1921  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.5968)  Acc@5: 100.0000 (100.0000)  Loss: -0.1451 (-0.1299)  time: 0.1920  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6951)  Acc@5: 100.0000 (100.0000)  Loss: -0.1550 (-0.1337)  time: 0.1918  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6324)  Acc@5: 100.0000 (100.0000)  Loss: -0.1550 (-0.1362)  time: 0.1915  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6926)  Acc@5: 100.0000 (100.0000)  Loss: -0.1452 (-0.1370)  time: 0.1912  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6479)  Acc@5: 100.0000 (100.0000)  Loss: -0.1451 (-0.1367)  time: 0.1918  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.6914)  Acc@5: 100.0000 (100.0000)  Loss: -0.1492 (-0.1372)  time: 0.1919  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7253)  Acc@5: 100.0000 (100.0000)  Loss: -0.1430 (-0.1374)  time: 0.1912  data: 0.0003  max mem: 12058
Train: Epoch[4/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)  Loss: -0.1426 (-0.1382)  time: 0.1911  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7748)  Acc@5: 100.0000 (100.0000)  Loss: -0.1527 (-0.1373)  time: 0.1909  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7934)  Acc@5: 100.0000 (100.0000)  Loss: -0.1478 (-0.1382)  time: 0.1910  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8092)  Acc@5: 100.0000 (100.0000)  Loss: -0.1478 (-0.1382)  time: 0.1908  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7784)  Acc@5: 100.0000 (100.0000)  Loss: -0.1486 (-0.1386)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7930)  Acc@5: 100.0000 (100.0000)  Loss: -0.1501 (-0.1393)  time: 0.1899  data: 0.0001  max mem: 12058
Train: Epoch[4/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7671)  Acc@5: 100.0000 (100.0000)  Loss: -0.1501 (-0.1393)  time: 0.1897  data: 0.0001  max mem: 12058
Train: Epoch[4/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7807)  Acc@5: 100.0000 (100.0000)  Loss: -0.1522 (-0.1399)  time: 0.1897  data: 0.0001  max mem: 12058
Train: Epoch[4/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7583)  Acc@5: 100.0000 (100.0000)  Loss: -0.1535 (-0.1398)  time: 0.1898  data: 0.0001  max mem: 12058
Train: Epoch[4/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7382)  Acc@5: 100.0000 (100.0000)  Loss: -0.1470 (-0.1396)  time: 0.1898  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7201)  Acc@5: 100.0000 (100.0000)  Loss: -0.1489 (-0.1394)  time: 0.1900  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7334)  Acc@5: 100.0000 (100.0000)  Loss: -0.1489 (-0.1396)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7455)  Acc@5: 100.0000 (100.0000)  Loss: -0.1462 (-0.1396)  time: 0.1898  data: 0.0001  max mem: 12058
Train: Epoch[4/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7565)  Acc@5: 100.0000 (100.0000)  Loss: -0.1489 (-0.1399)  time: 0.1899  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [240/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7666)  Acc@5: 100.0000 (100.0000)  Loss: -0.1478 (-0.1401)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7510)  Acc@5: 100.0000 (100.0000)  Loss: -0.1469 (-0.1400)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7605)  Acc@5: 100.0000 (100.0000)  Loss: -0.1497 (-0.1403)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7694)  Acc@5: 100.0000 (100.0000)  Loss: -0.1529 (-0.1404)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7776)  Acc@5: 100.0000 (100.0000)  Loss: -0.1466 (-0.1404)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7637)  Acc@5: 100.0000 (100.0000)  Loss: -0.1452 (-0.1402)  time: 0.1906  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7508)  Acc@5: 100.0000 (100.0000)  Loss: -0.1453 (-0.1401)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7588)  Acc@5: 100.0000 (100.0000)  Loss: -0.1518 (-0.1404)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7604)  Acc@5: 100.0000 (100.0000)  Loss: -0.1518 (-0.1405)  time: 0.1859  data: 0.0002  max mem: 12058
Train: Epoch[4/5] Total time: 0:00:59 (0.1915 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7604)  Acc@5: 100.0000 (100.0000)  Loss: -0.1518 (-0.1405)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.1620 (-0.1620)  time: 0.5162  data: 0.3218  max mem: 12058
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.4318)  Acc@5: 100.0000 (100.0000)  Loss: -0.1588 (-0.1366)  time: 0.2201  data: 0.0295  max mem: 12058
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7024)  Acc@5: 100.0000 (100.0000)  Loss: -0.1508 (-0.1401)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.7984)  Acc@5: 100.0000 (100.0000)  Loss: -0.1508 (-0.1410)  time: 0.1901  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8476)  Acc@5: 100.0000 (100.0000)  Loss: -0.1570 (-0.1435)  time: 0.1902  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8775)  Acc@5: 100.0000 (100.0000)  Loss: -0.1570 (-0.1454)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8975)  Acc@5: 100.0000 (100.0000)  Loss: -0.1507 (-0.1455)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8239)  Acc@5: 100.0000 (100.0000)  Loss: -0.1507 (-0.1453)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8457)  Acc@5: 100.0000 (100.0000)  Loss: -0.1529 (-0.1455)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8626)  Acc@5: 100.0000 (100.0000)  Loss: -0.1464 (-0.1455)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [100/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8762)  Acc@5: 100.0000 (100.0000)  Loss: -0.1493 (-0.1461)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [110/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8874)  Acc@5: 100.0000 (100.0000)  Loss: -0.1547 (-0.1456)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [120/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8967)  Acc@5: 100.0000 (100.0000)  Loss: -0.1532 (-0.1462)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [130/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9046)  Acc@5: 100.0000 (100.0000)  Loss: -0.1516 (-0.1462)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [140/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9113)  Acc@5: 100.0000 (100.0000)  Loss: -0.1511 (-0.1467)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [150/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9172)  Acc@5: 100.0000 (100.0000)  Loss: -0.1542 (-0.1472)  time: 0.1913  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [160/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9224)  Acc@5: 100.0000 (100.0000)  Loss: -0.1539 (-0.1472)  time: 0.1911  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [170/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9269)  Acc@5: 100.0000 (100.0000)  Loss: -0.1548 (-0.1476)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [180/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9309)  Acc@5: 100.0000 (100.0000)  Loss: -0.1562 (-0.1476)  time: 0.1908  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [190/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.9018)  Acc@5: 100.0000 (100.0000)  Loss: -0.1514 (-0.1474)  time: 0.1907  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [200/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8756)  Acc@5: 100.0000 (100.0000)  Loss: -0.1514 (-0.1473)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [210/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8815)  Acc@5: 100.0000 (100.0000)  Loss: -0.1503 (-0.1473)  time: 0.1910  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [220/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8869)  Acc@5: 100.0000 (100.0000)  Loss: -0.1499 (-0.1473)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [230/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8918)  Acc@5: 100.0000 (100.0000)  Loss: -0.1508 (-0.1474)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [240/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8963)  Acc@5: 100.0000 (100.0000)  Loss: -0.1500 (-0.1475)  time: 0.1909  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [250/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8755)  Acc@5: 100.0000 (100.0000)  Loss: -0.1496 (-0.1474)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [260/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8803)  Acc@5: 100.0000 (100.0000)  Loss: -0.1517 (-0.1476)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [270/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8847)  Acc@5: 100.0000 (100.0000)  Loss: -0.1540 (-0.1476)  time: 0.1903  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [280/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8888)  Acc@5: 100.0000 (100.0000)  Loss: -0.1538 (-0.1477)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8926)  Acc@5: 100.0000 (100.0000)  Loss: -0.1500 (-0.1475)  time: 0.1905  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8754)  Acc@5: 100.0000 (100.0000)  Loss: -0.1491 (-0.1474)  time: 0.1906  data: 0.0003  max mem: 12058
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8794)  Acc@5: 100.0000 (100.0000)  Loss: -0.1572 (-0.1477)  time: 0.1904  data: 0.0002  max mem: 12058
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8802)  Acc@5: 100.0000 (100.0000)  Loss: -0.1578 (-0.1478)  time: 0.1859  data: 0.0002  max mem: 12058
Train: Epoch[5/5] Total time: 0:01:00 (0.1918 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (99.8802)  Acc@5: 100.0000 (100.0000)  Loss: -0.1578 (-0.1478)
Test: [Task 1]  [ 0/63]  eta: 0:00:25  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  Loss: 1.6676 (1.6676)  time: 0.4019  data: 0.2832  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  Acc@1: 56.2500 (57.9545)  Acc@5: 93.7500 (93.7500)  Loss: 1.6676 (1.6113)  time: 0.1445  data: 0.0260  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  Acc@1: 56.2500 (59.2262)  Acc@5: 93.7500 (92.8571)  Loss: 1.5836 (1.5791)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  Acc@1: 56.2500 (60.4839)  Acc@5: 93.7500 (93.9516)  Loss: 1.3872 (1.5174)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 56.2500 (59.2988)  Acc@5: 93.7500 (94.0549)  Loss: 1.4645 (1.5148)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 62.5000 (60.1716)  Acc@5: 93.7500 (94.7304)  Loss: 1.5203 (1.4989)  time: 0.1189  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 62.5000 (61.0656)  Acc@5: 93.7500 (94.8770)  Loss: 1.2449 (1.4728)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 62.5000 (60.9000)  Acc@5: 100.0000 (95.0000)  Loss: 1.2449 (1.4683)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1238 s / it)
* Acc@1 60.900 Acc@5 95.000 loss 1.468
Test: [Task 1]  [ 0/63]  eta: 0:00:21  ASR: 0.0625 (0.0625)  ACC: 0.6875 (0.6875)  Loss: 4.0945 (4.0945)  time: 0.3488  data: 0.2256  max mem: 12058
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1648)  ACC: 0.5625 (0.5284)  Loss: 3.5437 (3.5189)  time: 0.1418  data: 0.0208  max mem: 12058
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1637)  ACC: 0.5000 (0.4762)  Loss: 3.4305 (3.5133)  time: 0.1206  data: 0.0004  max mem: 12058
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.1875 (0.1794)  ACC: 0.5000 (0.5000)  Loss: 3.2712 (3.4388)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.1875 (0.1692)  ACC: 0.5000 (0.4893)  Loss: 3.4573 (3.4988)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1679)  ACC: 0.5000 (0.5037)  Loss: 3.7288 (3.5661)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.1875 (0.1814)  ACC: 0.5625 (0.5082)  Loss: 3.5209 (3.5245)  time: 0.1195  data: 0.0003  max mem: 12058
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.1875 (0.1796)  ACC: 0.5000 (0.5060)  Loss: 3.5072 (3.5352)  time: 0.1167  data: 0.0002  max mem: 12058
Test: [Task 1] Total time: 0:00:07 (0.1242 s / it)
* ASR 0.180 loss 3.535
Test: [Task 2]  [ 0/63]  eta: 0:00:21  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 1.0485 (1.0485)  time: 0.3433  data: 0.2246  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (80.1136)  Acc@5: 93.7500 (95.4545)  Loss: 0.7887 (0.7734)  time: 0.1389  data: 0.0207  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  Acc@1: 75.0000 (78.5714)  Acc@5: 93.7500 (95.5357)  Loss: 0.7887 (0.8376)  time: 0.1184  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  Acc@1: 75.0000 (78.8306)  Acc@5: 93.7500 (95.3629)  Loss: 0.8487 (0.8503)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 75.0000 (77.8963)  Acc@5: 93.7500 (95.4268)  Loss: 0.8916 (0.8487)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 75.0000 (77.5735)  Acc@5: 93.7500 (95.5882)  Loss: 0.7876 (0.8459)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 75.0000 (77.9713)  Acc@5: 100.0000 (96.0041)  Loss: 0.7197 (0.8188)  time: 0.1184  data: 0.0002  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 75.0000 (77.8000)  Acc@5: 100.0000 (96.1000)  Loss: 0.6727 (0.8128)  time: 0.1156  data: 0.0002  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1226 s / it)
* Acc@1 77.800 Acc@5 96.100 loss 0.813
Test: [Task 2]  [ 0/63]  eta: 0:00:21  ASR: 0.1250 (0.1250)  ACC: 0.5000 (0.5000)  Loss: 3.6393 (3.6393)  time: 0.3476  data: 0.2246  max mem: 12058
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0966)  ACC: 0.6875 (0.6989)  Loss: 4.4868 (4.4694)  time: 0.1410  data: 0.0207  max mem: 12058
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1071)  ACC: 0.6875 (0.7024)  Loss: 4.1895 (4.3545)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 2]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1028)  ACC: 0.7500 (0.7077)  Loss: 4.5358 (4.4712)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.1052)  ACC: 0.7500 (0.7058)  Loss: 4.7646 (4.5151)  time: 0.1195  data: 0.0003  max mem: 12058
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.1029)  ACC: 0.6250 (0.6949)  Loss: 4.7295 (4.5942)  time: 0.1194  data: 0.0003  max mem: 12058
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0943)  ACC: 0.6875 (0.7070)  Loss: 4.7377 (4.6302)  time: 0.1194  data: 0.0003  max mem: 12058
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0923)  ACC: 0.7500 (0.7113)  Loss: 4.7377 (4.6403)  time: 0.1166  data: 0.0002  max mem: 12058
Test: [Task 2] Total time: 0:00:07 (0.1235 s / it)
* ASR 0.092 loss 4.640
Test: [Task 3]  [ 0/63]  eta: 0:00:22  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4430 (0.4430)  time: 0.3593  data: 0.2406  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.1591)  Loss: 0.4846 (0.6306)  time: 0.1404  data: 0.0222  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.0238)  Loss: 0.5566 (0.6616)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (82.4597)  Acc@5: 93.7500 (96.3710)  Loss: 0.6244 (0.6638)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (82.3171)  Acc@5: 93.7500 (96.0366)  Loss: 0.7643 (0.6874)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (82.5980)  Acc@5: 93.7500 (96.2010)  Loss: 0.6963 (0.6778)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (82.4795)  Acc@5: 100.0000 (96.5164)  Loss: 0.6216 (0.6855)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (82.4000)  Acc@5: 100.0000 (96.4000)  Loss: 0.6948 (0.6954)  time: 0.1157  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:08 (0.1278 s / it)
* Acc@1 82.400 Acc@5 96.400 loss 0.695
Test: [Task 3]  [ 0/63]  eta: 0:00:22  ASR: 0.1250 (0.1250)  ACC: 0.7500 (0.7500)  Loss: 5.6096 (5.6096)  time: 0.3555  data: 0.2294  max mem: 12058
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1307)  ACC: 0.7500 (0.7045)  Loss: 4.8949 (4.9082)  time: 0.1415  data: 0.0212  max mem: 12058
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1250)  ACC: 0.6875 (0.6994)  Loss: 4.9584 (5.0787)  time: 0.1201  data: 0.0004  max mem: 12058
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1230)  ACC: 0.6875 (0.7056)  Loss: 5.2555 (5.1505)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1326)  ACC: 0.6875 (0.6997)  Loss: 4.9539 (5.1048)  time: 0.1204  data: 0.0003  max mem: 12058
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.1250 (0.1324)  ACC: 0.6875 (0.7022)  Loss: 4.9539 (5.1052)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.1230)  ACC: 0.6875 (0.7018)  Loss: 5.1421 (5.1254)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1230)  ACC: 0.6875 (0.7024)  Loss: 5.0337 (5.1238)  time: 0.1169  data: 0.0003  max mem: 12058
Test: [Task 3] Total time: 0:00:07 (0.1242 s / it)
* ASR 0.123 loss 5.124
Test: [Task 4]  [ 0/63]  eta: 0:00:23  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.8696 (0.8696)  time: 0.3711  data: 0.2531  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (84.0909)  Acc@5: 100.0000 (98.2955)  Loss: 0.5317 (0.5744)  time: 0.1415  data: 0.0233  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (82.4405)  Acc@5: 93.7500 (97.0238)  Loss: 0.5317 (0.6086)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (82.6613)  Acc@5: 93.7500 (96.9758)  Loss: 0.6510 (0.6354)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (83.0793)  Acc@5: 100.0000 (97.5610)  Loss: 0.4913 (0.5942)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (83.2108)  Acc@5: 100.0000 (97.5490)  Loss: 0.4161 (0.5914)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (83.1967)  Acc@5: 100.0000 (97.4385)  Loss: 0.4932 (0.5942)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (83.3000)  Acc@5: 100.0000 (97.4000)  Loss: 0.4504 (0.5911)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1232 s / it)
* Acc@1 83.300 Acc@5 97.400 loss 0.591
Test: [Task 4]  [ 0/63]  eta: 0:00:23  ASR: 0.1875 (0.1875)  ACC: 0.6250 (0.6250)  Loss: 4.5976 (4.5976)  time: 0.3715  data: 0.2488  max mem: 12058
Test: [Task 4]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1534)  ACC: 0.6250 (0.6420)  Loss: 4.8584 (4.8232)  time: 0.1427  data: 0.0229  max mem: 12058
Test: [Task 4]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1310)  ACC: 0.6875 (0.6726)  Loss: 4.8632 (5.0808)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 4]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.1149)  ACC: 0.6875 (0.6875)  Loss: 5.1781 (5.1721)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 4]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.1113)  ACC: 0.7500 (0.6951)  Loss: 5.2949 (5.2136)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 4]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.1189)  ACC: 0.6875 (0.6887)  Loss: 5.2126 (5.1731)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 4]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.1127)  ACC: 0.6250 (0.6875)  Loss: 4.8770 (5.1939)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 4]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.1101)  ACC: 0.6250 (0.6875)  Loss: 4.9115 (5.2008)  time: 0.1169  data: 0.0003  max mem: 12058
Test: [Task 4] Total time: 0:00:07 (0.1246 s / it)
* ASR 0.110 loss 5.201
Test: [Task 5]  [ 0/63]  eta: 0:00:21  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.3316 (0.3316)  time: 0.3412  data: 0.2215  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (77.2727)  Acc@5: 100.0000 (97.1591)  Loss: 0.6494 (0.7246)  time: 0.1387  data: 0.0204  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (80.6548)  Acc@5: 100.0000 (97.6190)  Loss: 0.6344 (0.6313)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (81.0484)  Acc@5: 100.0000 (97.7823)  Loss: 0.4618 (0.6450)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (81.7073)  Acc@5: 100.0000 (98.1707)  Loss: 0.6140 (0.6378)  time: 0.1188  data: 0.0003  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (81.4951)  Acc@5: 100.0000 (97.7941)  Loss: 0.5979 (0.6452)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (81.1475)  Acc@5: 93.7500 (97.2336)  Loss: 0.6160 (0.6680)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (80.9000)  Acc@5: 93.7500 (97.2000)  Loss: 0.7084 (0.6875)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1228 s / it)
* Acc@1 80.900 Acc@5 97.200 loss 0.687
Test: [Task 5]  [ 0/63]  eta: 0:00:24  ASR: 0.1250 (0.1250)  ACC: 0.8125 (0.8125)  Loss: 5.2425 (5.2425)  time: 0.3860  data: 0.2637  max mem: 12058
Test: [Task 5]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.1307)  ACC: 0.7500 (0.6761)  Loss: 4.7812 (4.8135)  time: 0.1442  data: 0.0243  max mem: 12058
Test: [Task 5]  [20/63]  eta: 0:00:05  ASR: 0.1250 (0.1250)  ACC: 0.6875 (0.6905)  Loss: 4.7812 (4.9195)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 5]  [30/63]  eta: 0:00:04  ASR: 0.1250 (0.1169)  ACC: 0.6875 (0.6996)  Loss: 4.7803 (4.8947)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 5]  [40/63]  eta: 0:00:02  ASR: 0.1250 (0.1143)  ACC: 0.6875 (0.6921)  Loss: 4.8045 (4.9045)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 5]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.1103)  ACC: 0.6875 (0.6900)  Loss: 4.8045 (4.9061)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 5]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.1076)  ACC: 0.6875 (0.6895)  Loss: 4.7242 (4.9071)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 5]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.1121)  ACC: 0.6875 (0.6815)  Loss: 4.7242 (4.8624)  time: 0.1173  data: 0.0003  max mem: 12058
Test: [Task 5] Total time: 0:00:07 (0.1247 s / it)
* ASR 0.112 loss 4.862
Test: [Task 6]  [ 0/63]  eta: 0:00:23  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.5399 (0.5399)  time: 0.3778  data: 0.2603  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  Acc@1: 75.0000 (78.9773)  Acc@5: 100.0000 (98.2955)  Loss: 0.6329 (0.6712)  time: 0.1421  data: 0.0240  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (98.2143)  Loss: 0.6874 (0.7294)  time: 0.1186  data: 0.0004  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  Acc@1: 75.0000 (76.2097)  Acc@5: 100.0000 (98.1855)  Loss: 0.6829 (0.7272)  time: 0.1186  data: 0.0004  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  Acc@1: 75.0000 (75.3049)  Acc@5: 100.0000 (98.4756)  Loss: 0.6829 (0.7464)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  Acc@1: 75.0000 (75.8578)  Acc@5: 100.0000 (98.6520)  Loss: 0.7464 (0.7444)  time: 0.1186  data: 0.0004  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  Acc@1: 75.0000 (76.2295)  Acc@5: 100.0000 (98.4631)  Loss: 0.7151 (0.7419)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (76.5000)  Acc@5: 100.0000 (98.5000)  Loss: 0.7003 (0.7366)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1234 s / it)
* Acc@1 76.500 Acc@5 98.500 loss 0.737
Test: [Task 6]  [ 0/63]  eta: 0:00:23  ASR: 0.0625 (0.0625)  ACC: 0.6875 (0.6875)  Loss: 5.8547 (5.8547)  time: 0.3761  data: 0.2502  max mem: 12058
Test: [Task 6]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0398)  ACC: 0.7500 (0.7500)  Loss: 5.4546 (5.3480)  time: 0.1433  data: 0.0230  max mem: 12058
Test: [Task 6]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0417)  ACC: 0.7500 (0.7262)  Loss: 5.1045 (5.1632)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 6]  [30/63]  eta: 0:00:04  ASR: 0.0000 (0.0444)  ACC: 0.6875 (0.7177)  Loss: 5.1293 (5.1794)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 6]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0442)  ACC: 0.6875 (0.7180)  Loss: 5.1293 (5.1259)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 6]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0441)  ACC: 0.6875 (0.7120)  Loss: 5.1760 (5.1520)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 6]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0441)  ACC: 0.6875 (0.7059)  Loss: 5.1760 (5.1425)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 6]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0446)  ACC: 0.6875 (0.7073)  Loss: 5.0249 (5.1372)  time: 0.1170  data: 0.0003  max mem: 12058
Test: [Task 6] Total time: 0:00:07 (0.1245 s / it)
* ASR 0.045 loss 5.137
Test: [Task 7]  [ 0/63]  eta: 0:00:23  Acc@1: 50.0000 (50.0000)  Acc@5: 100.0000 (100.0000)  Loss: 1.2657 (1.2657)  time: 0.3696  data: 0.2486  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (78.4091)  Acc@5: 100.0000 (97.7273)  Loss: 0.6938 (0.7424)  time: 0.1415  data: 0.0230  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (78.2738)  Acc@5: 100.0000 (96.1310)  Loss: 0.6938 (0.8013)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (78.0242)  Acc@5: 93.7500 (96.1694)  Loss: 0.7707 (0.7879)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (79.4207)  Acc@5: 100.0000 (96.4939)  Loss: 0.7575 (0.7434)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  Acc@1: 75.0000 (78.5539)  Acc@5: 93.7500 (95.4657)  Loss: 0.8108 (0.7958)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  Acc@1: 75.0000 (78.9959)  Acc@5: 93.7500 (95.6967)  Loss: 0.8025 (0.7809)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  Acc@1: 75.0000 (78.8000)  Acc@5: 93.7500 (95.7000)  Loss: 0.8802 (0.7870)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1231 s / it)
* Acc@1 78.800 Acc@5 95.700 loss 0.787
Test: [Task 7]  [ 0/63]  eta: 0:00:22  ASR: 0.0625 (0.0625)  ACC: 0.5000 (0.5000)  Loss: 5.5907 (5.5907)  time: 0.3557  data: 0.2300  max mem: 12058
Test: [Task 7]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0852)  ACC: 0.7500 (0.7159)  Loss: 5.0465 (4.9461)  time: 0.1418  data: 0.0212  max mem: 12058
Test: [Task 7]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0893)  ACC: 0.7500 (0.7054)  Loss: 4.9777 (5.0060)  time: 0.1201  data: 0.0004  max mem: 12058
Test: [Task 7]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0887)  ACC: 0.6875 (0.7036)  Loss: 5.3174 (5.0835)  time: 0.1202  data: 0.0004  max mem: 12058
Test: [Task 7]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0899)  ACC: 0.6875 (0.7119)  Loss: 5.2167 (5.0683)  time: 0.1203  data: 0.0004  max mem: 12058
Test: [Task 7]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0895)  ACC: 0.7500 (0.7047)  Loss: 4.7757 (5.0203)  time: 0.1200  data: 0.0004  max mem: 12058
Test: [Task 7]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0891)  ACC: 0.6875 (0.7049)  Loss: 4.8270 (4.9933)  time: 0.1197  data: 0.0003  max mem: 12058
Test: [Task 7]  [62/63]  eta: 0:00:00  ASR: 0.1250 (0.0913)  ACC: 0.6875 (0.7034)  Loss: 4.7441 (4.9810)  time: 0.1169  data: 0.0003  max mem: 12058
Test: [Task 7] Total time: 0:00:07 (0.1241 s / it)
* ASR 0.091 loss 4.981
Test: [Task 8]  [ 0/63]  eta: 0:00:24  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4974 (0.4974)  time: 0.3839  data: 0.2637  max mem: 12058
Test: [Task 8]  [10/63]  eta: 0:00:07  Acc@1: 81.2500 (78.4091)  Acc@5: 93.7500 (96.0227)  Loss: 0.6620 (0.7451)  time: 0.1427  data: 0.0243  max mem: 12058
Test: [Task 8]  [20/63]  eta: 0:00:05  Acc@1: 81.2500 (80.3571)  Acc@5: 93.7500 (95.8333)  Loss: 0.6620 (0.7124)  time: 0.1186  data: 0.0004  max mem: 12058
Test: [Task 8]  [30/63]  eta: 0:00:04  Acc@1: 81.2500 (81.4516)  Acc@5: 93.7500 (96.1694)  Loss: 0.5607 (0.6659)  time: 0.1186  data: 0.0004  max mem: 12058
Test: [Task 8]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (82.0122)  Acc@5: 100.0000 (96.4939)  Loss: 0.4944 (0.6457)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 8]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (81.9853)  Acc@5: 100.0000 (96.3235)  Loss: 0.5502 (0.6356)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 8]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (81.3525)  Acc@5: 93.7500 (95.9016)  Loss: 0.6884 (0.6650)  time: 0.1187  data: 0.0003  max mem: 12058
Test: [Task 8]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (81.5000)  Acc@5: 93.7500 (96.0000)  Loss: 0.5779 (0.6538)  time: 0.1159  data: 0.0003  max mem: 12058
Test: [Task 8] Total time: 0:00:07 (0.1236 s / it)
* Acc@1 81.500 Acc@5 96.000 loss 0.654
Test: [Task 8]  [ 0/63]  eta: 0:00:23  ASR: 0.1250 (0.1250)  ACC: 0.8125 (0.8125)  Loss: 4.9252 (4.9252)  time: 0.3809  data: 0.2538  max mem: 12058
Test: [Task 8]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0909)  ACC: 0.6875 (0.6989)  Loss: 5.5406 (5.2975)  time: 0.1435  data: 0.0234  max mem: 12058
Test: [Task 8]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0863)  ACC: 0.7500 (0.7351)  Loss: 5.5406 (5.3833)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 8]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0827)  ACC: 0.7500 (0.7278)  Loss: 5.4064 (5.4212)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 8]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0854)  ACC: 0.6875 (0.7104)  Loss: 5.3665 (5.3707)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 8]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0809)  ACC: 0.6875 (0.7071)  Loss: 5.1472 (5.3512)  time: 0.1200  data: 0.0003  max mem: 12058
Test: [Task 8]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0850)  ACC: 0.6875 (0.6967)  Loss: 5.3121 (5.3422)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 8]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0823)  ACC: 0.6875 (0.6984)  Loss: 5.3346 (5.3779)  time: 0.1170  data: 0.0003  max mem: 12058
Test: [Task 8] Total time: 0:00:07 (0.1245 s / it)
* ASR 0.082 loss 5.378
Test: [Task 9]  [ 0/63]  eta: 0:00:21  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1621 (0.1621)  time: 0.3476  data: 0.2271  max mem: 12058
Test: [Task 9]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (90.3409)  Acc@5: 100.0000 (98.8636)  Loss: 0.3293 (0.3939)  time: 0.1394  data: 0.0210  max mem: 12058
Test: [Task 9]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.5119)  Loss: 0.3293 (0.4084)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 9]  [30/63]  eta: 0:00:04  Acc@1: 93.7500 (89.3145)  Acc@5: 100.0000 (98.9919)  Loss: 0.2985 (0.3801)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 9]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (89.1768)  Acc@5: 100.0000 (98.9329)  Loss: 0.2985 (0.3814)  time: 0.1188  data: 0.0004  max mem: 12058
Test: [Task 9]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (88.9706)  Acc@5: 100.0000 (98.6520)  Loss: 0.4163 (0.3961)  time: 0.1187  data: 0.0004  max mem: 12058
Test: [Task 9]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (89.7541)  Acc@5: 100.0000 (98.7705)  Loss: 0.3946 (0.3746)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 9]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (89.9000)  Acc@5: 100.0000 (98.8000)  Loss: 0.3713 (0.3667)  time: 0.1158  data: 0.0003  max mem: 12058
Test: [Task 9] Total time: 0:00:07 (0.1227 s / it)
* Acc@1 89.900 Acc@5 98.800 loss 0.367
Test: [Task 9]  [ 0/63]  eta: 0:00:23  ASR: 0.0625 (0.0625)  ACC: 0.8750 (0.8750)  Loss: 6.6895 (6.6895)  time: 0.3702  data: 0.2463  max mem: 12058
Test: [Task 9]  [10/63]  eta: 0:00:07  ASR: 0.0625 (0.0739)  ACC: 0.8125 (0.7670)  Loss: 5.4710 (5.4788)  time: 0.1431  data: 0.0227  max mem: 12058
Test: [Task 9]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0685)  ACC: 0.7500 (0.7768)  Loss: 5.4733 (5.5725)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 9]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0645)  ACC: 0.7500 (0.7843)  Loss: 5.5214 (5.6028)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 9]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0640)  ACC: 0.7500 (0.7744)  Loss: 5.6308 (5.6448)  time: 0.1199  data: 0.0003  max mem: 12058
Test: [Task 9]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0600)  ACC: 0.7500 (0.7770)  Loss: 5.7805 (5.6763)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 9]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0553)  ACC: 0.8750 (0.7971)  Loss: 5.9181 (5.7498)  time: 0.1196  data: 0.0003  max mem: 12058
Test: [Task 9]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0536)  ACC: 0.8750 (0.8006)  Loss: 5.9445 (5.7583)  time: 0.1167  data: 0.0003  max mem: 12058
Test: [Task 9] Total time: 0:00:07 (0.1247 s / it)
* ASR 0.054 loss 5.758
Test: [Task 10]  [ 0/63]  eta: 0:00:24  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.3914 (0.3914)  time: 0.3875  data: 0.2678  max mem: 12058
Test: [Task 10]  [10/63]  eta: 0:00:07  Acc@1: 87.5000 (89.2045)  Acc@5: 100.0000 (98.8636)  Loss: 0.3425 (0.3689)  time: 0.1429  data: 0.0246  max mem: 12058
Test: [Task 10]  [20/63]  eta: 0:00:05  Acc@1: 87.5000 (88.9881)  Acc@5: 100.0000 (99.4048)  Loss: 0.3425 (0.3782)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 10]  [30/63]  eta: 0:00:04  Acc@1: 87.5000 (89.1129)  Acc@5: 100.0000 (99.3952)  Loss: 0.3842 (0.3964)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 10]  [40/63]  eta: 0:00:02  Acc@1: 87.5000 (89.7866)  Acc@5: 100.0000 (99.0854)  Loss: 0.3983 (0.3841)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 10]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (89.8284)  Acc@5: 100.0000 (99.1422)  Loss: 0.2885 (0.3747)  time: 0.1186  data: 0.0003  max mem: 12058
Test: [Task 10]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (89.7541)  Acc@5: 100.0000 (98.9754)  Loss: 0.3512 (0.3802)  time: 0.1185  data: 0.0003  max mem: 12058
Test: [Task 10]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (89.8000)  Acc@5: 100.0000 (99.0000)  Loss: 0.3512 (0.3799)  time: 0.1157  data: 0.0003  max mem: 12058
Test: [Task 10] Total time: 0:00:07 (0.1235 s / it)
* Acc@1 89.800 Acc@5 99.000 loss 0.380
Test: [Task 10]  [ 0/63]  eta: 0:00:23  ASR: 0.0000 (0.0000)  ACC: 0.6875 (0.6875)  Loss: 5.0096 (5.0096)  time: 0.3787  data: 0.2556  max mem: 12058
Test: [Task 10]  [10/63]  eta: 0:00:07  ASR: 0.1250 (0.0909)  ACC: 0.7500 (0.7614)  Loss: 4.6073 (4.5612)  time: 0.1437  data: 0.0235  max mem: 12058
Test: [Task 10]  [20/63]  eta: 0:00:05  ASR: 0.0625 (0.0774)  ACC: 0.7500 (0.7589)  Loss: 4.6628 (4.8347)  time: 0.1203  data: 0.0003  max mem: 12058
Test: [Task 10]  [30/63]  eta: 0:00:04  ASR: 0.0625 (0.0887)  ACC: 0.7500 (0.7460)  Loss: 4.8893 (4.7773)  time: 0.1202  data: 0.0003  max mem: 12058
Test: [Task 10]  [40/63]  eta: 0:00:02  ASR: 0.0625 (0.0838)  ACC: 0.7500 (0.7470)  Loss: 4.8893 (4.8558)  time: 0.1198  data: 0.0003  max mem: 12058
Test: [Task 10]  [50/63]  eta: 0:00:01  ASR: 0.0625 (0.0784)  ACC: 0.7500 (0.7475)  Loss: 4.9024 (4.8341)  time: 0.1201  data: 0.0003  max mem: 12058
Test: [Task 10]  [60/63]  eta: 0:00:00  ASR: 0.0625 (0.0830)  ACC: 0.7500 (0.7480)  Loss: 4.6908 (4.8289)  time: 0.1199  data: 0.0002  max mem: 12058
Test: [Task 10]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.0813)  ACC: 0.7500 (0.7530)  Loss: 4.7909 (4.8427)  time: 0.1168  data: 0.0002  max mem: 12058
Test: [Task 10] Total time: 0:00:07 (0.1245 s / it)
* ASR 0.081 loss 4.843
[Average accuracy till task10]	ASR: 0.0970	Acc@1: 80.1800	Loss: 4.9460	Forgetting: 0.1283	Backward: -0.1196
Total training time: 3:08:30
[rank0]:[W129 22:33:53.851426963 ProcessGroupNCCL.cpp:1168] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
=== JOB_STATISTICS ===
=== current date     : Wed 29 Jan 2025 10:33:56 PM CET
= Job-ID             : 984777 on tinygpu
= Job-Name           : trigger_0_0.1_vit_base_patch16_224
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_sleeper/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_sleeper
= Queue/Partition    : v100
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 03:09:14
= Total RAM usage    : 6.2 GiB of requested  GiB (%)   
= Node list          : tg073
= Subm/Elig/Start/End: 2025-01-29T19:15:35 / 2025-01-29T19:15:35 / 2025-01-29T19:24:42 / 2025-01-29T22:33:56
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/woody         39.4G  1000.0G  1500.0G        N/A     269K   5,000K   7,500K        N/A    
    /home/hpc           95.0G   104.9G   209.7G        N/A      85K     500K   1,000K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
Tesla V100-PCIE-32GB, 00000000:18:00.0, 4102869, 88 %, 34 %, 14810 MiB, 11327213 ms
