### Starting TaskPrologue of job 966681 on tg085 at Sat 04 Jan 2025 06:39:19 AM CET
Running on cores 2-3,18-19,34-35,50-51 with governor ondemand
Sat Jan  4 06:39:20 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3080        On  |   00000000:1B:00.0 Off |                  N/A |
| 30%   36C    P8             16W /  300W |       2MiB /  10240MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', p_task_id=2, patience_epochs=10, pin_mem=True, poison_rate=0.1, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, trigger_path='trigger_2_vit_base_patch16_224.pt', unscale_lr=True, use_prompt_mask=False, use_trigger=True, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
True
trigger loaded
/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/engine.py:263: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  trigger = torch.load(args.trigger_path)
0 2
Train: Epoch[1/5]  [  0/313]  eta: 0:12:00  Lr: 0.0019 (0.0019)  Acc@1: 25.0000 (25.0000)  Acc@5: 43.7500 (43.7500)  Loss: 2.3091 (2.3091)  time: 2.3010  data: 0.8136  max mem: 2371
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:49  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (40.9091)  Acc@5: 75.0000 (73.2955)  Loss: 2.1764 (2.1620)  time: 0.3600  data: 0.0742  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:16  Lr: 0.0019 (0.0019)  Acc@1: 50.0000 (51.4881)  Acc@5: 87.5000 (80.3571)  Loss: 2.0327 (2.0359)  time: 0.1607  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:04  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (55.6452)  Acc@5: 93.7500 (84.2742)  Loss: 1.8576 (1.9455)  time: 0.1557  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:57  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (59.7561)  Acc@5: 93.7500 (86.8902)  Loss: 1.6623 (1.8447)  time: 0.1569  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (62.0098)  Acc@5: 93.7500 (88.4804)  Loss: 1.4252 (1.7606)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.4221)  Acc@5: 93.7500 (89.0369)  Loss: 1.3302 (1.6894)  time: 0.1553  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.1408)  Acc@5: 93.7500 (89.9648)  Loss: 1.2075 (1.6147)  time: 0.1548  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (66.9753)  Acc@5: 93.7500 (90.8179)  Loss: 1.1268 (1.5471)  time: 0.1551  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7198)  Acc@5: 93.7500 (91.3462)  Loss: 1.0733 (1.4971)  time: 0.1553  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1213)  Acc@5: 100.0000 (91.9554)  Loss: 0.9557 (1.4415)  time: 0.1553  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (69.7635)  Acc@5: 93.7500 (92.1734)  Loss: 0.9339 (1.3976)  time: 0.1553  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.2479)  Acc@5: 93.7500 (92.6136)  Loss: 0.9000 (1.3549)  time: 0.1557  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.9924)  Acc@5: 100.0000 (93.0821)  Loss: 0.8450 (1.3130)  time: 0.1560  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.8528)  Acc@5: 100.0000 (93.4397)  Loss: 0.7665 (1.2711)  time: 0.1561  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.5166)  Acc@5: 100.0000 (93.6672)  Loss: 0.6911 (1.2301)  time: 0.1562  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.8649)  Acc@5: 100.0000 (93.9053)  Loss: 0.6276 (1.1988)  time: 0.1562  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.5015)  Acc@5: 100.0000 (94.1155)  Loss: 0.6611 (1.1656)  time: 0.1563  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.6188)  Acc@5: 100.0000 (94.3025)  Loss: 0.6085 (1.1378)  time: 0.1564  data: 0.0002  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.2474)  Acc@5: 100.0000 (94.4372)  Loss: 0.5923 (1.1079)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.5958)  Acc@5: 93.7500 (94.4341)  Loss: 0.5806 (1.0841)  time: 0.1563  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.7927)  Acc@5: 100.0000 (94.6090)  Loss: 0.6030 (1.0631)  time: 0.1562  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.0566)  Acc@5: 100.0000 (94.7681)  Loss: 0.5741 (1.0410)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.2165)  Acc@5: 100.0000 (94.9134)  Loss: 0.5756 (1.0218)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.8817)  Acc@5: 100.0000 (95.0726)  Loss: 0.4548 (0.9949)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1952)  Acc@5: 100.0000 (95.1693)  Loss: 0.4640 (0.9765)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.5086)  Acc@5: 100.0000 (95.3065)  Loss: 0.5304 (0.9563)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:07  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.6836)  Acc@5: 100.0000 (95.4105)  Loss: 0.4691 (0.9400)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.9795)  Acc@5: 100.0000 (95.5738)  Loss: 0.4272 (0.9220)  time: 0.1569  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.0833)  Acc@5: 100.0000 (95.5971)  Loss: 0.4377 (0.9101)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.3463)  Acc@5: 100.0000 (95.6603)  Loss: 0.4430 (0.8942)  time: 0.1573  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4719)  Acc@5: 93.7500 (95.6793)  Loss: 0.4489 (0.8831)  time: 0.1573  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:51 (0.1636 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)
0 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.2601 (0.2601)  time: 0.3250  data: 0.1640  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (96.0227)  Loss: 0.6554 (0.5714)  time: 0.1727  data: 0.0152  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.0238)  Loss: 0.4286 (0.4585)  time: 0.1574  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.2581)  Acc@5: 100.0000 (96.9758)  Loss: 0.3460 (0.4481)  time: 0.1576  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (97.1037)  Loss: 0.3460 (0.4236)  time: 0.1578  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (97.4265)  Loss: 0.3617 (0.4173)  time: 0.1578  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.4385)  Loss: 0.3617 (0.4059)  time: 0.1579  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0669)  Acc@5: 100.0000 (97.6232)  Loss: 0.3543 (0.4041)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9506)  Acc@5: 100.0000 (97.6080)  Loss: 0.3646 (0.4007)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9973)  Acc@5: 100.0000 (97.5962)  Loss: 0.3185 (0.3968)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0347)  Acc@5: 100.0000 (97.6485)  Loss: 0.3185 (0.3957)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9527)  Acc@5: 100.0000 (97.7477)  Loss: 0.3314 (0.3899)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8326)  Acc@5: 100.0000 (97.7273)  Loss: 0.3314 (0.3894)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1603)  Acc@5: 100.0000 (97.6622)  Loss: 0.3256 (0.3833)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1312)  Acc@5: 93.7500 (97.5621)  Loss: 0.3241 (0.3847)  time: 0.1587  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9818)  Acc@5: 93.7500 (97.5579)  Loss: 0.3867 (0.3854)  time: 0.1594  data: 0.0004  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8509)  Acc@5: 100.0000 (97.5155)  Loss: 0.3258 (0.3839)  time: 0.1590  data: 0.0004  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9547)  Acc@5: 100.0000 (97.5512)  Loss: 0.2723 (0.3797)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8052)  Acc@5: 100.0000 (97.5138)  Loss: 0.3252 (0.3794)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9005)  Acc@5: 100.0000 (97.6113)  Loss: 0.2981 (0.3731)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8308)  Acc@5: 100.0000 (97.6990)  Loss: 0.2958 (0.3716)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0344)  Acc@5: 100.0000 (97.7488)  Loss: 0.2618 (0.3659)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8518)  Acc@5: 100.0000 (97.7093)  Loss: 0.2618 (0.3686)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.8084)  Loss: 0.2166 (0.3608)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.2324)  Acc@5: 100.0000 (97.8994)  Loss: 0.1579 (0.3563)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.1882)  Acc@5: 100.0000 (97.8586)  Loss: 0.2819 (0.3544)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9559)  Acc@5: 100.0000 (97.8448)  Loss: 0.3998 (0.3589)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9253)  Acc@5: 100.0000 (97.8782)  Loss: 0.3762 (0.3573)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8746)  Acc@5: 100.0000 (97.8648)  Loss: 0.3273 (0.3553)  time: 0.1587  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8703)  Acc@5: 100.0000 (97.8522)  Loss: 0.2411 (0.3530)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9909)  Acc@5: 100.0000 (97.9028)  Loss: 0.2340 (0.3493)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0836)  Acc@5: 100.0000 (97.9100)  Loss: 0.2207 (0.3477)  time: 0.1587  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)  time: 0.1551  data: 0.0002  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:49 (0.1589 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)
0 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1340 (0.1340)  time: 0.3631  data: 0.2036  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  Loss: 0.2430 (0.2785)  time: 0.1773  data: 0.0187  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.9167)  Loss: 0.3333 (0.3284)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.5887)  Loss: 0.2192 (0.2731)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.3232)  Loss: 0.1146 (0.2478)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.5294)  Loss: 0.1603 (0.2371)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.6557)  Acc@5: 100.0000 (98.2582)  Loss: 0.2495 (0.2615)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.9155)  Acc@5: 100.0000 (98.3275)  Loss: 0.2700 (0.2600)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3426)  Acc@5: 100.0000 (98.3025)  Loss: 0.2269 (0.2561)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4011)  Acc@5: 100.0000 (98.3516)  Loss: 0.2158 (0.2540)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0767)  Acc@5: 100.0000 (98.3292)  Loss: 0.2631 (0.2544)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5991)  Acc@5: 100.0000 (98.3671)  Loss: 0.1068 (0.2408)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0021)  Acc@5: 100.0000 (98.4504)  Loss: 0.1068 (0.2487)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5458)  Acc@5: 100.0000 (98.3779)  Loss: 0.1907 (0.2390)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7908)  Acc@5: 100.0000 (98.3599)  Loss: 0.2089 (0.2373)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6722)  Acc@5: 100.0000 (98.4272)  Loss: 0.2159 (0.2396)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8789)  Acc@5: 100.0000 (98.5248)  Loss: 0.1434 (0.2307)  time: 0.1587  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7325)  Acc@5: 100.0000 (98.5746)  Loss: 0.1122 (0.2309)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6367)  Acc@5: 100.0000 (98.5497)  Loss: 0.2248 (0.2341)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6819)  Acc@5: 100.0000 (98.5275)  Loss: 0.1644 (0.2297)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7226)  Acc@5: 100.0000 (98.5697)  Loss: 0.1072 (0.2288)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5818)  Acc@5: 100.0000 (98.5486)  Loss: 0.1899 (0.2336)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5950)  Acc@5: 100.0000 (98.5011)  Loss: 0.1946 (0.2318)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.5390)  Loss: 0.1946 (0.2297)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.4699)  Loss: 0.1495 (0.2286)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.5787)  Acc@5: 100.0000 (98.4064)  Loss: 0.1721 (0.2274)  time: 0.1591  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.3956)  Loss: 0.1582 (0.2251)  time: 0.1592  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7159)  Acc@5: 100.0000 (98.4087)  Loss: 0.0974 (0.2242)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7660)  Acc@5: 100.0000 (98.4208)  Loss: 0.1206 (0.2229)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7912)  Acc@5: 100.0000 (98.4107)  Loss: 0.1309 (0.2212)  time: 0.1595  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9186)  Acc@5: 100.0000 (98.4427)  Loss: 0.1289 (0.2183)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9775)  Acc@5: 100.0000 (98.4727)  Loss: 0.1218 (0.2151)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)  time: 0.1555  data: 0.0003  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:49 (0.1596 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)
0 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1105 (0.1105)  time: 0.3272  data: 0.1679  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  Loss: 0.1945 (0.1745)  time: 0.1744  data: 0.0155  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5119)  Loss: 0.1945 (0.1660)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.5887)  Loss: 0.1687 (0.1709)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.1707)  Loss: 0.1728 (0.1912)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (98.4069)  Loss: 0.1458 (0.1734)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (98.1557)  Loss: 0.1876 (0.1957)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4437)  Acc@5: 100.0000 (98.1514)  Loss: 0.2398 (0.2087)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4198)  Acc@5: 100.0000 (98.1481)  Loss: 0.3108 (0.2089)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.1456)  Loss: 0.1457 (0.2040)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.2673)  Loss: 0.1278 (0.2026)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3176)  Acc@5: 100.0000 (98.2545)  Loss: 0.2012 (0.2047)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0021)  Acc@5: 100.0000 (98.1405)  Loss: 0.2384 (0.2080)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1641)  Acc@5: 100.0000 (98.1393)  Loss: 0.2447 (0.2050)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5248)  Acc@5: 100.0000 (98.1826)  Loss: 0.1092 (0.1991)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7550)  Acc@5: 100.0000 (98.1788)  Loss: 0.0572 (0.1944)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6460)  Acc@5: 100.0000 (98.2143)  Loss: 0.0832 (0.1987)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5863)  Acc@5: 100.0000 (98.2091)  Loss: 0.1471 (0.1985)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8094)  Acc@5: 100.0000 (98.3080)  Loss: 0.1471 (0.1947)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8783)  Acc@5: 100.0000 (98.2657)  Loss: 0.0984 (0.1936)  time: 0.1588  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.2898)  Loss: 0.0847 (0.1901)  time: 0.1588  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9372)  Acc@5: 100.0000 (98.3412)  Loss: 0.1282 (0.1915)  time: 0.1588  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0758)  Acc@5: 100.0000 (98.3597)  Loss: 0.1562 (0.1883)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.3496)  Loss: 0.1421 (0.1869)  time: 0.1588  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1629)  Acc@5: 100.0000 (98.3143)  Loss: 0.1428 (0.1863)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2012)  Acc@5: 100.0000 (98.3566)  Loss: 0.1428 (0.1858)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1648)  Acc@5: 100.0000 (98.3477)  Loss: 0.2151 (0.1859)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0849)  Acc@5: 100.0000 (98.2934)  Loss: 0.2151 (0.1883)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1219)  Acc@5: 100.0000 (98.2874)  Loss: 0.1995 (0.1879)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1134)  Acc@5: 100.0000 (98.3247)  Loss: 0.1641 (0.1893)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1678)  Acc@5: 100.0000 (98.3804)  Loss: 0.1424 (0.1875)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1182)  Acc@5: 100.0000 (98.3521)  Loss: 0.1150 (0.1878)  time: 0.1588  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)  time: 0.1551  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:49 (0.1596 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)
0 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1773 (0.1773)  time: 0.3474  data: 0.1871  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  Loss: 0.1773 (0.1656)  time: 0.1764  data: 0.0173  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.5119)  Loss: 0.1756 (0.1675)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (97.9839)  Loss: 0.2191 (0.2073)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0610)  Acc@5: 100.0000 (98.3232)  Loss: 0.2191 (0.2225)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0490)  Acc@5: 100.0000 (98.4069)  Loss: 0.1584 (0.2164)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7336)  Acc@5: 100.0000 (98.2582)  Loss: 0.1712 (0.2224)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8592)  Acc@5: 100.0000 (98.1514)  Loss: 0.1792 (0.2243)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1080)  Acc@5: 100.0000 (98.1481)  Loss: 0.1045 (0.2147)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7527)  Acc@5: 100.0000 (98.2830)  Loss: 0.1749 (0.2228)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7772)  Acc@5: 100.0000 (98.4530)  Loss: 0.1946 (0.2173)  time: 0.1590  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7410)  Acc@5: 100.0000 (98.5360)  Loss: 0.2287 (0.2162)  time: 0.1589  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0207)  Acc@5: 100.0000 (98.6054)  Loss: 0.1936 (0.2105)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9714)  Acc@5: 100.0000 (98.6164)  Loss: 0.1936 (0.2113)  time: 0.1591  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3280)  Acc@5: 100.0000 (98.7145)  Loss: 0.1364 (0.2022)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3891)  Acc@5: 100.0000 (98.7169)  Loss: 0.1261 (0.2018)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.4425)  Acc@5: 100.0000 (98.7189)  Loss: 0.1274 (0.2008)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (98.7939)  Loss: 0.0427 (0.1903)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.9461)  Acc@5: 100.0000 (98.7569)  Loss: 0.0382 (0.1887)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9620)  Acc@5: 100.0000 (98.7565)  Loss: 0.1745 (0.1888)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2562)  Acc@5: 100.0000 (98.7562)  Loss: 0.1815 (0.1843)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1078)  Acc@5: 100.0000 (98.7263)  Loss: 0.1329 (0.1859)  time: 0.1592  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2557)  Acc@5: 100.0000 (98.7557)  Loss: 0.1382 (0.1829)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.7554)  Loss: 0.1170 (0.1814)  time: 0.1596  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3589)  Acc@5: 100.0000 (98.7811)  Loss: 0.1627 (0.1803)  time: 0.1596  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5040)  Acc@5: 100.0000 (98.7799)  Loss: 0.1687 (0.1783)  time: 0.1594  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5421)  Acc@5: 100.0000 (98.7548)  Loss: 0.1139 (0.1761)  time: 0.1595  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5775)  Acc@5: 100.0000 (98.7085)  Loss: 0.1439 (0.1787)  time: 0.1597  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6326)  Acc@5: 100.0000 (98.7100)  Loss: 0.1651 (0.1792)  time: 0.1597  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.7328)  Loss: 0.1124 (0.1769)  time: 0.1597  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7525)  Acc@5: 100.0000 (98.7126)  Loss: 0.1409 (0.1791)  time: 0.1595  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7966)  Acc@5: 100.0000 (98.6937)  Loss: 0.1640 (0.1763)  time: 0.1593  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)  time: 0.1556  data: 0.0003  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:50 (0.1601 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)
Test: [Task 1]  [ 0/63]  eta: 0:00:19  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4452 (0.4452)  time: 0.3088  data: 0.2100  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4146)  time: 0.1185  data: 0.0194  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4772)  time: 0.0995  data: 0.0004  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (96.7742)  Acc@5: 100.0000 (100.0000)  Loss: 0.3290 (0.4259)  time: 0.0995  data: 0.0004  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (100.0000)  Loss: 0.3048 (0.4234)  time: 0.0994  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.8775)  Loss: 0.3667 (0.4123)  time: 0.0994  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (99.8975)  Loss: 0.3730 (0.4057)  time: 0.0994  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (97.5000)  Acc@5: 100.0000 (99.9000)  Loss: 0.3730 (0.4065)  time: 0.0970  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:06 (0.1033 s / it)
* Acc@1 97.500 Acc@5 99.900 loss 0.407
Test: [Task 1]  [ 0/63]  eta: 0:00:24  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 0.9447 (0.9447)  time: 0.3891  data: 0.1893  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4545)  Loss: 0.7991 (0.8052)  time: 0.1433  data: 0.0175  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.5238)  Loss: 0.7991 (0.8714)  time: 0.1182  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7097)  Loss: 0.8554 (0.8626)  time: 0.1194  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6829)  Loss: 0.7118 (0.8626)  time: 0.1173  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7059)  Loss: 0.6848 (0.8602)  time: 0.1138  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.6066)  Loss: 0.6241 (0.8361)  time: 0.1121  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.5873)  Loss: 0.6223 (0.8394)  time: 0.1087  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:07 (0.1202 s / it)
* ASR 0.000 
[Average accuracy till task1]	ASR: 0.0000	ACC: 97.5000	Loss: 0.8394
1 2
Train: Epoch[1/5]  [  0/313]  eta: 0:01:42  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  Loss: 2.1099 (2.1099)  time: 0.3290  data: 0.1685  max mem: 2374
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 31.2500 (30.1136)  Acc@5: 75.0000 (72.1591)  Loss: 1.9865 (1.9809)  time: 0.1748  data: 0.0156  max mem: 2375
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (45.5357)  Acc@5: 87.5000 (81.5476)  Loss: 1.8626 (1.8644)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (54.8387)  Acc@5: 93.7500 (85.8871)  Loss: 1.5926 (1.7596)  time: 0.1590  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (60.2134)  Acc@5: 93.7500 (88.1098)  Loss: 1.4334 (1.6578)  time: 0.1589  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.2353)  Acc@5: 93.7500 (89.5833)  Loss: 1.2427 (1.5697)  time: 0.1588  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.6762)  Acc@5: 100.0000 (90.7787)  Loss: 1.0970 (1.4807)  time: 0.1588  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (67.9577)  Acc@5: 100.0000 (91.4613)  Loss: 0.9570 (1.4020)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1358)  Acc@5: 100.0000 (92.3611)  Loss: 0.8705 (1.3359)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.3297)  Acc@5: 100.0000 (92.8571)  Loss: 0.8177 (1.2761)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.5965)  Acc@5: 93.7500 (93.1312)  Loss: 0.6947 (1.2153)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (72.6914)  Acc@5: 100.0000 (93.5248)  Loss: 0.5696 (1.1590)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (73.7603)  Acc@5: 100.0000 (93.8533)  Loss: 0.5555 (1.1108)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (74.5229)  Acc@5: 100.0000 (94.1794)  Loss: 0.5153 (1.0672)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.8670)  Acc@5: 100.0000 (94.4149)  Loss: 0.5817 (1.0360)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.5381)  Acc@5: 100.0000 (94.5778)  Loss: 0.5817 (0.9992)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1258)  Acc@5: 93.7500 (94.6429)  Loss: 0.4608 (0.9683)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.4254)  Acc@5: 93.7500 (94.7003)  Loss: 0.4739 (0.9395)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8301)  Acc@5: 100.0000 (94.7859)  Loss: 0.5221 (0.9160)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.1270)  Acc@5: 100.0000 (94.9935)  Loss: 0.5221 (0.8944)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.2388)  Acc@5: 100.0000 (94.9938)  Loss: 0.5255 (0.8780)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (77.4289)  Acc@5: 100.0000 (95.1718)  Loss: 0.4888 (0.8588)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.7998)  Acc@5: 100.0000 (95.2489)  Loss: 0.3734 (0.8374)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.1115)  Acc@5: 100.0000 (95.3193)  Loss: 0.3270 (0.8161)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.3454)  Acc@5: 100.0000 (95.4876)  Loss: 0.3270 (0.7971)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6604)  Acc@5: 100.0000 (95.5428)  Loss: 0.3235 (0.7789)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.0469)  Acc@5: 100.0000 (95.6657)  Loss: 0.3235 (0.7623)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.1513)  Acc@5: 100.0000 (95.7334)  Loss: 0.3178 (0.7486)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.4262)  Acc@5: 100.0000 (95.7295)  Loss: 0.3178 (0.7341)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.5103)  Acc@5: 93.7500 (95.7259)  Loss: 0.3530 (0.7232)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.5681)  Acc@5: 93.7500 (95.7226)  Loss: 0.3800 (0.7128)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7629)  Acc@5: 100.0000 (95.8601)  Loss: 0.2846 (0.6983)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)  time: 0.1556  data: 0.0002  max mem: 2375
Train: Epoch[1/5] Total time: 0:00:50 (0.1598 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)
1 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.1860 (0.1860)  time: 0.3467  data: 0.1856  max mem: 2375
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.1591)  Loss: 0.3742 (0.3463)  time: 0.1762  data: 0.0171  max mem: 2375
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (97.6190)  Loss: 0.3607 (0.3357)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (97.9839)  Loss: 0.3258 (0.3426)  time: 0.1590  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6037)  Acc@5: 100.0000 (98.1707)  Loss: 0.3258 (0.3225)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8039)  Acc@5: 100.0000 (98.2843)  Loss: 0.2535 (0.3162)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.8484)  Loss: 0.2556 (0.3232)  time: 0.1590  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7711)  Acc@5: 100.0000 (97.8873)  Loss: 0.2959 (0.3084)  time: 0.1590  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8765)  Acc@5: 100.0000 (98.0710)  Loss: 0.2745 (0.3097)  time: 0.1589  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6841)  Acc@5: 100.0000 (98.0082)  Loss: 0.2606 (0.3087)  time: 0.1589  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0248)  Acc@5: 100.0000 (98.2054)  Loss: 0.2124 (0.2980)  time: 0.1589  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1914)  Acc@5: 100.0000 (98.1419)  Loss: 0.1280 (0.2909)  time: 0.1589  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1240)  Acc@5: 100.0000 (98.1405)  Loss: 0.2622 (0.2949)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0668)  Acc@5: 100.0000 (98.0439)  Loss: 0.3736 (0.2968)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8848)  Acc@5: 100.0000 (97.9167)  Loss: 0.2205 (0.2973)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8510)  Acc@5: 100.0000 (97.8891)  Loss: 0.2205 (0.2980)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9379)  Acc@5: 100.0000 (97.9814)  Loss: 0.2321 (0.2948)  time: 0.1591  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2705)  Acc@5: 100.0000 (97.9898)  Loss: 0.1739 (0.2870)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.5318)  Acc@5: 100.0000 (98.0663)  Loss: 0.1548 (0.2819)  time: 0.1589  data: 0.0002  max mem: 2375
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2749)  Acc@5: 100.0000 (98.0366)  Loss: 0.2536 (0.2836)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2923)  Acc@5: 100.0000 (98.1032)  Loss: 0.2834 (0.2845)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2192)  Acc@5: 100.0000 (98.1339)  Loss: 0.2328 (0.2855)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2093)  Acc@5: 100.0000 (98.1335)  Loss: 0.2043 (0.2840)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (98.1331)  Loss: 0.1866 (0.2817)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0104)  Acc@5: 100.0000 (98.1587)  Loss: 0.1948 (0.2808)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8108)  Acc@5: 100.0000 (98.1076)  Loss: 0.2127 (0.2852)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6983)  Acc@5: 100.0000 (98.0843)  Loss: 0.2127 (0.2849)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6863)  Acc@5: 100.0000 (98.0858)  Loss: 0.2319 (0.2854)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8310)  Acc@5: 100.0000 (98.1317)  Loss: 0.2170 (0.2810)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7723)  Acc@5: 100.0000 (98.1744)  Loss: 0.2126 (0.2810)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6553)  Acc@5: 100.0000 (98.1935)  Loss: 0.3128 (0.2850)  time: 0.1599  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5659)  Acc@5: 100.0000 (98.1712)  Loss: 0.3664 (0.2861)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)  time: 0.1560  data: 0.0003  max mem: 2375
Train: Epoch[2/5] Total time: 0:00:50 (0.1599 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)
1 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:49  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  Loss: 0.7543 (0.7543)  time: 0.3503  data: 0.1919  max mem: 2375
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.1591)  Loss: 0.2102 (0.2578)  time: 0.1771  data: 0.0177  max mem: 2375
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.0238)  Loss: 0.2338 (0.2732)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (97.5806)  Loss: 0.2109 (0.2446)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (97.8659)  Loss: 0.1356 (0.2257)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (98.1618)  Loss: 0.1610 (0.2279)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.3607)  Loss: 0.1860 (0.2199)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2676)  Acc@5: 100.0000 (98.1514)  Loss: 0.1860 (0.2191)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4969)  Acc@5: 100.0000 (98.2253)  Loss: 0.2359 (0.2140)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8132)  Acc@5: 100.0000 (98.2830)  Loss: 0.1575 (0.2099)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8812)  Acc@5: 100.0000 (98.2673)  Loss: 0.1877 (0.2141)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1059)  Acc@5: 100.0000 (98.3108)  Loss: 0.1590 (0.2060)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1901)  Acc@5: 100.0000 (98.3988)  Loss: 0.0767 (0.2019)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7844)  Acc@5: 100.0000 (98.4256)  Loss: 0.1569 (0.2102)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4805)  Acc@5: 100.0000 (98.3599)  Loss: 0.3168 (0.2153)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.3444)  Loss: 0.1465 (0.2069)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7624)  Acc@5: 100.0000 (98.3307)  Loss: 0.0906 (0.2040)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6594)  Acc@5: 100.0000 (98.3918)  Loss: 0.1291 (0.2055)  time: 0.1599  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4986)  Acc@5: 100.0000 (98.3771)  Loss: 0.2216 (0.2095)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5838)  Acc@5: 100.0000 (98.3312)  Loss: 0.2342 (0.2109)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6604)  Acc@5: 100.0000 (98.3209)  Loss: 0.1518 (0.2097)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6706)  Acc@5: 100.0000 (98.4005)  Loss: 0.1168 (0.2084)  time: 0.1596  data: 0.0002  max mem: 2375
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5667)  Acc@5: 100.0000 (98.3597)  Loss: 0.1304 (0.2083)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5260)  Acc@5: 100.0000 (98.3496)  Loss: 0.2766 (0.2094)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6183)  Acc@5: 100.0000 (98.4180)  Loss: 0.1779 (0.2083)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4542)  Acc@5: 100.0000 (98.4313)  Loss: 0.1755 (0.2115)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.3027)  Acc@5: 100.0000 (98.4195)  Loss: 0.2220 (0.2140)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3699)  Acc@5: 100.0000 (98.4317)  Loss: 0.2187 (0.2125)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2544)  Acc@5: 100.0000 (98.4653)  Loss: 0.1817 (0.2138)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1469)  Acc@5: 100.0000 (98.3892)  Loss: 0.2616 (0.2204)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0465)  Acc@5: 100.0000 (98.4219)  Loss: 0.2693 (0.2201)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0932)  Acc@5: 100.0000 (98.4325)  Loss: 0.2088 (0.2188)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)  time: 0.1557  data: 0.0003  max mem: 2375
Train: Epoch[3/5] Total time: 0:00:50 (0.1603 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)
1 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:50  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.4328 (0.4328)  time: 0.3536  data: 0.1947  max mem: 2375
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.7273)  Loss: 0.1321 (0.2000)  time: 0.1771  data: 0.0179  max mem: 2375
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  Loss: 0.1321 (0.1772)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1048)  Acc@5: 100.0000 (98.1855)  Loss: 0.1484 (0.1731)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.8049)  Acc@5: 100.0000 (98.4756)  Loss: 0.1517 (0.1607)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7745)  Loss: 0.1400 (0.1577)  time: 0.1595  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.6680)  Loss: 0.1704 (0.1715)  time: 0.1595  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9718)  Acc@5: 100.0000 (98.5035)  Loss: 0.1768 (0.1810)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.4568)  Loss: 0.1170 (0.1728)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6374)  Acc@5: 100.0000 (98.6264)  Loss: 0.1569 (0.1754)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6856)  Acc@5: 100.0000 (98.6386)  Loss: 0.1775 (0.1708)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4437)  Acc@5: 100.0000 (98.5360)  Loss: 0.1220 (0.1752)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2417)  Acc@5: 100.0000 (98.5537)  Loss: 0.1624 (0.1819)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3569)  Acc@5: 100.0000 (98.5687)  Loss: 0.1624 (0.1801)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.6259)  Loss: 0.2126 (0.1848)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1275)  Acc@5: 100.0000 (98.5099)  Loss: 0.2187 (0.1869)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9953)  Acc@5: 100.0000 (98.6025)  Loss: 0.2187 (0.1873)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.5746)  Loss: 0.1593 (0.1884)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0166)  Acc@5: 100.0000 (98.5843)  Loss: 0.1122 (0.1871)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0419)  Acc@5: 100.0000 (98.6257)  Loss: 0.0737 (0.1856)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.5386)  Loss: 0.1639 (0.1891)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7595)  Acc@5: 100.0000 (98.5486)  Loss: 0.2365 (0.1906)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9344)  Acc@5: 100.0000 (98.5860)  Loss: 0.1304 (0.1867)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8236)  Acc@5: 100.0000 (98.4848)  Loss: 0.1355 (0.1911)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6701)  Acc@5: 100.0000 (98.4959)  Loss: 0.1965 (0.1945)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6534)  Acc@5: 100.0000 (98.5060)  Loss: 0.1551 (0.1956)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.4914)  Loss: 0.1251 (0.1920)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6928)  Acc@5: 100.0000 (98.4317)  Loss: 0.0749 (0.1913)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7438)  Acc@5: 100.0000 (98.3763)  Loss: 0.1671 (0.1919)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7483)  Acc@5: 100.0000 (98.3247)  Loss: 0.1933 (0.1917)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7940)  Acc@5: 100.0000 (98.3181)  Loss: 0.1931 (0.1938)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6961)  Acc@5: 100.0000 (98.3320)  Loss: 0.2107 (0.1947)  time: 0.1599  data: 0.0003  max mem: 2375
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)  time: 0.1561  data: 0.0003  max mem: 2375
Train: Epoch[4/5] Total time: 0:00:50 (0.1602 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)
1 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:55  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1216 (0.1216)  time: 0.3699  data: 0.2033  max mem: 2375
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  Loss: 0.1216 (0.1545)  time: 0.1798  data: 0.0189  max mem: 2375
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.9167)  Loss: 0.2094 (0.2044)  time: 0.1603  data: 0.0004  max mem: 2375
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (98.1855)  Loss: 0.2597 (0.1879)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.4756)  Loss: 0.1875 (0.1984)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2941)  Acc@5: 100.0000 (98.1618)  Loss: 0.2440 (0.2058)  time: 0.1598  data: 0.0004  max mem: 2375
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.2582)  Loss: 0.1058 (0.1817)  time: 0.1598  data: 0.0004  max mem: 2375
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0915)  Acc@5: 100.0000 (98.1514)  Loss: 0.1057 (0.1895)  time: 0.1600  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6512)  Acc@5: 100.0000 (98.3025)  Loss: 0.0564 (0.1726)  time: 0.1601  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.2830)  Loss: 0.0814 (0.1805)  time: 0.1601  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3243)  Acc@5: 100.0000 (98.3911)  Loss: 0.2103 (0.1815)  time: 0.1599  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2613)  Acc@5: 100.0000 (98.4797)  Loss: 0.1329 (0.1796)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1570)  Acc@5: 100.0000 (98.2955)  Loss: 0.1806 (0.1853)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0687)  Acc@5: 100.0000 (98.2824)  Loss: 0.2078 (0.1867)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2145)  Acc@5: 100.0000 (98.2713)  Loss: 0.2207 (0.1884)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2583)  Acc@5: 100.0000 (98.3030)  Loss: 0.2118 (0.1879)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2189)  Acc@5: 100.0000 (98.1755)  Loss: 0.2118 (0.1911)  time: 0.1599  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [170/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9284)  Acc@5: 100.0000 (98.2091)  Loss: 0.2256 (0.1952)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0843)  Acc@5: 100.0000 (98.2390)  Loss: 0.1703 (0.1915)  time: 0.1598  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0275)  Acc@5: 100.0000 (98.1675)  Loss: 0.1533 (0.1914)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2251)  Acc@5: 100.0000 (98.2276)  Loss: 0.1273 (0.1861)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5225)  Acc@5: 100.0000 (98.2820)  Loss: 0.0470 (0.1798)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5385)  Acc@5: 100.0000 (98.2466)  Loss: 0.0528 (0.1818)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4989)  Acc@5: 100.0000 (98.1602)  Loss: 0.1128 (0.1838)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.1846)  Loss: 0.1082 (0.1820)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5538)  Acc@5: 100.0000 (98.1574)  Loss: 0.1564 (0.1862)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6858)  Acc@5: 100.0000 (98.2280)  Loss: 0.1103 (0.1825)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6467)  Acc@5: 100.0000 (98.2242)  Loss: 0.0471 (0.1826)  time: 0.1597  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7883)  Acc@5: 100.0000 (98.2651)  Loss: 0.1327 (0.1813)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.2388)  Loss: 0.1993 (0.1812)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8563)  Acc@5: 100.0000 (98.2558)  Loss: 0.1798 (0.1779)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8569)  Acc@5: 100.0000 (98.2717)  Loss: 0.1237 (0.1780)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)  time: 0.1558  data: 0.0002  max mem: 2375
Train: Epoch[5/5] Total time: 0:00:50 (0.1604 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)
Test: [Task 1]  [ 0/63]  eta: 0:00:20  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4822 (0.4822)  time: 0.3236  data: 0.2253  max mem: 2375
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.4626)  time: 0.1198  data: 0.0208  max mem: 2375
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.5112)  time: 0.0995  data: 0.0003  max mem: 2375
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (92.5403)  Acc@5: 100.0000 (100.0000)  Loss: 0.3944 (0.4803)  time: 0.0995  data: 0.0003  max mem: 2375
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (100.0000)  Loss: 0.3889 (0.4783)  time: 0.0994  data: 0.0003  max mem: 2375
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (100.0000)  Loss: 0.4046 (0.4563)  time: 0.0994  data: 0.0003  max mem: 2375
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (94.0574)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4489)  time: 0.0993  data: 0.0003  max mem: 2375
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (94.2000)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4479)  time: 0.0970  data: 0.0003  max mem: 2375
Test: [Task 1] Total time: 0:00:06 (0.1033 s / it)
* Acc@1 94.200 Acc@5 100.000 loss 0.448
Test: [Task 1]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  p_index: 3.0000 (3.0000)  Loss: 1.3748 (1.3748)  time: 0.3237  data: 0.1935  max mem: 2375
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.8182)  Loss: 0.8011 (0.9600)  time: 0.1327  data: 0.0179  max mem: 2375
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7143)  Loss: 0.7302 (0.9678)  time: 0.1136  data: 0.0003  max mem: 2375
Test: [Task 1]  [30/63]  eta: 0:00:03  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.7097)  Loss: 0.7263 (0.9432)  time: 0.1144  data: 0.0003  max mem: 2375
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.6341)  Loss: 0.7944 (0.9167)  time: 0.1135  data: 0.0003  max mem: 2375
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6275)  Loss: 0.8317 (0.8986)  time: 0.1127  data: 0.0003  max mem: 2375
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5738)  Loss: 0.8317 (0.8748)  time: 0.1129  data: 0.0003  max mem: 2375
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.5397)  Loss: 0.8317 (0.8693)  time: 0.1090  data: 0.0003  max mem: 2375
Test: [Task 1] Total time: 0:00:07 (0.1167 s / it)
* ASR 0.000 
Test: [Task 2]  [ 0/63]  eta: 0:00:17  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5181 (0.5181)  time: 0.2848  data: 0.1856  max mem: 2375
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  Loss: 0.4899 (0.5298)  time: 0.1163  data: 0.0172  max mem: 2375
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.7024)  Loss: 0.5569 (0.6075)  time: 0.0994  data: 0.0003  max mem: 2375
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (94.7581)  Acc@5: 100.0000 (98.9919)  Loss: 0.6074 (0.6052)  time: 0.0994  data: 0.0003  max mem: 2375
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (94.3598)  Acc@5: 100.0000 (98.9329)  Loss: 0.5342 (0.5841)  time: 0.0994  data: 0.0003  max mem: 2375
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (98.8971)  Loss: 0.5183 (0.5826)  time: 0.0994  data: 0.0003  max mem: 2375
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (94.3648)  Acc@5: 100.0000 (99.0779)  Loss: 0.4840 (0.5593)  time: 0.0994  data: 0.0003  max mem: 2375
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.1000)  Loss: 0.4790 (0.5517)  time: 0.0971  data: 0.0003  max mem: 2375
Test: [Task 2] Total time: 0:00:06 (0.1027 s / it)
* Acc@1 94.500 Acc@5 99.100 loss 0.552
Test: [Task 2]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 1.1199 (1.1199)  time: 0.3056  data: 0.1713  max mem: 2375
Test: [Task 2]  [10/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4545)  Loss: 0.7590 (0.8849)  time: 0.1309  data: 0.0159  max mem: 2375
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.4762)  Loss: 0.9014 (0.9361)  time: 0.1134  data: 0.0005  max mem: 2375
Test: [Task 2]  [30/63]  eta: 0:00:03  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5161)  Loss: 0.9699 (0.9312)  time: 0.1140  data: 0.0005  max mem: 2375
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5122)  Loss: 0.9225 (0.9327)  time: 0.1148  data: 0.0003  max mem: 2375
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.5882)  Loss: 0.9993 (0.9536)  time: 0.1152  data: 0.0003  max mem: 2375
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6230)  Loss: 0.9121 (0.9525)  time: 0.1158  data: 0.0003  max mem: 2375
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6032)  Loss: 0.8898 (0.9416)  time: 0.1144  data: 0.0003  max mem: 2375
Test: [Task 2] Total time: 0:00:07 (0.1180 s / it)
* ASR 0.000 
[Average accuracy till task2]	ASR: 0.0000	ACC: 94.3500	Loss: 0.9055	Forgetting: 0.0000	Backward: 0.0000
2 2
Train: Epoch[1/5]  [  0/313]  eta: 0:01:47  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  Loss: 2.1259 (2.1259)  time: 0.3432  data: 0.1847  max mem: 2375
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 56.2500 (48.8636)  Acc@5: 87.5000 (80.6818)  Loss: 1.9327 (1.9322)  time: 0.1757  data: 0.0170  max mem: 2375
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (87.7976)  Loss: 1.7528 (1.7779)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7419)  Acc@5: 100.0000 (90.5242)  Loss: 1.4664 (1.6438)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.1890)  Acc@5: 100.0000 (91.7683)  Loss: 1.2569 (1.5223)  time: 0.1589  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.8971)  Acc@5: 100.0000 (92.5245)  Loss: 1.0197 (1.4171)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.3074)  Acc@5: 100.0000 (93.2377)  Loss: 0.9046 (1.3266)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.0563)  Acc@5: 93.7500 (93.6620)  Loss: 0.8592 (1.2529)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8519)  Acc@5: 100.0000 (93.9043)  Loss: 0.6655 (1.1759)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.7473)  Acc@5: 93.7500 (94.1621)  Loss: 0.5769 (1.1137)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6510)  Acc@5: 93.7500 (94.3688)  Loss: 0.5593 (1.0554)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.2230)  Acc@5: 93.7500 (94.5946)  Loss: 0.5113 (1.0125)  time: 0.1592  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.2872)  Acc@5: 100.0000 (94.6798)  Loss: 0.5113 (0.9766)  time: 0.1593  data: 0.0002  max mem: 2375
Train: Epoch[1/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.3893)  Acc@5: 100.0000 (94.9427)  Loss: 0.5161 (0.9428)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.6543)  Acc@5: 100.0000 (95.2128)  Loss: 0.4068 (0.9073)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.8013)  Acc@5: 100.0000 (95.3642)  Loss: 0.3873 (0.8760)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.1242)  Acc@5: 100.0000 (95.4969)  Loss: 0.3963 (0.8448)  time: 0.1596  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.3363)  Acc@5: 100.0000 (95.5775)  Loss: 0.3963 (0.8184)  time: 0.1595  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.6630)  Acc@5: 100.0000 (95.7873)  Loss: 0.3650 (0.7932)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.9882)  Acc@5: 100.0000 (95.8770)  Loss: 0.3364 (0.7703)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9391)  Acc@5: 100.0000 (95.9577)  Loss: 0.3827 (0.7542)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9834)  Acc@5: 100.0000 (95.9716)  Loss: 0.4242 (0.7381)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2217)  Acc@5: 93.7500 (95.9559)  Loss: 0.2844 (0.7200)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.1039)  Loss: 0.3615 (0.7079)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.5612)  Acc@5: 100.0000 (96.1618)  Loss: 0.3468 (0.6907)  time: 0.1592  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.7231)  Acc@5: 100.0000 (96.2400)  Loss: 0.3363 (0.6771)  time: 0.1590  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9444)  Acc@5: 100.0000 (96.3362)  Loss: 0.2425 (0.6616)  time: 0.1591  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9188)  Acc@5: 100.0000 (96.4253)  Loss: 0.3351 (0.6533)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1619)  Acc@5: 100.0000 (96.4413)  Loss: 0.3351 (0.6412)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1521)  Acc@5: 100.0000 (96.4347)  Loss: 0.2624 (0.6313)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.1844)  Acc@5: 100.0000 (96.4286)  Loss: 0.3063 (0.6233)  time: 0.1594  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3352)  Acc@5: 100.0000 (96.5233)  Loss: 0.2832 (0.6131)  time: 0.1593  data: 0.0003  max mem: 2375
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)  time: 0.1555  data: 0.0003  max mem: 2375
Train: Epoch[1/5] Total time: 0:00:50 (0.1599 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)
Train: Epoch[1/5]  [  0/313]  eta: 0:03:10  Lr: 0.001875  Loss: 2.3687  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.0000)  time: 0.6078  data: 0.1748  max mem: 2444
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:05  Lr: 0.001875  Loss: 1.4883  ASR: 0.0000 (0.1176)  p_index: 1.0000 (1.5455)  time: 0.2171  data: 0.0163  max mem: 2652
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:56  Lr: 0.001875  Loss: 1.1866  ASR: 0.0000 (0.1250)  p_index: 1.0000 (1.1429)  time: 0.1723  data: 0.0004  max mem: 2652
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:53  Lr: 0.001875  Loss: 0.6662  ASR: 0.0000 (0.0769)  p_index: 1.0000 (1.2581)  time: 0.1750  data: 0.0004  max mem: 2746
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.7130  ASR: 0.0000 (0.0962)  p_index: 1.0000 (1.2683)  time: 0.1821  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.9667  ASR: 0.0000 (0.0857)  p_index: 1.0000 (1.3725)  time: 0.1822  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:46  Lr: 0.001875  Loss: 0.5881  ASR: 0.0000 (0.0690)  p_index: 2.0000 (1.4262)  time: 0.1814  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.7144  ASR: 0.0000 (0.0707)  p_index: 1.0000 (1.3944)  time: 0.1763  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:42  Lr: 0.001875  Loss: 0.6062  ASR: 0.0000 (0.0631)  p_index: 1.0000 (1.3704)  time: 0.1746  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:40  Lr: 0.001875  Loss: 0.6795  ASR: 0.0000 (0.0787)  p_index: 1.0000 (1.3956)  time: 0.1769  data: 0.0003  max mem: 2746
Train: Epoch[1/5]  [100/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5621  ASR: 0.0000 (0.0780)  p_index: 1.0000 (1.3960)  time: 0.1769  data: 0.0003  max mem: 2747
Train: Epoch[1/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.8153  ASR: 0.0000 (0.0962)  p_index: 1.0000 (1.4054)  time: 0.1767  data: 0.0003  max mem: 2747
Train: Epoch[1/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.7771  ASR: 0.0000 (0.0971)  p_index: 2.0000 (1.4463)  time: 0.1773  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [130/313]  eta: 0:00:33  Lr: 0.001875  Loss: 0.3859  ASR: 0.0000 (0.1005)  p_index: 2.0000 (1.4427)  time: 0.1755  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [140/313]  eta: 0:00:31  Lr: 0.001875  Loss: 0.7083  ASR: 0.0000 (0.0962)  p_index: 2.0000 (1.4752)  time: 0.1760  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [150/313]  eta: 0:00:29  Lr: 0.001875  Loss: 0.6457  ASR: 0.0000 (0.1009)  p_index: 2.0000 (1.5099)  time: 0.1768  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [160/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.8522  ASR: 0.0000 (0.1079)  p_index: 1.0000 (1.4969)  time: 0.1732  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.6928  ASR: 0.0000 (0.1055)  p_index: 1.0000 (1.4971)  time: 0.1715  data: 0.0003  max mem: 2750
Train: Epoch[1/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.6715  ASR: 0.0000 (0.1123)  p_index: 1.0000 (1.5249)  time: 0.1739  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.7514  ASR: 0.0000 (0.1126)  p_index: 2.0000 (1.5340)  time: 0.1746  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [200/313]  eta: 0:00:20  Lr: 0.001875  Loss: 0.7751  ASR: 0.0000 (0.1136)  p_index: 1.0000 (1.5323)  time: 0.1742  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.5264  ASR: 0.0000 (0.1142)  p_index: 1.0000 (1.5355)  time: 0.1735  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.5965  ASR: 0.0000 (0.1101)  p_index: 2.0000 (1.5611)  time: 0.1749  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.8340  ASR: 0.0000 (0.1080)  p_index: 1.0000 (1.5238)  time: 0.1719  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.7875  ASR: 0.0000 (0.1061)  p_index: 1.0000 (1.5643)  time: 0.1726  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5727  ASR: 0.0000 (0.1114)  p_index: 2.0000 (1.5737)  time: 0.1759  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4679  ASR: 0.0000 (0.1171)  p_index: 2.0000 (1.5709)  time: 0.1727  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3769  ASR: 0.0000 (0.1160)  p_index: 2.0000 (1.5904)  time: 0.1741  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.4202  ASR: 0.0000 (0.1131)  p_index: 2.0000 (1.5730)  time: 0.1728  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.3085  ASR: 0.0000 (0.1118)  p_index: 1.0000 (1.5670)  time: 0.1706  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.6481  ASR: 0.0000 (0.1083)  p_index: 1.0000 (1.5648)  time: 0.1716  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7432  ASR: 0.0000 (0.1056)  p_index: 1.0000 (1.5531)  time: 0.1705  data: 0.0003  max mem: 2945
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7499  ASR: 0.0000 (0.1072)  p_index: 1.0000 (1.5495)  time: 0.1709  data: 0.0002  max mem: 2945
Train: Epoch[1/5] Total time: 0:00:55 (0.1765 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.7499  ASR: 0.0000 (0.1072)  p_index: 1.0000 (1.5495)
poisoned
2 2
Train: Epoch[2/5]  [  0/313]  eta: 0:02:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 93.7500 (93.7500)  Loss: 0.4434 (0.4434)  time: 0.4200  data: 0.2586  max mem: 2945
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  Loss: 0.2050 (0.2390)  time: 0.1829  data: 0.0237  max mem: 2945
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  Loss: 0.1931 (0.2445)  time: 0.1593  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9032)  Acc@5: 100.0000 (98.7903)  Loss: 0.0905 (0.1905)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.3476)  Acc@5: 100.0000 (98.9329)  Loss: 0.0671 (0.2054)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2549)  Acc@5: 100.0000 (98.6520)  Loss: 0.1897 (0.2120)  time: 0.1593  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.9631)  Acc@5: 100.0000 (98.2582)  Loss: 0.2243 (0.2389)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3556)  Acc@5: 100.0000 (98.2394)  Loss: 0.2159 (0.2221)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1111)  Acc@5: 100.0000 (98.2253)  Loss: 0.1452 (0.2322)  time: 0.1593  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.2143)  Loss: 0.1914 (0.2245)  time: 0.1592  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6955)  Acc@5: 100.0000 (98.3292)  Loss: 0.1540 (0.2209)  time: 0.1592  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8806)  Acc@5: 100.0000 (98.3671)  Loss: 0.1149 (0.2130)  time: 0.1593  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8802)  Acc@5: 100.0000 (98.2438)  Loss: 0.1445 (0.2151)  time: 0.1595  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7844)  Acc@5: 100.0000 (98.2824)  Loss: 0.2012 (0.2153)  time: 0.1596  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9238)  Acc@5: 100.0000 (98.4043)  Loss: 0.1437 (0.2101)  time: 0.1594  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1689)  Acc@5: 100.0000 (98.4272)  Loss: 0.1141 (0.2039)  time: 0.1594  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8401)  Acc@5: 100.0000 (98.4084)  Loss: 0.1390 (0.2074)  time: 0.1595  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [170/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6959)  Acc@5: 100.0000 (98.3918)  Loss: 0.2217 (0.2079)  time: 0.1594  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8439)  Acc@5: 100.0000 (98.3771)  Loss: 0.1423 (0.2037)  time: 0.1593  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9110)  Acc@5: 100.0000 (98.4620)  Loss: 0.0578 (0.2000)  time: 0.1593  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.1269)  Acc@5: 100.0000 (98.4453)  Loss: 0.0132 (0.1946)  time: 0.1595  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.3519)  Acc@5: 100.0000 (98.4893)  Loss: 0.0276 (0.1885)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4152)  Acc@5: 100.0000 (98.5294)  Loss: 0.0618 (0.1860)  time: 0.1596  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3377)  Acc@5: 100.0000 (98.5119)  Loss: 0.1392 (0.1893)  time: 0.1594  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4481)  Acc@5: 100.0000 (98.5218)  Loss: 0.1392 (0.1850)  time: 0.1595  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5249)  Acc@5: 100.0000 (98.5558)  Loss: 0.0314 (0.1817)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5632)  Loss: 0.1055 (0.1814)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5231)  Acc@5: 100.0000 (98.5240)  Loss: 0.1240 (0.1822)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5890)  Acc@5: 100.0000 (98.5098)  Loss: 0.1421 (0.1808)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5215)  Acc@5: 100.0000 (98.5180)  Loss: 0.1530 (0.1816)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4169)  Acc@5: 100.0000 (98.5673)  Loss: 0.2097 (0.1831)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4799)  Acc@5: 100.0000 (98.5531)  Loss: 0.1981 (0.1830)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (87.4201)  Acc@5: 100.0000 (98.5623)  Loss: 0.1981 (0.1847)  time: 0.1560  data: 0.0003  max mem: 2945
Train: Epoch[2/5] Total time: 0:00:50 (0.1604 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (87.4201)  Acc@5: 100.0000 (98.5623)  Loss: 0.1981 (0.1847)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:02  Lr: 0.001875  Loss: 0.7140  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.0000)  time: 0.3902  data: 0.1939  max mem: 2945
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.3904  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.6364)  time: 0.1998  data: 0.0179  max mem: 2945
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.4572  ASR: 0.0000 (0.0714)  p_index: 1.0000 (1.3333)  time: 0.1763  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.7884  ASR: 0.0000 (0.1064)  p_index: 1.0000 (1.5161)  time: 0.1746  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2298  ASR: 0.0000 (0.1639)  p_index: 1.0000 (1.4878)  time: 0.1759  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:46  Lr: 0.001875  Loss: 1.0900  ASR: 0.0000 (0.1449)  p_index: 1.0000 (1.3529)  time: 0.1710  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:44  Lr: 0.001875  Loss: 0.4565  ASR: 0.0000 (0.1205)  p_index: 1.0000 (1.3607)  time: 0.1699  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.5197  ASR: 0.0000 (0.1010)  p_index: 1.0000 (1.3944)  time: 0.1733  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.9538  ASR: 0.0000 (0.1102)  p_index: 1.0000 (1.4568)  time: 0.1741  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.3589  ASR: 0.0000 (0.1250)  p_index: 1.0000 (1.4066)  time: 0.1723  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [100/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.2829  ASR: 0.0000 (0.1250)  p_index: 1.0000 (1.4257)  time: 0.1715  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [110/313]  eta: 0:00:35  Lr: 0.001875  Loss: 0.5796  ASR: 0.0000 (0.1218)  p_index: 1.0000 (1.4054)  time: 0.1718  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [120/313]  eta: 0:00:33  Lr: 0.001875  Loss: 0.5505  ASR: 0.0000 (0.1279)  p_index: 1.0000 (1.4215)  time: 0.1727  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.0528  ASR: 0.0000 (0.1223)  p_index: 1.0000 (1.4351)  time: 0.1737  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.5941  ASR: 0.0000 (0.1194)  p_index: 1.0000 (1.4255)  time: 0.1723  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2859  ASR: 0.0000 (0.1131)  p_index: 1.0000 (1.4636)  time: 0.1741  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [160/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.5510  ASR: 0.0000 (0.1097)  p_index: 1.0000 (1.4720)  time: 0.1745  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [170/313]  eta: 0:00:24  Lr: 0.001875  Loss: 0.4592  ASR: 0.0000 (0.1016)  p_index: 1.0000 (1.4971)  time: 0.1738  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.3662  ASR: 0.0000 (0.0970)  p_index: 2.0000 (1.4807)  time: 0.1725  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.5456  ASR: 0.0000 (0.1021)  p_index: 1.0000 (1.4869)  time: 0.1713  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [200/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.6126  ASR: 0.0000 (0.0960)  p_index: 2.0000 (1.5025)  time: 0.1739  data: 0.0002  max mem: 2945
Train: Epoch[2/5]  [210/313]  eta: 0:00:17  Lr: 0.001875  Loss: 0.9838  ASR: 0.0000 (0.0966)  p_index: 2.0000 (1.5213)  time: 0.1746  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.7351  ASR: 0.0000 (0.0931)  p_index: 1.0000 (1.5068)  time: 0.1729  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.4842  ASR: 0.0000 (0.0914)  p_index: 1.0000 (1.5152)  time: 0.1725  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.4510  ASR: 0.0000 (0.0924)  p_index: 1.0000 (1.5270)  time: 0.1743  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.001875  Loss: 0.8460  ASR: 0.0000 (0.0995)  p_index: 2.0000 (1.5618)  time: 0.1770  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.2813  ASR: 0.0000 (0.0988)  p_index: 1.0000 (1.5517)  time: 0.1758  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.6649  ASR: 0.0000 (0.0962)  p_index: 1.0000 (1.5720)  time: 0.1742  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.9846  ASR: 0.0000 (0.0975)  p_index: 2.0000 (1.5694)  time: 0.1740  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.8345  ASR: 0.0000 (0.0967)  p_index: 1.0000 (1.5636)  time: 0.1719  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.3341  ASR: 0.0000 (0.0987)  p_index: 1.0000 (1.5482)  time: 0.1710  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7448  ASR: 0.0000 (0.0998)  p_index: 1.0000 (1.5466)  time: 0.1715  data: 0.0003  max mem: 2945
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.1426  ASR: 0.0000 (0.0988)  p_index: 1.0000 (1.5527)  time: 0.1693  data: 0.0002  max mem: 2945
Train: Epoch[2/5] Total time: 0:00:54 (0.1742 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.1426  ASR: 0.0000 (0.0988)  p_index: 1.0000 (1.5527)
poisoned
2 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:43  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4266 (0.4266)  time: 0.3298  data: 0.1657  max mem: 2945
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (99.4318)  Loss: 0.0421 (0.1870)  time: 0.1754  data: 0.0153  max mem: 2945
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.9881)  Acc@5: 100.0000 (99.1071)  Loss: 0.0072 (0.1628)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.3226)  Acc@5: 100.0000 (98.9919)  Loss: 0.0348 (0.1301)  time: 0.1597  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3293)  Acc@5: 100.0000 (98.9329)  Loss: 0.1158 (0.1484)  time: 0.1598  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3382)  Acc@5: 100.0000 (99.0196)  Loss: 0.0940 (0.1390)  time: 0.1599  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2418)  Acc@5: 100.0000 (99.0779)  Loss: 0.0830 (0.1366)  time: 0.1601  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.4683)  Acc@5: 100.0000 (99.0317)  Loss: 0.1360 (0.1561)  time: 0.1601  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.9660)  Acc@5: 100.0000 (99.1512)  Loss: 0.1125 (0.1398)  time: 0.1599  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.6676)  Acc@5: 100.0000 (99.2445)  Loss: 0.0243 (0.1462)  time: 0.1598  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.4282)  Acc@5: 100.0000 (99.0718)  Loss: 0.1563 (0.1508)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.5135)  Acc@5: 100.0000 (99.0428)  Loss: 0.1563 (0.1495)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1715)  Acc@5: 100.0000 (98.9669)  Loss: 0.1201 (0.1563)  time: 0.1601  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.4542)  Acc@5: 100.0000 (98.9981)  Loss: 0.0713 (0.1514)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.0319)  Acc@5: 100.0000 (98.7589)  Loss: 0.1449 (0.1635)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0795)  Acc@5: 100.0000 (98.7583)  Loss: 0.1453 (0.1628)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (87.7717)  Acc@5: 100.0000 (98.6413)  Loss: 0.1476 (0.1695)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [170/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (87.8289)  Acc@5: 100.0000 (98.6111)  Loss: 0.1730 (0.1687)  time: 0.1596  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9489)  Acc@5: 100.0000 (98.5843)  Loss: 0.1023 (0.1641)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0563)  Acc@5: 100.0000 (98.5929)  Loss: 0.0645 (0.1617)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9975)  Acc@5: 100.0000 (98.6318)  Loss: 0.0965 (0.1597)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9147)  Acc@5: 100.0000 (98.6374)  Loss: 0.1056 (0.1587)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8111)  Acc@5: 100.0000 (98.5577)  Loss: 0.1593 (0.1615)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8788)  Acc@5: 100.0000 (98.6201)  Loss: 0.1334 (0.1595)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8890)  Acc@5: 100.0000 (98.6255)  Loss: 0.1334 (0.1592)  time: 0.1595  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0229)  Acc@5: 100.0000 (98.6803)  Loss: 0.1388 (0.1562)  time: 0.1594  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0029)  Acc@5: 100.0000 (98.6590)  Loss: 0.0677 (0.1549)  time: 0.1594  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0996)  Acc@5: 100.0000 (98.6854)  Loss: 0.0054 (0.1514)  time: 0.1594  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1005)  Acc@5: 100.0000 (98.6432)  Loss: 0.0242 (0.1513)  time: 0.1595  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1229)  Acc@5: 100.0000 (98.6469)  Loss: 0.1189 (0.1502)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.2890)  Acc@5: 100.0000 (98.6088)  Loss: 0.0878 (0.1480)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.3240)  Acc@5: 100.0000 (98.6133)  Loss: 0.0518 (0.1471)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.2987)  Acc@5: 100.0000 (98.6022)  Loss: 0.0714 (0.1471)  time: 0.1560  data: 0.0003  max mem: 2945
Train: Epoch[3/5] Total time: 0:00:50 (0.1604 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.2987)  Acc@5: 100.0000 (98.6022)  Loss: 0.0714 (0.1471)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:05  Lr: 0.001875  Loss: 1.0210  ASR: 0.0000 (0.0000)  p_index: 5.0000 (5.0000)  time: 0.4002  data: 0.1961  max mem: 2945
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:00  Lr: 0.001875  Loss: 0.0784  ASR: 0.0000 (0.0385)  p_index: 2.0000 (2.3636)  time: 0.1995  data: 0.0181  max mem: 2945
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:55  Lr: 0.001875  Loss: 0.6742  ASR: 0.0000 (0.0465)  p_index: 2.0000 (2.0476)  time: 0.1779  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.4257  ASR: 0.0000 (0.0536)  p_index: 1.0000 (1.8065)  time: 0.1750  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.2747  ASR: 0.0000 (0.0870)  p_index: 1.0000 (1.6829)  time: 0.1741  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.7594  ASR: 0.0000 (0.0805)  p_index: 1.0000 (1.7059)  time: 0.1762  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.6315  ASR: 0.0000 (0.0762)  p_index: 2.0000 (1.7213)  time: 0.1796  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.3326  ASR: 0.0000 (0.0984)  p_index: 1.0000 (1.7183)  time: 0.1785  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.3387  ASR: 0.0000 (0.1045)  p_index: 1.0000 (1.6543)  time: 0.1749  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.3680  ASR: 0.0000 (0.0987)  p_index: 1.0000 (1.6703)  time: 0.1755  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [100/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.1849  ASR: 0.0000 (0.0988)  p_index: 2.0000 (1.7030)  time: 0.1770  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.4327  ASR: 0.0000 (0.0924)  p_index: 1.0000 (1.6577)  time: 0.1742  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.9957  ASR: 0.0000 (0.0863)  p_index: 1.0000 (1.6281)  time: 0.1711  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.6258  ASR: 0.0000 (0.0870)  p_index: 1.0000 (1.5802)  time: 0.1704  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.9386  ASR: 0.0000 (0.0933)  p_index: 1.0000 (1.5957)  time: 0.1727  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.0827  ASR: 0.0000 (0.0917)  p_index: 1.0000 (1.5894)  time: 0.1737  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [160/313]  eta: 0:00:26  Lr: 0.001875  Loss: 0.1369  ASR: 0.0000 (0.0952)  p_index: 1.0000 (1.5652)  time: 0.1710  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.7511  ASR: 0.0000 (0.0906)  p_index: 1.0000 (1.5497)  time: 0.1721  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.2417  ASR: 0.0000 (0.0964)  p_index: 1.0000 (1.5470)  time: 0.1739  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.4886  ASR: 0.0000 (0.0983)  p_index: 1.0000 (1.5445)  time: 0.1735  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [200/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.7887  ASR: 0.0000 (0.1097)  p_index: 2.0000 (1.5871)  time: 0.1762  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.2470  ASR: 0.0000 (0.1124)  p_index: 2.0000 (1.6019)  time: 0.1802  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.5230  ASR: 0.0000 (0.1086)  p_index: 1.0000 (1.5837)  time: 0.1786  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.2597  ASR: 0.0000 (0.1117)  p_index: 1.0000 (1.5887)  time: 0.1770  data: 0.0002  max mem: 2945
Train: Epoch[3/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.6277  ASR: 0.0000 (0.1088)  p_index: 2.0000 (1.6017)  time: 0.1765  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5990  ASR: 0.0000 (0.1034)  p_index: 2.0000 (1.6175)  time: 0.1764  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.6808  ASR: 0.0000 (0.1038)  p_index: 1.0000 (1.6245)  time: 0.1767  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.2846  ASR: 0.0000 (0.1039)  p_index: 1.0000 (1.5978)  time: 0.1720  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.7411  ASR: 0.0000 (0.1018)  p_index: 1.0000 (1.6085)  time: 0.1724  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.7938  ASR: 0.0000 (0.1000)  p_index: 2.0000 (1.6151)  time: 0.1749  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.9849  ASR: 0.0000 (0.1010)  p_index: 1.0000 (1.6113)  time: 0.1746  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.4828  ASR: 0.0000 (0.0980)  p_index: 1.0000 (1.6077)  time: 0.1742  data: 0.0003  max mem: 2945
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2621  ASR: 0.0000 (0.0980)  p_index: 1.0000 (1.5974)  time: 0.1683  data: 0.0002  max mem: 2945
Train: Epoch[3/5] Total time: 0:00:55 (0.1758 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2621  ASR: 0.0000 (0.0980)  p_index: 1.0000 (1.5974)
poisoned
2 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:56  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0147 (0.0147)  time: 0.3716  data: 0.2113  max mem: 2945
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (91.4773)  Acc@5: 100.0000 (99.4318)  Loss: -0.0110 (0.0358)  time: 0.1787  data: 0.0195  max mem: 2945
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2857)  Acc@5: 100.0000 (98.8095)  Loss: 0.0803 (0.1179)  time: 0.1596  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3065)  Acc@5: 100.0000 (98.5887)  Loss: 0.2017 (0.1404)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.7195)  Acc@5: 100.0000 (98.3232)  Loss: 0.1459 (0.1378)  time: 0.1596  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.9706)  Acc@5: 100.0000 (98.2843)  Loss: 0.1271 (0.1277)  time: 0.1596  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3443)  Acc@5: 100.0000 (98.5656)  Loss: 0.0494 (0.1130)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3486)  Acc@5: 100.0000 (98.5915)  Loss: 0.0494 (0.1115)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.5062)  Acc@5: 100.0000 (98.7654)  Loss: 0.0579 (0.1033)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.6978)  Acc@5: 100.0000 (98.8324)  Loss: 0.0579 (0.0984)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.6658)  Acc@5: 100.0000 (98.6386)  Loss: 0.0613 (0.0984)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4144)  Acc@5: 100.0000 (98.5923)  Loss: 0.1397 (0.1084)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4112)  Acc@5: 100.0000 (98.6570)  Loss: 0.1567 (0.1107)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4561)  Acc@5: 100.0000 (98.6641)  Loss: 0.0859 (0.1080)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.1401)  Acc@5: 100.0000 (98.7145)  Loss: 0.0667 (0.1138)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.1556)  Acc@5: 100.0000 (98.7997)  Loss: 0.0667 (0.1118)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2081)  Acc@5: 100.0000 (98.8742)  Loss: 0.0663 (0.1095)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [170/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4371)  Acc@5: 100.0000 (98.9035)  Loss: 0.0881 (0.1079)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.5373)  Acc@5: 100.0000 (98.8950)  Loss: -0.0208 (0.1070)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4306)  Acc@5: 100.0000 (98.8874)  Loss: 0.0533 (0.1107)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3035)  Acc@5: 100.0000 (98.8184)  Loss: 0.0986 (0.1156)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2773)  Acc@5: 100.0000 (98.8744)  Loss: 0.1130 (0.1152)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.2251)  Acc@5: 100.0000 (98.8688)  Loss: 0.1130 (0.1179)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.0693)  Acc@5: 100.0000 (98.8366)  Loss: 0.1588 (0.1220)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.1857)  Acc@5: 100.0000 (98.8330)  Loss: 0.1291 (0.1208)  time: 0.1598  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.3675)  Acc@5: 100.0000 (98.8546)  Loss: 0.0816 (0.1162)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3918)  Acc@5: 100.0000 (98.8985)  Loss: -0.0049 (0.1147)  time: 0.1600  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4834)  Acc@5: 100.0000 (98.9161)  Loss: 0.0622 (0.1135)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.4795)  Acc@5: 100.0000 (98.8657)  Loss: 0.0984 (0.1137)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4115)  Acc@5: 100.0000 (98.8832)  Loss: 0.1302 (0.1153)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3895)  Acc@5: 100.0000 (98.8995)  Loss: 0.0749 (0.1154)  time: 0.1599  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.4293)  Acc@5: 100.0000 (98.9148)  Loss: 0.1302 (0.1157)  time: 0.1597  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3970)  Acc@5: 100.0000 (98.9217)  Loss: 0.1321 (0.1171)  time: 0.1559  data: 0.0002  max mem: 2945
Train: Epoch[4/5] Total time: 0:00:50 (0.1606 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.3970)  Acc@5: 100.0000 (98.9217)  Loss: 0.1321 (0.1171)
Train: Epoch[4/5]  [  0/313]  eta: 0:01:59  Lr: 0.001875  Loss: 0.2848  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  time: 0.3822  data: 0.1857  max mem: 2945
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:59  Lr: 0.001875  Loss: 0.5911  ASR: 0.0000 (0.1176)  p_index: 2.0000 (1.5455)  time: 0.1959  data: 0.0171  max mem: 2945
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:54  Lr: 0.001875  Loss: 0.6147  ASR: 0.0000 (0.0741)  p_index: 1.0000 (1.2857)  time: 0.1755  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.1763  ASR: 0.0000 (0.0455)  p_index: 1.0000 (1.4194)  time: 0.1769  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.6369  ASR: 0.0000 (0.0500)  p_index: 1.0000 (1.4634)  time: 0.1782  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.6651  ASR: 0.0000 (0.0366)  p_index: 2.0000 (1.6078)  time: 0.1760  data: 0.0002  max mem: 2945
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.1055  ASR: 0.0000 (0.0588)  p_index: 2.0000 (1.6721)  time: 0.1760  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.5386  ASR: 0.0000 (0.0940)  p_index: 1.0000 (1.6479)  time: 0.1748  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5448  ASR: 0.0000 (0.0764)  p_index: 2.0000 (1.7778)  time: 0.1769  data: 0.0003  max mem: 2945
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.4502  ASR: 0.0000 (0.0745)  p_index: 2.0000 (1.7692)  time: 0.1801  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [100/313]  eta: 0:00:38  Lr: 0.001875  Loss: 0.5683  ASR: 0.0000 (0.0734)  p_index: 1.0000 (1.7525)  time: 0.1782  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.3597  ASR: 0.0000 (0.0842)  p_index: 1.0000 (1.7117)  time: 0.1753  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.5561  ASR: 0.0000 (0.0821)  p_index: 1.0000 (1.7107)  time: 0.1751  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.4007  ASR: 0.0000 (0.0868)  p_index: 1.0000 (1.6718)  time: 0.1735  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.3814  ASR: 0.0000 (0.0897)  p_index: 1.0000 (1.6596)  time: 0.1741  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.3627  ASR: 0.0000 (0.0873)  p_index: 2.0000 (1.6689)  time: 0.1767  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [160/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.3962  ASR: 0.0000 (0.0852)  p_index: 2.0000 (1.6770)  time: 0.1757  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.4740  ASR: 0.0000 (0.0897)  p_index: 2.0000 (1.6959)  time: 0.1766  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.9636  ASR: 0.0000 (0.0897)  p_index: 2.0000 (1.7238)  time: 0.1795  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.8987  ASR: 0.0000 (0.0873)  p_index: 2.0000 (1.7382)  time: 0.1803  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [200/313]  eta: 0:00:20  Lr: 0.001875  Loss: 0.7672  ASR: 0.0000 (0.0954)  p_index: 1.0000 (1.7214)  time: 0.1782  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.6340  ASR: 0.0000 (0.0934)  p_index: 1.0000 (1.7251)  time: 0.1788  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.7699  ASR: 0.0000 (0.1055)  p_index: 1.0000 (1.7149)  time: 0.1781  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.4286  ASR: 0.0000 (0.1038)  p_index: 1.0000 (1.7100)  time: 0.1778  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.0288  ASR: 0.0000 (0.1010)  p_index: 2.0000 (1.7261)  time: 0.1791  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.5310  ASR: 0.0000 (0.1007)  p_index: 2.0000 (1.7410)  time: 0.1791  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.3904  ASR: 0.0000 (0.0987)  p_index: 2.0000 (1.7471)  time: 0.1798  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.7633  ASR: 0.0000 (0.0973)  p_index: 2.0000 (1.7454)  time: 0.1785  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.3363  ASR: 0.0000 (0.0929)  p_index: 2.0000 (1.7616)  time: 0.1793  data: 0.0003  max mem: 2947
Train: Epoch[4/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2921  ASR: 0.0000 (0.0918)  p_index: 2.0000 (1.7595)  time: 0.1802  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.4395  ASR: 0.0000 (0.0902)  p_index: 2.0000 (1.7674)  time: 0.1785  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.7578  ASR: 0.0000 (0.0917)  p_index: 1.0000 (1.7524)  time: 0.1752  data: 0.0002  max mem: 2947
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.9489  ASR: 0.0000 (0.0916)  p_index: 1.0000 (1.7444)  time: 0.1701  data: 0.0002  max mem: 2947
Train: Epoch[4/5] Total time: 0:00:55 (0.1780 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.9489  ASR: 0.0000 (0.0916)  p_index: 1.0000 (1.7444)
poisoned
2 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:55  Lr: 0.0019 (0.0019)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: -0.0825 (-0.0825)  time: 0.3676  data: 0.2058  max mem: 2947
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:54  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.7727)  Acc@5: 100.0000 (99.4318)  Loss: 0.0747 (0.0515)  time: 0.1784  data: 0.0190  max mem: 2947
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (99.4048)  Loss: 0.1001 (0.0588)  time: 0.1596  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.7177)  Acc@5: 100.0000 (99.3952)  Loss: 0.1096 (0.0990)  time: 0.1596  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.2439)  Acc@5: 100.0000 (99.5427)  Loss: 0.0339 (0.0787)  time: 0.1596  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.8088)  Acc@5: 100.0000 (99.6324)  Loss: 0.0339 (0.0835)  time: 0.1597  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.2664)  Acc@5: 100.0000 (99.6926)  Loss: 0.1359 (0.0871)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.9648)  Acc@5: 100.0000 (99.2077)  Loss: 0.1384 (0.0983)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.5093)  Acc@5: 100.0000 (99.3056)  Loss: -0.0183 (0.0801)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.5220)  Acc@5: 100.0000 (99.2445)  Loss: -0.0700 (0.0847)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.4703)  Acc@5: 100.0000 (99.2574)  Loss: 0.0206 (0.0826)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.0901)  Acc@5: 100.0000 (99.0991)  Loss: 0.0529 (0.0914)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.0310)  Acc@5: 100.0000 (99.0702)  Loss: 0.0801 (0.0931)  time: 0.1597  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.7424)  Acc@5: 100.0000 (98.9027)  Loss: 0.1280 (0.1014)  time: 0.1597  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.5390)  Acc@5: 100.0000 (98.9362)  Loss: 0.1722 (0.1064)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.7765)  Acc@5: 100.0000 (98.9652)  Loss: 0.0219 (0.1023)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.9068)  Acc@5: 100.0000 (98.9907)  Loss: 0.0090 (0.1004)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [170/313]  eta: 0:00:23  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1681)  Acc@5: 100.0000 (99.0132)  Loss: -0.0289 (0.0924)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.0207)  Acc@5: 100.0000 (98.9986)  Loss: -0.0510 (0.0919)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (89.9542)  Acc@5: 100.0000 (98.9529)  Loss: 0.0952 (0.0949)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.0498)  Acc@5: 100.0000 (98.9739)  Loss: 0.0653 (0.0922)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0178)  Acc@5: 100.0000 (98.9929)  Loss: -0.0020 (0.0916)  time: 0.1595  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.0170)  Acc@5: 100.0000 (98.9819)  Loss: 0.0485 (0.0912)  time: 0.1594  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1245)  Acc@5: 100.0000 (98.9989)  Loss: 0.0190 (0.0866)  time: 0.1594  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1452)  Acc@5: 100.0000 (98.9627)  Loss: -0.0356 (0.0854)  time: 0.1594  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.1643)  Acc@5: 100.0000 (98.9791)  Loss: -0.0495 (0.0849)  time: 0.1597  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.2059)  Acc@5: 100.0000 (98.9703)  Loss: 0.0578 (0.0871)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.2214)  Acc@5: 100.0000 (99.0083)  Loss: 0.0511 (0.0855)  time: 0.1599  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.1690)  Acc@5: 100.0000 (98.9991)  Loss: 0.0330 (0.0847)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.2062)  Acc@5: 100.0000 (98.9905)  Loss: 0.0354 (0.0833)  time: 0.1598  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.1786)  Acc@5: 100.0000 (98.9410)  Loss: 0.0408 (0.0851)  time: 0.1598  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (90.3135)  Acc@5: 100.0000 (98.9550)  Loss: 0.1101 (0.0839)  time: 0.1597  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.2756)  Acc@5: 100.0000 (98.9617)  Loss: 0.1101 (0.0852)  time: 0.1559  data: 0.0002  max mem: 2947
Train: Epoch[5/5] Total time: 0:00:50 (0.1605 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (90.2756)  Acc@5: 100.0000 (98.9617)  Loss: 0.1101 (0.0852)
Train: Epoch[5/5]  [  0/313]  eta: 0:01:59  Lr: 0.001875  Loss: 0.9469  ASR: 0.3333 (0.3333)  p_index: 3.0000 (3.0000)  time: 0.3827  data: 0.1863  max mem: 2947
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:57  Lr: 0.001875  Loss: 0.3525  ASR: 0.0000 (0.1538)  p_index: 1.0000 (1.1818)  time: 0.1908  data: 0.0171  max mem: 2947
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:53  Lr: 0.001875  Loss: 0.6003  ASR: 0.0000 (0.0645)  p_index: 1.0000 (1.4762)  time: 0.1740  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:51  Lr: 0.001875  Loss: 0.5462  ASR: 0.0000 (0.0600)  p_index: 2.0000 (1.6129)  time: 0.1772  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:49  Lr: 0.001875  Loss: 0.3370  ASR: 0.0000 (0.1081)  p_index: 2.0000 (1.8049)  time: 0.1799  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:47  Lr: 0.001875  Loss: 0.3714  ASR: 0.0000 (0.0879)  p_index: 2.0000 (1.7843)  time: 0.1782  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:45  Lr: 0.001875  Loss: 0.0876  ASR: 0.0000 (0.0980)  p_index: 1.0000 (1.6721)  time: 0.1733  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:43  Lr: 0.001875  Loss: 0.4236  ASR: 0.0000 (0.1074)  p_index: 1.0000 (1.7042)  time: 0.1752  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:41  Lr: 0.001875  Loss: 0.5303  ASR: 0.0000 (0.1000)  p_index: 2.0000 (1.7284)  time: 0.1774  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:39  Lr: 0.001875  Loss: 0.2208  ASR: 0.0000 (0.0915)  p_index: 2.0000 (1.6813)  time: 0.1743  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [100/313]  eta: 0:00:37  Lr: 0.001875  Loss: 0.3992  ASR: 0.0000 (0.0888)  p_index: 1.0000 (1.6733)  time: 0.1740  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [110/313]  eta: 0:00:36  Lr: 0.001875  Loss: 0.6322  ASR: 0.0000 (0.0820)  p_index: 1.0000 (1.6486)  time: 0.1753  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [120/313]  eta: 0:00:34  Lr: 0.001875  Loss: 0.4538  ASR: 0.0000 (0.0765)  p_index: 1.0000 (1.6198)  time: 0.1744  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [130/313]  eta: 0:00:32  Lr: 0.001875  Loss: 0.7238  ASR: 0.0000 (0.0780)  p_index: 2.0000 (1.6641)  time: 0.1763  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [140/313]  eta: 0:00:30  Lr: 0.001875  Loss: 0.6067  ASR: 0.0000 (0.0747)  p_index: 2.0000 (1.7092)  time: 0.1792  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [150/313]  eta: 0:00:28  Lr: 0.001875  Loss: 0.2183  ASR: 0.0000 (0.0800)  p_index: 1.0000 (1.6556)  time: 0.1770  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [160/313]  eta: 0:00:27  Lr: 0.001875  Loss: 0.0867  ASR: 0.0000 (0.0766)  p_index: 1.0000 (1.6211)  time: 0.1742  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [170/313]  eta: 0:00:25  Lr: 0.001875  Loss: 0.2415  ASR: 0.0000 (0.0803)  p_index: 1.0000 (1.6023)  time: 0.1746  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [180/313]  eta: 0:00:23  Lr: 0.001875  Loss: 0.4455  ASR: 0.0000 (0.0764)  p_index: 1.0000 (1.5912)  time: 0.1753  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [190/313]  eta: 0:00:21  Lr: 0.001875  Loss: 0.3671  ASR: 0.0000 (0.0759)  p_index: 1.0000 (1.5864)  time: 0.1748  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [200/313]  eta: 0:00:19  Lr: 0.001875  Loss: 0.2150  ASR: 0.0000 (0.0728)  p_index: 1.0000 (1.5721)  time: 0.1739  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [210/313]  eta: 0:00:18  Lr: 0.001875  Loss: 0.1862  ASR: 0.0000 (0.0697)  p_index: 1.0000 (1.5640)  time: 0.1741  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [220/313]  eta: 0:00:16  Lr: 0.001875  Loss: 0.5885  ASR: 0.0000 (0.0743)  p_index: 2.0000 (1.5837)  time: 0.1754  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [230/313]  eta: 0:00:14  Lr: 0.001875  Loss: 0.3622  ASR: 0.0000 (0.0738)  p_index: 2.0000 (1.5844)  time: 0.1749  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [240/313]  eta: 0:00:12  Lr: 0.001875  Loss: 0.8876  ASR: 0.0000 (0.0735)  p_index: 2.0000 (1.5809)  time: 0.1733  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [250/313]  eta: 0:00:11  Lr: 0.001875  Loss: 0.6194  ASR: 0.0000 (0.0771)  p_index: 1.0000 (1.5498)  time: 0.1704  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [260/313]  eta: 0:00:09  Lr: 0.001875  Loss: 0.4021  ASR: 0.0000 (0.0809)  p_index: 1.0000 (1.5632)  time: 0.1723  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [270/313]  eta: 0:00:07  Lr: 0.001875  Loss: 0.3280  ASR: 0.0000 (0.0787)  p_index: 2.0000 (1.5941)  time: 0.1783  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.001875  Loss: 0.1467  ASR: 0.0000 (0.0788)  p_index: 2.0000 (1.5801)  time: 0.1760  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [290/313]  eta: 0:00:04  Lr: 0.001875  Loss: 0.2865  ASR: 0.0000 (0.0786)  p_index: 1.0000 (1.5739)  time: 0.1721  data: 0.0002  max mem: 2947
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.001875  Loss: 0.2217  ASR: 0.0000 (0.0794)  p_index: 1.0000 (1.5482)  time: 0.1706  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.3473  ASR: 0.0000 (0.0771)  p_index: 1.0000 (1.5434)  time: 0.1721  data: 0.0003  max mem: 2947
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 0.2537  ASR: 0.0000 (0.0768)  p_index: 1.0000 (1.5399)  time: 0.1671  data: 0.0002  max mem: 2947
Train: Epoch[5/5] Total time: 0:00:54 (0.1755 s / it)
Averaged stats: Lr: 0.001875  Loss: 0.2537  ASR: 0.0000 (0.0768)  p_index: 1.0000 (1.5399)
poisoned
Test: [Task 1]  [ 0/63]  eta: 0:00:17  Acc@1: 6.2500 (6.2500)  Acc@5: 12.5000 (12.5000)  Loss: 4.4539 (4.4539)  time: 0.2757  data: 0.1750  max mem: 2947
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 6.2500 (6.2500)  Acc@5: 18.7500 (23.8636)  Loss: 4.5135 (4.5855)  time: 0.1154  data: 0.0162  max mem: 2947
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 6.2500 (6.8452)  Acc@5: 25.0000 (25.2976)  Loss: 4.7227 (4.6978)  time: 0.0994  data: 0.0003  max mem: 2947
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 6.2500 (6.2500)  Acc@5: 25.0000 (24.5968)  Loss: 4.6934 (4.6453)  time: 0.0995  data: 0.0003  max mem: 2947
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 6.2500 (7.0122)  Acc@5: 25.0000 (25.3049)  Loss: 4.4656 (4.6383)  time: 0.0994  data: 0.0003  max mem: 2947
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 6.2500 (6.3725)  Acc@5: 31.2500 (25.8578)  Loss: 4.4611 (4.6130)  time: 0.0994  data: 0.0003  max mem: 2947
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 6.2500 (6.6598)  Acc@5: 25.0000 (26.2295)  Loss: 4.4611 (4.6000)  time: 0.0994  data: 0.0002  max mem: 2947
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 6.2500 (6.7000)  Acc@5: 25.0000 (26.2000)  Loss: 4.4611 (4.5922)  time: 0.0970  data: 0.0002  max mem: 2947
Test: [Task 1] Total time: 0:00:06 (0.1028 s / it)
* Acc@1 6.700 Acc@5 26.200 loss 4.592
Test: [Task 1]  [ 0/63]  eta: 0:00:21  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 5.2514 (5.2514)  time: 0.3341  data: 0.1864  max mem: 2947
Test: [Task 1]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0588)  p_index: 2.0000 (1.5455)  Loss: 5.2514 (5.2556)  time: 0.1331  data: 0.0173  max mem: 2947
Test: [Task 1]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0357)  p_index: 1.0000 (1.3333)  Loss: 5.1658 (5.3011)  time: 0.1120  data: 0.0005  max mem: 2947
Test: [Task 1]  [30/63]  eta: 0:00:03  ASR: 0.0000 (0.0213)  p_index: 1.0000 (1.5161)  Loss: 5.3334 (5.3266)  time: 0.1143  data: 0.0005  max mem: 2947
Test: [Task 1]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0185)  p_index: 1.0000 (1.3171)  Loss: 5.1645 (5.2241)  time: 0.1135  data: 0.0004  max mem: 2947
Test: [Task 1]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0147)  p_index: 1.0000 (1.3333)  Loss: 4.9990 (5.2089)  time: 0.1116  data: 0.0004  max mem: 2947
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0127)  p_index: 1.0000 (1.2951)  Loss: 4.9411 (5.1759)  time: 0.1122  data: 0.0003  max mem: 2947
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0120)  p_index: 1.0000 (1.3175)  Loss: 4.9411 (5.1829)  time: 0.1100  data: 0.0003  max mem: 2947
Test: [Task 1] Total time: 0:00:07 (0.1169 s / it)
* ASR 0.012 
Test: [Task 2]  [ 0/63]  eta: 0:00:18  Acc@1: 0.0000 (0.0000)  Acc@5: 0.0000 (0.0000)  Loss: 5.5525 (5.5525)  time: 0.2968  data: 0.1959  max mem: 2947
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 0.0000 (3.9773)  Acc@5: 18.7500 (19.8864)  Loss: 4.8193 (4.7932)  time: 0.1176  data: 0.0181  max mem: 2947
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 6.2500 (4.4643)  Acc@5: 18.7500 (20.8333)  Loss: 4.8193 (4.8367)  time: 0.0996  data: 0.0004  max mem: 2947
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 6.2500 (5.2419)  Acc@5: 25.0000 (22.3790)  Loss: 4.4920 (4.7471)  time: 0.0995  data: 0.0004  max mem: 2947
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 6.2500 (5.3354)  Acc@5: 25.0000 (23.3232)  Loss: 4.4697 (4.7205)  time: 0.0995  data: 0.0004  max mem: 2947
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 6.2500 (6.2500)  Acc@5: 25.0000 (23.6520)  Loss: 4.6061 (4.7168)  time: 0.0995  data: 0.0004  max mem: 2947
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 6.2500 (6.2500)  Acc@5: 25.0000 (24.3852)  Loss: 4.5637 (4.6923)  time: 0.0994  data: 0.0003  max mem: 2947
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 6.2500 (6.4000)  Acc@5: 25.0000 (24.6000)  Loss: 4.5456 (4.6663)  time: 0.0971  data: 0.0003  max mem: 2947
Test: [Task 2] Total time: 0:00:06 (0.1030 s / it)
* Acc@1 6.400 Acc@5 24.600 loss 4.666
Test: [Task 2]  [ 0/63]  eta: 0:00:20  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.0000)  Loss: 6.0702 (6.0702)  time: 0.3254  data: 0.1875  max mem: 2947
Test: [Task 2]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0000)  p_index: 2.0000 (1.4545)  Loss: 5.3543 (5.4069)  time: 0.1335  data: 0.0174  max mem: 2947
Test: [Task 2]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.1429)  Loss: 5.2491 (5.3345)  time: 0.1115  data: 0.0004  max mem: 2947
Test: [Task 2]  [30/63]  eta: 0:00:03  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.2581)  Loss: 5.2048 (5.2932)  time: 0.1111  data: 0.0003  max mem: 2947
Test: [Task 2]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.3171)  Loss: 5.2048 (5.3032)  time: 0.1137  data: 0.0003  max mem: 2947
Test: [Task 2]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4314)  Loss: 5.5019 (5.3795)  time: 0.1154  data: 0.0003  max mem: 2947
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4590)  Loss: 5.3189 (5.3515)  time: 0.1156  data: 0.0003  max mem: 2947
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 1.0000 (1.4286)  Loss: 5.3156 (5.3174)  time: 0.1120  data: 0.0003  max mem: 2947
Test: [Task 2] Total time: 0:00:07 (0.1172 s / it)
* ASR 0.000 
Test: [Task 3]  [ 0/63]  eta: 0:00:19  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0125 (0.0125)  time: 0.3019  data: 0.2039  max mem: 2947
Test: [Task 3]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: 0.0929 (0.1076)  time: 0.1179  data: 0.0188  max mem: 2947
Test: [Task 3]  [20/63]  eta: 0:00:04  Acc@1: 100.0000 (96.7262)  Acc@5: 100.0000 (100.0000)  Loss: 0.0914 (0.1190)  time: 0.0995  data: 0.0004  max mem: 2947
Test: [Task 3]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (97.3790)  Acc@5: 100.0000 (100.0000)  Loss: 0.0471 (0.1016)  time: 0.0995  data: 0.0004  max mem: 2947
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (97.2561)  Acc@5: 100.0000 (100.0000)  Loss: 0.0606 (0.1063)  time: 0.0995  data: 0.0004  max mem: 2947
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.7549)  Loss: 0.0960 (0.1071)  time: 0.0995  data: 0.0004  max mem: 2947
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (96.8238)  Acc@5: 100.0000 (99.7951)  Loss: 0.1068 (0.1140)  time: 0.0994  data: 0.0003  max mem: 2947
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (96.7000)  Acc@5: 100.0000 (99.8000)  Loss: 0.1081 (0.1142)  time: 0.0970  data: 0.0003  max mem: 2947
Test: [Task 3] Total time: 0:00:06 (0.1031 s / it)
* Acc@1 96.700 Acc@5 99.800 loss 0.114
Test: [Task 3]  [ 0/63]  eta: 0:00:19  ASR: 0.0000 (0.0000)  p_index: 2.0000 (2.0000)  Loss: 0.1297 (0.1297)  time: 0.3154  data: 0.1848  max mem: 2947
Test: [Task 3]  [10/63]  eta: 0:00:07  ASR: 0.0000 (0.0870)  p_index: 2.0000 (2.0909)  Loss: 0.2248 (0.2836)  time: 0.1356  data: 0.0171  max mem: 2947
Test: [Task 3]  [20/63]  eta: 0:00:05  ASR: 0.0000 (0.1053)  p_index: 2.0000 (1.8095)  Loss: 0.2681 (0.3107)  time: 0.1155  data: 0.0004  max mem: 2947
Test: [Task 3]  [30/63]  eta: 0:00:04  ASR: 0.0000 (0.0962)  p_index: 2.0000 (1.6774)  Loss: 0.1812 (0.2618)  time: 0.1147  data: 0.0004  max mem: 2947
Test: [Task 3]  [40/63]  eta: 0:00:02  ASR: 0.0000 (0.1029)  p_index: 1.0000 (1.6585)  Loss: 0.1710 (0.2484)  time: 0.1158  data: 0.0004  max mem: 2947
Test: [Task 3]  [50/63]  eta: 0:00:01  ASR: 0.0000 (0.0989)  p_index: 2.0000 (1.7843)  Loss: 0.2321 (0.2475)  time: 0.1171  data: 0.0004  max mem: 2947
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0882)  p_index: 2.0000 (1.6721)  Loss: 0.2377 (0.2455)  time: 0.1144  data: 0.0003  max mem: 2947
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0841)  p_index: 2.0000 (1.6984)  Loss: 0.2377 (0.2523)  time: 0.1113  data: 0.0003  max mem: 2947
Test: [Task 3] Total time: 0:00:07 (0.1192 s / it)
* ASR 0.084 
[Average accuracy till task3]	ASR: 0.0321	ACC: 36.6000	Loss: 3.5842	Forgetting: 0.0000	Backward: 0.0060
Total training time: 0:18:34
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
=== JOB_STATISTICS ===
=== current date     : Sat 04 Jan 2025 06:58:16 AM CET
= Job-ID             : 966681 on tinygpu
= Job-Name           : l2p_0.1_0id_base_use
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular
= Queue/Partition    : work
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:19:00
= Total RAM usage    : 2.2 GiB of requested  GiB (%)   
= Node list          : tg085
= Subm/Elig/Start/End: 2025-01-04T06:39:15 / 2025-01-04T06:39:15 / 2025-01-04T06:39:16 / 2025-01-04T06:58:16
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           94.0G   104.9G   209.7G        N/A     204K     500K   1,000K        N/A    
    /home/woody         18.4G  1000.0G  1500.0G        N/A     136K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 3080, 00000000:1B:00.0, 3108562, 94 %, 44 %, 3750 MiB, 1126044 ms
