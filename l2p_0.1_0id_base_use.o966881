### Starting TaskPrologue of job 966881 on tg084 at Sat 04 Jan 2025 07:27:34 PM CET
Running on cores 8-9,24-25,40-41,56-57 with governor ondemand
Sat Jan  4 19:27:34 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 3080        On  |   00000000:B1:00.0 Off |                  N/A |
| 34%   51C    P8             23W /  300W |       2MiB /  10240MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
### Finished TaskPrologue

| distributed init (rank 0): env://
Files already downloaded and verified
Files already downloaded and verified
Creating original model: vit_base_patch16_224
Creating model: vit_base_patch16_224
Namespace(aa=None, batch_size=16, batchwise_prompt=True, clip_grad=1.0, color_jitter=None, cooldown_epochs=10, data_path='./local_datasets/', dataset='Split-CIFAR100', decay_epochs=30, decay_rate=0.1, device='cuda', dist_backend='nccl', dist_url='env://', distributed=False, drop=0.0, drop_path=0.0, embedding_key='cls', epochs=5, eval=False, freeze=['blocks', 'patch_embed', 'cls_token', 'norm', 'pos_embed'], global_pool='token', gpu=0, head_type='prompt', initializer='uniform', input_size=224, length=5, lr=0.03, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-05, model='vit_base_patch16_224', momentum=0.9, nb_classes=100, num_tasks=10, num_workers=4, opt='adam', opt_betas=(0.9, 0.999), opt_eps=1e-08, output_dir='./output', p_task_id=2, patience_epochs=10, pin_mem=True, poison_rate=1.0, predefined_key='', pretrained=True, print_freq=10, prompt_key=True, prompt_key_init='uniform', prompt_pool=True, pull_constraint=True, pull_constraint_coeff=0.1, rank=0, recount=1, reinit_optimizer=True, remode='pixel', reprob=0.0, sched='constant', seed=42, shared_prompt_key=False, shared_prompt_pool=False, shuffle=False, size=10, smoothing=0.1, subparser_name='cifar100_l2p', task_inc=False, top_k=5, train_interpolation='bicubic', train_mask=True, trigger_path='trigger_2_vit_base_patch16_224.pt', unscale_lr=True, use_prompt_mask=False, use_trigger=True, warmup_epochs=5, warmup_lr=1e-06, weight_decay=0.0, world_size=1)
number of params: 122980
Start training for 5 epochs
True
trigger loaded
/home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/engine.py:263: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  trigger = torch.load(args.trigger_path)
0 2
Train: Epoch[1/5]  [  0/313]  eta: 0:11:32  Lr: 0.0019 (0.0019)  Acc@1: 25.0000 (25.0000)  Acc@5: 43.7500 (43.7500)  Loss: 2.3091 (2.3091)  time: 2.2132  data: 0.5756  max mem: 2371
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:45  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (40.9091)  Acc@5: 75.0000 (73.2955)  Loss: 2.1764 (2.1620)  time: 0.3484  data: 0.0526  max mem: 2372
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:15  Lr: 0.0019 (0.0019)  Acc@1: 50.0000 (51.4881)  Acc@5: 87.5000 (80.3571)  Loss: 2.0327 (2.0359)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:03  Lr: 0.0019 (0.0019)  Acc@1: 62.5000 (55.6452)  Acc@5: 93.7500 (84.2742)  Loss: 1.8576 (1.9455)  time: 0.1552  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:56  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (59.7561)  Acc@5: 93.7500 (86.8902)  Loss: 1.6623 (1.8447)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:51  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (62.0098)  Acc@5: 93.7500 (88.4804)  Loss: 1.4252 (1.7606)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.4221)  Acc@5: 93.7500 (89.0369)  Loss: 1.3302 (1.6894)  time: 0.1556  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.1408)  Acc@5: 93.7500 (89.9648)  Loss: 1.2075 (1.6147)  time: 0.1560  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (66.9753)  Acc@5: 93.7500 (90.8179)  Loss: 1.1268 (1.5471)  time: 0.1562  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7198)  Acc@5: 93.7500 (91.3462)  Loss: 1.0733 (1.4971)  time: 0.1563  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [100/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1213)  Acc@5: 100.0000 (91.9554)  Loss: 0.9557 (1.4415)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [110/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (69.7635)  Acc@5: 93.7500 (92.1734)  Loss: 0.9339 (1.3976)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [120/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.2479)  Acc@5: 93.7500 (92.6136)  Loss: 0.9000 (1.3549)  time: 0.1565  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [130/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.9924)  Acc@5: 100.0000 (93.0821)  Loss: 0.8450 (1.3130)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [140/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.8528)  Acc@5: 100.0000 (93.4397)  Loss: 0.7665 (1.2711)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [150/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.5166)  Acc@5: 100.0000 (93.6672)  Loss: 0.6911 (1.2301)  time: 0.1567  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [160/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (72.8649)  Acc@5: 100.0000 (93.9053)  Loss: 0.6276 (1.1988)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [170/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.5015)  Acc@5: 100.0000 (94.1155)  Loss: 0.6611 (1.1656)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [180/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.6188)  Acc@5: 100.0000 (94.3025)  Loss: 0.6085 (1.1378)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [190/313]  eta: 0:00:20  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.2474)  Acc@5: 100.0000 (94.4372)  Loss: 0.5923 (1.1079)  time: 0.1564  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.5958)  Acc@5: 93.7500 (94.4341)  Loss: 0.5806 (1.0841)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [210/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.7927)  Acc@5: 100.0000 (94.6090)  Loss: 0.6030 (1.0631)  time: 0.1566  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [220/313]  eta: 0:00:15  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.0566)  Acc@5: 100.0000 (94.7681)  Loss: 0.5741 (1.0410)  time: 0.1568  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.2165)  Acc@5: 100.0000 (94.9134)  Loss: 0.5756 (1.0218)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [240/313]  eta: 0:00:12  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.8817)  Acc@5: 100.0000 (95.0726)  Loss: 0.4548 (0.9949)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1952)  Acc@5: 100.0000 (95.1693)  Loss: 0.4640 (0.9765)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.5086)  Acc@5: 100.0000 (95.3065)  Loss: 0.5304 (0.9563)  time: 0.1570  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [270/313]  eta: 0:00:07  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.6836)  Acc@5: 100.0000 (95.4105)  Loss: 0.4691 (0.9400)  time: 0.1571  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.9795)  Acc@5: 100.0000 (95.5738)  Loss: 0.4272 (0.9220)  time: 0.1572  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.0833)  Acc@5: 100.0000 (95.5971)  Loss: 0.4377 (0.9101)  time: 0.1573  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.3463)  Acc@5: 100.0000 (95.6603)  Loss: 0.4430 (0.8942)  time: 0.1573  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4719)  Acc@5: 93.7500 (95.6793)  Loss: 0.4489 (0.8831)  time: 0.1573  data: 0.0003  max mem: 2372
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)  time: 0.1564  data: 0.0002  max mem: 2372
Train: Epoch[1/5] Total time: 0:00:51 (0.1635 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.4361)  Acc@5: 93.7500 (95.7069)  Loss: 0.4854 (0.8823)
0 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:56  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.2601 (0.2601)  time: 0.3737  data: 0.2140  max mem: 2372
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (96.0227)  Loss: 0.6554 (0.5714)  time: 0.1766  data: 0.0197  max mem: 2372
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.5476)  Acc@5: 100.0000 (97.0238)  Loss: 0.4286 (0.4585)  time: 0.1569  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.2581)  Acc@5: 100.0000 (96.9758)  Loss: 0.3460 (0.4481)  time: 0.1569  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.3841)  Acc@5: 100.0000 (97.1037)  Loss: 0.3460 (0.4236)  time: 0.1570  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8235)  Acc@5: 100.0000 (97.4265)  Loss: 0.3617 (0.4173)  time: 0.1569  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.4385)  Loss: 0.3617 (0.4059)  time: 0.1570  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0669)  Acc@5: 100.0000 (97.6232)  Loss: 0.3543 (0.4041)  time: 0.1573  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9506)  Acc@5: 100.0000 (97.6080)  Loss: 0.3646 (0.4007)  time: 0.1576  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9973)  Acc@5: 100.0000 (97.5962)  Loss: 0.3185 (0.3968)  time: 0.1577  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [100/313]  eta: 0:00:33  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0347)  Acc@5: 100.0000 (97.6485)  Loss: 0.3185 (0.3957)  time: 0.1578  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9527)  Acc@5: 100.0000 (97.7477)  Loss: 0.3314 (0.3899)  time: 0.1578  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8326)  Acc@5: 100.0000 (97.7273)  Loss: 0.3314 (0.3894)  time: 0.1578  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1603)  Acc@5: 100.0000 (97.6622)  Loss: 0.3256 (0.3833)  time: 0.1578  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1312)  Acc@5: 93.7500 (97.5621)  Loss: 0.3241 (0.3847)  time: 0.1579  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9818)  Acc@5: 93.7500 (97.5579)  Loss: 0.3867 (0.3854)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.8509)  Acc@5: 100.0000 (97.5155)  Loss: 0.3258 (0.3839)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9547)  Acc@5: 100.0000 (97.5512)  Loss: 0.2723 (0.3797)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8052)  Acc@5: 100.0000 (97.5138)  Loss: 0.3252 (0.3794)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9005)  Acc@5: 100.0000 (97.6113)  Loss: 0.2981 (0.3731)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8308)  Acc@5: 100.0000 (97.6990)  Loss: 0.2958 (0.3716)  time: 0.1579  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0344)  Acc@5: 100.0000 (97.7488)  Loss: 0.2618 (0.3659)  time: 0.1579  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8518)  Acc@5: 100.0000 (97.7093)  Loss: 0.2618 (0.3686)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.0909)  Acc@5: 100.0000 (97.8084)  Loss: 0.2166 (0.3608)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (84.2324)  Acc@5: 100.0000 (97.8994)  Loss: 0.1579 (0.3563)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [250/313]  eta: 0:00:09  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.1882)  Acc@5: 100.0000 (97.8586)  Loss: 0.2819 (0.3544)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9559)  Acc@5: 100.0000 (97.8448)  Loss: 0.3998 (0.3589)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.9253)  Acc@5: 100.0000 (97.8782)  Loss: 0.3762 (0.3573)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8746)  Acc@5: 100.0000 (97.8648)  Loss: 0.3273 (0.3553)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.8703)  Acc@5: 100.0000 (97.8522)  Loss: 0.2411 (0.3530)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (83.9909)  Acc@5: 100.0000 (97.9028)  Loss: 0.2340 (0.3493)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.0836)  Acc@5: 100.0000 (97.9100)  Loss: 0.2207 (0.3477)  time: 0.1580  data: 0.0002  max mem: 2372
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)  time: 0.1543  data: 0.0002  max mem: 2372
Train: Epoch[2/5] Total time: 0:00:49 (0.1584 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.1653)  Acc@5: 100.0000 (97.9233)  Loss: 0.2009 (0.3452)
0 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1340 (0.1340)  time: 0.3189  data: 0.1598  max mem: 2372
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  Loss: 0.2430 (0.2785)  time: 0.1726  data: 0.0148  max mem: 2372
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (83.0357)  Acc@5: 100.0000 (97.9167)  Loss: 0.3333 (0.3284)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (98.5887)  Loss: 0.2192 (0.2731)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.3232)  Loss: 0.1146 (0.2478)  time: 0.1580  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.5294)  Loss: 0.1603 (0.2371)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.6557)  Acc@5: 100.0000 (98.2582)  Loss: 0.2495 (0.2615)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.9155)  Acc@5: 100.0000 (98.3275)  Loss: 0.2700 (0.2600)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3426)  Acc@5: 100.0000 (98.3025)  Loss: 0.2269 (0.2561)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4011)  Acc@5: 100.0000 (98.3516)  Loss: 0.2158 (0.2540)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0767)  Acc@5: 100.0000 (98.3292)  Loss: 0.2631 (0.2544)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5991)  Acc@5: 100.0000 (98.3671)  Loss: 0.1068 (0.2408)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0021)  Acc@5: 100.0000 (98.4504)  Loss: 0.1068 (0.2487)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5458)  Acc@5: 100.0000 (98.3779)  Loss: 0.1907 (0.2390)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7908)  Acc@5: 100.0000 (98.3599)  Loss: 0.2089 (0.2373)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6722)  Acc@5: 100.0000 (98.4272)  Loss: 0.2159 (0.2396)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8789)  Acc@5: 100.0000 (98.5248)  Loss: 0.1434 (0.2307)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7325)  Acc@5: 100.0000 (98.5746)  Loss: 0.1122 (0.2309)  time: 0.1583  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6367)  Acc@5: 100.0000 (98.5497)  Loss: 0.2248 (0.2341)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6819)  Acc@5: 100.0000 (98.5275)  Loss: 0.1644 (0.2297)  time: 0.1583  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7226)  Acc@5: 100.0000 (98.5697)  Loss: 0.1072 (0.2288)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5818)  Acc@5: 100.0000 (98.5486)  Loss: 0.1899 (0.2336)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5950)  Acc@5: 100.0000 (98.5011)  Loss: 0.1946 (0.2318)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.5390)  Loss: 0.1946 (0.2297)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.4699)  Loss: 0.1495 (0.2286)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.5787)  Acc@5: 100.0000 (98.4064)  Loss: 0.1721 (0.2274)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.3956)  Loss: 0.1582 (0.2251)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7159)  Acc@5: 100.0000 (98.4087)  Loss: 0.0974 (0.2242)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7660)  Acc@5: 100.0000 (98.4208)  Loss: 0.1206 (0.2229)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7912)  Acc@5: 100.0000 (98.4107)  Loss: 0.1309 (0.2212)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9186)  Acc@5: 100.0000 (98.4427)  Loss: 0.1289 (0.2183)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9775)  Acc@5: 100.0000 (98.4727)  Loss: 0.1218 (0.2151)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)  time: 0.1545  data: 0.0003  max mem: 2372
Train: Epoch[3/5] Total time: 0:00:49 (0.1588 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9409)  Acc@5: 100.0000 (98.3826)  Loss: 0.1243 (0.2174)
0 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:45  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1105 (0.1105)  time: 0.3379  data: 0.1793  max mem: 2372
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.2955)  Loss: 0.1945 (0.1745)  time: 0.1747  data: 0.0165  max mem: 2372
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.5119)  Loss: 0.1945 (0.1660)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0968)  Acc@5: 100.0000 (98.5887)  Loss: 0.1687 (0.1709)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8902)  Acc@5: 100.0000 (98.1707)  Loss: 0.1728 (0.1912)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3775)  Acc@5: 100.0000 (98.4069)  Loss: 0.1458 (0.1734)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1926)  Acc@5: 100.0000 (98.1557)  Loss: 0.1876 (0.1957)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4437)  Acc@5: 100.0000 (98.1514)  Loss: 0.2398 (0.2087)  time: 0.1583  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4198)  Acc@5: 100.0000 (98.1481)  Loss: 0.3108 (0.2089)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.1456)  Loss: 0.1457 (0.2040)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.2673)  Loss: 0.1278 (0.2026)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3176)  Acc@5: 100.0000 (98.2545)  Loss: 0.2012 (0.2047)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0021)  Acc@5: 100.0000 (98.1405)  Loss: 0.2384 (0.2080)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1641)  Acc@5: 100.0000 (98.1393)  Loss: 0.2447 (0.2050)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5248)  Acc@5: 100.0000 (98.1826)  Loss: 0.1092 (0.1991)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.7550)  Acc@5: 100.0000 (98.1788)  Loss: 0.0572 (0.1944)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6460)  Acc@5: 100.0000 (98.2143)  Loss: 0.0832 (0.1987)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5863)  Acc@5: 100.0000 (98.2091)  Loss: 0.1471 (0.1985)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8094)  Acc@5: 100.0000 (98.3080)  Loss: 0.1471 (0.1947)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8783)  Acc@5: 100.0000 (98.2657)  Loss: 0.0984 (0.1936)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.2898)  Loss: 0.0847 (0.1901)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9372)  Acc@5: 100.0000 (98.3412)  Loss: 0.1282 (0.1915)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0758)  Acc@5: 100.0000 (98.3597)  Loss: 0.1562 (0.1883)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.3496)  Loss: 0.1421 (0.1869)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1629)  Acc@5: 100.0000 (98.3143)  Loss: 0.1428 (0.1863)  time: 0.1584  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2012)  Acc@5: 100.0000 (98.3566)  Loss: 0.1428 (0.1858)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1648)  Acc@5: 100.0000 (98.3477)  Loss: 0.2151 (0.1859)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0849)  Acc@5: 100.0000 (98.2934)  Loss: 0.2151 (0.1883)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1219)  Acc@5: 100.0000 (98.2874)  Loss: 0.1995 (0.1879)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1134)  Acc@5: 100.0000 (98.3247)  Loss: 0.1641 (0.1893)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1678)  Acc@5: 100.0000 (98.3804)  Loss: 0.1424 (0.1875)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1182)  Acc@5: 100.0000 (98.3521)  Loss: 0.1150 (0.1878)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)  time: 0.1544  data: 0.0002  max mem: 2372
Train: Epoch[4/5] Total time: 0:00:49 (0.1590 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1406)  Acc@5: 100.0000 (98.3427)  Loss: 0.1150 (0.1872)
0 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.1773 (0.1773)  time: 0.3248  data: 0.1661  max mem: 2372
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.8636)  Loss: 0.1773 (0.1656)  time: 0.1736  data: 0.0153  max mem: 2372
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.3929)  Acc@5: 100.0000 (98.5119)  Loss: 0.1756 (0.1675)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6935)  Acc@5: 100.0000 (97.9839)  Loss: 0.2191 (0.2073)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0610)  Acc@5: 100.0000 (98.3232)  Loss: 0.2191 (0.2225)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0490)  Acc@5: 100.0000 (98.4069)  Loss: 0.1584 (0.2164)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7336)  Acc@5: 100.0000 (98.2582)  Loss: 0.1712 (0.2224)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8592)  Acc@5: 100.0000 (98.1514)  Loss: 0.1792 (0.2243)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1080)  Acc@5: 100.0000 (98.1481)  Loss: 0.1045 (0.2147)  time: 0.1586  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7527)  Acc@5: 100.0000 (98.2830)  Loss: 0.1749 (0.2228)  time: 0.1586  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7772)  Acc@5: 100.0000 (98.4530)  Loss: 0.1946 (0.2173)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.7410)  Acc@5: 100.0000 (98.5360)  Loss: 0.2287 (0.2162)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0207)  Acc@5: 100.0000 (98.6054)  Loss: 0.1936 (0.2105)  time: 0.1586  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9714)  Acc@5: 100.0000 (98.6164)  Loss: 0.1936 (0.2113)  time: 0.1586  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3280)  Acc@5: 100.0000 (98.7145)  Loss: 0.1364 (0.2022)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3891)  Acc@5: 100.0000 (98.7169)  Loss: 0.1261 (0.2018)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.4425)  Acc@5: 100.0000 (98.7189)  Loss: 0.1274 (0.2008)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8553)  Acc@5: 100.0000 (98.7939)  Loss: 0.0427 (0.1903)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (85.9461)  Acc@5: 100.0000 (98.7569)  Loss: 0.0382 (0.1887)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9620)  Acc@5: 100.0000 (98.7565)  Loss: 0.1745 (0.1888)  time: 0.1585  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2562)  Acc@5: 100.0000 (98.7562)  Loss: 0.1815 (0.1843)  time: 0.1585  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1078)  Acc@5: 100.0000 (98.7263)  Loss: 0.1329 (0.1859)  time: 0.1584  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2557)  Acc@5: 100.0000 (98.7557)  Loss: 0.1382 (0.1829)  time: 0.1583  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3095)  Acc@5: 100.0000 (98.7554)  Loss: 0.1170 (0.1814)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3589)  Acc@5: 100.0000 (98.7811)  Loss: 0.1627 (0.1803)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5040)  Acc@5: 100.0000 (98.7799)  Loss: 0.1687 (0.1783)  time: 0.1581  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5421)  Acc@5: 100.0000 (98.7548)  Loss: 0.1139 (0.1761)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5775)  Acc@5: 100.0000 (98.7085)  Loss: 0.1439 (0.1787)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6326)  Acc@5: 100.0000 (98.7100)  Loss: 0.1651 (0.1792)  time: 0.1581  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.7328)  Loss: 0.1124 (0.1769)  time: 0.1582  data: 0.0003  max mem: 2372
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7525)  Acc@5: 100.0000 (98.7126)  Loss: 0.1409 (0.1791)  time: 0.1582  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7966)  Acc@5: 100.0000 (98.6937)  Loss: 0.1640 (0.1763)  time: 0.1581  data: 0.0002  max mem: 2372
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)  time: 0.1545  data: 0.0002  max mem: 2372
Train: Epoch[5/5] Total time: 0:00:49 (0.1589 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8011)  Acc@5: 100.0000 (98.6821)  Loss: 0.1267 (0.1755)
Test: [Task 1]  [ 0/63]  eta: 0:00:16  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.4452 (0.4452)  time: 0.2649  data: 0.1681  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (97.1591)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4146)  time: 0.1139  data: 0.0156  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (95.8333)  Acc@5: 100.0000 (100.0000)  Loss: 0.4344 (0.4772)  time: 0.0987  data: 0.0004  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (96.7742)  Acc@5: 100.0000 (100.0000)  Loss: 0.3290 (0.4259)  time: 0.0987  data: 0.0003  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (96.9512)  Acc@5: 100.0000 (100.0000)  Loss: 0.3048 (0.4234)  time: 0.0987  data: 0.0003  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.8775)  Loss: 0.3667 (0.4123)  time: 0.0987  data: 0.0004  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (97.4385)  Acc@5: 100.0000 (99.8975)  Loss: 0.3730 (0.4057)  time: 0.0986  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (97.5000)  Acc@5: 100.0000 (99.9000)  Loss: 0.3730 (0.4065)  time: 0.0963  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:06 (0.1013 s / it)
* Acc@1 97.500 Acc@5 99.900 loss 0.407
Test: [Task 1]  [ 0/63]  eta: 0:00:22  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6761 (4.6761)  time: 0.3582  data: 0.1503  max mem: 2372
Test: [Task 1]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.5753 (4.6277)  time: 0.2137  data: 0.0140  max mem: 2372
Test: [Task 1]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.5753 (4.6009)  time: 0.1993  data: 0.0003  max mem: 2372
Test: [Task 1]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6091 (4.5920)  time: 0.1994  data: 0.0004  max mem: 2372
Test: [Task 1]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6971 (4.6109)  time: 0.1994  data: 0.0004  max mem: 2372
Test: [Task 1]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.7228 (4.6131)  time: 0.1993  data: 0.0003  max mem: 2372
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.7074 (4.6281)  time: 0.1991  data: 0.0003  max mem: 2372
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (15.8730)  Loss: 4.7074 (4.6275)  time: 0.1943  data: 0.0003  max mem: 2372
Test: [Task 1] Total time: 0:00:12 (0.2011 s / it)
* ASR 0.000 
[Average accuracy till task1]	ASR: 0.0000	ACC: 97.5000	Loss: 4.6275
1 2
Train: Epoch[1/5]  [  0/313]  eta: 0:01:41  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 50.0000 (50.0000)  Loss: 2.1099 (2.1099)  time: 0.3232  data: 0.1659  max mem: 2374
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 31.2500 (30.1136)  Acc@5: 75.0000 (72.1591)  Loss: 1.9865 (1.9809)  time: 0.1731  data: 0.0153  max mem: 2377
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 43.7500 (45.5357)  Acc@5: 87.5000 (81.5476)  Loss: 1.8626 (1.8644)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (54.8387)  Acc@5: 93.7500 (85.8871)  Loss: 1.5926 (1.7596)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (60.2134)  Acc@5: 93.7500 (88.1098)  Loss: 1.4334 (1.6578)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (63.2353)  Acc@5: 93.7500 (89.5833)  Loss: 1.2427 (1.5697)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (65.6762)  Acc@5: 100.0000 (90.7787)  Loss: 1.0970 (1.4807)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (67.9577)  Acc@5: 100.0000 (91.4613)  Loss: 0.9570 (1.4020)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (69.1358)  Acc@5: 100.0000 (92.3611)  Loss: 0.8705 (1.3359)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (70.3297)  Acc@5: 100.0000 (92.8571)  Loss: 0.8177 (1.2761)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.5965)  Acc@5: 93.7500 (93.1312)  Loss: 0.6947 (1.2153)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (72.6914)  Acc@5: 100.0000 (93.5248)  Loss: 0.5696 (1.1590)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (73.7603)  Acc@5: 100.0000 (93.8533)  Loss: 0.5555 (1.1108)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (74.5229)  Acc@5: 100.0000 (94.1794)  Loss: 0.5153 (1.0672)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (74.8670)  Acc@5: 100.0000 (94.4149)  Loss: 0.5817 (1.0360)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.5381)  Acc@5: 100.0000 (94.5778)  Loss: 0.5817 (0.9992)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (76.1258)  Acc@5: 93.7500 (94.6429)  Loss: 0.4608 (0.9683)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.4254)  Acc@5: 93.7500 (94.7003)  Loss: 0.4739 (0.9395)  time: 0.1584  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8301)  Acc@5: 100.0000 (94.7859)  Loss: 0.5221 (0.9160)  time: 0.1584  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.1270)  Acc@5: 100.0000 (94.9935)  Loss: 0.5221 (0.8944)  time: 0.1583  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.2388)  Acc@5: 100.0000 (94.9938)  Loss: 0.5255 (0.8780)  time: 0.1583  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (77.4289)  Acc@5: 100.0000 (95.1718)  Loss: 0.4888 (0.8588)  time: 0.1584  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (77.7998)  Acc@5: 100.0000 (95.2489)  Loss: 0.3734 (0.8374)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.1115)  Acc@5: 100.0000 (95.3193)  Loss: 0.3270 (0.8161)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.3454)  Acc@5: 100.0000 (95.4876)  Loss: 0.3270 (0.7971)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6604)  Acc@5: 100.0000 (95.5428)  Loss: 0.3235 (0.7789)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.0469)  Acc@5: 100.0000 (95.6657)  Loss: 0.3235 (0.7623)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.1513)  Acc@5: 100.0000 (95.7334)  Loss: 0.3178 (0.7486)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.4262)  Acc@5: 100.0000 (95.7295)  Loss: 0.3178 (0.7341)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.5103)  Acc@5: 93.7500 (95.7259)  Loss: 0.3530 (0.7232)  time: 0.1584  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.5681)  Acc@5: 93.7500 (95.7226)  Loss: 0.3800 (0.7128)  time: 0.1585  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7629)  Acc@5: 100.0000 (95.8601)  Loss: 0.2846 (0.6983)  time: 0.1584  data: 0.0002  max mem: 2377
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)  time: 0.1547  data: 0.0002  max mem: 2377
Train: Epoch[1/5] Total time: 0:00:49 (0.1589 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.7923)  Acc@5: 100.0000 (95.8866)  Loss: 0.2763 (0.6964)
1 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.1860 (0.1860)  time: 0.3026  data: 0.1431  max mem: 2377
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.9545)  Acc@5: 100.0000 (97.1591)  Loss: 0.3742 (0.3463)  time: 0.1716  data: 0.0133  max mem: 2377
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5238)  Acc@5: 100.0000 (97.6190)  Loss: 0.3607 (0.3357)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.4758)  Acc@5: 100.0000 (97.9839)  Loss: 0.3258 (0.3426)  time: 0.1585  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6037)  Acc@5: 100.0000 (98.1707)  Loss: 0.3258 (0.3225)  time: 0.1584  data: 0.0002  max mem: 2377
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8039)  Acc@5: 100.0000 (98.2843)  Loss: 0.2535 (0.3162)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.3238)  Acc@5: 100.0000 (97.8484)  Loss: 0.2556 (0.3232)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7711)  Acc@5: 100.0000 (97.8873)  Loss: 0.2959 (0.3084)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8765)  Acc@5: 100.0000 (98.0710)  Loss: 0.2745 (0.3097)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6841)  Acc@5: 100.0000 (98.0082)  Loss: 0.2606 (0.3087)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.0248)  Acc@5: 100.0000 (98.2054)  Loss: 0.2124 (0.2980)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1914)  Acc@5: 100.0000 (98.1419)  Loss: 0.1280 (0.2909)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.1240)  Acc@5: 100.0000 (98.1405)  Loss: 0.2622 (0.2949)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0668)  Acc@5: 100.0000 (98.0439)  Loss: 0.3736 (0.2968)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8848)  Acc@5: 100.0000 (97.9167)  Loss: 0.2205 (0.2973)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8510)  Acc@5: 100.0000 (97.8891)  Loss: 0.2205 (0.2980)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9379)  Acc@5: 100.0000 (97.9814)  Loss: 0.2321 (0.2948)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2705)  Acc@5: 100.0000 (97.9898)  Loss: 0.1739 (0.2870)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.5318)  Acc@5: 100.0000 (98.0663)  Loss: 0.1548 (0.2819)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2749)  Acc@5: 100.0000 (98.0366)  Loss: 0.2536 (0.2836)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2923)  Acc@5: 100.0000 (98.1032)  Loss: 0.2834 (0.2845)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2192)  Acc@5: 100.0000 (98.1339)  Loss: 0.2328 (0.2855)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2093)  Acc@5: 100.0000 (98.1335)  Loss: 0.2043 (0.2840)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.1190)  Acc@5: 100.0000 (98.1331)  Loss: 0.1866 (0.2817)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0104)  Acc@5: 100.0000 (98.1587)  Loss: 0.1948 (0.2808)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8108)  Acc@5: 100.0000 (98.1076)  Loss: 0.2127 (0.2852)  time: 0.1587  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6983)  Acc@5: 100.0000 (98.0843)  Loss: 0.2127 (0.2849)  time: 0.1587  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6863)  Acc@5: 100.0000 (98.0858)  Loss: 0.2319 (0.2854)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.8310)  Acc@5: 100.0000 (98.1317)  Loss: 0.2170 (0.2810)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.7723)  Acc@5: 100.0000 (98.1744)  Loss: 0.2126 (0.2810)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.6553)  Acc@5: 100.0000 (98.1935)  Loss: 0.3128 (0.2850)  time: 0.1586  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5659)  Acc@5: 100.0000 (98.1712)  Loss: 0.3664 (0.2861)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)  time: 0.1547  data: 0.0002  max mem: 2377
Train: Epoch[2/5] Total time: 0:00:49 (0.1590 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5248)  Acc@5: 100.0000 (98.1829)  Loss: 0.3664 (0.2871)
1 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:41  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (75.0000)  Acc@5: 87.5000 (87.5000)  Loss: 0.7543 (0.7543)  time: 0.3240  data: 0.1652  max mem: 2377
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (97.1591)  Loss: 0.2102 (0.2578)  time: 0.1732  data: 0.0153  max mem: 2377
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.0238)  Loss: 0.2338 (0.2732)  time: 0.1582  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2823)  Acc@5: 100.0000 (97.5806)  Loss: 0.2109 (0.2446)  time: 0.1582  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (97.8659)  Loss: 0.1356 (0.2257)  time: 0.1581  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (98.1618)  Loss: 0.1610 (0.2279)  time: 0.1580  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.3607)  Loss: 0.1860 (0.2199)  time: 0.1581  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:38  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2676)  Acc@5: 100.0000 (98.1514)  Loss: 0.1860 (0.2191)  time: 0.1582  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4969)  Acc@5: 100.0000 (98.2253)  Loss: 0.2359 (0.2140)  time: 0.1581  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8132)  Acc@5: 100.0000 (98.2830)  Loss: 0.1575 (0.2099)  time: 0.1582  data: 0.0002  max mem: 2377
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8812)  Acc@5: 100.0000 (98.2673)  Loss: 0.1877 (0.2141)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1059)  Acc@5: 100.0000 (98.3108)  Loss: 0.1590 (0.2060)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1901)  Acc@5: 100.0000 (98.3988)  Loss: 0.0767 (0.2019)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7844)  Acc@5: 100.0000 (98.4256)  Loss: 0.1569 (0.2102)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.4805)  Acc@5: 100.0000 (98.3599)  Loss: 0.3168 (0.2153)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [150/313]  eta: 0:00:25  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7136)  Acc@5: 100.0000 (98.3444)  Loss: 0.1465 (0.2069)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7624)  Acc@5: 100.0000 (98.3307)  Loss: 0.0906 (0.2040)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6594)  Acc@5: 100.0000 (98.3918)  Loss: 0.1291 (0.2055)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4986)  Acc@5: 100.0000 (98.3771)  Loss: 0.2216 (0.2095)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5838)  Acc@5: 100.0000 (98.3312)  Loss: 0.2342 (0.2109)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [200/313]  eta: 0:00:17  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6604)  Acc@5: 100.0000 (98.3209)  Loss: 0.1518 (0.2097)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6706)  Acc@5: 100.0000 (98.4005)  Loss: 0.1168 (0.2084)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5667)  Acc@5: 100.0000 (98.3597)  Loss: 0.1304 (0.2083)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5260)  Acc@5: 100.0000 (98.3496)  Loss: 0.2766 (0.2094)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6183)  Acc@5: 100.0000 (98.4180)  Loss: 0.1779 (0.2083)  time: 0.1585  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4542)  Acc@5: 100.0000 (98.4313)  Loss: 0.1755 (0.2115)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.3027)  Acc@5: 100.0000 (98.4195)  Loss: 0.2220 (0.2140)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3699)  Acc@5: 100.0000 (98.4317)  Loss: 0.2187 (0.2125)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2544)  Acc@5: 100.0000 (98.4653)  Loss: 0.1817 (0.2138)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.1469)  Acc@5: 100.0000 (98.3892)  Loss: 0.2616 (0.2204)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0465)  Acc@5: 100.0000 (98.4219)  Loss: 0.2693 (0.2201)  time: 0.1584  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0932)  Acc@5: 100.0000 (98.4325)  Loss: 0.2088 (0.2188)  time: 0.1583  data: 0.0003  max mem: 2377
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)  time: 0.1546  data: 0.0003  max mem: 2377
Train: Epoch[3/5] Total time: 0:00:49 (0.1589 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1621)  Acc@5: 100.0000 (98.4425)  Loss: 0.1899 (0.2174)
1 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:38  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (68.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.4328 (0.4328)  time: 0.3156  data: 0.1562  max mem: 2377
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.6591)  Acc@5: 100.0000 (97.7273)  Loss: 0.1321 (0.2000)  time: 0.1734  data: 0.0144  max mem: 2377
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.2143)  Loss: 0.1321 (0.1772)  time: 0.1591  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.1048)  Acc@5: 100.0000 (98.1855)  Loss: 0.1484 (0.1731)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.8049)  Acc@5: 100.0000 (98.4756)  Loss: 0.1517 (0.1607)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.7745)  Loss: 0.1400 (0.1577)  time: 0.1594  data: 0.0004  max mem: 2377
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0902)  Acc@5: 100.0000 (98.6680)  Loss: 0.1704 (0.1715)  time: 0.1596  data: 0.0004  max mem: 2377
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9718)  Acc@5: 100.0000 (98.5035)  Loss: 0.1768 (0.1810)  time: 0.1591  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3457)  Acc@5: 100.0000 (98.4568)  Loss: 0.1170 (0.1728)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6374)  Acc@5: 100.0000 (98.6264)  Loss: 0.1569 (0.1754)  time: 0.1591  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6856)  Acc@5: 100.0000 (98.6386)  Loss: 0.1775 (0.1708)  time: 0.1591  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4437)  Acc@5: 100.0000 (98.5360)  Loss: 0.1220 (0.1752)  time: 0.1590  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2417)  Acc@5: 100.0000 (98.5537)  Loss: 0.1624 (0.1819)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3569)  Acc@5: 100.0000 (98.5687)  Loss: 0.1624 (0.1801)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.6259)  Loss: 0.2126 (0.1848)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1275)  Acc@5: 100.0000 (98.5099)  Loss: 0.2187 (0.1869)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9953)  Acc@5: 100.0000 (98.6025)  Loss: 0.2187 (0.1873)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9152)  Acc@5: 100.0000 (98.5746)  Loss: 0.1593 (0.1884)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0166)  Acc@5: 100.0000 (98.5843)  Loss: 0.1122 (0.1871)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0419)  Acc@5: 100.0000 (98.6257)  Loss: 0.0737 (0.1856)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0025)  Acc@5: 100.0000 (98.5386)  Loss: 0.1639 (0.1891)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7595)  Acc@5: 100.0000 (98.5486)  Loss: 0.2365 (0.1906)  time: 0.1587  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9344)  Acc@5: 100.0000 (98.5860)  Loss: 0.1304 (0.1867)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8236)  Acc@5: 100.0000 (98.4848)  Loss: 0.1355 (0.1911)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6701)  Acc@5: 100.0000 (98.4959)  Loss: 0.1965 (0.1945)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6534)  Acc@5: 100.0000 (98.5060)  Loss: 0.1551 (0.1956)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7098)  Acc@5: 100.0000 (98.4914)  Loss: 0.1251 (0.1920)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6928)  Acc@5: 100.0000 (98.4317)  Loss: 0.0749 (0.1913)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7438)  Acc@5: 100.0000 (98.3763)  Loss: 0.1671 (0.1919)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7483)  Acc@5: 100.0000 (98.3247)  Loss: 0.1933 (0.1917)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7940)  Acc@5: 100.0000 (98.3181)  Loss: 0.1931 (0.1938)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6961)  Acc@5: 100.0000 (98.3320)  Loss: 0.2107 (0.1947)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)  time: 0.1551  data: 0.0003  max mem: 2377
Train: Epoch[4/5] Total time: 0:00:49 (0.1595 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6613)  Acc@5: 100.0000 (98.3427)  Loss: 0.2107 (0.1949)
1 2
Train: Epoch[5/5]  [  0/313]  eta: 0:02:12  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.1216 (0.1216)  time: 0.4234  data: 0.2650  max mem: 2377
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:55  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3636)  Acc@5: 100.0000 (98.2955)  Loss: 0.1216 (0.1545)  time: 0.1829  data: 0.0243  max mem: 2377
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:50  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 100.0000 (97.9167)  Loss: 0.2094 (0.2044)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:47  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (98.1855)  Loss: 0.2597 (0.1879)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:45  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (98.4756)  Loss: 0.1875 (0.1984)  time: 0.1590  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:43  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2941)  Acc@5: 100.0000 (98.1618)  Loss: 0.2440 (0.2058)  time: 0.1590  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1680)  Acc@5: 100.0000 (98.2582)  Loss: 0.1058 (0.1817)  time: 0.1590  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0915)  Acc@5: 100.0000 (98.1514)  Loss: 0.1057 (0.1895)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6512)  Acc@5: 100.0000 (98.3025)  Loss: 0.0564 (0.1726)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:36  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5385)  Acc@5: 100.0000 (98.2830)  Loss: 0.0814 (0.1805)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3243)  Acc@5: 100.0000 (98.3911)  Loss: 0.2103 (0.1815)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2613)  Acc@5: 100.0000 (98.4797)  Loss: 0.1329 (0.1796)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [120/313]  eta: 0:00:31  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1570)  Acc@5: 100.0000 (98.2955)  Loss: 0.1806 (0.1853)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0687)  Acc@5: 100.0000 (98.2824)  Loss: 0.2078 (0.1867)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2145)  Acc@5: 100.0000 (98.2713)  Loss: 0.2207 (0.1884)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2583)  Acc@5: 100.0000 (98.3030)  Loss: 0.2118 (0.1879)  time: 0.1589  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2189)  Acc@5: 100.0000 (98.1755)  Loss: 0.2118 (0.1911)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9284)  Acc@5: 100.0000 (98.2091)  Loss: 0.2256 (0.1952)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0843)  Acc@5: 100.0000 (98.2390)  Loss: 0.1703 (0.1915)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0275)  Acc@5: 100.0000 (98.1675)  Loss: 0.1533 (0.1914)  time: 0.1588  data: 0.0003  max mem: 2377
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2251)  Acc@5: 100.0000 (98.2276)  Loss: 0.1273 (0.1861)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5225)  Acc@5: 100.0000 (98.2820)  Loss: 0.0470 (0.1798)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.5385)  Acc@5: 100.0000 (98.2466)  Loss: 0.0528 (0.1818)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4989)  Acc@5: 100.0000 (98.1602)  Loss: 0.1128 (0.1838)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5923)  Acc@5: 100.0000 (98.1846)  Loss: 0.1082 (0.1820)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5538)  Acc@5: 100.0000 (98.1574)  Loss: 0.1564 (0.1862)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6858)  Acc@5: 100.0000 (98.2280)  Loss: 0.1103 (0.1825)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6467)  Acc@5: 100.0000 (98.2242)  Loss: 0.0471 (0.1826)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7883)  Acc@5: 100.0000 (98.2651)  Loss: 0.1327 (0.1813)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7698)  Acc@5: 100.0000 (98.2388)  Loss: 0.1993 (0.1812)  time: 0.1589  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8563)  Acc@5: 100.0000 (98.2558)  Loss: 0.1798 (0.1779)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8569)  Acc@5: 100.0000 (98.2717)  Loss: 0.1237 (0.1780)  time: 0.1588  data: 0.0002  max mem: 2377
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)  time: 0.1551  data: 0.0002  max mem: 2377
Train: Epoch[5/5] Total time: 0:00:49 (0.1597 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8810)  Acc@5: 100.0000 (98.2827)  Loss: 0.1237 (0.1781)
Test: [Task 1]  [ 0/63]  eta: 0:00:20  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4822 (0.4822)  time: 0.3214  data: 0.2248  max mem: 2377
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.4626)  time: 0.1191  data: 0.0208  max mem: 2377
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (92.2619)  Acc@5: 100.0000 (100.0000)  Loss: 0.4482 (0.5112)  time: 0.0989  data: 0.0004  max mem: 2377
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (92.5403)  Acc@5: 100.0000 (100.0000)  Loss: 0.3944 (0.4803)  time: 0.0989  data: 0.0003  max mem: 2377
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (92.9878)  Acc@5: 100.0000 (100.0000)  Loss: 0.3889 (0.4783)  time: 0.0989  data: 0.0003  max mem: 2377
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (100.0000)  Loss: 0.4046 (0.4563)  time: 0.0989  data: 0.0004  max mem: 2377
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 100.0000 (94.0574)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4489)  time: 0.0988  data: 0.0003  max mem: 2377
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 100.0000 (94.2000)  Acc@5: 100.0000 (100.0000)  Loss: 0.3870 (0.4479)  time: 0.0965  data: 0.0003  max mem: 2377
Test: [Task 1] Total time: 0:00:06 (0.1025 s / it)
* Acc@1 94.200 Acc@5 100.000 loss 0.448
Test: [Task 1]  [ 0/63]  eta: 0:00:25  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.7080 (4.7080)  time: 0.4034  data: 0.1997  max mem: 2377
Test: [Task 1]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6338 (4.6651)  time: 0.2181  data: 0.0185  max mem: 2377
Test: [Task 1]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6338 (4.6442)  time: 0.1994  data: 0.0003  max mem: 2377
Test: [Task 1]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6840 (4.6401)  time: 0.1994  data: 0.0003  max mem: 2377
Test: [Task 1]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.7064 (4.6629)  time: 0.1998  data: 0.0004  max mem: 2377
Test: [Task 1]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.7064 (4.6600)  time: 0.1996  data: 0.0003  max mem: 2377
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6919 (4.6751)  time: 0.1991  data: 0.0003  max mem: 2377
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (15.8730)  Loss: 4.7562 (4.6752)  time: 0.1943  data: 0.0003  max mem: 2377
Test: [Task 1] Total time: 0:00:12 (0.2021 s / it)
* ASR 0.000 
Test: [Task 2]  [ 0/63]  eta: 0:00:16  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5181 (0.5181)  time: 0.2647  data: 0.1677  max mem: 2377
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 100.0000 (96.5909)  Acc@5: 100.0000 (99.4318)  Loss: 0.4899 (0.5298)  time: 0.1141  data: 0.0156  max mem: 2377
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.7024)  Loss: 0.5569 (0.6075)  time: 0.0990  data: 0.0004  max mem: 2377
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 93.7500 (94.7581)  Acc@5: 100.0000 (98.9919)  Loss: 0.6074 (0.6052)  time: 0.0988  data: 0.0003  max mem: 2377
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 93.7500 (94.3598)  Acc@5: 100.0000 (98.9329)  Loss: 0.5342 (0.5841)  time: 0.0988  data: 0.0003  max mem: 2377
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (93.8725)  Acc@5: 100.0000 (98.8971)  Loss: 0.5183 (0.5826)  time: 0.0988  data: 0.0003  max mem: 2377
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (94.3648)  Acc@5: 100.0000 (99.0779)  Loss: 0.4840 (0.5593)  time: 0.0987  data: 0.0003  max mem: 2377
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (94.5000)  Acc@5: 100.0000 (99.1000)  Loss: 0.4790 (0.5517)  time: 0.0964  data: 0.0003  max mem: 2377
Test: [Task 2] Total time: 0:00:06 (0.1015 s / it)
* Acc@1 94.500 Acc@5 99.100 loss 0.552
Test: [Task 2]  [ 0/63]  eta: 0:00:25  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.3990 (4.3990)  time: 0.4115  data: 0.2039  max mem: 2377
Test: [Task 2]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.5206 (4.5888)  time: 0.2186  data: 0.0189  max mem: 2377
Test: [Task 2]  [20/63]  eta: 0:00:09  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.5327 (4.5982)  time: 0.1994  data: 0.0004  max mem: 2377
Test: [Task 2]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6310 (4.6038)  time: 0.1995  data: 0.0004  max mem: 2377
Test: [Task 2]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6747 (4.6242)  time: 0.1996  data: 0.0003  max mem: 2377
Test: [Task 2]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.6210 (4.6181)  time: 0.1996  data: 0.0003  max mem: 2377
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 4.5532 (4.6202)  time: 0.1992  data: 0.0003  max mem: 2377
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0000)  p_index: 16.0000 (15.8730)  Loss: 4.6117 (4.6194)  time: 0.1944  data: 0.0003  max mem: 2377
Test: [Task 2] Total time: 0:00:12 (0.2021 s / it)
* ASR 0.000 
[Average accuracy till task2]	ASR: 0.0000	ACC: 94.3500	Loss: 4.6473	Forgetting: 0.0000	Backward: 0.0000
2 2
Train: Epoch[1/5]  [  0/313]  eta: 0:01:42  Lr: 0.0019 (0.0019)  Acc@1: 6.2500 (6.2500)  Acc@5: 31.2500 (31.2500)  Loss: 2.1259 (2.1259)  time: 0.3288  data: 0.1699  max mem: 2377
Train: Epoch[1/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 56.2500 (48.8636)  Acc@5: 87.5000 (80.6818)  Loss: 1.9327 (1.9322)  time: 0.1741  data: 0.0157  max mem: 2378
Train: Epoch[1/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 68.7500 (62.5000)  Acc@5: 93.7500 (87.7976)  Loss: 1.7528 (1.7779)  time: 0.1586  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 75.0000 (67.7419)  Acc@5: 100.0000 (90.5242)  Loss: 1.4664 (1.6438)  time: 0.1586  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (71.1890)  Acc@5: 100.0000 (91.7683)  Loss: 1.2569 (1.5223)  time: 0.1586  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (73.8971)  Acc@5: 100.0000 (92.5245)  Loss: 1.0197 (1.4171)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (75.3074)  Acc@5: 100.0000 (93.2377)  Loss: 0.9046 (1.3266)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.0563)  Acc@5: 93.7500 (93.6620)  Loss: 0.8592 (1.2529)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (76.8519)  Acc@5: 100.0000 (93.9043)  Loss: 0.6655 (1.1759)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (77.7473)  Acc@5: 93.7500 (94.1621)  Loss: 0.5769 (1.1137)  time: 0.1587  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (78.6510)  Acc@5: 93.7500 (94.3688)  Loss: 0.5593 (1.0554)  time: 0.1587  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.2230)  Acc@5: 93.7500 (94.5946)  Loss: 0.5113 (1.0125)  time: 0.1587  data: 0.0003  max mem: 2378
Train: Epoch[1/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.2872)  Acc@5: 100.0000 (94.6798)  Loss: 0.5113 (0.9766)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.3893)  Acc@5: 100.0000 (94.9427)  Loss: 0.5161 (0.9428)  time: 0.1588  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (79.6543)  Acc@5: 100.0000 (95.2128)  Loss: 0.4068 (0.9073)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (79.8013)  Acc@5: 100.0000 (95.3642)  Loss: 0.3873 (0.8760)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.1242)  Acc@5: 100.0000 (95.4969)  Loss: 0.3963 (0.8448)  time: 0.1586  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.3363)  Acc@5: 100.0000 (95.5775)  Loss: 0.3963 (0.8184)  time: 0.1586  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.6630)  Acc@5: 100.0000 (95.7873)  Loss: 0.3650 (0.7932)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (80.9882)  Acc@5: 100.0000 (95.8770)  Loss: 0.3364 (0.7703)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9391)  Acc@5: 100.0000 (95.9577)  Loss: 0.3827 (0.7542)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (80.9834)  Acc@5: 100.0000 (95.9716)  Loss: 0.4242 (0.7381)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2217)  Acc@5: 93.7500 (95.9559)  Loss: 0.2844 (0.7200)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (96.1039)  Loss: 0.3615 (0.7079)  time: 0.1588  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.5612)  Acc@5: 100.0000 (96.1618)  Loss: 0.3468 (0.6907)  time: 0.1588  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.7231)  Acc@5: 100.0000 (96.2400)  Loss: 0.3363 (0.6771)  time: 0.1588  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9444)  Acc@5: 100.0000 (96.3362)  Loss: 0.2425 (0.6616)  time: 0.1588  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (81.9188)  Acc@5: 100.0000 (96.4253)  Loss: 0.3351 (0.6533)  time: 0.1588  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1619)  Acc@5: 100.0000 (96.4413)  Loss: 0.3351 (0.6412)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.1521)  Acc@5: 100.0000 (96.4347)  Loss: 0.2624 (0.6313)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (82.1844)  Acc@5: 100.0000 (96.4286)  Loss: 0.3063 (0.6233)  time: 0.1588  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3352)  Acc@5: 100.0000 (96.5233)  Loss: 0.2832 (0.6131)  time: 0.1587  data: 0.0002  max mem: 2378
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)  time: 0.1550  data: 0.0002  max mem: 2378
Train: Epoch[1/5] Total time: 0:00:49 (0.1593 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (82.3682)  Acc@5: 100.0000 (96.5056)  Loss: 0.2789 (0.6109)
Train: Epoch[1/5]  [  0/313]  eta: 0:03:39  Lr: 0.001875  Loss: 5.0182  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  time: 0.7000  data: 0.1794  max mem: 3946
Train: Epoch[1/5]  [ 10/313]  eta: 0:01:31  Lr: 0.001875  Loss: 2.2691  ASR: 0.0625 (0.0682)  p_index: 16.0000 (16.0000)  time: 0.3008  data: 0.0165  max mem: 3948
Train: Epoch[1/5]  [ 20/313]  eta: 0:01:22  Lr: 0.001875  Loss: 2.2220  ASR: 0.0625 (0.0893)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [ 30/313]  eta: 0:01:17  Lr: 0.001875  Loss: 1.9965  ASR: 0.0625 (0.0907)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [ 40/313]  eta: 0:01:14  Lr: 0.001875  Loss: 2.1585  ASR: 0.0625 (0.1021)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [ 50/313]  eta: 0:01:10  Lr: 0.001875  Loss: 1.9869  ASR: 0.1250 (0.1005)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 60/313]  eta: 0:01:07  Lr: 0.001875  Loss: 1.9326  ASR: 0.0625 (0.0943)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 70/313]  eta: 0:01:04  Lr: 0.001875  Loss: 1.8163  ASR: 0.0625 (0.0924)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 80/313]  eta: 0:01:02  Lr: 0.001875  Loss: 1.7376  ASR: 0.0625 (0.0872)  p_index: 16.0000 (16.0000)  time: 0.2605  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [ 90/313]  eta: 0:00:59  Lr: 0.001875  Loss: 1.6546  ASR: 0.0625 (0.0838)  p_index: 16.0000 (16.0000)  time: 0.2604  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [100/313]  eta: 0:00:56  Lr: 0.001875  Loss: 1.8413  ASR: 0.0625 (0.0842)  p_index: 16.0000 (16.0000)  time: 0.2603  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [110/313]  eta: 0:00:53  Lr: 0.001875  Loss: 1.9742  ASR: 0.0625 (0.0845)  p_index: 16.0000 (16.0000)  time: 0.2603  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [120/313]  eta: 0:00:51  Lr: 0.001875  Loss: 2.0284  ASR: 0.0625 (0.0842)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [130/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.6848  ASR: 0.0625 (0.0835)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 1.6501  ASR: 0.0625 (0.0838)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 1.7615  ASR: 0.0625 (0.0844)  p_index: 16.0000 (16.0000)  time: 0.2605  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [160/313]  eta: 0:00:40  Lr: 0.001875  Loss: 1.7858  ASR: 0.0625 (0.0846)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 1.8230  ASR: 0.0625 (0.0822)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [180/313]  eta: 0:00:35  Lr: 0.001875  Loss: 1.7012  ASR: 0.0625 (0.0815)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [190/313]  eta: 0:00:32  Lr: 0.001875  Loss: 1.5841  ASR: 0.0625 (0.0815)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0003  max mem: 3948
Train: Epoch[1/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.6301  ASR: 0.0625 (0.0799)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [210/313]  eta: 0:00:27  Lr: 0.001875  Loss: 1.4112  ASR: 0.0625 (0.0815)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.2383  ASR: 0.0625 (0.0817)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.5618  ASR: 0.0625 (0.0798)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [240/313]  eta: 0:00:19  Lr: 0.001875  Loss: 1.5567  ASR: 0.0625 (0.0796)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.9297  ASR: 0.0625 (0.0799)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 1.8428  ASR: 0.0625 (0.0802)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.9711  ASR: 0.0625 (0.0819)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 2.0623  ASR: 0.0625 (0.0805)  p_index: 16.0000 (16.0000)  time: 0.2616  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [290/313]  eta: 0:00:06  Lr: 0.001875  Loss: 1.5226  ASR: 0.0625 (0.0797)  p_index: 16.0000 (16.0000)  time: 0.2614  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.5841  ASR: 0.0625 (0.0789)  p_index: 16.0000 (16.0000)  time: 0.2614  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.4708  ASR: 0.0625 (0.0778)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3948
Train: Epoch[1/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 2.1753  ASR: 0.0000 (0.0774)  p_index: 16.0000 (15.9744)  time: 0.2584  data: 0.0002  max mem: 3948
Train: Epoch[1/5] Total time: 0:01:22 (0.2625 s / it)
Averaged stats: Lr: 0.001875  Loss: 2.1753  ASR: 0.0000 (0.0774)  p_index: 16.0000 (15.9744)
poisoned
2 2
Train: Epoch[2/5]  [  0/313]  eta: 0:01:53  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 93.7500 (93.7500)  Loss: 0.5683 (0.5683)  time: 0.3634  data: 0.2045  max mem: 3948
Train: Epoch[2/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7955)  Acc@5: 100.0000 (96.0227)  Loss: 0.2447 (0.3246)  time: 0.1774  data: 0.0188  max mem: 3948
Train: Epoch[2/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.2262)  Acc@5: 93.7500 (95.8333)  Loss: 0.2933 (0.3523)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8871)  Acc@5: 100.0000 (96.9758)  Loss: 0.2560 (0.2961)  time: 0.1587  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.6707)  Acc@5: 100.0000 (96.9512)  Loss: 0.2167 (0.3062)  time: 0.1587  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7843)  Acc@5: 100.0000 (97.0588)  Loss: 0.3380 (0.3175)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 60/313]  eta: 0:00:41  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.5287)  Acc@5: 100.0000 (96.7213)  Loss: 0.3570 (0.3410)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.0352)  Acc@5: 100.0000 (96.9190)  Loss: 0.3044 (0.3198)  time: 0.1589  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (84.9537)  Acc@5: 100.0000 (96.6049)  Loss: 0.2603 (0.3312)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.2335)  Acc@5: 100.0000 (96.7720)  Loss: 0.2762 (0.3216)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3960)  Acc@5: 100.0000 (96.9059)  Loss: 0.1872 (0.3159)  time: 0.1588  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7545)  Acc@5: 100.0000 (97.0158)  Loss: 0.1809 (0.3041)  time: 0.1588  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7438)  Acc@5: 100.0000 (96.9525)  Loss: 0.2053 (0.3059)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.6870)  Acc@5: 100.0000 (97.0420)  Loss: 0.2863 (0.3032)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8156)  Acc@5: 100.0000 (97.2074)  Loss: 0.2279 (0.2961)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9685)  Acc@5: 100.0000 (97.3096)  Loss: 0.1770 (0.2878)  time: 0.1589  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.8307)  Acc@5: 100.0000 (97.3214)  Loss: 0.1770 (0.2890)  time: 0.1588  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.7822)  Acc@5: 100.0000 (97.3684)  Loss: 0.2368 (0.2884)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9807)  Acc@5: 100.0000 (97.4102)  Loss: 0.1940 (0.2827)  time: 0.1588  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0275)  Acc@5: 100.0000 (97.5458)  Loss: 0.1324 (0.2776)  time: 0.1588  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1629)  Acc@5: 100.0000 (97.5435)  Loss: 0.0993 (0.2717)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3448)  Acc@5: 100.0000 (97.5711)  Loss: 0.1022 (0.2651)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4253)  Acc@5: 100.0000 (97.5962)  Loss: 0.1373 (0.2617)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3907)  Acc@5: 100.0000 (97.5920)  Loss: 0.2235 (0.2640)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4627)  Acc@5: 100.0000 (97.6400)  Loss: 0.2309 (0.2592)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5538)  Acc@5: 100.0000 (97.6843)  Loss: 0.0896 (0.2556)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5661)  Acc@5: 100.0000 (97.7011)  Loss: 0.1159 (0.2542)  time: 0.1588  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5544)  Acc@5: 100.0000 (97.6937)  Loss: 0.2321 (0.2542)  time: 0.1587  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6103)  Acc@5: 100.0000 (97.7091)  Loss: 0.1774 (0.2514)  time: 0.1587  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6409)  Acc@5: 100.0000 (97.7019)  Loss: 0.1512 (0.2505)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5656)  Acc@5: 100.0000 (97.7367)  Loss: 0.2572 (0.2514)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5957)  Acc@5: 100.0000 (97.7090)  Loss: 0.2572 (0.2505)  time: 0.1587  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.5415)  Acc@5: 100.0000 (97.6837)  Loss: 0.2572 (0.2521)  time: 0.1551  data: 0.0002  max mem: 3948
Train: Epoch[2/5] Total time: 0:00:49 (0.1595 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.5415)  Acc@5: 100.0000 (97.6837)  Loss: 0.2572 (0.2521)
Train: Epoch[2/5]  [  0/313]  eta: 0:02:25  Lr: 0.001875  Loss: 2.1073  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  time: 0.4655  data: 0.2016  max mem: 3948
Train: Epoch[2/5]  [ 10/313]  eta: 0:01:24  Lr: 0.001875  Loss: 1.4882  ASR: 0.0625 (0.0795)  p_index: 16.0000 (16.0000)  time: 0.2791  data: 0.0185  max mem: 3948
Train: Epoch[2/5]  [ 20/313]  eta: 0:01:19  Lr: 0.001875  Loss: 1.5607  ASR: 0.1250 (0.1012)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 30/313]  eta: 0:01:15  Lr: 0.001875  Loss: 1.4632  ASR: 0.1250 (0.0948)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 40/313]  eta: 0:01:12  Lr: 0.001875  Loss: 1.2991  ASR: 0.1250 (0.1006)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 50/313]  eta: 0:01:09  Lr: 0.001875  Loss: 2.3311  ASR: 0.0625 (0.0944)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 1.3932  ASR: 0.0625 (0.0932)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [ 70/313]  eta: 0:01:04  Lr: 0.001875  Loss: 1.6968  ASR: 0.1250 (0.0995)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 80/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.7959  ASR: 0.1250 (0.0988)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 0.9240  ASR: 0.0625 (0.1003)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0003  max mem: 3948
Train: Epoch[2/5]  [100/313]  eta: 0:00:55  Lr: 0.001875  Loss: 1.2209  ASR: 0.1250 (0.1021)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [110/313]  eta: 0:00:53  Lr: 0.001875  Loss: 1.2642  ASR: 0.0625 (0.0985)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.8516  ASR: 0.0625 (0.0997)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [130/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.4119  ASR: 0.1250 (0.0992)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 1.7029  ASR: 0.1250 (0.0993)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 1.2487  ASR: 0.0625 (0.0977)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [160/313]  eta: 0:00:40  Lr: 0.001875  Loss: 1.3616  ASR: 0.0625 (0.0974)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 1.3937  ASR: 0.0625 (0.0947)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.6612  ASR: 0.0000 (0.0925)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [190/313]  eta: 0:00:32  Lr: 0.001875  Loss: 1.6433  ASR: 0.0625 (0.0939)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.4001  ASR: 0.1250 (0.0933)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 1.5134  ASR: 0.0625 (0.0921)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.4419  ASR: 0.0625 (0.0930)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.5684  ASR: 0.0625 (0.0923)  p_index: 16.0000 (16.0000)  time: 0.2614  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [240/313]  eta: 0:00:19  Lr: 0.001875  Loss: 1.3342  ASR: 0.0625 (0.0934)  p_index: 16.0000 (16.0000)  time: 0.2617  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.7031  ASR: 0.1250 (0.0949)  p_index: 16.0000 (16.0000)  time: 0.2617  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 1.4267  ASR: 0.0625 (0.0936)  p_index: 16.0000 (16.0000)  time: 0.2616  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.3459  ASR: 0.0625 (0.0929)  p_index: 16.0000 (16.0000)  time: 0.2616  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 1.2870  ASR: 0.0625 (0.0936)  p_index: 16.0000 (16.0000)  time: 0.2617  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [290/313]  eta: 0:00:06  Lr: 0.001875  Loss: 1.7135  ASR: 0.1250 (0.0941)  p_index: 16.0000 (16.0000)  time: 0.2620  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.6119  ASR: 0.0625 (0.0932)  p_index: 16.0000 (16.0000)  time: 0.2619  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 2.2696  ASR: 0.0625 (0.0924)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3948
Train: Epoch[2/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.0202  ASR: 0.0625 (0.0920)  p_index: 16.0000 (15.9744)  time: 0.2549  data: 0.0002  max mem: 3948
Train: Epoch[2/5] Total time: 0:01:21 (0.2615 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.0202  ASR: 0.0625 (0.0920)  p_index: 16.0000 (15.9744)
poisoned
2 2
Train: Epoch[3/5]  [  0/313]  eta: 0:01:48  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.5315 (0.5315)  time: 0.3470  data: 0.1881  max mem: 3948
Train: Epoch[3/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9318)  Acc@5: 100.0000 (98.2955)  Loss: 0.1586 (0.2837)  time: 0.1760  data: 0.0173  max mem: 3948
Train: Epoch[3/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6071)  Acc@5: 100.0000 (98.5119)  Loss: 0.1390 (0.2625)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8952)  Acc@5: 100.0000 (98.9919)  Loss: 0.1607 (0.2324)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1280)  Acc@5: 100.0000 (98.6280)  Loss: 0.2041 (0.2430)  time: 0.1589  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2745)  Acc@5: 100.0000 (98.4069)  Loss: 0.2288 (0.2380)  time: 0.1590  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7828)  Acc@5: 100.0000 (98.5656)  Loss: 0.1454 (0.2262)  time: 0.1589  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0915)  Acc@5: 100.0000 (98.5915)  Loss: 0.1654 (0.2369)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9599)  Acc@5: 100.0000 (98.6883)  Loss: 0.1690 (0.2168)  time: 0.1589  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6758)  Acc@5: 100.0000 (98.6951)  Loss: 0.1251 (0.2214)  time: 0.1590  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6337)  Acc@5: 100.0000 (98.4530)  Loss: 0.2674 (0.2233)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8806)  Acc@5: 100.0000 (98.4797)  Loss: 0.2043 (0.2170)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.6219)  Acc@5: 100.0000 (98.3471)  Loss: 0.1376 (0.2245)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7366)  Acc@5: 100.0000 (98.3779)  Loss: 0.1376 (0.2194)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2589)  Acc@5: 100.0000 (98.2713)  Loss: 0.2186 (0.2313)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2583)  Acc@5: 100.0000 (98.1788)  Loss: 0.2286 (0.2317)  time: 0.1589  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.8696)  Acc@5: 100.0000 (98.0202)  Loss: 0.2690 (0.2393)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.9649)  Acc@5: 100.0000 (98.0629)  Loss: 0.2711 (0.2378)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9807)  Acc@5: 100.0000 (98.0318)  Loss: 0.1379 (0.2327)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.0602)  Acc@5: 100.0000 (98.0366)  Loss: 0.1379 (0.2296)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.9764)  Acc@5: 100.0000 (98.1032)  Loss: 0.1612 (0.2275)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0486)  Acc@5: 100.0000 (98.0746)  Loss: 0.1649 (0.2252)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0577)  Acc@5: 100.0000 (98.0486)  Loss: 0.1718 (0.2289)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1201)  Acc@5: 100.0000 (98.0790)  Loss: 0.1592 (0.2255)  time: 0.1590  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0218)  Acc@5: 100.0000 (98.0809)  Loss: 0.1592 (0.2254)  time: 0.1590  data: 0.0003  max mem: 3948
Train: Epoch[3/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0309)  Acc@5: 100.0000 (98.1325)  Loss: 0.1813 (0.2229)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.1590)  Acc@5: 100.0000 (98.1322)  Loss: 0.0733 (0.2208)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2315)  Acc@5: 100.0000 (98.2011)  Loss: 0.0733 (0.2173)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.2767)  Acc@5: 100.0000 (98.1762)  Loss: 0.0847 (0.2165)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.3402)  Acc@5: 100.0000 (98.2174)  Loss: 0.1475 (0.2147)  time: 0.1589  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5033)  Acc@5: 100.0000 (98.2143)  Loss: 0.1190 (0.2115)  time: 0.1588  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5354)  Acc@5: 100.0000 (98.2114)  Loss: 0.1264 (0.2105)  time: 0.1587  data: 0.0002  max mem: 3948
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5615)  Acc@5: 100.0000 (98.2029)  Loss: 0.1264 (0.2103)  time: 0.1550  data: 0.0002  max mem: 3948
Train: Epoch[3/5] Total time: 0:00:49 (0.1595 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.5615)  Acc@5: 100.0000 (98.2029)  Loss: 0.1264 (0.2103)
Train: Epoch[3/5]  [  0/313]  eta: 0:02:19  Lr: 0.001875  Loss: 1.7332  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  time: 0.4446  data: 0.1788  max mem: 3948
Train: Epoch[3/5]  [ 10/313]  eta: 0:01:24  Lr: 0.001875  Loss: 1.2742  ASR: 0.0625 (0.1023)  p_index: 16.0000 (16.0000)  time: 0.2776  data: 0.0164  max mem: 3949
Train: Epoch[3/5]  [ 20/313]  eta: 0:01:19  Lr: 0.001875  Loss: 1.5671  ASR: 0.0625 (0.1012)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 30/313]  eta: 0:01:15  Lr: 0.001875  Loss: 1.4010  ASR: 0.0625 (0.1008)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 40/313]  eta: 0:01:12  Lr: 0.001875  Loss: 1.5952  ASR: 0.0625 (0.0976)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 50/313]  eta: 0:01:09  Lr: 0.001875  Loss: 1.4933  ASR: 0.0625 (0.0993)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 1.1481  ASR: 0.0625 (0.0932)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 70/313]  eta: 0:01:04  Lr: 0.001875  Loss: 1.6086  ASR: 0.0625 (0.0924)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 80/313]  eta: 0:01:01  Lr: 0.001875  Loss: 0.9994  ASR: 0.1250 (0.0965)  p_index: 16.0000 (16.0000)  time: 0.2604  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 1.2071  ASR: 0.1250 (0.0948)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [100/313]  eta: 0:00:55  Lr: 0.001875  Loss: 1.6352  ASR: 0.0625 (0.0928)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [110/313]  eta: 0:00:53  Lr: 0.001875  Loss: 1.2128  ASR: 0.0625 (0.0912)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.7526  ASR: 0.0625 (0.0919)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [130/313]  eta: 0:00:47  Lr: 0.001875  Loss: 1.3780  ASR: 0.0625 (0.0916)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 1.5075  ASR: 0.1250 (0.0935)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 1.4441  ASR: 0.1250 (0.0940)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [160/313]  eta: 0:00:40  Lr: 0.001875  Loss: 1.1563  ASR: 0.0625 (0.0936)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 1.2660  ASR: 0.0625 (0.0921)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.5081  ASR: 0.0625 (0.0932)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [190/313]  eta: 0:00:32  Lr: 0.001875  Loss: 1.5020  ASR: 0.0625 (0.0936)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.8233  ASR: 0.1250 (0.0964)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 1.7845  ASR: 0.1250 (0.0989)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.5744  ASR: 0.1250 (0.0981)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.4302  ASR: 0.0625 (0.0990)  p_index: 16.0000 (16.0000)  time: 0.2615  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [240/313]  eta: 0:00:19  Lr: 0.001875  Loss: 1.2431  ASR: 0.1250 (0.0991)  p_index: 16.0000 (16.0000)  time: 0.2616  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.5080  ASR: 0.0625 (0.0989)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 1.3543  ASR: 0.1250 (0.1001)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.6812  ASR: 0.1250 (0.1008)  p_index: 16.0000 (16.0000)  time: 0.2605  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 1.5341  ASR: 0.1250 (0.1001)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [290/313]  eta: 0:00:06  Lr: 0.001875  Loss: 1.7230  ASR: 0.0625 (0.0997)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.5783  ASR: 0.0625 (0.0990)  p_index: 16.0000 (16.0000)  time: 0.2605  data: 0.0002  max mem: 3949
Train: Epoch[3/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.8318  ASR: 0.0625 (0.0987)  p_index: 16.0000 (16.0000)  time: 0.2604  data: 0.0003  max mem: 3949
Train: Epoch[3/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.2977  ASR: 0.0625 (0.0994)  p_index: 16.0000 (15.9744)  time: 0.2543  data: 0.0002  max mem: 3949
Train: Epoch[3/5] Total time: 0:01:21 (0.2613 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.2977  ASR: 0.0625 (0.0994)  p_index: 16.0000 (15.9744)
poisoned
2 2
Train: Epoch[4/5]  [  0/313]  eta: 0:01:45  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 93.7500 (93.7500)  Loss: 0.0891 (0.0891)  time: 0.3356  data: 0.1771  max mem: 3949
Train: Epoch[4/5]  [ 10/313]  eta: 0:00:52  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (89.2045)  Acc@5: 100.0000 (98.8636)  Loss: 0.0829 (0.1395)  time: 0.1748  data: 0.0163  max mem: 3949
Train: Epoch[4/5]  [ 20/313]  eta: 0:00:48  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.7143)  Acc@5: 100.0000 (98.2143)  Loss: 0.2133 (0.2201)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (84.8790)  Acc@5: 100.0000 (97.9839)  Loss: 0.2389 (0.2457)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (85.3659)  Acc@5: 100.0000 (97.7134)  Loss: 0.2506 (0.2378)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0294)  Acc@5: 100.0000 (97.9167)  Loss: 0.1550 (0.2159)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.8852)  Acc@5: 100.0000 (98.2582)  Loss: 0.0787 (0.1964)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (86.8838)  Acc@5: 100.0000 (98.2394)  Loss: 0.0816 (0.1897)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1142)  Acc@5: 100.0000 (98.4568)  Loss: 0.1191 (0.1805)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0192)  Acc@5: 100.0000 (98.5577)  Loss: 0.1095 (0.1752)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1906)  Acc@5: 100.0000 (98.4530)  Loss: 0.1294 (0.1714)  time: 0.1589  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.9932)  Acc@5: 100.0000 (98.4234)  Loss: 0.1612 (0.1799)  time: 0.1589  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.8802)  Acc@5: 100.0000 (98.3988)  Loss: 0.2060 (0.1863)  time: 0.1589  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.3092)  Acc@5: 100.0000 (98.4256)  Loss: 0.1012 (0.1785)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1897)  Acc@5: 100.0000 (98.4486)  Loss: 0.1116 (0.1838)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1689)  Acc@5: 100.0000 (98.5099)  Loss: 0.1592 (0.1817)  time: 0.1589  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1894)  Acc@5: 100.0000 (98.6025)  Loss: 0.1781 (0.1800)  time: 0.1589  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3538)  Acc@5: 100.0000 (98.6842)  Loss: 0.1727 (0.1777)  time: 0.1588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.5691)  Acc@5: 100.0000 (98.6533)  Loss: 0.0174 (0.1745)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4346)  Acc@5: 100.0000 (98.5275)  Loss: 0.0856 (0.1782)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2823)  Acc@5: 100.0000 (98.4142)  Loss: 0.1804 (0.1823)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (87.2038)  Acc@5: 100.0000 (98.4597)  Loss: 0.1919 (0.1830)  time: 0.1589  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2172)  Acc@5: 100.0000 (98.4729)  Loss: 0.1919 (0.1852)  time: 0.1589  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0400)  Acc@5: 100.0000 (98.4578)  Loss: 0.2158 (0.1889)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1110)  Acc@5: 100.0000 (98.4440)  Loss: 0.1954 (0.1869)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3257)  Acc@5: 100.0000 (98.5060)  Loss: 0.1410 (0.1818)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2605)  Acc@5: 100.0000 (98.5393)  Loss: 0.1410 (0.1822)  time: 0.1588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3386)  Acc@5: 100.0000 (98.5470)  Loss: 0.1712 (0.1810)  time: 0.1588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3665)  Acc@5: 100.0000 (98.5320)  Loss: 0.1217 (0.1802)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.3497)  Acc@5: 100.0000 (98.5395)  Loss: 0.1588 (0.1813)  time: 0.1588  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4169)  Acc@5: 100.0000 (98.5465)  Loss: 0.1204 (0.1812)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4397)  Acc@5: 100.0000 (98.5732)  Loss: 0.1216 (0.1808)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4002)  Acc@5: 100.0000 (98.5823)  Loss: 0.1283 (0.1818)  time: 0.1551  data: 0.0002  max mem: 3949
Train: Epoch[4/5] Total time: 0:00:49 (0.1594 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.4002)  Acc@5: 100.0000 (98.5823)  Loss: 0.1283 (0.1818)
Train: Epoch[4/5]  [  0/313]  eta: 0:02:21  Lr: 0.001875  Loss: 1.3757  ASR: 0.1250 (0.1250)  p_index: 16.0000 (16.0000)  time: 0.4537  data: 0.1883  max mem: 3949
Train: Epoch[4/5]  [ 10/313]  eta: 0:01:24  Lr: 0.001875  Loss: 1.1456  ASR: 0.0625 (0.0852)  p_index: 16.0000 (16.0000)  time: 0.2785  data: 0.0173  max mem: 3949
Train: Epoch[4/5]  [ 20/313]  eta: 0:01:19  Lr: 0.001875  Loss: 1.8304  ASR: 0.1250 (0.1071)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 30/313]  eta: 0:01:15  Lr: 0.001875  Loss: 1.3587  ASR: 0.1250 (0.1109)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 40/313]  eta: 0:01:12  Lr: 0.001875  Loss: 1.4403  ASR: 0.0625 (0.1037)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 50/313]  eta: 0:01:09  Lr: 0.001875  Loss: 1.2797  ASR: 0.0625 (0.0980)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 1.4195  ASR: 0.0625 (0.0953)  p_index: 16.0000 (16.0000)  time: 0.2614  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 70/313]  eta: 0:01:04  Lr: 0.001875  Loss: 1.1838  ASR: 0.1250 (0.1030)  p_index: 16.0000 (16.0000)  time: 0.2612  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 80/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.3378  ASR: 0.1250 (0.1003)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 1.0589  ASR: 0.0625 (0.1016)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [100/313]  eta: 0:00:56  Lr: 0.001875  Loss: 1.2728  ASR: 0.1250 (0.1058)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [110/313]  eta: 0:00:53  Lr: 0.001875  Loss: 1.2042  ASR: 0.1250 (0.1047)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.2768  ASR: 0.0625 (0.1059)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [130/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.3123  ASR: 0.0625 (0.1064)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 1.4589  ASR: 0.0625 (0.1059)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 1.0836  ASR: 0.0625 (0.1051)  p_index: 16.0000 (16.0000)  time: 0.2605  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [160/313]  eta: 0:00:40  Lr: 0.001875  Loss: 1.5406  ASR: 0.0625 (0.1044)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 1.4606  ASR: 0.1250 (0.1078)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 1.8720  ASR: 0.1250 (0.1070)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [190/313]  eta: 0:00:32  Lr: 0.001875  Loss: 1.4701  ASR: 0.0625 (0.1070)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.4817  ASR: 0.0625 (0.1063)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 1.4055  ASR: 0.0625 (0.1057)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.7548  ASR: 0.0625 (0.1058)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.0738  ASR: 0.0625 (0.1036)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [240/313]  eta: 0:00:19  Lr: 0.001875  Loss: 1.5729  ASR: 0.0625 (0.1035)  p_index: 16.0000 (16.0000)  time: 0.2614  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.4393  ASR: 0.0625 (0.1056)  p_index: 16.0000 (16.0000)  time: 0.2615  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 2.0508  ASR: 0.0625 (0.1049)  p_index: 16.0000 (16.0000)  time: 0.2617  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.2790  ASR: 0.0625 (0.1042)  p_index: 16.0000 (16.0000)  time: 0.2620  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 1.2936  ASR: 0.1250 (0.1041)  p_index: 16.0000 (16.0000)  time: 0.2616  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [290/313]  eta: 0:00:06  Lr: 0.001875  Loss: 1.2653  ASR: 0.1250 (0.1052)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0003  max mem: 3949
Train: Epoch[4/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.1026  ASR: 0.0625 (0.1047)  p_index: 16.0000 (16.0000)  time: 0.2614  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.2688  ASR: 0.0625 (0.1053)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[4/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.7413  ASR: 0.1250 (0.1056)  p_index: 16.0000 (15.9744)  time: 0.2547  data: 0.0002  max mem: 3949
Train: Epoch[4/5] Total time: 0:01:21 (0.2615 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.7413  ASR: 0.1250 (0.1056)  p_index: 16.0000 (15.9744)
poisoned
2 2
Train: Epoch[5/5]  [  0/313]  eta: 0:01:50  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (93.7500)  Acc@5: 100.0000 (100.0000)  Loss: 0.0959 (0.0959)  time: 0.3545  data: 0.1974  max mem: 3949
Train: Epoch[5/5]  [ 10/313]  eta: 0:00:53  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (98.8636)  Loss: 0.1482 (0.1720)  time: 0.1764  data: 0.0182  max mem: 3949
Train: Epoch[5/5]  [ 20/313]  eta: 0:00:49  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.0119)  Acc@5: 100.0000 (98.2143)  Loss: 0.1745 (0.1649)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 30/313]  eta: 0:00:46  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (85.2823)  Acc@5: 100.0000 (98.3871)  Loss: 0.1794 (0.2050)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 40/313]  eta: 0:00:44  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.4329)  Acc@5: 100.0000 (98.6280)  Loss: 0.1081 (0.1732)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 50/313]  eta: 0:00:42  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.7647)  Acc@5: 100.0000 (98.6520)  Loss: 0.1144 (0.1762)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 60/313]  eta: 0:00:40  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8852)  Acc@5: 100.0000 (98.8730)  Loss: 0.1592 (0.1744)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 70/313]  eta: 0:00:39  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.6197)  Acc@5: 100.0000 (98.6796)  Loss: 0.2216 (0.1900)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 80/313]  eta: 0:00:37  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.5000)  Acc@5: 100.0000 (98.8426)  Loss: 0.0655 (0.1673)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:35  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.6374)  Acc@5: 100.0000 (98.7637)  Loss: 0.0106 (0.1721)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [100/313]  eta: 0:00:34  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.5619)  Acc@5: 100.0000 (98.8861)  Loss: 0.0916 (0.1705)  time: 0.1586  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [110/313]  eta: 0:00:32  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.2748)  Acc@5: 100.0000 (98.8739)  Loss: 0.1619 (0.1808)  time: 0.1587  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [120/313]  eta: 0:00:30  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.1384)  Acc@5: 100.0000 (98.8120)  Loss: 0.1761 (0.1847)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [130/313]  eta: 0:00:29  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (86.8798)  Acc@5: 100.0000 (98.8073)  Loss: 0.2266 (0.1894)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [140/313]  eta: 0:00:27  Lr: 0.0019 (0.0019)  Acc@1: 81.2500 (86.7908)  Acc@5: 100.0000 (98.7145)  Loss: 0.2266 (0.1922)  time: 0.1589  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [150/313]  eta: 0:00:26  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.0861)  Acc@5: 100.0000 (98.7169)  Loss: 0.0895 (0.1862)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [160/313]  eta: 0:00:24  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.3447)  Acc@5: 100.0000 (98.6801)  Loss: 0.0698 (0.1824)  time: 0.1589  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [170/313]  eta: 0:00:22  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (87.6827)  Acc@5: 100.0000 (98.6842)  Loss: 0.0039 (0.1719)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [180/313]  eta: 0:00:21  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7072)  Acc@5: 100.0000 (98.7224)  Loss: -0.0128 (0.1695)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [190/313]  eta: 0:00:19  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.6963)  Acc@5: 100.0000 (98.6911)  Loss: 0.1280 (0.1712)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [200/313]  eta: 0:00:18  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8109)  Acc@5: 100.0000 (98.6940)  Loss: 0.1035 (0.1668)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [210/313]  eta: 0:00:16  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.7666)  Acc@5: 100.0000 (98.6374)  Loss: 0.0657 (0.1665)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [220/313]  eta: 0:00:14  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8111)  Acc@5: 100.0000 (98.5860)  Loss: 0.1314 (0.1658)  time: 0.1586  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [230/313]  eta: 0:00:13  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.8247)  Acc@5: 100.0000 (98.6201)  Loss: 0.0858 (0.1612)  time: 0.1586  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [240/313]  eta: 0:00:11  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9149)  Acc@5: 100.0000 (98.6255)  Loss: 0.0235 (0.1599)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [250/313]  eta: 0:00:10  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (87.9233)  Acc@5: 100.0000 (98.6554)  Loss: 0.0722 (0.1600)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [260/313]  eta: 0:00:08  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.0029)  Acc@5: 100.0000 (98.6351)  Loss: 0.1375 (0.1618)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [270/313]  eta: 0:00:06  Lr: 0.0019 (0.0019)  Acc@1: 93.7500 (88.0766)  Acc@5: 100.0000 (98.6854)  Loss: 0.0729 (0.1591)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [280/313]  eta: 0:00:05  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1005)  Acc@5: 100.0000 (98.6877)  Loss: 0.0637 (0.1575)  time: 0.1588  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [290/313]  eta: 0:00:03  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1229)  Acc@5: 100.0000 (98.6254)  Loss: 0.0418 (0.1554)  time: 0.1588  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [300/313]  eta: 0:00:02  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1437)  Acc@5: 100.0000 (98.6296)  Loss: 0.1031 (0.1576)  time: 0.1587  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1431)  Acc@5: 100.0000 (98.6133)  Loss: 0.1540 (0.1557)  time: 0.1587  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1789)  Acc@5: 100.0000 (98.6222)  Loss: 0.1764 (0.1567)  time: 0.1550  data: 0.0002  max mem: 3949
Train: Epoch[5/5] Total time: 0:00:49 (0.1594 s / it)
Averaged stats: Lr: 0.0019 (0.0019)  Acc@1: 87.5000 (88.1789)  Acc@5: 100.0000 (98.6222)  Loss: 0.1764 (0.1567)
Train: Epoch[5/5]  [  0/313]  eta: 0:02:34  Lr: 0.001875  Loss: 1.4091  ASR: 0.1250 (0.1250)  p_index: 16.0000 (16.0000)  time: 0.4934  data: 0.2238  max mem: 3949
Train: Epoch[5/5]  [ 10/313]  eta: 0:01:25  Lr: 0.001875  Loss: 1.6524  ASR: 0.0625 (0.1023)  p_index: 16.0000 (16.0000)  time: 0.2817  data: 0.0205  max mem: 3949
Train: Epoch[5/5]  [ 20/313]  eta: 0:01:19  Lr: 0.001875  Loss: 1.7704  ASR: 0.0625 (0.0863)  p_index: 16.0000 (16.0000)  time: 0.2605  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 30/313]  eta: 0:01:15  Lr: 0.001875  Loss: 0.8363  ASR: 0.0625 (0.0867)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 40/313]  eta: 0:01:12  Lr: 0.001875  Loss: 0.9590  ASR: 0.0625 (0.0930)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 50/313]  eta: 0:01:09  Lr: 0.001875  Loss: 1.4277  ASR: 0.0625 (0.0895)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 60/313]  eta: 0:01:06  Lr: 0.001875  Loss: 1.1668  ASR: 0.0625 (0.0902)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [ 70/313]  eta: 0:01:04  Lr: 0.001875  Loss: 0.9427  ASR: 0.0625 (0.0924)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 80/313]  eta: 0:01:01  Lr: 0.001875  Loss: 1.4801  ASR: 0.1250 (0.0965)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [ 90/313]  eta: 0:00:58  Lr: 0.001875  Loss: 1.1255  ASR: 0.1250 (0.0955)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [100/313]  eta: 0:00:56  Lr: 0.001875  Loss: 1.6514  ASR: 0.1250 (0.0972)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [110/313]  eta: 0:00:53  Lr: 0.001875  Loss: 1.4325  ASR: 0.1250 (0.0991)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [120/313]  eta: 0:00:50  Lr: 0.001875  Loss: 1.5399  ASR: 0.1250 (0.1002)  p_index: 16.0000 (16.0000)  time: 0.2608  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [130/313]  eta: 0:00:48  Lr: 0.001875  Loss: 1.3274  ASR: 0.0625 (0.0997)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [140/313]  eta: 0:00:45  Lr: 0.001875  Loss: 1.5793  ASR: 0.1250 (0.1015)  p_index: 16.0000 (16.0000)  time: 0.2607  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [150/313]  eta: 0:00:42  Lr: 0.001875  Loss: 1.2088  ASR: 0.1250 (0.1047)  p_index: 16.0000 (16.0000)  time: 0.2609  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [160/313]  eta: 0:00:40  Lr: 0.001875  Loss: 1.5067  ASR: 0.1250 (0.1040)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [170/313]  eta: 0:00:37  Lr: 0.001875  Loss: 1.2882  ASR: 0.0625 (0.1042)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [180/313]  eta: 0:00:34  Lr: 0.001875  Loss: 2.1476  ASR: 0.0625 (0.1039)  p_index: 16.0000 (16.0000)  time: 0.2611  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [190/313]  eta: 0:00:32  Lr: 0.001875  Loss: 1.0487  ASR: 0.0625 (0.1041)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [200/313]  eta: 0:00:29  Lr: 0.001875  Loss: 1.2816  ASR: 0.0625 (0.1042)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [210/313]  eta: 0:00:26  Lr: 0.001875  Loss: 1.7750  ASR: 0.0625 (0.1028)  p_index: 16.0000 (16.0000)  time: 0.2606  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [220/313]  eta: 0:00:24  Lr: 0.001875  Loss: 1.0984  ASR: 0.0625 (0.1038)  p_index: 16.0000 (16.0000)  time: 0.2610  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [230/313]  eta: 0:00:21  Lr: 0.001875  Loss: 1.4898  ASR: 0.1250 (0.1036)  p_index: 16.0000 (16.0000)  time: 0.2615  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [240/313]  eta: 0:00:19  Lr: 0.001875  Loss: 1.4530  ASR: 0.0625 (0.1027)  p_index: 16.0000 (16.0000)  time: 0.2615  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [250/313]  eta: 0:00:16  Lr: 0.001875  Loss: 1.4347  ASR: 0.0625 (0.1026)  p_index: 16.0000 (16.0000)  time: 0.2615  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [260/313]  eta: 0:00:13  Lr: 0.001875  Loss: 0.9529  ASR: 0.1250 (0.1034)  p_index: 16.0000 (16.0000)  time: 0.2616  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [270/313]  eta: 0:00:11  Lr: 0.001875  Loss: 1.3028  ASR: 0.1250 (0.1040)  p_index: 16.0000 (16.0000)  time: 0.2619  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [280/313]  eta: 0:00:08  Lr: 0.001875  Loss: 1.5820  ASR: 0.0625 (0.1041)  p_index: 16.0000 (16.0000)  time: 0.2619  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [290/313]  eta: 0:00:06  Lr: 0.001875  Loss: 1.3608  ASR: 0.0625 (0.1044)  p_index: 16.0000 (16.0000)  time: 0.2619  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [300/313]  eta: 0:00:03  Lr: 0.001875  Loss: 1.1021  ASR: 0.0625 (0.1028)  p_index: 16.0000 (16.0000)  time: 0.2620  data: 0.0002  max mem: 3949
Train: Epoch[5/5]  [310/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.6190  ASR: 0.0625 (0.1031)  p_index: 16.0000 (16.0000)  time: 0.2613  data: 0.0003  max mem: 3949
Train: Epoch[5/5]  [312/313]  eta: 0:00:00  Lr: 0.001875  Loss: 1.1850  ASR: 0.1250 (0.1032)  p_index: 16.0000 (15.9744)  time: 0.2550  data: 0.0002  max mem: 3949
Train: Epoch[5/5] Total time: 0:01:21 (0.2617 s / it)
Averaged stats: Lr: 0.001875  Loss: 1.1850  ASR: 0.1250 (0.1032)  p_index: 16.0000 (15.9744)
poisoned
Test: [Task 1]  [ 0/63]  eta: 0:00:18  Acc@1: 81.2500 (81.2500)  Acc@5: 100.0000 (100.0000)  Loss: 0.6805 (0.6805)  time: 0.2932  data: 0.1956  max mem: 3949
Test: [Task 1]  [10/63]  eta: 0:00:06  Acc@1: 81.2500 (78.9773)  Acc@5: 100.0000 (98.2955)  Loss: 0.7538 (0.7999)  time: 0.1166  data: 0.0181  max mem: 3949
Test: [Task 1]  [20/63]  eta: 0:00:04  Acc@1: 81.2500 (78.8690)  Acc@5: 100.0000 (97.9167)  Loss: 0.7823 (0.8467)  time: 0.0989  data: 0.0004  max mem: 3949
Test: [Task 1]  [30/63]  eta: 0:00:03  Acc@1: 81.2500 (80.0403)  Acc@5: 100.0000 (97.7823)  Loss: 0.7611 (0.8162)  time: 0.0988  data: 0.0004  max mem: 3949
Test: [Task 1]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (80.6402)  Acc@5: 100.0000 (97.8659)  Loss: 0.7611 (0.8112)  time: 0.0988  data: 0.0004  max mem: 3949
Test: [Task 1]  [50/63]  eta: 0:00:01  Acc@1: 87.5000 (81.6176)  Acc@5: 100.0000 (97.7941)  Loss: 0.6388 (0.7809)  time: 0.0988  data: 0.0004  max mem: 3949
Test: [Task 1]  [60/63]  eta: 0:00:00  Acc@1: 87.5000 (81.6598)  Acc@5: 100.0000 (97.9508)  Loss: 0.6388 (0.7686)  time: 0.0987  data: 0.0003  max mem: 3949
Test: [Task 1]  [62/63]  eta: 0:00:00  Acc@1: 81.2500 (81.6000)  Acc@5: 100.0000 (98.0000)  Loss: 0.6388 (0.7663)  time: 0.0963  data: 0.0003  max mem: 3949
Test: [Task 1] Total time: 0:00:06 (0.1021 s / it)
* Acc@1 81.600 Acc@5 98.000 loss 0.766
Test: [Task 1]  [ 0/63]  eta: 0:00:25  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 12.2003 (12.2003)  time: 0.4009  data: 0.2011  max mem: 3949
Test: [Task 1]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0057)  p_index: 16.0000 (16.0000)  Loss: 12.7765 (12.6320)  time: 0.2181  data: 0.0186  max mem: 3949
Test: [Task 1]  [20/63]  eta: 0:00:09  ASR: 0.0000 (0.0119)  p_index: 16.0000 (16.0000)  Loss: 12.5732 (12.5790)  time: 0.1997  data: 0.0003  max mem: 3949
Test: [Task 1]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0081)  p_index: 16.0000 (16.0000)  Loss: 12.5223 (12.5385)  time: 0.1997  data: 0.0003  max mem: 3949
Test: [Task 1]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0076)  p_index: 16.0000 (16.0000)  Loss: 12.5223 (12.5522)  time: 0.1997  data: 0.0003  max mem: 3949
Test: [Task 1]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0061)  p_index: 16.0000 (16.0000)  Loss: 12.5347 (12.5703)  time: 0.1997  data: 0.0004  max mem: 3949
Test: [Task 1]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0082)  p_index: 16.0000 (16.0000)  Loss: 12.5609 (12.5791)  time: 0.1994  data: 0.0003  max mem: 3949
Test: [Task 1]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0080)  p_index: 16.0000 (15.8730)  Loss: 12.5347 (12.5764)  time: 0.1946  data: 0.0003  max mem: 3949
Test: [Task 1] Total time: 0:00:12 (0.2022 s / it)
* ASR 0.008 
Test: [Task 2]  [ 0/63]  eta: 0:00:18  Acc@1: 87.5000 (87.5000)  Acc@5: 100.0000 (100.0000)  Loss: 0.8719 (0.8719)  time: 0.2987  data: 0.2017  max mem: 3949
Test: [Task 2]  [10/63]  eta: 0:00:06  Acc@1: 87.5000 (83.5227)  Acc@5: 100.0000 (97.1591)  Loss: 0.7879 (0.8529)  time: 0.1170  data: 0.0187  max mem: 3949
Test: [Task 2]  [20/63]  eta: 0:00:04  Acc@1: 81.2500 (80.6548)  Acc@5: 93.7500 (95.5357)  Loss: 0.9005 (0.9720)  time: 0.0988  data: 0.0004  max mem: 3949
Test: [Task 2]  [30/63]  eta: 0:00:03  Acc@1: 81.2500 (82.4597)  Acc@5: 93.7500 (95.1613)  Loss: 0.9323 (0.9376)  time: 0.0987  data: 0.0004  max mem: 3949
Test: [Task 2]  [40/63]  eta: 0:00:02  Acc@1: 81.2500 (82.7744)  Acc@5: 100.0000 (95.7317)  Loss: 0.8542 (0.9184)  time: 0.0987  data: 0.0004  max mem: 3949
Test: [Task 2]  [50/63]  eta: 0:00:01  Acc@1: 81.2500 (83.0882)  Acc@5: 100.0000 (95.9559)  Loss: 0.7445 (0.8997)  time: 0.0987  data: 0.0004  max mem: 3949
Test: [Task 2]  [60/63]  eta: 0:00:00  Acc@1: 81.2500 (82.8893)  Acc@5: 100.0000 (96.4139)  Loss: 0.7402 (0.8757)  time: 0.0987  data: 0.0004  max mem: 3949
Test: [Task 2]  [62/63]  eta: 0:00:00  Acc@1: 87.5000 (83.1000)  Acc@5: 100.0000 (96.5000)  Loss: 0.7326 (0.8686)  time: 0.0964  data: 0.0003  max mem: 3949
Test: [Task 2] Total time: 0:00:06 (0.1020 s / it)
* Acc@1 83.100 Acc@5 96.500 loss 0.869
Test: [Task 2]  [ 0/63]  eta: 0:00:25  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 12.6250 (12.6250)  time: 0.3981  data: 0.1983  max mem: 3949
Test: [Task 2]  [10/63]  eta: 0:00:11  ASR: 0.0000 (0.0000)  p_index: 16.0000 (16.0000)  Loss: 12.6603 (12.7453)  time: 0.2175  data: 0.0184  max mem: 3949
Test: [Task 2]  [20/63]  eta: 0:00:08  ASR: 0.0000 (0.0060)  p_index: 16.0000 (16.0000)  Loss: 12.6603 (12.6951)  time: 0.1994  data: 0.0004  max mem: 3949
Test: [Task 2]  [30/63]  eta: 0:00:06  ASR: 0.0000 (0.0040)  p_index: 16.0000 (16.0000)  Loss: 12.7924 (12.7153)  time: 0.1995  data: 0.0004  max mem: 3949
Test: [Task 2]  [40/63]  eta: 0:00:04  ASR: 0.0000 (0.0046)  p_index: 16.0000 (16.0000)  Loss: 12.8268 (12.7466)  time: 0.1994  data: 0.0004  max mem: 3949
Test: [Task 2]  [50/63]  eta: 0:00:02  ASR: 0.0000 (0.0049)  p_index: 16.0000 (16.0000)  Loss: 12.6493 (12.7112)  time: 0.1994  data: 0.0003  max mem: 3949
Test: [Task 2]  [60/63]  eta: 0:00:00  ASR: 0.0000 (0.0041)  p_index: 16.0000 (16.0000)  Loss: 12.4198 (12.6594)  time: 0.1992  data: 0.0003  max mem: 3949
Test: [Task 2]  [62/63]  eta: 0:00:00  ASR: 0.0000 (0.0040)  p_index: 16.0000 (15.8730)  Loss: 12.4056 (12.6434)  time: 0.1945  data: 0.0003  max mem: 3949
Test: [Task 2] Total time: 0:00:12 (0.2021 s / it)
* ASR 0.004 
Test: [Task 3]  [ 0/63]  eta: 0:00:19  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)  Loss: 0.0908 (0.0908)  time: 0.3053  data: 0.2076  max mem: 3949
Test: [Task 3]  [10/63]  eta: 0:00:06  Acc@1: 93.7500 (94.8864)  Acc@5: 100.0000 (99.4318)  Loss: 0.2296 (0.2510)  time: 0.1175  data: 0.0192  max mem: 3949
Test: [Task 3]  [20/63]  eta: 0:00:04  Acc@1: 93.7500 (94.9405)  Acc@5: 100.0000 (99.7024)  Loss: 0.2678 (0.2651)  time: 0.0987  data: 0.0003  max mem: 3949
Test: [Task 3]  [30/63]  eta: 0:00:03  Acc@1: 100.0000 (95.7661)  Acc@5: 100.0000 (99.7984)  Loss: 0.1808 (0.2452)  time: 0.0987  data: 0.0003  max mem: 3949
Test: [Task 3]  [40/63]  eta: 0:00:02  Acc@1: 100.0000 (95.5793)  Acc@5: 100.0000 (99.8476)  Loss: 0.2072 (0.2578)  time: 0.0987  data: 0.0003  max mem: 3949
Test: [Task 3]  [50/63]  eta: 0:00:01  Acc@1: 93.7500 (95.5882)  Acc@5: 100.0000 (99.6324)  Loss: 0.2394 (0.2559)  time: 0.0987  data: 0.0003  max mem: 3949
Test: [Task 3]  [60/63]  eta: 0:00:00  Acc@1: 93.7500 (95.2869)  Acc@5: 100.0000 (99.5902)  Loss: 0.2521 (0.2652)  time: 0.0987  data: 0.0003  max mem: 3949
Test: [Task 3]  [62/63]  eta: 0:00:00  Acc@1: 93.7500 (95.1000)  Acc@5: 100.0000 (99.6000)  Loss: 0.2801 (0.2691)  time: 0.0963  data: 0.0003  max mem: 3949
Test: [Task 3] Total time: 0:00:06 (0.1022 s / it)
* Acc@1 95.100 Acc@5 99.600 loss 0.269
Test: [Task 3]  [ 0/63]  eta: 0:00:24  ASR: 0.0625 (0.0625)  p_index: 16.0000 (16.0000)  Loss: 0.6770 (0.6770)  time: 0.3870  data: 0.1838  max mem: 3949
Test: [Task 3]  [10/63]  eta: 0:00:11  ASR: 0.0625 (0.0852)  p_index: 16.0000 (16.0000)  Loss: 0.9506 (0.9712)  time: 0.2161  data: 0.0171  max mem: 3949
Test: [Task 3]  [20/63]  eta: 0:00:08  ASR: 0.0625 (0.1042)  p_index: 16.0000 (16.0000)  Loss: 0.9545 (1.0108)  time: 0.1989  data: 0.0004  max mem: 3949
Test: [Task 3]  [30/63]  eta: 0:00:06  ASR: 0.0625 (0.1069)  p_index: 16.0000 (16.0000)  Loss: 0.9051 (0.9847)  time: 0.1987  data: 0.0004  max mem: 3949
Test: [Task 3]  [40/63]  eta: 0:00:04  ASR: 0.0625 (0.1098)  p_index: 16.0000 (16.0000)  Loss: 0.8625 (0.9475)  time: 0.1990  data: 0.0004  max mem: 3949
Test: [Task 3]  [50/63]  eta: 0:00:02  ASR: 0.0625 (0.1078)  p_index: 16.0000 (16.0000)  Loss: 0.8994 (0.9508)  time: 0.1993  data: 0.0004  max mem: 3949
Test: [Task 3]  [60/63]  eta: 0:00:00  ASR: 0.1250 (0.1066)  p_index: 16.0000 (16.0000)  Loss: 0.9721 (0.9581)  time: 0.1991  data: 0.0004  max mem: 3949
Test: [Task 3]  [62/63]  eta: 0:00:00  ASR: 0.0625 (0.1050)  p_index: 16.0000 (15.8730)  Loss: 0.9722 (0.9560)  time: 0.1943  data: 0.0003  max mem: 3949
Test: [Task 3] Total time: 0:00:12 (0.2014 s / it)
* ASR 0.105 
[Average accuracy till task3]	ASR: 0.0390	ACC: 86.6000	Loss: 8.7253	Forgetting: 0.0000	Backward: 0.0060
Total training time: 0:21:15
/home/woody/iwi1/iwi1102h/software/private/conda/envs/l2p/lib/python3.8/site-packages/torch/distributed/launch.py:208: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  main()
=== JOB_STATISTICS ===
=== current date     : Sat 04 Jan 2025 07:49:11 PM CET
= Job-ID             : 966881 on tinygpu
= Job-Name           : l2p_0.1_0id_base_use
= Job-Command        : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular/train_cifar100_l2p.sh
= Initial workdir    : /home/hpc/iwi1/iwi1102h/Backdoor/L2P_Backdoor_modular
= Queue/Partition    : work
= Slurm account      : iwi1 with QOS=normal
= Requested resources:  for 1-00:00:00
= Elapsed runtime    : 00:21:41
= Total RAM usage    : 2.2 GiB of requested  GiB (%)   
= Node list          : tg084
= Subm/Elig/Start/End: 2025-01-04T18:54:46 / 2025-01-04T18:54:46 / 2025-01-04T19:27:30 / 2025-01-04T19:49:11
======================
=== Quota infos ======
    Path              Used     SoftQ    HardQ    Gracetime  Filec    FileQ    FiHaQ    FileGrace    
    /home/hpc           94.0G   104.9G   209.7G        N/A     204K     500K   1,000K        N/A    
    /home/vault          0.0K  1048.6G  2097.2G        N/A       1      200K     400K        N/A    
    /home/woody         18.4G  1000.0G  1500.0G        N/A     136K   5,000K   7,500K        N/A    
======================
=== GPU utilization ==
gpu_name, gpu_bus_id, pid, gpu_utilization [%], mem_utilization [%], max_memory_usage [MiB], time [ms]
NVIDIA GeForce RTX 3080, 00000000:B1:00.0, 847221, 95 %, 45 %, 4946 MiB, 1285070 ms
